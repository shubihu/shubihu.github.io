

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/avatar.png">
  <link rel="icon" href="/img/avatar.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="Pytorch通常使用Dataset和DataLoader这两个工具类来构建数据管道">
  <meta name="author" content="">
  <meta name="keywords" content="">
  <meta name="description" content="Pytorch通常使用Dataset和DataLoader这两个工具类来构建数据管道">
<meta property="og:type" content="article">
<meta property="og:title" content="Pytorch学习笔记7-Dataset和DataLoader">
<meta property="og:url" content="https://shubihu.github.io/2022/01/21/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07-Dataset%E5%92%8CDataLoader/index.html">
<meta property="og:site_name" content="梳碧湖">
<meta property="og:description" content="Pytorch通常使用Dataset和DataLoader这两个工具类来构建数据管道">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-01-21T05:24:33.000Z">
<meta property="article:modified_time" content="2022-03-10T01:41:13.891Z">
<meta property="article:tag" content="Pytorch">
<meta name="twitter:card" content="summary">
  
    <!-- Google tag (gtag.js) --> <script async src="https://www.googletagmanager.com/gtag/js?id=G-K7MWV4M9MY"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag("js", new Date());
gtag("config", "G-K7MWV4M9MY"); </script> <script> var _hmt = _hmt || []; (function() { var hm = document.createElement("script"); hm.src = "https://hm.baidu.com/hm.js?18ed691a6c5a383daf5d728b432c6bcb"; var s = document.getElementsByTagName("script")[0];  s.parentNode.insertBefore(hm, s); })(); </script> <script src="https://cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9177497528922586" crossorigin="anonymous"></script>
  
  <title>Pytorch学习笔记7-Dataset和DataLoader - 梳碧湖</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"shubihu.github.io","root":"/","version":"1.8.12","typing":{"enable":true,"typeSpeed":70,"cursorChar":"","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":"❡"},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"FOWqJriwiUxghpNnDaD7X3ao-gzGzoHsz","app_key":"wgi1Wsw2eg7be0kqLc6vhVHj","server_url":"https://fowqjriw.lc-cn-n1-shared.com"}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>梳碧湖</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/cat/">
                <i class="iconfont icon-brush"></i>
                撸猫
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                Tools
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/yahaha.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="Pytorch学习笔记7-Dataset和DataLoader">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-01-21 13:24" pubdate>
        2022年1月21日 下午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      11k 字
    </span>
  

  

  
  
    
      <!-- LeanCloud 统计文章PV -->
      <span id="leancloud-page-views-container" class="post-meta" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="leancloud-page-views"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Pytorch学习笔记7-Dataset和DataLoader</h1>
            
              <p class="note note-info">
                
                  由于时效问题，该文某些代码、技术可能已经过期，请注意！！！本文最后更新于：4 年前
                
              </p>
            
            <div class="markdown-body">
              <h2 id="Pytorch通常使用Dataset和DataLoader这两个工具类来构建数据管道"><a href="#Pytorch通常使用Dataset和DataLoader这两个工具类来构建数据管道" class="headerlink" title="Pytorch通常使用Dataset和DataLoader这两个工具类来构建数据管道"></a>Pytorch通常使用Dataset和DataLoader这两个工具类来构建数据管道</h2><span id="more"></span>

<p>Dataset定义了数据集的内容，它相当于一个类似列表的数据结构，具有确定的长度，能够用索引获取数据集中的元素。<br>而DataLoader定义了按batch加载数据集的方法，它是一个实现了__iter_方法的可迭代对象，每次迭代输出一个batch的数据。<br>DataLoader能够控制batch的大小，batch中元素的采样方法，以及将batch结果整理成模型所需输入形式的方法，并且能够使用多进程读取数据。<br>在绝大部分情况下，用户只需实现Dataset的__len__方法和__getitem__方法，就可以轻松构建自己的数据集，并用默认数据管道进行加载。</p>
<h5 id="Dataset和DataLoader概述"><a href="#Dataset和DataLoader概述" class="headerlink" title="Dataset和DataLoader概述"></a>Dataset和DataLoader概述</h5><h6 id="1，获取一个batch数据的步骤"><a href="#1，获取一个batch数据的步骤" class="headerlink" title="1，获取一个batch数据的步骤"></a>1，获取一个batch数据的步骤</h6><p>(假定数据集的特征和标签分别表示为张量X和Y，数据集可以表示为(X,Y), 假定batch大小为m)</p>
<p>1，首先我们要确定数据集的长度n。</p>
<p>结果类似：n = 1000。</p>
<p>2，然后我们从0到n-1的范围中抽样出m个数(batch大小)。</p>
<p>假定m=4, 拿到的结果是一个列表，类似：indices = [1,4,8,9]</p>
<p>3，接着我们从数据集中去取这m个数对应下标的元素。</p>
<p>拿到的结果是一个元组列表，类似：samples = [(X[1],Y[1]),(X[4],Y[4]),(X[8],Y[8]),(X[9],Y[9])]</p>
<p>4，最后我们将结果整理成两个张量作为输出。</p>
<p>拿到的结果是两个张量，类似batch = (features,labels)，</p>
<p>其中 features = torch.stack([X[1],X[4],X[8],X[9]])</p>
<p>labels = torch.stack([Y[1],Y[4],Y[8],Y[9]])</p>
<h6 id="2，Dataset和DataLoader的功能分工"><a href="#2，Dataset和DataLoader的功能分工" class="headerlink" title="2，Dataset和DataLoader的功能分工"></a>2，Dataset和DataLoader的功能分工</h6><p>上述第1个步骤确定数据集的长度是由 Dataset的__len__ 方法实现的。</p>
<p>第2个步骤从0到n-1的范围中抽样出m个数的方法是由 DataLoader的 sampler和 batch_sampler参数指定的。</p>
<p>sampler参数指定单个元素抽样方法，一般无需用户设置，程序默认在DataLoader的参数shuffle=True时采用随机抽样，shuffle=False时采用顺序抽样。</p>
<p>batch_sampler参数将多个抽样的元素整理成一个列表，一般无需用户设置，默认方法在DataLoader的参数drop_last=True时会丢弃数据集最后一个长度不能被batch大小整除的批次，在drop_last=False时保留最后一个批次。</p>
<p>第3个步骤的核心逻辑根据下标取数据集中的元素 是由 Dataset的 __getitem__方法实现的。</p>
<p>第4个步骤的逻辑由DataLoader的参数collate_fn指定。一般情况下也无需用户设置。</p>
<h6 id="3，Dataset和DataLoader的主要接口"><a href="#3，Dataset和DataLoader的主要接口" class="headerlink" title="3，Dataset和DataLoader的主要接口"></a>3，Dataset和DataLoader的主要接口</h6><p>以下是 Dataset和 DataLoader的核心接口逻辑伪代码，不完全和源码一致。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch <br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Dataset</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">pass</span><br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">raise</span> NotImplementedError<br>        <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span>(<span class="hljs-params">self,index</span>):</span><br>        <span class="hljs-keyword">raise</span> NotImplementedError<br>        <br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DataLoader</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,dataset,batch_size,collate_fn,shuffle = <span class="hljs-literal">True</span>,drop_last = <span class="hljs-literal">False</span></span>):</span><br>        self.dataset = dataset<br>        self.sampler =torch.utils.data.RandomSampler <span class="hljs-keyword">if</span> shuffle <span class="hljs-keyword">else</span> \<br>           torch.utils.data.SequentialSampler<br>        self.batch_sampler = torch.utils.data.BatchSampler<br>        self.sample_iter = self.batch_sampler(<br>            self.sampler(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(dataset))),<br>            batch_size = batch_size,drop_last = drop_last)<br>        <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__next__</span>(<span class="hljs-params">self</span>):</span><br>        indices = <span class="hljs-built_in">next</span>(self.sample_iter)<br>        batch = self.collate_fn([self.dataset[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> indices])<br>        <span class="hljs-keyword">return</span> batch<br></code></pre></td></tr></table></figure>

<h5 id="使用Dataset创建数据集"><a href="#使用Dataset创建数据集" class="headerlink" title="使用Dataset创建数据集"></a>使用Dataset创建数据集</h5><p>Dataset创建数据集常用的方法有：</p>
<ul>
<li><p>使用 torch.utils.data.TensorDataset 根据Tensor创建数据集(numpy的array，Pandas的DataFrame需要先转换成Tensor)。</p>
</li>
<li><p>使用 torchvision.datasets.ImageFolder 根据图片目录创建图片数据集。</p>
</li>
<li><p>继承 torch.utils.data.Dataset 创建自定义数据集。</p>
</li>
</ul>
<p>此外，还可以通过</p>
<ul>
<li><p>torch.utils.data.random_split 将一个数据集分割成多份，常用于分割训练集，验证集和测试集。</p>
</li>
<li><p>调用Dataset的加法运算符(+)将多个数据集合并成一个数据集。</p>
</li>
</ul>
<h6 id="1，根据Tensor创建数据集"><a href="#1，根据Tensor创建数据集" class="headerlink" title="1，根据Tensor创建数据集"></a>1，根据Tensor创建数据集</h6><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><span class="hljs-keyword">import</span> torch <br><span class="hljs-title">from</span> torch.utils.data <span class="hljs-keyword">import</span> TensorDataset,Dataset,DataLoader,random_split <br></code></pre></td></tr></table></figure>

<figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-meta"># 根据Tensor创建数据集</span><br><br><span class="hljs-title">from</span> sklearn <span class="hljs-keyword">import</span> datasets <br><span class="hljs-title">iris</span> = datasets.load_iris()<br><span class="hljs-title">ds_iris</span> = <span class="hljs-type">TensorDataset</span>(torch.tensor(iris.<span class="hljs-class"><span class="hljs-keyword">data</span>),torch.tensor(<span class="hljs-title">iris</span>.<span class="hljs-title">target</span>))</span><br><br><span class="hljs-meta"># 分割成训练集和预测集</span><br><span class="hljs-title">n_train</span> = int(len(ds_iris)*<span class="hljs-number">0.8</span>)<br><span class="hljs-title">n_valid</span> = len(ds_iris) - n_train<br><span class="hljs-title">ds_train</span>,ds_valid = random_split(ds_iris,[n_train,n_valid])<br><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">type</span>(<span class="hljs-title">ds_iris</span>))</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">type</span>(<span class="hljs-title">ds_train</span>))</span><br></code></pre></td></tr></table></figure>

<figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs maxima"># 使用DataLoader加载数据集<br>dl_train,dl_valid = DataLoader(ds_train,batch_size = <span class="hljs-number">8</span>),DataLoader(ds_valid,batch_size = <span class="hljs-number">8</span>)<br><br><span class="hljs-keyword">for</span> <span class="hljs-built_in">features</span>,<span class="hljs-built_in">labels</span> <span class="hljs-keyword">in</span> dl_train:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">features</span>,<span class="hljs-built_in">labels</span>)<br>    <span class="hljs-built_in">break</span><br></code></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"># 演示加法运算符（<span class="hljs-string">`+`</span>）的合并作用<br>ds_data = ds_train + ds_valid<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;len(ds_train) = &#x27;</span>,<span class="hljs-built_in">len</span>(ds_train))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;len(ds_valid) = &#x27;</span>,<span class="hljs-built_in">len</span>(ds_valid))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;len(ds_train+ds_valid) = &#x27;</span>,<span class="hljs-built_in">len</span>(ds_data))<br></code></pre></td></tr></table></figure>

<h6 id="2，根据图片目录创建图片数据集"><a href="#2，根据图片目录创建图片数据集" class="headerlink" title="2，根据图片目录创建图片数据集"></a>2，根据图片目录创建图片数据集</h6><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><span class="hljs-keyword">import</span> torch <br><span class="hljs-title">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-title">from</span> torchvision <span class="hljs-keyword">import</span> transforms,datasets<br></code></pre></td></tr></table></figure>

<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-comment">#一些常用的图片增强操作</span><br>from PIL <span class="hljs-built_in">import</span> Image<br><span class="hljs-attr">img</span> = Image.open(&#x27;/home/kesci/input/data6936/data/cat.jpeg&#x27;)<br><br><span class="hljs-comment"># 随机数值翻转</span><br>transforms.RandomVerticalFlip()(img)<br><br><span class="hljs-comment">#随机旋转</span><br>transforms.RandomRotation(<span class="hljs-number">45</span>)(img)<br><br><span class="hljs-comment"># 定义图片增强操作</span><br><span class="hljs-attr">transform_train</span> = transforms.Compose([<br>   transforms.RandomHorizontalFlip(), <span class="hljs-comment">#随机水平翻转</span><br>   transforms.RandomVerticalFlip(), <span class="hljs-comment">#随机垂直翻转</span><br>   transforms.RandomRotation(<span class="hljs-number">45</span>),  <span class="hljs-comment">#随机在45度角度内旋转</span><br>   transforms.ToTensor() <span class="hljs-comment">#转换成张量</span><br>  ]<br>) <br><br><span class="hljs-attr">transform_valid</span> = transforms.Compose([<br>    transforms.ToTensor()<br>  ]<br>)<br><br></code></pre></td></tr></table></figure>

<figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs maxima"># 根据图片目录创建数据集<br>ds_train = datasets.ImageFolder(<span class="hljs-string">&quot;/home/kesci/input/data6936/data/cifar2/train/&quot;</span>,<br>            <span class="hljs-built_in">transform</span> = transform_train,target_transform= <span class="hljs-built_in">lambda</span> t:torch.tensor([t]).<span class="hljs-built_in">float</span>())<br>ds_valid = datasets.ImageFolder(<span class="hljs-string">&quot;/home/kesci/input/data6936/data/cifar2/test/&quot;</span>,<br>            <span class="hljs-built_in">transform</span> = transform_train,target_transform= <span class="hljs-built_in">lambda</span> t:torch.tensor([t]).<span class="hljs-built_in">float</span>())<br><br><span class="hljs-built_in">print</span>(ds_train.class_to_idx)<br></code></pre></td></tr></table></figure>

<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 使用DataLoader加载数据集</span><br>dl_train = DataLoader(ds_train,batch_size = 50,shuffle = <span class="hljs-literal">True</span>,<span class="hljs-attribute">num_workers</span>=3)<br>dl_valid = DataLoader(ds_valid,batch_size = 50,shuffle = <span class="hljs-literal">True</span>,<span class="hljs-attribute">num_workers</span>=3)<br><br><span class="hljs-keyword">for</span> features,labels <span class="hljs-keyword">in</span> dl_train:<br>    <span class="hljs-builtin-name">print</span>(features.shape)<br>    <span class="hljs-builtin-name">print</span>(labels.shape)<br>    break<br><br></code></pre></td></tr></table></figure>

<h6 id="创建自定义数据集"><a href="#创建自定义数据集" class="headerlink" title="创建自定义数据集"></a>创建自定义数据集</h6><p>下面通过继承Dataset类创建imdb文本分类任务的自定义数据集。</p>
<p>大概思路如下：首先，对训练集文本分词构建词典。然后将训练集文本和测试集文本数据转换成token单词编码。</p>
<p>接着将转换成单词编码的训练集数据和测试集数据按样本分割成多个文件，一个文件代表一个样本。</p>
<p>最后，我们可以根据文件名列表获取对应序号的样本内容，从而构建Dataset数据集。</p>
<figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd <br><span class="hljs-title">from</span> collections <span class="hljs-keyword">import</span> OrderedDict<br><span class="hljs-keyword">import</span> re,string<br><br><span class="hljs-type">MAX_WORDS</span> = <span class="hljs-number">10000</span>  # 仅考虑最高频的<span class="hljs-number">10000</span>个词<br><span class="hljs-type">MAX_LEN</span> = <span class="hljs-number">200</span>  # 每个样本保留<span class="hljs-number">200</span>个词的长度<br><span class="hljs-type">BATCH_SIZE</span> = <span class="hljs-number">20</span> <br><br><span class="hljs-title">train_data_path</span> = &#x27;/home/kesci/input/data6936/<span class="hljs-class"><span class="hljs-keyword">data</span>/imdb/train.tsv&#x27;</span><br><span class="hljs-title">test_data_path</span> = &#x27;/home/kesci/input/data6936/<span class="hljs-class"><span class="hljs-keyword">data</span>/imdb/test.tsv&#x27;</span><br><span class="hljs-title">train_token_path</span> = &#x27;/home/kesci/input/data6936/<span class="hljs-class"><span class="hljs-keyword">data</span>/imdb/train_token.tsv&#x27;</span><br><span class="hljs-title">test_token_path</span> =  &#x27;/home/kesci/input/data6936/<span class="hljs-class"><span class="hljs-keyword">data</span>/imdb/test_token.tsv&#x27;</span><br><span class="hljs-title">train_samples_path</span> = &#x27;/home/kesci/input/data6936/<span class="hljs-class"><span class="hljs-keyword">data</span>/imdb/train_samples/&#x27;</span><br><span class="hljs-title">test_samples_path</span> =  &#x27;/home/kesci/input/data6936/<span class="hljs-class"><span class="hljs-keyword">data</span>/imdb/test_samples/&#x27;</span><br></code></pre></td></tr></table></figure>

<p>首先我们构建词典，并保留最高频的MAX_WORDS个词。</p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs applescript"><span class="hljs-comment">##构建词典</span><br><br>word_count_dict = &#123;&#125;<br><br><span class="hljs-comment">#清洗文本</span><br>def clean_text(<span class="hljs-built_in">text</span>):<br>    lowercase = <span class="hljs-built_in">text</span>.lower().replace(<span class="hljs-string">&quot;\n&quot;</span>,<span class="hljs-string">&quot; &quot;</span>)<br>    stripped_html = re.sub(&#x27;&lt;br /&gt;&#x27;, &#x27; &#x27;,lowercase)<br>    cleaned_punctuation = re.sub(&#x27;[%s]&#x27;%re.escape(<span class="hljs-built_in">string</span>.punctuation),&#x27;&#x27;,stripped_html)<br><span class="hljs-built_in">    return</span> cleaned_punctuation<br><br><span class="hljs-keyword">with</span> open(train_data_path,<span class="hljs-string">&quot;r&quot;</span>,encoding = &#x27;utf<span class="hljs-number">-8</span>&#x27;) <span class="hljs-keyword">as</span> f:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<br>        label,<span class="hljs-built_in">text</span> = line.split(<span class="hljs-string">&quot;\t&quot;</span>)<br>        cleaned_text = clean_text(<span class="hljs-built_in">text</span>)<br>        <span class="hljs-keyword">for</span> <span class="hljs-built_in">word</span> <span class="hljs-keyword">in</span> cleaned_text.split(<span class="hljs-string">&quot; &quot;</span>):<br>            word_count_dict[<span class="hljs-built_in">word</span>] = word_count_dict.<span class="hljs-keyword">get</span>(<span class="hljs-built_in">word</span>,<span class="hljs-number">0</span>)+<span class="hljs-number">1</span> <br><br>df_word_dict = pd.DataFrame(pd.Series(word_count_dict,<span class="hljs-built_in">name</span> = <span class="hljs-string">&quot;count&quot;</span>))<br>df_word_dict = df_word_dict.sort_values(<span class="hljs-keyword">by</span> = <span class="hljs-string">&quot;count&quot;</span>,ascending =False)<br><br>df_word_dict = df_word_dict[<span class="hljs-number">0</span>:MAX_WORDS<span class="hljs-number">-2</span>] <span class="hljs-comment">#  </span><br>df_word_dict[<span class="hljs-string">&quot;word_id&quot;</span>] = range(<span class="hljs-number">2</span>,MAX_WORDS) <span class="hljs-comment">#编号0和1分别留给未知词&lt;unkown&gt;和填充&lt;padding&gt;</span><br><br>word_id_dict = df_word_dict[<span class="hljs-string">&quot;word_id&quot;</span>].to_dict()<br><br>df_word_dict.head(<span class="hljs-number">10</span>)<br></code></pre></td></tr></table></figure>

<p>然后我们利用构建好的词典，将文本转换成token序号。</p>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver"><span class="hljs-comment">#转换token</span><br><br><span class="hljs-comment"># 填充文本</span><br>def pad(data_list,pad_length):<br>    padded_list = data_list.copy()<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(data_list)&gt; pad_length:<br>         padded_list = data_list[-pad_length:]<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(data_list)&lt; pad_length:<br>         padded_list = [<span class="hljs-number">1</span>]*(pad_length-<span class="hljs-built_in">len</span>(data_list))+data_list<br>    <span class="hljs-literal">return</span> padded_list<br><br>def text_to_token(text_file,token_file):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(text_file,<span class="hljs-string">&quot;r&quot;</span>,encoding = <span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> fin,\<br>      <span class="hljs-built_in">open</span>(token_file,<span class="hljs-string">&quot;w&quot;</span>,encoding = <span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> fout:<br>        <span class="hljs-keyword">for</span> <span class="hljs-built_in">line</span> <span class="hljs-keyword">in</span> fin:<br>            label,<span class="hljs-keyword">text</span> = <span class="hljs-built_in">line</span>.<span class="hljs-built_in">split</span>(<span class="hljs-string">&quot;\t&quot;</span>)<br>            cleaned_text = clean_text(<span class="hljs-keyword">text</span>)<br>            word_token_list = [word_id_dict.<span class="hljs-built_in">get</span>(<span class="hljs-built_in">word</span>, <span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> <span class="hljs-built_in">word</span> <span class="hljs-keyword">in</span> cleaned_text.<span class="hljs-built_in">split</span>(<span class="hljs-string">&quot; &quot;</span>)]<br>            pad_list = pad(word_token_list,MAX_LEN)<br>            out_line = label+<span class="hljs-string">&quot;\t&quot;</span>+<span class="hljs-string">&quot; &quot;</span>.join([str(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> pad_list])<br>            fout.<span class="hljs-built_in">write</span>(out_line+<span class="hljs-string">&quot;\n&quot;</span>)<br>        <br>text_to_token(train_data_path,train_token_path)<br>text_to_token(test_data_path,test_token_path)<br></code></pre></td></tr></table></figure>

<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"># 分割样本<br>import os<br><br><span class="hljs-keyword">if</span> not os.path.exists(train_samples_path):<br>    os.mkdir(train_samples_path)<br>    <br><span class="hljs-keyword">if</span> not os.path.exists(test_samples_path):<br>    os.mkdir(test_samples_path)<br>    <br>    <br>def split<span class="hljs-constructor">_samples(<span class="hljs-params">token_path</span>,<span class="hljs-params">samples_dir</span>)</span>:<br>    <span class="hljs-keyword">with</span> <span class="hljs-keyword">open</span>(token_path,<span class="hljs-string">&quot;r&quot;</span>,encoding = &#x27;utf-<span class="hljs-number">8</span>&#x27;) <span class="hljs-keyword">as</span> fin:<br>        i = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> fin:<br>            <span class="hljs-keyword">with</span> <span class="hljs-keyword">open</span>(samples_dir+<span class="hljs-string">&quot;%d.txt&quot;</span>%i,<span class="hljs-string">&quot;w&quot;</span>,encoding = <span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> fout:<br>                fout.write(line)<br>            i = i+<span class="hljs-number">1</span><br><br>split<span class="hljs-constructor">_samples(<span class="hljs-params">train_token_path</span>,<span class="hljs-params">train_samples_path</span>)</span><br>split<span class="hljs-constructor">_samples(<span class="hljs-params">test_token_path</span>,<span class="hljs-params">test_samples_path</span>)</span><br></code></pre></td></tr></table></figure>
<p>一切准备就绪，我们可以创建数据集Dataset, 从文件名称列表中读取文件内容了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">imdbDataset</span>(<span class="hljs-params">Dataset</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,samples_dir</span>):</span><br>        self.samples_dir = samples_dir<br>        self.samples_paths = os.listdir(samples_dir)<br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.samples_paths)<br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span>(<span class="hljs-params">self,index</span>):</span><br>        path = self.samples_dir + self.samples_paths[index]<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(path,<span class="hljs-string">&quot;r&quot;</span>,encoding = <span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>            line = f.readline()<br>            label,tokens = line.split(<span class="hljs-string">&quot;\t&quot;</span>)<br>            label = torch.tensor([<span class="hljs-built_in">float</span>(label)],dtype = torch.<span class="hljs-built_in">float</span>)<br>            feature = torch.tensor([<span class="hljs-built_in">int</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> tokens.split(<span class="hljs-string">&quot; &quot;</span>)],dtype = torch.long)<br>            <span class="hljs-keyword">return</span>  (feature,label)<br></code></pre></td></tr></table></figure>

<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">ds_train</span> = imdbDataset(train_samples_path)<br><span class="hljs-attr">ds_test</span> = imdbDataset(test_samples_path)<br></code></pre></td></tr></table></figure>

<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">dl_train = <span class="hljs-constructor">DataLoader(<span class="hljs-params">ds_train</span>,<span class="hljs-params">batch_size</span> = BATCH_SIZE,<span class="hljs-params">shuffle</span> = True,<span class="hljs-params">num_workers</span>=4)</span><br>dl_test = <span class="hljs-constructor">DataLoader(<span class="hljs-params">ds_test</span>,<span class="hljs-params">batch_size</span> = BATCH_SIZE,<span class="hljs-params">num_workers</span>=4)</span><br><br><span class="hljs-keyword">for</span> features,labels <span class="hljs-keyword">in</span> dl_train:<br>    print(features)<br>    print(labels)<br>    break<br></code></pre></td></tr></table></figure>

<p>最后构建模型测试一下数据集管道是否可用。</p>
<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">import torch<br>from torch import nn <br>import importlib <br>from torchkeras import Model,summary<br><br><span class="hljs-keyword">class</span> <span class="hljs-constructor">Net(Model)</span>:<br>    <br>    def <span class="hljs-constructor">__init__(<span class="hljs-params">self</span>)</span>:<br>        super(Net, self).<span class="hljs-constructor">__init__()</span><br>        <br>        #设置padding_idx参数后将在训练过程中将填充的token始终赋值为<span class="hljs-number">0</span>向量<br>        self.embedding = nn.<span class="hljs-constructor">Embedding(<span class="hljs-params">num_embeddings</span> = MAX_WORDS,<span class="hljs-params">embedding_dim</span> = 3,<span class="hljs-params">padding_idx</span> = 1)</span><br>        self.conv = nn.<span class="hljs-constructor">Sequential()</span><br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;conv_1&quot;</span>,<span class="hljs-params">nn</span>.Conv1d(<span class="hljs-params">in_channels</span> = 3,<span class="hljs-params">out_channels</span> = 16,<span class="hljs-params">kernel_size</span> = 5)</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;pool_1&quot;</span>,<span class="hljs-params">nn</span>.MaxPool1d(<span class="hljs-params">kernel_size</span> = 2)</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;relu_1&quot;</span>,<span class="hljs-params">nn</span>.ReLU()</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;conv_2&quot;</span>,<span class="hljs-params">nn</span>.Conv1d(<span class="hljs-params">in_channels</span> = 16,<span class="hljs-params">out_channels</span> = 128,<span class="hljs-params">kernel_size</span> = 2)</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;pool_2&quot;</span>,<span class="hljs-params">nn</span>.MaxPool1d(<span class="hljs-params">kernel_size</span> = 2)</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;relu_2&quot;</span>,<span class="hljs-params">nn</span>.ReLU()</span>)<br>        <br>        self.dense = nn.<span class="hljs-constructor">Sequential()</span><br>        self.dense.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;flatten&quot;</span>,<span class="hljs-params">nn</span>.Flatten()</span>)<br>        self.dense.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;linear&quot;</span>,<span class="hljs-params">nn</span>.Linear(6144,1)</span>)<br>        self.dense.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;sigmoid&quot;</span>,<span class="hljs-params">nn</span>.Sigmoid()</span>)<br>        <br>    def forward(self,x):<br>        x = self.embedding(x).transpose(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)<br>        x = self.conv(x)<br>        y = self.dense(x)<br>        return y<br>        <br>model = <span class="hljs-constructor">Net()</span><br>print(model)<br><br>model.summary(input_shape = (<span class="hljs-number">200</span>,),input_dtype = torch.LongTensor)<br></code></pre></td></tr></table></figure>

<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"># 编译模型<br>def accuracy(y_pred,y_true):<br>    y_pred = torch.where(y_pred&gt;<span class="hljs-number">0.5</span>,torch.ones<span class="hljs-constructor">_like(<span class="hljs-params">y_pred</span>,<span class="hljs-params">dtype</span> = <span class="hljs-params">torch</span>.<span class="hljs-params">float32</span>)</span>,<br>                      torch.zeros<span class="hljs-constructor">_like(<span class="hljs-params">y_pred</span>,<span class="hljs-params">dtype</span> = <span class="hljs-params">torch</span>.<span class="hljs-params">float32</span>)</span>)<br>    acc = torch.mean(<span class="hljs-number">1</span>-torch.abs(y_true-y_pred))<br>    return acc<br><br>model.compile(loss_func = nn.<span class="hljs-constructor">BCELoss()</span>,optimizer= torch.optim.<span class="hljs-constructor">Adagrad(<span class="hljs-params">model</span>.<span class="hljs-params">parameters</span>()</span>,lr = <span class="hljs-number">0.02</span>),<br>             metrics_dict=&#123;<span class="hljs-string">&quot;accuracy&quot;</span>:accuracy&#125;)<br></code></pre></td></tr></table></figure>

<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># 训练模型</span><br><span class="hljs-attribute">dfhistory</span> = model.fit(<span class="hljs-number">10</span>,dl_train,dl_val=dl_test,log_step_freq= <span class="hljs-number">200</span>)<br></code></pre></td></tr></table></figure>

<h5 id="使用DataLoader加载数据集"><a href="#使用DataLoader加载数据集" class="headerlink" title="使用DataLoader加载数据集"></a>使用DataLoader加载数据集</h5><p>DataLoader能够控制batch的大小，batch中元素的采样方法，以及将batch结果整理成模型所需输入形式的方法，并且能够使用多进程读取数据。</p>
<p>DataLoader的函数签名如下。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs routeros">DataLoader(  <br>    dataset,  <br>    <span class="hljs-attribute">batch_size</span>=1,  <br>    <span class="hljs-attribute">shuffle</span>=<span class="hljs-literal">False</span>,  <br>    <span class="hljs-attribute">sampler</span>=None,  <br>    <span class="hljs-attribute">batch_sampler</span>=None,  <br>    <span class="hljs-attribute">num_workers</span>=0,  <br>    <span class="hljs-attribute">collate_fn</span>=None,  <br>    <span class="hljs-attribute">pin_memory</span>=<span class="hljs-literal">False</span>,  <br>    <span class="hljs-attribute">drop_last</span>=<span class="hljs-literal">False</span>,  <br>    <span class="hljs-attribute">timeout</span>=0,  <br>    <span class="hljs-attribute">worker_init_fn</span>=None,  <br>    <span class="hljs-attribute">multiprocessing_context</span>=None,  <br>)<br></code></pre></td></tr></table></figure>

<p>一般情况下，我们仅仅会配置 dataset, batch_size, shuffle, num_workers, drop_last这五个参数，其他参数使用默认值即可。</p>
<p>DataLoader除了可以加载我们前面讲的 torch.utils.data.Dataset 外，还能够加载另外一种数据集 torch.utils.data.IterableDataset。</p>
<p>和Dataset数据集相当于一种列表结构不同，IterableDataset相当于一种迭代器结构。 它更加复杂，一般较少使用。</p>
<ul>
<li>dataset : 数据集</li>
<li>batch_size: 批次大小</li>
<li>shuffle: 是否乱序</li>
<li>sampler: 样本采样函数，一般无需设置。</li>
<li>batch_sampler: 批次采样函数，一般无需设置。</li>
<li>num_workers: 使用多进程读取数据，设置的进程数。</li>
<li>collate_fn: 整理一个批次数据的函数。</li>
<li>pin_memory: 是否设置为锁业内存。默认为False，锁业内存不会使用虚拟内存(硬盘)，从锁业内存拷贝到GPU上速度会更快。</li>
<li>drop_last: 是否丢弃最后一个样本数量不足batch_size批次数据。</li>
<li>timeout: 加载一个数据批次的最长等待时间，一般无需设置。</li>
<li>worker_init_fn: 每个worker中dataset的初始化函数，常用于 IterableDataset。一般不使用。</li>
</ul>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-comment">#构建输入数据管道</span><br><span class="hljs-attr">ds</span> = TensorDataset(torch.arange(<span class="hljs-number">1</span>,<span class="hljs-number">50</span>))<br><span class="hljs-attr">dl</span> = DataLoader(ds,<br>                <span class="hljs-attr">batch_size</span> = <span class="hljs-number">10</span>,<br>                <span class="hljs-attr">shuffle=</span> True,<br>                <span class="hljs-attr">num_workers=2,</span><br>                <span class="hljs-attr">drop_last</span> = True)<br><span class="hljs-comment">#迭代数据</span><br>for batch, <span class="hljs-keyword">in</span> dl:<br>    print(batch)<br></code></pre></td></tr></table></figure>


<p>搬运自：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li>
</ul>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/Pytorch/">Pytorch</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Pytorch/">Pytorch</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/01/24/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08-%E6%A8%A1%E5%9E%8B%E5%B1%82layers/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Pytorch学习笔记8-模型层layers</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/01/20/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06-nn-functional%E5%92%8Cnn-Module/">
                        <span class="hidden-mobile">Pytorch学习笔记6-nn.functional和nn.Module</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments" lazyload>
                
                  
                
                
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"FOWqJriwiUxghpNnDaD7X3ao-gzGzoHsz","appKey":"wgi1Wsw2eg7be0kqLc6vhVHj","placeholder":"说点什么","path":"window.location.pathname","avatar":"retro","meta":["nick","mail","link"],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false,"requiredFields":[]},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          Fluid.plugins.initFancyBox('#valine .vcontent img:not(.vemoji)');
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
      <div class="col-lg-7 mx-auto nopadding-x-md">
        <div class="container custom mx-auto">
          <script src="https://eqcn.ajz.miesnfu.com/wp-content/plugins/wp-3d-pony/live2dw/lib/L2Dwidget.min.js"></script> <script src="/js/wanko.js"></script>
        </div>
      </div>
    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- LeanCloud 统计PV -->
        <span id="leancloud-site-pv-container" style="display: none">
            总访问量 
            <span id="leancloud-site-pv"></span>
             次
          </span>
      
      
        <!-- LeanCloud 统计UV -->
        <span id="leancloud-site-uv-container" style="display: none">
            总访客数 
            <span id="leancloud-site-uv"></span>
             人
          </span>
      

    
  </div>


  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>



  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js" ></script>
  




  <script defer src="/js/leancloud.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>












  

  

  

  

  

  




  
<script src="/js/xin_valine.js"></script>



<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


<!-- hexo injector body_end start -->
  <div id="aplayer"></div>
  <link defer rel="stylesheet" href="https://cdn.staticfile.org/aplayer/1.10.1/APlayer.min.css" />
  <script src="https://cdn.staticfile.org/aplayer/1.10.1/APlayer.min.js"></script>
  <script defer src="/js/aplayer.js"></script>
<!-- hexo injector body_end end --></body>
</html>
