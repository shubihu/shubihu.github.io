<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>AI爬虫测试</title>
    <link href="/2024/06/19/AI%E7%88%AC%E8%99%AB%E6%B5%8B%E8%AF%95/"/>
    <url>/2024/06/19/AI%E7%88%AC%E8%99%AB%E6%B5%8B%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<h2 id="测试的框架：Firecrawl-crawlai-Scrapegraph-ai"><a href="#测试的框架：Firecrawl-crawlai-Scrapegraph-ai" class="headerlink" title="测试的框架：Firecrawl, crawlai, Scrapegraph-ai"></a>测试的框架：Firecrawl, crawlai, Scrapegraph-ai</h2><span id="more"></span><p>个人测试效果比较好的是Scrapegraph-ai, 可以使用openai，也可以使用ollama调用本地llm</p><h4 id="openai"><a href="#openai" class="headerlink" title="openai"></a>openai</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> scrapegraphai.graphs <span class="hljs-keyword">import</span> SmartScraperGraph<br><span class="hljs-keyword">from</span> scrapegraphai.utils <span class="hljs-keyword">import</span> prettify_exec_info<br><span class="hljs-keyword">import</span> nest_asyncio<br>nest_asyncio.apply()<br><br><span class="hljs-comment"># 设置环境变量(现有版本需要设置全局环境，不然会报错)</span><br>os.environ[<span class="hljs-string">&#x27;OPENAI_API_KEY&#x27;</span>] = <span class="hljs-string">&#x27;****&#x27;</span><br>os.environ[<span class="hljs-string">&#x27;OPENAI_API_BASE&#x27;</span>] = <span class="hljs-string">&#x27;***&#x27;</span><br><br>OPENAI_BASE_URL=<span class="hljs-string">&quot;****&quot;</span><br>OPENAI_API_KEY=<span class="hljs-string">&quot;****&quot;</span><br><br><br>graph_config = &#123;<br>   <span class="hljs-string">&quot;llm&quot;</span>: &#123;<br>      <span class="hljs-string">&quot;api_key&quot;</span>: OPENAI_API_KEY,<br>      <span class="hljs-string">&quot;model&quot;</span>: <span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,<br>      <span class="hljs-string">&quot;base_url&quot;</span>:OPENAI_BASE_URL<br>   &#125;,<br><span class="hljs-comment">#     &quot;embeddings&quot;: &#123;</span><br><span class="hljs-comment">#         &quot;model&quot;: &quot;ollama/nomic-embed-text&quot;,</span><br><span class="hljs-comment">#         &quot;base_url&quot;: &quot;****&quot;,  # set Ollama URL</span><br><span class="hljs-comment">#     &#125;,</span><br>    <span class="hljs-string">&quot;headless&quot;</span>:<span class="hljs-literal">True</span><br>&#125;<br><br><br>start = time.time()<br><br>PROMPT = <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">Please provide the following information, which is typically found on the school&#x27;s About page:</span><br><span class="hljs-string">1. Founding date</span><br><span class="hljs-string">2. School history</span><br><span class="hljs-string">3. School philosophy</span><br><span class="hljs-string">4. School motto</span><br><span class="hljs-string">5. School vision</span><br><span class="hljs-string">6. School mission</span><br><span class="hljs-string">7. School values</span><br><span class="hljs-string"></span><br><span class="hljs-string">Please visit the school&#x27;s official website, navigate to the About or similar page, and extract the above information. If you cannot find all the details, please provide as much relevant information as possible. Thank you!</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br>smart_scraper_graph = SmartScraperGraph(<br>   prompt=PROMPT,<br>   <span class="hljs-comment"># also accepts a string with the already downloaded HTML code</span><br>   source=<span class="hljs-string">&quot;https://www.nyu.edu&quot;</span>,<br>   config=graph_config<br>)<br><br>result = smart_scraper_graph.run()<br><span class="hljs-built_in">print</span>(result)<br><br>end = time.time()<br><br><span class="hljs-built_in">print</span>(end - start)<br></code></pre></td></tr></table></figure><h4 id="ollama-本地-llm"><a href="#ollama-本地-llm" class="headerlink" title="ollama 本地 llm"></a>ollama 本地 llm</h4><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-keyword">from</span> scrapegraphai.graphs import SmartScraperGraph<br><br>start = time.time()<br><br>graph_config = &#123;<br>    <span class="hljs-string">&quot;llm&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;model&quot;</span>: <span class="hljs-string">&quot;ollama/qwen2:latest&quot;</span>,<br>        <span class="hljs-string">&quot;temperature&quot;</span>: 0,<br>        <span class="hljs-string">&quot;format&quot;</span>: <span class="hljs-string">&quot;json&quot;</span>,  # Ollama needs the format <span class="hljs-keyword">to</span> be specified explicitly<br>        <span class="hljs-string">&quot;base_url&quot;</span>: <span class="hljs-string">&quot;****&quot;</span>,  # <span class="hljs-builtin-name">set</span> Ollama URL<br>    &#125;,<br>    <span class="hljs-string">&quot;embeddings&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;model&quot;</span>: <span class="hljs-string">&quot;ollama/nomic-embed-text&quot;</span>,<br>        <span class="hljs-string">&quot;base_url&quot;</span>: <span class="hljs-string">&quot;****&quot;</span>,  # <span class="hljs-builtin-name">set</span> Ollama URL<br>    &#125;,<br>    <span class="hljs-string">&quot;verbose&quot;</span>: <span class="hljs-literal">True</span>,<br>&#125;<br><br>smart_scraper_graph = SmartScraperGraph(<br>    <span class="hljs-attribute">prompt</span>=PROMPT,<br>    # also accepts a string with the already downloaded HTML code<br>    <span class="hljs-attribute">source</span>=<span class="hljs-string">&quot;https://www.nyu.edu&quot;</span>,<br>    <span class="hljs-attribute">config</span>=graph_config<br>)<br><br>result = smart_scraper_graph.<span class="hljs-builtin-name">run</span>()<br><span class="hljs-builtin-name">print</span>(result)<br>end = time.time()<br><br><span class="hljs-builtin-name">print</span>(end - start)<br></code></pre></td></tr></table></figure><p>另外 Scrapegraph-ai 自带搜索功能，目前支持搜索的引擎是google , duckduckgo, 后期会支持bing. 不过现在版本还不能切换搜索引擎，可以自行改源码切换。</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs clean"><span class="hljs-keyword">from</span> scrapegraphai.graphs <span class="hljs-keyword">import</span> SearchGraph<br>start = time.time()<br># Define the configuration for the graph<br>graph_config = &#123;<br>    <span class="hljs-string">&quot;llm&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;model&quot;</span>: <span class="hljs-string">&quot;ollama/qwen2:latest&quot;</span>,<br>        <span class="hljs-string">&quot;temperature&quot;</span>: <span class="hljs-number">0</span>,<br>        <span class="hljs-string">&quot;format&quot;</span>: <span class="hljs-string">&quot;json&quot;</span>,  # Ollama needs the format to be specified explicitly<br>        <span class="hljs-string">&quot;base_url&quot;</span>: <span class="hljs-string">&quot;*****&quot;</span>,  # set Ollama URL<br>    &#125;,<br>    <span class="hljs-string">&quot;embeddings&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;model&quot;</span>: <span class="hljs-string">&quot;ollama/nomic-embed-text&quot;</span>,<br>        <span class="hljs-string">&quot;base_url&quot;</span>: <span class="hljs-string">&quot;*****&quot;</span>,  # set Ollama URL<br>    &#125;,<br>    <span class="hljs-string">&quot;headless&quot;</span>:<span class="hljs-literal">False</span>,<br>    <span class="hljs-string">&quot;max_results&quot;</span>: <span class="hljs-number">2</span>,<br>&#125;<br><br><br># graph_config = &#123;<br>#    <span class="hljs-string">&quot;llm&quot;</span>: &#123;<br>#       <span class="hljs-string">&quot;api_key&quot;</span>: OPENAI_API_KEY,<br>#       <span class="hljs-string">&quot;model&quot;</span>: <span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,<br>#       <span class="hljs-string">&quot;base_url&quot;</span>:OPENAI_BASE_URL<br>#    &#125;,<br>#     <span class="hljs-string">&quot;embeddings&quot;</span>: &#123;<br>#         <span class="hljs-string">&quot;model&quot;</span>: <span class="hljs-string">&quot;ollama/nomic-embed-text&quot;</span>,<br>#         <span class="hljs-string">&quot;base_url&quot;</span>: <span class="hljs-string">&quot;*****&quot;</span>,  # set Ollama URL<br>#     &#125;,<br>#     <span class="hljs-string">&quot;headless&quot;</span>:<span class="hljs-literal">False</span>,<br>#     <span class="hljs-string">&quot;max_results&quot;</span>: <span class="hljs-number">2</span>,<br># &#125;<br><br><br><br># Create the SearchGraph <span class="hljs-keyword">instance</span><br>search_graph = SearchGraph(<br>    prompt=<span class="hljs-string">&quot;纽约大学的校训是什么&quot;</span>,<br>    config=graph_config<br>)<br><br># Run the graph<br>result = search_graph.run()<br>print(result)<br>end = time.time()<br><br>print(end - start)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Spider, GPT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>会议助手——实时语音识别,翻译及GPT Answer</title>
    <link href="/2024/01/29/%E4%BC%9A%E8%AE%AE%E5%8A%A9%E6%89%8B%E2%80%94%E2%80%94%E5%AE%9E%E6%97%B6%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB-%E7%BF%BB%E8%AF%91%E5%8F%8AGPT-Answer/"/>
    <url>/2024/01/29/%E4%BC%9A%E8%AE%AE%E5%8A%A9%E6%89%8B%E2%80%94%E2%80%94%E5%AE%9E%E6%97%B6%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB-%E7%BF%BB%E8%AF%91%E5%8F%8AGPT-Answer/</url>
    
    <content type="html"><![CDATA[<h2 id="大模型提升会议效率"><a href="#大模型提升会议效率" class="headerlink" title="大模型提升会议效率"></a>大模型提升会议效率</h2><span id="more"></span><p>语音识别组件: react-speech-kit, 项目地址:<a href="https://github.com/MikeyParton/react-speech-kit">https://github.com/MikeyParton/react-speech-kit</a><br>翻译api参考: <a href="https://blog.zhuanjie.ltd/2023/10/05/api-with-cloudflare/">https://blog.zhuanjie.ltd/2023/10/05/api-with-cloudflare/</a></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import os<br>import azure.cognitiveservices.speech as speechsdk<br><span class="hljs-keyword">from</span> sparkdesk_api.core import SparkAPI<br><span class="hljs-comment"># 默认api接口版本为3.1，配置其他版本需要指定Version参数（2.1或者1.1）</span><br><br>sparkAPI = SparkAPI(<br>    <span class="hljs-attribute">app_id</span>=<span class="hljs-string">&#x27;9829fafe&#x27;</span>,<br>    <span class="hljs-attribute">api_secret</span>=<span class="hljs-string">&#x27;******&#x27;</span>,<br>    <span class="hljs-attribute">api_key</span>=<span class="hljs-string">&#x27;******&#x27;</span>,<br>    # <span class="hljs-attribute">version</span>=3.1<br>)<br><br><span class="hljs-keyword">from</span> zhipuai import ZhipuAI<span class="hljs-built_in"></span><br><span class="hljs-built_in">client </span>= ZhipuAI(<span class="hljs-attribute">api_key</span>=<span class="hljs-string">&quot;****&quot;</span>) # 请填写您自己的APIKey<br><br>def chatglm(message):<br>    response = client.chat.completions.create(<br>      <span class="hljs-attribute">model</span>=<span class="hljs-string">&quot;glm-4&quot;</span>,  # 填写需要调用的模型名称<br>        messages=[<br>            &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: message&#125;,<br>        ],<br>        <span class="hljs-attribute">stream</span>=<span class="hljs-literal">False</span>,<br>        )<br>    <span class="hljs-builtin-name">print</span>(response.choices[0].message.content)<br><br>def chatSpark(message):<br>    ai_reply = sparkAPI.chat(message)<br>    <span class="hljs-builtin-name">print</span>(ai_reply)<br><br>speech_key, service_region = <span class="hljs-string">&quot;f739afd4250b410aaedca2967c1a78f1&quot;</span>, <span class="hljs-string">&quot;eastus&quot;</span><br>speech_config = speechsdk.SpeechConfig(<span class="hljs-attribute">subscription</span>=speech_key, <span class="hljs-attribute">region</span>=service_region,speech_recognition_language=&quot;zh-cn&quot;)<br><br><span class="hljs-comment"># Creates a recognizer with the given settings</span><br>speech_recognizer = speechsdk.SpeechRecognizer(<span class="hljs-attribute">speech_config</span>=speech_config)<br><br><span class="hljs-comment"># print(&quot;Say something...&quot;)</span><br><br><span class="hljs-comment"># result = speech_recognizer.recognize_once()</span><br><br><span class="hljs-comment"># if result.reason == speechsdk.ResultReason.RecognizedSpeech:</span><br><span class="hljs-comment">#     print(&quot;Recognized: &#123;&#125;&quot;.format(result.text))</span><br><span class="hljs-comment"># elif result.reason == speechsdk.ResultReason.NoMatch:</span><br><span class="hljs-comment">#     print(&quot;No speech could be recognized: &#123;&#125;&quot;.format(result.no_match_details))</span><br><span class="hljs-comment"># elif result.reason == speechsdk.ResultReason.Canceled:</span><br><span class="hljs-comment">#     cancellation_details = result.cancellation_details</span><br><span class="hljs-comment">#     print(&quot;Speech Recognition canceled: &#123;&#125;&quot;.format(cancellation_details.reason))</span><br><span class="hljs-comment">#     if cancellation_details.reason == speechsdk.CancellationReason.Error:</span><br><span class="hljs-comment">#         print(&quot;Error details: &#123;&#125;&quot;.format(cancellation_details.error_details))</span><br><br><br>def chatSpark(message):<br>    ai_reply = sparkAPI.chat(message)<br>    <span class="hljs-builtin-name">print</span>(ai_reply)<br><br><br>text_ls = []<br><br><br>def recognized_callback(evt):<br>    <span class="hljs-keyword">if</span> evt.result.text:<br>        <span class="hljs-builtin-name">print</span>(<span class="hljs-string">&quot;Recognized: &#123;&#125;&quot;</span>.format(evt.result.text))<br>        text_ls.append(evt.result.text)<br>        chatSpark(evt.result.text)<br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;退出&quot;</span> <span class="hljs-keyword">in</span> evt.result.text.lower():<br>        <span class="hljs-builtin-name">print</span>(<span class="hljs-string">&#x27;byebye&#x27;</span>)<br>        os._exit(0)<br>        # speech_recognizer.stop_continuous_recognition()<br><br><br><br>def cancelled_callback(evt):<br>    <span class="hljs-builtin-name">print</span>(<span class="hljs-string">&quot;Cancelled: &#123;&#125;&quot;</span>.format(evt.result.error_details))<br><br>speech_recognizer = speechsdk.SpeechRecognizer(<span class="hljs-attribute">speech_config</span>=speech_config)<br>speech_recognizer.recognized.connect(recognized_callback)<br>speech_recognizer.session_stopped.connect(cancelled_callback)<br><br><span class="hljs-builtin-name">print</span>(<span class="hljs-string">&quot;Say something...&quot;</span>)<br>speech_recognizer.start_continuous_recognition()<br><br><br><br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    pass<br><br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RAG实战——选择最佳embeding和rerank模型测试效果</title>
    <link href="/2024/01/25/RAG%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E9%80%89%E6%8B%A9%E6%9C%80%E4%BD%B3embeding%E5%92%8Crerank%E6%A8%A1%E5%9E%8B%E6%B5%8B%E8%AF%95%E6%95%88%E6%9E%9C/"/>
    <url>/2024/01/25/RAG%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E9%80%89%E6%8B%A9%E6%9C%80%E4%BD%B3embeding%E5%92%8Crerank%E6%A8%A1%E5%9E%8B%E6%B5%8B%E8%AF%95%E6%95%88%E6%9E%9C/</url>
    
    <content type="html"><![CDATA[<h2 id="基础使用-embeding和rerank"><a href="#基础使用-embeding和rerank" class="headerlink" title="基础使用 embeding和rerank"></a>基础使用 embeding和rerank</h2><span id="more"></span><p>为了衡量我们的检索系统的有效性，我们选择被广泛接受的两个指标：Hit Rate和 Mean Reciprocal Rank (MRR)。<br>命中率（Hit Rate）：命中率计算在前k个检索到的文档中找到正确答案的查询的百分比。简单地说，这是关于我们的系统在前几次猜测中正确的频率。<br>平均倒数排名（Mean Reciprocal Rank, MRR）：对于每个查询，MRR通过查看排名最高的相关文档的排名来评估系统的准确性。具体来说，它是所有查询中这些排名的倒数的平均值。因此，如果第一个相关文档是最高结果，则倒数为1；如果是第二个，则倒数为1/2，依此类推。</p><h4 id="选择最佳组合"><a href="#选择最佳组合" class="headerlink" title="选择最佳组合"></a>选择最佳组合</h4><p>代码参考: <a href="https://colab.research.google.com/drive/1TxDVA__uimVPOJiMEQgP5fwHiqgKqm4-?usp=sharing">https://colab.research.google.com/drive/1TxDVA__uimVPOJiMEQgP5fwHiqgKqm4-?usp=sharing</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> llama_index <span class="hljs-keyword">import</span> GPTKeywordTableIndex, VectorStoreIndex, SimpleDirectoryReader, ServiceContext<br><span class="hljs-keyword">from</span> llama_index.node_parser <span class="hljs-keyword">import</span> SimpleNodeParser<br><span class="hljs-comment"># LLM</span><br><span class="hljs-keyword">from</span> llama_index.llms <span class="hljs-keyword">import</span> AzureOpenAI<br><br><span class="hljs-comment"># Embeddings</span><br><span class="hljs-keyword">from</span> llama_index.embeddings <span class="hljs-keyword">import</span> OpenAIEmbedding, HuggingFaceEmbedding, CohereEmbedding<br><span class="hljs-comment"># from langchain.embeddings import VoyageEmbeddings, GooglePalmEmbeddings</span><br><br><span class="hljs-comment"># Retrievers</span><br><span class="hljs-keyword">from</span> llama_index.retrievers <span class="hljs-keyword">import</span> (<br>    BaseRetriever,<br>    VectorIndexRetriever,<br>)<br><br><span class="hljs-comment"># Rerankers</span><br><span class="hljs-keyword">from</span> llama_index.indices.query.schema <span class="hljs-keyword">import</span> QueryBundle, QueryType<br><span class="hljs-keyword">from</span> llama_index.schema <span class="hljs-keyword">import</span> NodeWithScore<br><span class="hljs-comment"># from llama_index.indices.postprocessor.cohere_rerank import CohereRerank</span><br><span class="hljs-keyword">from</span> llama_index.indices.postprocessor <span class="hljs-keyword">import</span> SentenceTransformerRerank<br><span class="hljs-keyword">from</span> llama_index.finetuning.embeddings.common <span class="hljs-keyword">import</span> EmbeddingQAFinetuneDataset<br><br><span class="hljs-comment"># Evaluator</span><br><span class="hljs-keyword">from</span> llama_index.evaluation <span class="hljs-keyword">import</span> (<br>    generate_question_context_pairs,<br>    EmbeddingQAFinetuneDataset,<br>)<br><span class="hljs-keyword">from</span> llama_index.evaluation <span class="hljs-keyword">import</span> RetrieverEvaluator<br><br><br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> openai<br><br><br>documents = SimpleDirectoryReader(input_files=[<span class="hljs-string">&quot;data/tmp_files/11845723.pdf.txt&quot;</span>]).load_data()<br><span class="hljs-comment"># documents = SimpleDirectoryReader(&#x27;./data&#x27;).load_data()</span><br>node_parser = SimpleNodeParser.from_defaults(chunk_size=<span class="hljs-number">1024</span>)<br>nodes = node_parser.get_nodes_from_documents(documents)<br><br><br><span class="hljs-comment"># 初始化 AzureOpenAI 对象</span><br>llm = AzureOpenAI(<br>    engine=<span class="hljs-string">&quot;gpt3&quot;</span>,<br>    model=<span class="hljs-string">&quot;gpt-35-turbo-16k&quot;</span>,<br>    temperature=<span class="hljs-number">0.0</span>,<br>    azure_endpoint=<span class="hljs-string">&quot;xxx&quot;</span>,<br>    api_key=<span class="hljs-string">&quot;xxx&quot;</span>,<br>    api_version=<span class="hljs-string">&quot;2023-07-01-preview&quot;</span>,<br>)<br><br>EMBEDDINGS = &#123;<br>    <span class="hljs-string">&quot;bge-large-en&quot;</span>: HuggingFaceEmbedding(model_name=<span class="hljs-string">&#x27;/data/database/hg-embed/bge-large-en-v1.5&#x27;</span>, device=<span class="hljs-string">&#x27;cuda&#x27;</span>), <span class="hljs-comment"># You can use mean pooling by addin pooling=&#x27;mean&#x27; parameter</span><br>    <span class="hljs-string">&quot;bge-large-zh&quot;</span>: HuggingFaceEmbedding(model_name=<span class="hljs-string">&#x27;/data/database/hg-embed/bge-large-zh-v1.5&#x27;</span>, device=<span class="hljs-string">&#x27;cuda&#x27;</span>),<br>    <span class="hljs-string">&quot;bce-base&quot;</span>: HuggingFaceEmbedding(model_name=<span class="hljs-string">&#x27;/data/database/hg-embed/bce-embedding-base_v1&#x27;</span>, device=<span class="hljs-string">&#x27;cpu&#x27;</span>),<br>    <span class="hljs-string">&quot;JinaAI-Base&quot;</span>: HuggingFaceEmbedding(model_name=<span class="hljs-string">&#x27;/data/database/hg-embed/jina-embeddings-v2-base-en&#x27;</span>, device=<span class="hljs-string">&#x27;cuda&#x27;</span>),<br><br>&#125;<br><br>RERANKERS = &#123;<br>    <span class="hljs-string">&quot;WithoutReranker&quot;</span>: <span class="hljs-string">&quot;None&quot;</span>,<br>    <span class="hljs-string">&quot;bce-reranker-base&quot;</span>: SentenceTransformerRerank(model=<span class="hljs-string">&quot;/data/database/hg-embed/bce-reranker-base_v1&quot;</span>, top_n=<span class="hljs-number">5</span>),<br>    <span class="hljs-string">&quot;bge-reranker-large&quot;</span>: SentenceTransformerRerank(model=<span class="hljs-string">&quot;/data/database/hg-embed/bge-reranker-large&quot;</span>, top_n=<span class="hljs-number">5</span>)<br>&#125;<br><br><br><span class="hljs-comment"># Prompt to generate questions</span><br>qa_generate_prompt_tmpl = <span class="hljs-string">&quot;&quot;&quot;\</span><br><span class="hljs-string">Context information is below.</span><br><span class="hljs-string">---------------------</span><br><span class="hljs-string">&#123;context_str&#125;</span><br><span class="hljs-string">---------------------</span><br><span class="hljs-string">Given the context information and not prior knowledge.</span><br><span class="hljs-string">generate only questions based on the below query.</span><br><span class="hljs-string">You are a Professor. Your task is to setup \</span><br><span class="hljs-string">&#123;num_questions_per_chunk&#125; questions for an upcoming \</span><br><span class="hljs-string">quiz/examination. The questions should be diverse in nature \</span><br><span class="hljs-string">across the document. The questions should not contain options, not start with Q1/ Q2. \</span><br><span class="hljs-string">Restrict the questions to the context information provided.\</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>qa_dataset = generate_question_context_pairs(<br>    nodes, llm=llm, num_questions_per_chunk=<span class="hljs-number">2</span><br>)<br><br><span class="hljs-comment"># function to clean the dataset</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">filter_qa_dataset</span>(<span class="hljs-params">qa_dataset</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Filters out queries from the qa_dataset that contain certain phrases and the corresponding</span><br><span class="hljs-string">    entries in the relevant_docs, and creates a new EmbeddingQAFinetuneDataset object with</span><br><span class="hljs-string">    the filtered data.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    :param qa_dataset: An object that has &#x27;queries&#x27;, &#x27;corpus&#x27;, and &#x27;relevant_docs&#x27; attributes.</span><br><span class="hljs-string">    :return: An EmbeddingQAFinetuneDataset object with the filtered queries, corpus and relevant_docs.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-comment"># Extract keys from queries and relevant_docs that need to be removed</span><br>    queries_relevant_docs_keys_to_remove = &#123;<br>        k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> qa_dataset.queries.items()<br>        <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;Here are 2&#x27;</span> <span class="hljs-keyword">in</span> v <span class="hljs-keyword">or</span> <span class="hljs-string">&#x27;Here are two&#x27;</span> <span class="hljs-keyword">in</span> v<br>    &#125;<br><br>    <span class="hljs-comment"># Filter queries and relevant_docs using dictionary comprehensions</span><br>    filtered_queries = &#123;<br>        k: v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> qa_dataset.queries.items()<br>        <span class="hljs-keyword">if</span> k <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> queries_relevant_docs_keys_to_remove<br>    &#125;<br>    filtered_relevant_docs = &#123;<br>        k: v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> qa_dataset.relevant_docs.items()<br>        <span class="hljs-keyword">if</span> k <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> queries_relevant_docs_keys_to_remove<br>    &#125;<br><br>    <span class="hljs-comment"># Create a new instance of EmbeddingQAFinetuneDataset with the filtered data</span><br>    <span class="hljs-keyword">return</span> EmbeddingQAFinetuneDataset(<br>        queries=filtered_queries,<br>        corpus=qa_dataset.corpus,<br>        relevant_docs=filtered_relevant_docs<br>    )<br><br><span class="hljs-comment"># filter out pairs with phrases `Here are 2 questions based on provided context`</span><br>qa_dataset = filter_qa_dataset(qa_dataset)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">display_results</span>(<span class="hljs-params">embedding_name, reranker_name, eval_results</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;Display results from evaluate.&quot;&quot;&quot;</span><br><br>    metric_dicts = []<br>    <span class="hljs-keyword">for</span> eval_result <span class="hljs-keyword">in</span> eval_results:<br>        metric_dict = eval_result.metric_vals_dict<br>        metric_dicts.append(metric_dict)<br><br>    full_df = pd.DataFrame(metric_dicts)<br><br>    hit_rate = full_df[<span class="hljs-string">&quot;hit_rate&quot;</span>].mean()<br>    mrr = full_df[<span class="hljs-string">&quot;mrr&quot;</span>].mean()<br><br>    metric_df = pd.DataFrame(<br>        &#123;<span class="hljs-string">&quot;Embedding&quot;</span>: [embedding_name], <span class="hljs-string">&quot;Reranker&quot;</span>: [reranker_name], <span class="hljs-string">&quot;hit_rate&quot;</span>: [hit_rate], <span class="hljs-string">&quot;mrr&quot;</span>: [mrr]&#125;<br>    )<br><br>    <span class="hljs-keyword">return</span> metric_df<br><br>results_df = pd.DataFrame()<br><br><span class="hljs-comment"># Define Retriever</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CustomRetriever</span>(<span class="hljs-params">BaseRetriever</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;Custom retriever that performs both Vector search and Knowledge Graph search&quot;&quot;&quot;</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params"></span></span><br><span class="hljs-params"><span class="hljs-function">        self,</span></span><br><span class="hljs-params"><span class="hljs-function">        vector_retriever: VectorIndexRetriever,</span></span><br><span class="hljs-params"><span class="hljs-function">    </span>) -&gt; <span class="hljs-literal">None</span>:</span><br>        <span class="hljs-string">&quot;&quot;&quot;Init params.&quot;&quot;&quot;</span><br><br>        self._vector_retriever = vector_retriever<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_retrieve</span>(<span class="hljs-params">self, query_bundle: QueryBundle</span>) -&gt; <span class="hljs-type">List</span>[NodeWithScore]:</span><br>        <span class="hljs-string">&quot;&quot;&quot;Retrieve nodes given query.&quot;&quot;&quot;</span><br><br>        retrieved_nodes = self._vector_retriever.retrieve(query_bundle)<br><br>        <span class="hljs-keyword">if</span> reranker != <span class="hljs-string">&#x27;None&#x27;</span>:<br>            retrieved_nodes = reranker.postprocess_nodes(retrieved_nodes, query_bundle)<br>        <span class="hljs-keyword">else</span>:<br>            retrieved_nodes = retrieved_nodes[:<span class="hljs-number">5</span>]<br><br>        <span class="hljs-keyword">return</span> retrieved_nodes<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_aretrieve</span>(<span class="hljs-params">self, query_bundle: QueryBundle</span>) -&gt; <span class="hljs-type">List</span>[NodeWithScore]:</span><br>        <span class="hljs-string">&quot;&quot;&quot;Asynchronously retrieve nodes given query.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Implemented by the user.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">return</span> self._retrieve(query_bundle)<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">aretrieve</span>(<span class="hljs-params">self, str_or_query_bundle: QueryType</span>) -&gt; <span class="hljs-type">List</span>[NodeWithScore]:</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(str_or_query_bundle, <span class="hljs-built_in">str</span>):<br>            str_or_query_bundle = QueryBundle(str_or_query_bundle)<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">await</span> self._aretrieve(str_or_query_bundle)<br><br><span class="hljs-comment"># Loop over embeddings</span><br><span class="hljs-keyword">for</span> embed_name, embed_model <span class="hljs-keyword">in</span> EMBEDDINGS.items():<br>    <br>    service_context = ServiceContext.from_defaults(llm=<span class="hljs-literal">None</span>, embed_model=embed_model)<br>    vector_index = VectorStoreIndex(nodes, service_context=service_context)<br>    vector_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k=<span class="hljs-number">10</span>, service_context=service_context)<br>    <br>    <span class="hljs-comment"># Loop over rerankers</span><br>    <span class="hljs-keyword">for</span> rerank_name, reranker <span class="hljs-keyword">in</span> RERANKERS.items():<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Running Evaluation for Embedding Model: <span class="hljs-subst">&#123;embed_name&#125;</span> and Reranker: <span class="hljs-subst">&#123;rerank_name&#125;</span>&quot;</span>)<br>        custom_retriever = CustomRetriever(vector_retriever)<br><br>        retriever_evaluator = RetrieverEvaluator.from_metric_names(<br>            [<span class="hljs-string">&quot;mrr&quot;</span>, <span class="hljs-string">&quot;hit_rate&quot;</span>], retriever=custom_retriever<br>        )<br>        eval_results = <span class="hljs-keyword">await</span> retriever_evaluator.aevaluate_dataset(qa_dataset)<br><br>        current_df = display_results(embed_name, rerank_name, eval_results)<br>        results_df = pd.concat([results_df, current_df], ignore_index=<span class="hljs-literal">True</span>)<br><br></code></pre></td></tr></table></figure><p>根据以上代码执行的结果选择最佳组合，比如bge-large-en 和 bce-reranker-base进行检索</p><h4 id="RAG-Rerank检索"><a href="#RAG-Rerank检索" class="headerlink" title="RAG + Rerank检索"></a>RAG + Rerank检索</h4><h5 id="基础RAG"><a href="#基础RAG" class="headerlink" title="基础RAG"></a>基础RAG</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-keyword">from</span> llama_index import ServiceContext, VectorStoreIndex, SimpleDirectoryReader<br><span class="hljs-keyword">from</span> llama_index.embeddings import OpenAIEmbedding, HuggingFaceEmbedding, CohereEmbedding<br><span class="hljs-keyword">from</span> llama_index.node_parser import SimpleNodeParser<br><br><span class="hljs-keyword">from</span> typing import List<br><span class="hljs-comment"># Retrievers</span><br><span class="hljs-keyword">from</span> llama_index.retrievers import (<br>    BaseRetriever,<br>    VectorIndexRetriever,<br>)<br><br><span class="hljs-comment"># Rerankers</span><br><span class="hljs-keyword">from</span> llama_index.indices.query.schema import QueryBundle, QueryType<br><span class="hljs-keyword">from</span> llama_index.schema import NodeWithScore<br><span class="hljs-comment"># from llama_index.indices.postprocessor.cohere_rerank import CohereRerank</span><br><span class="hljs-keyword">from</span> llama_index.indices.postprocessor import SentenceTransformerRerank<br><span class="hljs-keyword">from</span> llama_index.finetuning.embeddings.common import EmbeddingQAFinetuneDataset<br><br>embed_model = HuggingFaceEmbedding(<span class="hljs-attribute">model_name</span>=<span class="hljs-string">&#x27;/data/database/hg-embed/bge-large-en-v1.5&#x27;</span>, <span class="hljs-attribute">device</span>=<span class="hljs-string">&#x27;cuda:1&#x27;</span>)<br><br>documents = SimpleDirectoryReader(input_files=[<span class="hljs-string">&quot;data/ssh_btmp.pdf&quot;</span>]).load_data()<br>node_parser = SimpleNodeParser.from_defaults(<span class="hljs-attribute">chunk_size</span>=512, <span class="hljs-attribute">chunk_overlap</span>=100)<br>nodes = node_parser.get_nodes_from_documents(documents)<br><br>query_bundle = QueryBundle(<span class="hljs-string">&#x27;如何查看攻击者ip&#x27;</span>)<br>service_context = ServiceContext.from_defaults(<span class="hljs-attribute">llm</span>=None, <span class="hljs-attribute">embed_model</span>=embed_model)<br>vector_index = VectorStoreIndex(nodes, <span class="hljs-attribute">service_context</span>=service_context)<br>vector_retriever = VectorIndexRetriever(<span class="hljs-attribute">index</span>=vector_index, <span class="hljs-attribute">similarity_top_k</span>=5, <span class="hljs-attribute">service_context</span>=service_context)<br><br>retrieved_nodes = vector_retriever.retrieve(query_bundle)<br><span class="hljs-comment"># retrieved_nodes</span><br><span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> retrieved_nodes:<br>    <span class="hljs-builtin-name">print</span>(<span class="hljs-string">&#x27;文本:&#x27;</span>,r.get_text())<br>    <span class="hljs-builtin-name">print</span>(<span class="hljs-string">&#x27;Score:&#x27;</span>, r.score)<br></code></pre></td></tr></table></figure><h5 id="Rerank"><a href="#Rerank" class="headerlink" title="Rerank"></a>Rerank</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs routeros">reranker = SentenceTransformerRerank(<span class="hljs-attribute">model</span>=<span class="hljs-string">&quot;/data/database/hg-embed/bce-reranker-base_v1&quot;</span>, <span class="hljs-attribute">top_n</span>=1)<br>retrieved_nodes = reranker.postprocess_nodes(retrieved_nodes, query_bundle)<br><span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> retrieved_nodes:<br>    <span class="hljs-builtin-name">print</span>(<span class="hljs-string">&#x27;文本:&#x27;</span>,r.get_text())<br>    <span class="hljs-builtin-name">print</span>(<span class="hljs-string">&#x27;Score:&#x27;</span>, r.score)<br></code></pre></td></tr></table></figure><p>最后可以用Rerank的结果再喂给LLM获取答案。</p><p>参考:<br><a href="https://blog.csdn.net/wshzd/article/details/135092669?spm=1001.2014.3001.5502">https://blog.csdn.net/wshzd/article/details/135092669?spm=1001.2014.3001.5502</a><br><a href="https://mp.weixin.qq.com/s/SypSZwApvNBnPQwk7Uw5aA">https://mp.weixin.qq.com/s/SypSZwApvNBnPQwk7Uw5aA</a></p>]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RAG</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>自建谷歌镜像</title>
    <link href="/2023/12/18/%E8%87%AA%E5%BB%BA%E8%B0%B7%E6%AD%8C%E9%95%9C%E5%83%8F/"/>
    <url>/2023/12/18/%E8%87%AA%E5%BB%BA%E8%B0%B7%E6%AD%8C%E9%95%9C%E5%83%8F/</url>
    
    <content type="html"><![CDATA[<h2 id="使用-nginx-反向代理谷歌"><a href="#使用-nginx-反向代理谷歌" class="headerlink" title="使用 nginx 反向代理谷歌"></a>使用 nginx 反向代理谷歌</h2><span id="more"></span><h3 id="大提前：拥有一台国外-VPS"><a href="#大提前：拥有一台国外-VPS" class="headerlink" title="大提前：拥有一台国外 VPS"></a>大提前：拥有一台国外 VPS</h3><p>搭建好的地址如下：</p><ul><li>谷歌镜像地址：<a href="https://search.letsthink.top/">https://search.letsthink.top</a></li><li>谷歌学术镜像地址：<a href="https://search.letsthink.top/scholar/?hl=zh-CN">https://search.letsthink.top/scholar/?hl=zh-CN</a></li></ul><p>项目地址：<a href="https://github.com/cuber/ngx_http_google_filter_module%EF%BC%8C%E8%BF%99%E4%B8%AA%E9%A1%B9%E7%9B%AE%E6%98%AF%E8%80%81%E9%A1%B9%E7%9B%AE%E4%BA%86%EF%BC%8C%E5%8F%AF%E8%83%BD%E4%B8%8D%E5%A4%AA%E6%94%AF%E6%8C%81%E9%AB%98%E7%89%88%E6%9C%AC%E7%9A%84nginx%E3%80%82%E8%BF%99%E9%87%8C%E5%8F%AF%E4%BB%A5%E5%8F%82%E8%80%83%E8%BF%99%E7%AF%87%E5%8D%9A%E5%AE%A2%EF%BC%9Ahttps://blog.oyi.me/619">https://github.com/cuber/ngx_http_google_filter_module，这个项目是老项目了，可能不太支持高版本的nginx。这里可以参考这篇博客：https://blog.oyi.me/619</a></p><h3 id="搭建方法（这里以已经安装了nginx为例（比如使用-apt-install-nginx-已经安装过了））"><a href="#搭建方法（这里以已经安装了nginx为例（比如使用-apt-install-nginx-已经安装过了））" class="headerlink" title="搭建方法（这里以已经安装了nginx为例（比如使用 apt install nginx 已经安装过了））"></a>搭建方法（这里以已经安装了nginx为例（比如使用 <code>apt install nginx</code> 已经安装过了））</h3><p>主要是使用了两个nginx的模块 <code>ngx_http_substitutions_filter_module</code> 和 <code>ngx_http_google_filter_module</code></p><h4 id="下载模块"><a href="#下载模块" class="headerlink" title="下载模块"></a>下载模块</h4><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">git clone https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/yaoweibin/</span>ngx_http_substitutions_filter_module<br>git clone https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/cuber/</span>ngx_http_google_filter_module<br></code></pre></td></tr></table></figure><h4 id="查看已经安装的nginx的编译参数"><a href="#查看已经安装的nginx的编译参数" class="headerlink" title="查看已经安装的nginx的编译参数"></a>查看已经安装的nginx的编译参数</h4><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">nginx -V</span><br></code></pre></td></tr></table></figure><p>输出信息如下，后续主要用的就是configure arguments后的内容(这里我已经是重新编译后的参数了)</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs javascript">nginx version: nginx/<span class="hljs-number">1.18</span><span class="hljs-number">.0</span><br>built by gcc <span class="hljs-number">9.4</span><span class="hljs-number">.0</span> (Ubuntu <span class="hljs-number">9.4</span><span class="hljs-number">.0</span>-1ubuntu1~<span class="hljs-number">20.04</span><span class="hljs-number">.2</span>)<br>built <span class="hljs-keyword">with</span> OpenSSL <span class="hljs-number">1.1</span>.1f  <span class="hljs-number">31</span> Mar <span class="hljs-number">2020</span><br>TLS SNI support enabled<br>configure <span class="hljs-built_in">arguments</span>: --<span class="hljs-keyword">with</span>-cc-opt=<span class="hljs-string">&#x27;-g -O2 -fdebug-prefix-map=/build/nginx-lUTckl/nginx-1.18.0=. -fstack-protector-strong -Wformat -Werror=format-security -fPIC -Wdate-time -D_FORTIFY_SOURCE=2&#x27;</span> --<span class="hljs-keyword">with</span>-ld-opt=<span class="hljs-string">&#x27;-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -fPIC&#x27;</span> --prefix=<span class="hljs-regexp">/usr/</span>share/nginx --conf-path=<span class="hljs-regexp">/etc/</span>nginx/nginx.conf --http-log-path=<span class="hljs-regexp">/var/</span>log/nginx/access.log --error-log-path=<span class="hljs-regexp">/var/</span>log/nginx/error.log --lock-path=<span class="hljs-regexp">/var/</span>lock/nginx.lock --pid-path=<span class="hljs-regexp">/run/</span>nginx.pid --modules-path=<span class="hljs-regexp">/usr/</span>lib/nginx/modules --http-client-body-temp-path=<span class="hljs-regexp">/var/</span>lib/nginx/body --http-fastcgi-temp-path=<span class="hljs-regexp">/var/</span>lib/nginx/fastcgi --http-proxy-temp-path=<span class="hljs-regexp">/var/</span>lib/nginx/proxy --http-scgi-temp-path=<span class="hljs-regexp">/var/</span>lib/nginx/scgi --http-uwsgi-temp-path=<span class="hljs-regexp">/var/</span>lib/nginx/uwsgi --<span class="hljs-keyword">with</span>-debug --<span class="hljs-keyword">with</span>-compat --<span class="hljs-keyword">with</span>-pcre-jit --<span class="hljs-keyword">with</span>-http_ssl_module --<span class="hljs-keyword">with</span>-http_stub_status_module --<span class="hljs-keyword">with</span>-http_realip_module --<span class="hljs-keyword">with</span>-http_auth_request_module --<span class="hljs-keyword">with</span>-http_v2_module --<span class="hljs-keyword">with</span>-http_dav_module --<span class="hljs-keyword">with</span>-http_slice_module --<span class="hljs-keyword">with</span>-threads --<span class="hljs-keyword">with</span>-http_addition_module --<span class="hljs-keyword">with</span>-http_gunzip_module --<span class="hljs-keyword">with</span>-http_gzip_static_module --<span class="hljs-keyword">with</span>-http_image_filter_module=dynamic --<span class="hljs-keyword">with</span>-http_sub_module --<span class="hljs-keyword">with</span>-http_xslt_module=dynamic --<span class="hljs-keyword">with</span>-stream=dynamic --<span class="hljs-keyword">with</span>-stream_ssl_module --<span class="hljs-keyword">with</span>-mail=dynamic --<span class="hljs-keyword">with</span>-mail_ssl_module --add-<span class="hljs-built_in">module</span>=<span class="hljs-regexp">/etc/</span>nginx/modules-available/ngx_http_substitutions_filter_module --add-dynamic-<span class="hljs-built_in">module</span>=<span class="hljs-regexp">/etc/</span>nginx/modules-available/ngx_http_google_filter_module<br></code></pre></td></tr></table></figure><h4 id="下载对应版本的nginx源码，各版本地址：http-nginx-org-download"><a href="#下载对应版本的nginx源码，各版本地址：http-nginx-org-download" class="headerlink" title="下载对应版本的nginx源码，各版本地址：http://nginx.org/download"></a>下载对应版本的nginx源码，各版本地址：<a href="http://nginx.org/download">http://nginx.org/download</a></h4><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">wget http:<span class="hljs-regexp">//</span>nginx.org<span class="hljs-regexp">/download/</span>nginx-<span class="hljs-number">1.18</span>.<span class="hljs-number">0</span>.tar.gz<br></code></pre></td></tr></table></figure><h4 id="解压重新编译-编译时使用-add-dynamic-module-和-add-module"><a href="#解压重新编译-编译时使用-add-dynamic-module-和-add-module" class="headerlink" title="解压重新编译, 编译时使用 add-dynamic-module 和 add-module"></a>解压重新编译, 编译时使用 add-dynamic-module 和 add-module</h4><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs livescript">tar -xzvf nginx-<span class="hljs-number">1.18</span>.<span class="hljs-number">0.tar</span>.gz &amp;&amp; cd nginx-<span class="hljs-number">1.18</span>.<span class="hljs-number">0</span><br>./configure <span class="hljs-string">\</span><br>  &lt;your configuration&gt; <span class="hljs-string">\</span><br>  --add-dynamic-<span class="hljs-built_in">module</span>=&lt;<span class="hljs-regexp">/path/to/</span>&gt;ngx_http_google_filter_module <span class="hljs-string">\</span><br>  --add-<span class="hljs-built_in">module</span>=&lt;<span class="hljs-regexp">/path/to/</span>&gt;ngx_http_substitutions_filter_module<br> <span class="hljs-comment"># 编译</span><br> make<br></code></pre></td></tr></table></figure><h4 id="这里不要进行-make-install-上述编译完就在-objs-目录下生成了nginx文件"><a href="#这里不要进行-make-install-上述编译完就在-objs-目录下生成了nginx文件" class="headerlink" title="这里不要进行 make install , 上述编译完就在 objs 目录下生成了nginx文件"></a>这里不要进行 make install , 上述编译完就在 objs 目录下生成了nginx文件</h4><p> 替换原有的 nginx 文件， 可使用 <code>which nginx</code> 查找位置，然后使用 <code>cp</code> 替换<br> <figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">cp -rf objs<span class="hljs-regexp">/nginx /u</span>sr<span class="hljs-regexp">/sbin/</span>nginx<br></code></pre></td></tr></table></figure></p><h4 id="修改-nginx-conf，一定要在文件开头把动态包加载进去"><a href="#修改-nginx-conf，一定要在文件开头把动态包加载进去" class="headerlink" title="修改 nginx.conf，一定要在文件开头把动态包加载进去"></a>修改 nginx.conf，一定要在文件开头把动态包加载进去</h4> <figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">load_module <span class="hljs-regexp">/xxx路径/</span>objs/ngx_http_google_filter_module.so;<br></code></pre></td></tr></table></figure><h4 id="server配置"><a href="#server配置" class="headerlink" title="server配置"></a>server配置</h4> <figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs nginx"> <span class="hljs-section">server</span> &#123;<br>  <span class="hljs-attribute">server_name</span> &lt;你的域名&gt;;<br>  <span class="hljs-attribute">listen</span> <span class="hljs-number">443</span>;<br><br>  <span class="hljs-attribute">ssl</span> <span class="hljs-literal">on</span>;<br>  <span class="hljs-attribute">ssl_certificate</span> &lt;你的证书&gt;;<br>  <span class="hljs-attribute">ssl_certificate_key</span> &lt;你的私钥&gt;;<br><br>  <span class="hljs-attribute">resolver</span> <span class="hljs-number">8.8.8.8</span>;<br>  <span class="hljs-attribute">location</span> / &#123;<br>    <span class="hljs-attribute">google</span> <span class="hljs-literal">on</span>;<br>    <span class="hljs-attribute">google_scholar</span> <span class="hljs-literal">on</span>;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="重启nginx"><a href="#重启nginx" class="headerlink" title="重启nginx"></a>重启nginx</h4><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">service nginx restart 或者 nginx -s <span class="hljs-keyword">reload</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>nginx</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>设置NAT转发以通过网关服务器实现内网访问外网</title>
    <link href="/2023/12/13/%E8%AE%BE%E7%BD%AENAT%E8%BD%AC%E5%8F%91%E4%BB%A5%E9%80%9A%E8%BF%87%E7%BD%91%E5%85%B3%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E7%8E%B0%E5%86%85%E7%BD%91%E8%AE%BF%E9%97%AE%E5%A4%96%E7%BD%91/"/>
    <url>/2023/12/13/%E8%AE%BE%E7%BD%AENAT%E8%BD%AC%E5%8F%91%E4%BB%A5%E9%80%9A%E8%BF%87%E7%BD%91%E5%85%B3%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E7%8E%B0%E5%86%85%E7%BD%91%E8%AE%BF%E9%97%AE%E5%A4%96%E7%BD%91/</url>
    
    <content type="html"><![CDATA[<h2 id="内网服务器启动上网服务"><a href="#内网服务器启动上网服务" class="headerlink" title="内网服务器启动上网服务"></a>内网服务器启动上网服务</h2><span id="more"></span><p>场景如下：一个小HPC有一个master节点, 1个 node1 节点, master节点可以上网冲浪, node1节点无法冲浪</p><p>方案：使用NAT转发使node1通过master上网冲浪</p><h3 id="步骤一：IP转发"><a href="#步骤一：IP转发" class="headerlink" title="步骤一：IP转发"></a>步骤一：IP转发</h3><p>在master节点编辑 /etc/sysctl.conf 文件，在该文件中确保以下行取消注释并设置为 1，以允许IP转发：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">net</span>.ipv<span class="hljs-number">4</span>.ip_forward=<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>然后执行 <code>sysctl -p</code> 应用更改。</p><h3 id="步骤二：配置NAT规则"><a href="#步骤二：配置NAT规则" class="headerlink" title="步骤二：配置NAT规则"></a>步骤二：配置NAT规则</h3><p>在master节点使用 iptables 设置NAT规则来将 node1 的流量转发至外网。你需要选择哪个网络接口连向外网（举例使用 eth0）：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">sudo</span> iptables -t nat -A POSTROUTING -o eth<span class="hljs-number">0</span> -j MASQUERADE<br></code></pre></td></tr></table></figure><p>这行命令会把所有经过 master 节点的流量都进行源地址转换（即，伪装成 master 节点），使得 node1 的流量看起来像是从 master 节点发起的。<br>将规则保存到一个文件，如 /etc/iptables/rules.v4，然后在 /etc/rc.local 或其他启动脚本中通过 iptables-restore 来加载它们：</p><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arcade">sudo iptables-save &gt; <span class="hljs-regexp">/etc/i</span>ptables/rules.v4<br></code></pre></td></tr></table></figure><p>并在启动脚本中添加：</p><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arcade">sudo iptables-restore &lt; <span class="hljs-regexp">/etc/i</span>ptables/rules.v4<br></code></pre></td></tr></table></figure><p>PS: 如何判断 master 节点上的网络接口是连接外网的</p><ul><li><p>查看接口配置和连接的网络：<br>常用的命令是 ip addr show 或者 ifconfig（如果系统上安装了）。这些命令列出了所有接口的IP地址及其状态。一般来说，连接到外网的接口通常拥有公网IP地址或者动态分配的私网IP地址，并且这个地址能够通过路由器访问到互联网。</p></li><li><p>检查路由表：<br>使用 ip route show 或者 route -n 命令来查看系统的路由表。默认路由（0.0.0.0/0 或者 just default）指向的接口通常就是用于连接到外网的接口。</p></li><li><p>测试网络连接：<br>可以尝试使用 ping 命令测试不同的接口与外网通信。对于每个网络接口，可以使用 ping -I <interface_name> 8.8.8.8 来测试。能够成功发送和接收数据包的接口很可能就是连接到外网的。</p></li></ul><h3 id="步骤三：配置防火墙规则（如果有防火墙的话）"><a href="#步骤三：配置防火墙规则（如果有防火墙的话）" class="headerlink" title="步骤三：配置防火墙规则（如果有防火墙的话）"></a>步骤三：配置防火墙规则（如果有防火墙的话）</h3><p>如果你的系统使用防火墙，比如 UFW 或 Firewalld，你需要确保它们配置成允许流量转发：</p><p>在 master 节点, 对于UFW，可能要编辑 /etc/default/ufw 文件：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">DEFAULT_FORWARD_POLICY</span>=<span class="hljs-string">&quot;ACCEPT&quot;</span><br></code></pre></td></tr></table></figure><p>然后，配置UFW规则来允许流量通过，或者直接用 iptables。</p><h3 id="步骤四：在-node1-上配置网关"><a href="#步骤四：在-node1-上配置网关" class="headerlink" title="步骤四：在 node1 上配置网关"></a>步骤四：在 node1 上配置网关</h3><p>在 node1 节点上，你可能需要配置默认网关指向 master 节点的内网IP，这样所有默认路由的外网流量才会通过 master 节点。你可以使用 route 或者 ip route 命令来设置这个：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">sudo<span class="hljs-built_in"> route </span><span class="hljs-builtin-name">add</span><span class="hljs-built_in"> default </span>gw master内网IP地址<br></code></pre></td></tr></table></figure><p>或者</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">sudo<span class="hljs-built_in"> ip route </span><span class="hljs-builtin-name">add</span><span class="hljs-built_in"> default </span>via master内网IP地址<br></code></pre></td></tr></table></figure><h3 id="步骤五：测试配置"><a href="#步骤五：测试配置" class="headerlink" title="步骤五：测试配置"></a>步骤五：测试配置</h3><p>完成配置后，从 node1 尝试ping外网地址，比如：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">ping</span> <span class="hljs-number">8.8.8.8</span><br></code></pre></td></tr></table></figure><p>如果可以ping通，再尝试解析域名，这可以确认DNS解析是否也正常工作：</p><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs autoit"><span class="hljs-built_in">ping</span> baidu.com<br></code></pre></td></tr></table></figure><p>如果所有步骤操作正确，node1 应该能够通过 master 节点访问外网。</p><p>PS:DNS 配置：</p><ul><li><p>检查 node1 上的 /etc/resolv.conf 文件，确保它包含正确的 DNS 服务器信息：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">cat <span class="hljs-regexp">/etc/</span>resolv.conf<br></code></pre></td></tr></table></figure><p>里面应该列出至少一个 nameserver，例如：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">nameserver</span> <span class="hljs-number">8.8.8.8</span><br>nameserver <span class="hljs-number">8.8.4.4</span><br></code></pre></td></tr></table></figure><p>这里 8.8.8.8 和 8.8.4.4 是 Google 的公共 DNS 服务器。</p></li><li><p>尝试使用公共 DNS 服务器：<br>如果 resolv.conf 没有列出 DNS 服务器，或者列出的 DNS 服务器不工作，你可以尝试更换为公共 DNS，如 Google 的 DNS：</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gradle">echo <span class="hljs-string">&#x27;nameserver 8.8.8.8&#x27;</span> | sudo tee <span class="hljs-regexp">/etc/</span>resolv.conf &gt; <span class="hljs-regexp">/dev/</span><span class="hljs-keyword">null</span><br></code></pre></td></tr></table></figure></li></ul>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NAT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pandora-next详细使用</title>
    <link href="/2023/12/08/pandora-next%E8%AF%A6%E7%BB%86%E4%BD%BF%E7%94%A8/"/>
    <url>/2023/12/08/pandora-next%E8%AF%A6%E7%BB%86%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><h3 id="项目地址-https-github-com-pandora-next-deploy"><a href="#项目地址-https-github-com-pandora-next-deploy" class="headerlink" title="项目地址 https://github.com/pandora-next/deploy"></a>项目地址 <a href="https://github.com/pandora-next/deploy">https://github.com/pandora-next/deploy</a></h3><h3 id="免费共享的GPT地址：https-chat-shared3-zhile-io-shared-html-v-2"><a href="#免费共享的GPT地址：https-chat-shared3-zhile-io-shared-html-v-2" class="headerlink" title="免费共享的GPT地址：https://chat-shared3.zhile.io/shared.html?v=2"></a>免费共享的GPT地址：<a href="https://chat-shared3.zhile.io/shared.html?v=2">https://chat-shared3.zhile.io/shared.html?v=2</a></h3><p>这里共享了2622个普通号和22个gpt4 plus号，而且完全免费，包括gpt4 plus。使用方法也很简单，随便看中哪个小框框点进去，再随便设置个密码就可以进去了。<br>关于4.0plus版（冒金光的就是4.0，其他都是普通版）：plus版貌似不是都能用, 如何判断冒金光的哪个能用？个人总结：冒着金光而且框框发红的应该就可以用，虽然用的人多。冒着金光但是框框是绿的大概率就不能用，绿色代表用的人少，毕竟是4.0，而且免费，怎么可能会人少呢，除非不能用。</p><h3 id="自行部署"><a href="#自行部署" class="headerlink" title="自行部署"></a>自行部署</h3><p>这个项目如果自己有账号也可以自行部署，全程无需科学上网（感谢大佬提供的代理服务）。<br>不过自行部署也是有额度限制的（根据自己的github账号注册时长限制每天多少条提问的额度）</p><p>PS: 根据项目文档也可以0额度消耗使用，比如下面两种登录方式，test1登录每提问一个消耗一个额度，使用test2登录，提问不消耗额度。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs json">&#123;<br>  <span class="hljs-attr">&quot;test1&quot;</span>: &#123;<br>    <span class="hljs-attr">&quot;token&quot;</span>: &#x27;access_token&#x27;,    <br>    <span class="hljs-attr">&quot;shared&quot;</span>: <span class="hljs-literal">false</span>,<br>    <span class="hljs-attr">&quot;show_user_info&quot;</span>: <span class="hljs-literal">false</span><br>  &#125;,<br>  <span class="hljs-attr">&quot;test2&quot;</span>: &#123;<br>    <span class="hljs-attr">&quot;token&quot;</span>: <span class="hljs-string">&quot;用户名,密码&quot;</span>,<br>    <span class="hljs-attr">&quot;password&quot;</span>: <span class="hljs-string">&quot;12345&quot;</span>   ## 此密码可以随便填，主要用于页面登录<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>另外如果部署后想用脚本批量提问也是可以的，不过使用后端api提问貌似都是要消耗额度（登录是最消耗额度的，相当于提问了100个）。<br>部分后端API使用方法如下（下面url地址里的test123456是config.json里的proxy_api_prefix）：<br>config.json</p><figure class="highlight clojure"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs clojure">&#123;<br>  <span class="hljs-string">&quot;bind&quot;</span>: <span class="hljs-string">&quot;127.0.0.1:8181&quot;</span>,<br>  <span class="hljs-string">&quot;tls&quot;</span>: &#123;<br>    <span class="hljs-string">&quot;enabled&quot;</span>: <span class="hljs-literal">false</span>,<br>    <span class="hljs-string">&quot;cert_file&quot;</span>: <span class="hljs-string">&quot;&quot;</span>,<br>    <span class="hljs-string">&quot;key_file&quot;</span>: <span class="hljs-string">&quot;&quot;</span><br>  &#125;,<br>  <span class="hljs-string">&quot;timeout&quot;</span>: <span class="hljs-number">600</span>,<br>  <span class="hljs-string">&quot;proxy_url&quot;</span>: <span class="hljs-string">&quot;&quot;</span>,<br>  <span class="hljs-string">&quot;license_id&quot;</span>: <span class="hljs-string">&quot;&quot;</span>,     ## 这个就是用来获取额度的<br>  <span class="hljs-string">&quot;public_share&quot;</span>: <span class="hljs-literal">false</span>,<br>  <span class="hljs-string">&quot;site_password&quot;</span>: <span class="hljs-string">&quot;&quot;</span>,<br>  <span class="hljs-string">&quot;setup_password&quot;</span>: <span class="hljs-string">&quot;&quot;</span>,<br>  <span class="hljs-string">&quot;server_tokens&quot;</span>: <span class="hljs-literal">true</span>,<br>  <span class="hljs-string">&quot;proxy_api_prefix&quot;</span>: <span class="hljs-string">&quot;test123456&quot;</span>,<br>  <span class="hljs-string">&quot;isolated_conv_title&quot;</span>: <span class="hljs-string">&quot;*&quot;</span>,<br>  <span class="hljs-string">&quot;captcha&quot;</span>: &#123;<br>    <span class="hljs-string">&quot;provider&quot;</span>: <span class="hljs-string">&quot;&quot;</span>,<br>    <span class="hljs-string">&quot;site_key&quot;</span>: <span class="hljs-string">&quot;&quot;</span>,<br>    <span class="hljs-string">&quot;site_secret&quot;</span>: <span class="hljs-string">&quot;&quot;</span>,<br>    <span class="hljs-string">&quot;site_login&quot;</span>: <span class="hljs-literal">false</span>,<br>    <span class="hljs-string">&quot;setup_login&quot;</span>: <span class="hljs-literal">false</span>,<br>    <span class="hljs-string">&quot;oai_username&quot;</span>: <span class="hljs-literal">false</span>,<br>    <span class="hljs-string">&quot;oai_password&quot;</span>: <span class="hljs-literal">false</span><br>  &#125;,<br>  <span class="hljs-string">&quot;whitelist&quot;</span>: null<br>&#125;<br></code></pre></td></tr></table></figure><ul><li><p>POST /api/auth/login 登录获取access token，需要使用urlencode form传递username 和 password 参数。</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs nix"><br><span class="hljs-comment"># curl 版</span><br>curl -X POST http://<span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">8181</span>/test123456/api/auth/login \<br>     -H <span class="hljs-string">&quot;Content-Type: application/x-www-form-urlencoded&quot;</span>  \<br>     -d <span class="hljs-string">&quot;username=***&amp;password=***&quot;</span> <br><br> <span class="hljs-comment"># python版 </span><br><span class="hljs-built_in">import</span> requests<br><br><span class="hljs-attr">url</span> = <span class="hljs-string">&quot;http://127.0.0.1:8181/test123456/api/auth/login&quot;</span><br><span class="hljs-attr">data</span> = &#123;<br>    <span class="hljs-string">&quot;username&quot;</span>: <span class="hljs-string">&quot;你的用户名&quot;</span>,<br>    <span class="hljs-string">&quot;password&quot;</span>: <span class="hljs-string">&quot;你的密码&quot;</span><br>&#125;<br><span class="hljs-attr">headers</span> = &#123;<br>    <span class="hljs-string">&quot;Content-Type&quot;</span>: <span class="hljs-string">&quot;application/x-www-form-urlencoded&quot;</span><br>&#125;<br><br><span class="hljs-attr">response</span> = requests.post(url, <span class="hljs-attr">data=data,</span> <span class="hljs-attr">headers=headers)</span><br><br>print(response.text)<br></code></pre></td></tr></table></figure><p>该请求可以获得access token 和 session token，关于各种token可查看该文档：<a href="https://fakeopen.org/Token/Access.html">https://fakeopen.org/Token/Access.html</a></p></li><li><p>POST /api/auth/session 通过session token获取access token，使用urlencode form传递session_token参数。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs awk"><br><span class="hljs-comment"># curl 版</span><br>curl -X POST http:<span class="hljs-regexp">//</span><span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">8181</span><span class="hljs-regexp">/test123456/</span>api<span class="hljs-regexp">/auth/</span>session \<br>     -H <span class="hljs-string">&quot;Content-Type: application/x-www-form-urlencoded&quot;</span>  \<br>     -d <span class="hljs-string">&quot;session_token=***&quot;</span> <br>     <br><span class="hljs-comment"># python版 </span><br>import requests<br><br>url = <span class="hljs-string">&quot;http://127.0.0.1:8181/test123456/api/auth/session&quot;</span><br><br>payload = &#123;<br>    <span class="hljs-string">&#x27;session_token&#x27;</span>: <span class="hljs-string">&#x27;***&#x27;</span>  <span class="hljs-comment"># 替换 *** 为你的 session_token</span><br>&#125;<br><br>headers = &#123;<br>    <span class="hljs-string">&#x27;Content-Type&#x27;</span>: <span class="hljs-string">&#x27;application/x-www-form-urlencoded&#x27;</span><br>&#125;<br><br>response = requests.post(url, headers=headers, data=payload)<br>print(response.text)<br></code></pre></td></tr></table></figure></li><li><p>POST /api/token/register 生成share token ，需要使用urlencode form传递unique_name (unique_name随便填就可)和 access_token 参数。</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-comment"># curl 版</span><br>curl -X POST http://<span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">8181</span>/test123456/api/token/register <br>     -H <span class="hljs-string">&quot;Content-Type: application/x-www-form-urlencoded&quot;</span> <br>     -d <span class="hljs-string">&quot;unique_name=***&amp;access_token=***&quot;</span><br>      <br><span class="hljs-comment"># python版</span><br><span class="hljs-built_in">import</span> requests<br><br><span class="hljs-attr">url</span> = <span class="hljs-string">&quot;http://127.0.0.1:8181/test123456/api/token/register&quot;</span><br><span class="hljs-attr">payload</span> = &#123;<br>    <span class="hljs-string">&quot;unique_name&quot;</span>: <span class="hljs-string">&quot;你的unique_name&quot;</span>,  <span class="hljs-comment"># 替换为你的实际 unique_name</span><br>    <span class="hljs-string">&quot;access_token&quot;</span>: <span class="hljs-string">&quot;你的access_token&quot;</span>  <span class="hljs-comment"># 替换为你的实际 access token</span><br>&#125;<br><span class="hljs-attr">headers</span> = &#123;<br>    <span class="hljs-string">&quot;Content-Type&quot;</span>: <span class="hljs-string">&quot;application/x-www-form-urlencoded&quot;</span><br>&#125;<br><br><span class="hljs-attr">response</span> = requests.post(url, <span class="hljs-attr">data=payload,</span> <span class="hljs-attr">headers=headers)</span><br><br>print(response.text)<br></code></pre></td></tr></table></figure><p>另外share token也可在这个地址获取：<a href="https://ai.fakeopen.com/token">https://ai.fakeopen.com/token</a></p></li><li><p>POST /v1/chat/completions 使用ChatGPT模拟API的请求接口，支持share token和pool token。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs scala"># curl 版<br>curl  -<span class="hljs-type">X</span> <span class="hljs-type">POST</span> <span class="hljs-symbol">&#x27;http</span>:<span class="hljs-comment">//127.0.0.1:8181/test123456/v1/chat/completions&#x27; \ </span><br>-<span class="hljs-type">H</span> <span class="hljs-symbol">&#x27;Content</span>-<span class="hljs-type">Type</span>: application/json&#x27; \<br>-<span class="hljs-type">H</span> <span class="hljs-symbol">&#x27;Authorization</span>: <span class="hljs-type">Bearer</span> share_token&#x27; \<br>-d &#x27;&#123;    <br>    <span class="hljs-string">&quot;model&quot;</span>: <span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,<br>    <span class="hljs-string">&quot;messages&quot;</span>: [<br>        &#123;<br>            <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>,<br>            <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;you are a helpful assistant&quot;</span><br>        &#125;,<br>        &#123;<br>            <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,<br>            <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;hello&quot;</span><br>        &#125;<br>    ],<br>    <span class="hljs-string">&quot;temperature&quot;</span>: <span class="hljs-number">0.7</span><br>&#125;&#x27;<br><br># python版<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> json<br><br>url = <span class="hljs-symbol">&#x27;http</span>:<span class="hljs-comment">//127.0.0.1:8181/test123456/v1/chat/completions&#x27;</span><br>headers = &#123;<br>    <span class="hljs-symbol">&#x27;Content</span>-<span class="hljs-type">Type</span>&#x27;: <span class="hljs-symbol">&#x27;application</span>/json&#x27;,<br>    <span class="hljs-symbol">&#x27;Authorizatio</span>n&#x27;: <span class="hljs-symbol">&#x27;Bearer</span> share_token&#x27;  # 替换 <span class="hljs-symbol">&#x27;share_toke</span>n&#x27; 为你的实际共享令牌<br>&#125;<br>data = &#123;<br>    <span class="hljs-symbol">&#x27;mode</span>l&#x27;: <span class="hljs-symbol">&#x27;gpt</span><span class="hljs-number">-3.5</span>-turbo&#x27;,<br>    <span class="hljs-symbol">&#x27;message</span>s&#x27;: [<br>        &#123;<br>            <span class="hljs-symbol">&#x27;rol</span>e&#x27;: <span class="hljs-symbol">&#x27;syste</span>m&#x27;,<br>            <span class="hljs-symbol">&#x27;conten</span>t&#x27;: <span class="hljs-symbol">&#x27;you</span> are a helpful assistant&#x27;<br>        &#125;,<br>        &#123;<br>            <span class="hljs-symbol">&#x27;rol</span>e&#x27;: <span class="hljs-symbol">&#x27;use</span>r&#x27;,<br>            <span class="hljs-symbol">&#x27;conten</span>t&#x27;: <span class="hljs-symbol">&#x27;hell</span>o&#x27;<br>        &#125;<br>    ],<br>    <span class="hljs-symbol">&#x27;temperatur</span>e&#x27;: <span class="hljs-number">0.7</span><br>&#125;<br><br>response = requests.post(url, headers=headers, json=data)<br><br>print(response.text)<br></code></pre></td></tr></table></figure></li><li><p>/backend-api/* ChatGPT网页版接口(暂时没搞明白怎么请求，先留个坑)</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import uuid<br>auth0_url = <span class="hljs-string">&quot;http://127.0.0.1:8181/backend-api/conversation&quot;</span><br><br>headers =  &#123;<br>        <span class="hljs-string">&#x27;X-Authorization&#x27;</span>:<span class="hljs-string">&#x27;Bearer xxx&#x27;</span>,<br>        <span class="hljs-string">&#x27;User-Agent&#x27;</span>: <span class="hljs-string">&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36&quot;</span>,<br>        <span class="hljs-string">&#x27;Content-Type&#x27;</span>: <span class="hljs-string">&#x27;application/json&#x27;</span>,<br>        <span class="hljs-string">&#x27;Accept&#x27;</span>: <span class="hljs-string">&#x27;text/event-stream&#x27;</span>,<br>        <span class="hljs-string">&#x27;Host&#x27;</span>:<span class="hljs-string">&#x27;127.0.0.1:8181&#x27;</span>,<br>        <span class="hljs-string">&#x27;Origin&#x27;</span>:<span class="hljs-string">&#x27;http://127.0.0.1:8181&#x27;</span>,<br>        <span class="hljs-string">&#x27;Referer&#x27;</span>:<span class="hljs-string">&#x27;http://127.0.0.1:8181&#x27;</span>,<br>        <span class="hljs-string">&#x27;Proxy-Connection&#x27;</span>:<span class="hljs-string">&#x27;keep-alive&#x27;</span>,<br>        <span class="hljs-string">&#x27;Cookie&#x27;</span>: <span class="hljs-string">&#x27;&#x27;</span><br>    &#125;<br><br><br>model = <span class="hljs-string">&quot;text-davinci-002-render-sha&quot;</span><br>prompt = <span class="hljs-string">&#x27;hello&#x27;</span><br><br>data = &#123;<br>    <span class="hljs-string">&quot;action&quot;</span>: <span class="hljs-string">&quot;next&quot;</span>,<br>    <span class="hljs-string">&quot;messages&quot;</span>: [&#123;<span class="hljs-string">&quot;id&quot;</span>: str(uuid.uuid4()), <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: &#123;<span class="hljs-string">&quot;content_type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;parts&quot;</span>: [prompt]&#125;&#125;],<br>    <span class="hljs-string">&quot;conversationId&quot;</span>: str(uuid.uuid4()),<br>    <span class="hljs-string">&quot;parentMessageId&quot;</span>: str(uuid.uuid4()),<br>    <span class="hljs-string">&quot;model&quot;</span>: model<br>&#125;<br>res = requests.post(<span class="hljs-attribute">url</span>=auth0_url, <span class="hljs-attribute">headers</span>=headers, <span class="hljs-attribute">json</span>=data)<br><span class="hljs-builtin-name">print</span>(res.text)<br></code></pre></td></tr></table></figure></li></ul>]]></content>
    
    
    <categories>
      
      <category>GPT</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pandora</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>react-i18next实现网站国际化</title>
    <link href="/2023/11/29/react-i18next%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%AB%99%E5%9B%BD%E9%99%85%E5%8C%96/"/>
    <url>/2023/11/29/react-i18next%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%AB%99%E5%9B%BD%E9%99%85%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><p>经过网络上简单调研最终选择了react-i18next来实现中英切换。安装就不说了，实现的脚本都放到assests文件夹里了。</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">assets<br>├── i18n.<span class="hljs-keyword">js</span><br><span class="hljs-keyword"></span>├── locales<br>│   ├── cn.<span class="hljs-keyword">json</span><br><span class="hljs-keyword"></span>│   ├── en.<span class="hljs-keyword">json</span><br><span class="hljs-keyword"></span>│   └── resources.<span class="hljs-keyword">js</span><br><span class="hljs-keyword"></span>└── useCustomTranslation.<span class="hljs-keyword">js</span><br></code></pre></td></tr></table></figure><h4 id="i18n-js"><a href="#i18n-js" class="headerlink" title="i18n.js"></a>i18n.js</h4><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">import</span> &#123; initReactI18next &#125; <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;react-i18next&#x27;</span>;<br><span class="hljs-keyword">import</span> i18n <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;i18next&#x27;</span>;<br><span class="hljs-keyword">import</span> resources <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;./locales/resources.js&#x27;</span>;<br><br><span class="hljs-keyword">let</span> localLang = sessionStorage.getItem(<span class="hljs-string">&#x27;lang&#x27;</span>);<br><span class="hljs-keyword">const</span> browserLang = navigator.language;<br><br><span class="hljs-keyword">if</span> (!localLang) &#123;<br>  localLang = browserLang === <span class="hljs-string">&#x27;zh-CN&#x27;</span> ? <span class="hljs-string">&#x27;zh-CN&#x27;</span> : <span class="hljs-string">&#x27;en-US&#x27;</span>;<br>&#125;<br><br>i18n<br>  .use(initReactI18next) <span class="hljs-comment">// passes i18n down to react-i18next</span><br>  .init(&#123;<br>    resources,<br>    <span class="hljs-attr">lng</span>: localLang, <br>    <span class="hljs-attr">interpolation</span>: &#123;<br>      <span class="hljs-attr">escapeValue</span>: <span class="hljs-literal">false</span>, <span class="hljs-comment">// react already safes from xss</span><br>    &#125;,<br>  &#125;);<br><br><span class="hljs-keyword">export</span> <span class="hljs-keyword">default</span> i18n;<br><br></code></pre></td></tr></table></figure><h4 id="useCustomTranslation-js"><a href="#useCustomTranslation-js" class="headerlink" title="useCustomTranslation.js"></a>useCustomTranslation.js</h4><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">import</span> &#123; useTranslation &#125; <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;react-i18next&#x27;</span>;<br><br><span class="hljs-keyword">export</span> <span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">useCustomTranslation</span>(<span class="hljs-params"></span>) </span>&#123;<br>  <span class="hljs-keyword">const</span> [t, i18n] = useTranslation();<br><br>  <span class="hljs-keyword">const</span> toggleI18n = <span class="hljs-function">() =&gt;</span> &#123;<br>    <span class="hljs-keyword">const</span> locale = i18n.language === <span class="hljs-string">&quot;zh-CN&quot;</span> ? <span class="hljs-string">&quot;en-US&quot;</span> : <span class="hljs-string">&quot;zh-CN&quot;</span>;<br>    i18n.changeLanguage(locale);<br>  &#125;;<br><br>  <span class="hljs-keyword">return</span> &#123; t, toggleI18n &#125;;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="resources-js"><a href="#resources-js" class="headerlink" title="resources.js"></a>resources.js</h4><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">import</span> en <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;./en.json&#x27;</span>;<br><span class="hljs-keyword">import</span> cn <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;./cn.json&#x27;</span>;<br><br><span class="hljs-keyword">const</span> resources = &#123;<br>  <span class="hljs-string">&#x27;en-US&#x27;</span>: &#123;<br>    <span class="hljs-attr">translation</span>: en,<br>  &#125;,<br>  <span class="hljs-string">&#x27;zh-CN&#x27;</span>: &#123;<br>    <span class="hljs-attr">translation</span>: cn,<br>  &#125;<br>&#125;;<br><br><span class="hljs-keyword">export</span> <span class="hljs-keyword">default</span> resources;<br></code></pre></td></tr></table></figure><h4 id="cn-json、en-json"><a href="#cn-json、en-json" class="headerlink" title="cn.json、en.json"></a>cn.json、en.json</h4><p>参考格式</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-comment">// locales/en-US.json</span><br>&#123;<br><span class="hljs-attr">&quot;hello&quot;</span>:<span class="hljs-string">&quot;Hello&quot;</span><br>&#125;<br><span class="hljs-comment">// locales/zh-CN.json</span><br>&#123;<br><span class="hljs-attr">&quot;hello&quot;</span>:<span class="hljs-string">&quot;你好&quot;</span><br>&#125;<br></code></pre></td></tr></table></figure><h2 id="如何使用"><a href="#如何使用" class="headerlink" title="如何使用"></a>如何使用</h2><p>1、在index.js中全局导入i18n.js</p><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs aspectj"><span class="hljs-keyword">import</span> <span class="hljs-string">&#x27;./assets/i18n&#x27;</span>;<br></code></pre></td></tr></table></figure><p>2、在需要转换的页面导入useCustomTranslation.js</p><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs coffeescript"><span class="hljs-keyword">import</span> &#123; useCustomTranslation &#125; <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;./assets/useCustomTranslation&#x27;</span>;<br><br><span class="hljs-comment">## 在组件中定义</span><br>const Welcome = <span class="hljs-function"><span class="hljs-params">()</span> =&gt;</span> &#123;<br>  const &#123; t, toggleI18n &#125; = useCustomTranslation();<br>  <span class="hljs-keyword">return</span> (<br>    &lt;div&gt;<br>     国际化测试数据： &#123;t(<span class="hljs-string">&#x27;hello&#x27;</span>)&#125;<br>    &lt;/div&gt;<br>  );<br>&#125;;<br><span class="hljs-keyword">export</span> <span class="hljs-keyword">default</span> Welcome;<br><br></code></pre></td></tr></table></figure><p>完整代码：<a href="https://github.com/shubihu/letsthink.git">https://github.com/shubihu/letsthink.git</a></p><p>参考：<a href="https://blog.csdn.net/muou_hang/article/details/119647094">https://blog.csdn.net/muou_hang/article/details/119647094</a></p>]]></content>
    
    
    <categories>
      
      <category>React</category>
      
    </categories>
    
    
    <tags>
      
      <tag>国际化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>免费从0到1上线一个网站</title>
    <link href="/2023/11/21/%E5%85%8D%E8%B4%B9%E4%BB%8E0%E5%88%B01%E4%B8%8A%E7%BA%BF%E4%B8%80%E4%B8%AA%E7%BD%91%E7%AB%99/"/>
    <url>/2023/11/21/%E5%85%8D%E8%B4%B9%E4%BB%8E0%E5%88%B01%E4%B8%8A%E7%BA%BF%E4%B8%80%E4%B8%AA%E7%BD%91%E7%AB%99/</url>
    
    <content type="html"><![CDATA[<h2 id="网站开发全流程"><a href="#网站开发全流程" class="headerlink" title="网站开发全流程"></a>网站开发全流程</h2><span id="more"></span><h4 id="上线网站需要的资源："><a href="#上线网站需要的资源：" class="headerlink" title="上线网站需要的资源："></a>上线网站需要的资源：</h4><p>服务器：微软云Azure、AWS等新用户第一年免费<br>域名：硅云新用户第一年免费<br>ssl证书：腾讯云、七牛云等都提供一年免费证书<br>cdn：各大云服务商也有免费额度，另外也可使用cloudflare的免费计划<br>logo：腾讯家的在线免费设计平台AIDesign<br>网站备案：因为用的是Azure，服务器在国外，所以无需备案。</p><h4 id="我的小破站地址：https-letsthink-top"><a href="#我的小破站地址：https-letsthink-top" class="headerlink" title="我的小破站地址：https://letsthink.top/"></a>我的小破站地址：<a href="https://letsthink.top/">https://letsthink.top/</a></h4><p>做网站的初衷：学习一整套流程，练习 react和fastapi 。网站现有3个示例（系统监控，AI聊天，一个生物上可视化的demo），后续依据精力添加更多功能组件。</p><p>网站没啥设计，所以有点丑！</p><h4 id="开源地址：https-github-com-shubihu-letsthink"><a href="#开源地址：https-github-com-shubihu-letsthink" class="headerlink" title="开源地址：https://github.com/shubihu/letsthink"></a>开源地址：<a href="https://github.com/shubihu/letsthink">https://github.com/shubihu/letsthink</a></h4><h4 id="开发过程踩的坑"><a href="#开发过程踩的坑" class="headerlink" title="开发过程踩的坑"></a>开发过程踩的坑</h4><p>nginx配置websocket的坑，经过不懈的测试，http的配置：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs awk">server &#123;<br>        listen <span class="hljs-number">80</span>;<br>        listen [::]:<span class="hljs-number">80</span>;<br>        server_name www.letsthink.top letsthink.top;<br>        root <span class="hljs-regexp">/home/y</span>ahaha<span class="hljs-regexp">/think/</span>frontend;   <span class="hljs-comment">## 网站编译好的文件地址</span><br>​<br>    <span class="hljs-comment">## 网站路由</span><br>    location / &#123;                   <br>        alias <span class="hljs-regexp">/home/y</span>ahaha<span class="hljs-regexp">/think/</span>frontend/;<br>        try_files <span class="hljs-variable">$uri</span> <span class="hljs-variable">$uri</span><span class="hljs-regexp">/ /i</span>ndex.html;<br>    &#125;<br>​<br>    <span class="hljs-comment">## websocket api</span><br>    location <span class="hljs-regexp">/ws/</span>socket.io &#123;<br>      proxy_pass http:<span class="hljs-regexp">//</span><span class="hljs-number">172.190</span>.<span class="hljs-number">79.138</span>:<span class="hljs-number">8000</span>;<br>      proxy_http_version <span class="hljs-number">1.1</span>;<br>      proxy_read_timeout <span class="hljs-number">60</span>s;<br>      proxy_send_timeout <span class="hljs-number">60</span>s;<br>      proxy_set_header Upgrade <span class="hljs-variable">$http_upgrade</span>;<br>      proxy_set_header Connection <span class="hljs-string">&quot;Upgrade&quot;</span>;<br>      proxy_set_header Host <span class="hljs-variable">$host</span>;<br>      proxy_set_header Sec-WebSocket-Version <span class="hljs-number">13</span>;<br>      proxy_set_header Sec-WebSocket-Key <span class="hljs-variable">$http_sec_websocket_key</span>;<br>    &#125;<br> &#125;   <br></code></pre></td></tr></table></figure><p>使用curl命令测试</p><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs excel">curl -i -<span class="hljs-built_in">N</span> -H <span class="hljs-string">&quot;Connection: Upgrade&quot;</span> -H <span class="hljs-string">&quot;Upgrade: websocket&quot;</span> -H <span class="hljs-string">&quot;Host: 172.190.79.138:8000&quot;</span> -H <span class="hljs-string">&quot;Origin: http://letsthink.top&quot;</span> -H <span class="hljs-string">&quot;Sec-WebSocket-Version: 13&quot;</span> -H <span class="hljs-string">&quot;Sec-WebSocket-Key: QpTG8BznnrVH8BUMkRWdfg==&quot;</span> <span class="hljs-string">&quot;http://172.190.79.138:8000/ws/socket.io/?EIO=4&amp;transport=websocket&quot;</span><br></code></pre></td></tr></table></figure><p>最终https配置：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs awk">server &#123;<br>    listen <span class="hljs-number">80</span>;<br>    listen [::]:<span class="hljs-number">80</span>;<br>    server_name www.letsthink.top letsthink.top;<br>​<br>    <span class="hljs-comment"># 自动重定向HTTP到HTTPS</span><br>    return <span class="hljs-number">301</span> https:<span class="hljs-regexp">//</span><span class="hljs-variable">$host</span><span class="hljs-variable">$request_uri</span>;<br>  &#125;<br>​<br>  server &#123;<br>    listen <span class="hljs-number">443</span> ssl http2;<br>    listen [::]:<span class="hljs-number">443</span> ssl http2;<br>    server_name www.letsthink.top letsthink.top;<br>​<br>    ssl_certificate <span class="hljs-regexp">/home/y</span>ahaha<span class="hljs-regexp">/think/</span>ssl/letsthink.top_bundle.crt;  <span class="hljs-comment"># 替换为SSL证书路径</span><br>    ssl_certificate_key <span class="hljs-regexp">/home/y</span>ahaha<span class="hljs-regexp">/think/</span>ssl/letsthink.top.key;  <span class="hljs-comment"># 替换为SSL证书私钥路径</span><br>​<br>    ssl_session_timeout <span class="hljs-number">10</span>m;<br>    <span class="hljs-comment">#请按照以下协议配置</span><br>    ssl_protocols TLSv1.<span class="hljs-number">2</span> TLSv1.<span class="hljs-number">3</span>; <br>    <span class="hljs-comment">#请按照以下套件配置，配置加密套件，写法遵循 openssl 标准。</span><br>    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; <br>    ssl_prefer_server_ciphers on;<br>​<br>    <span class="hljs-comment"># logging</span><br>    access_log <span class="hljs-regexp">/var/</span>log<span class="hljs-regexp">/nginx/</span>access.log combined buffer=<span class="hljs-number">512</span>k flush=<span class="hljs-number">1</span>m;<br>    error_log <span class="hljs-regexp">/var/</span>log<span class="hljs-regexp">/nginx/</span>error.log warn;<br>​<br>    root <span class="hljs-regexp">/home/y</span>ahaha<span class="hljs-regexp">/think/</span>frontend;   <span class="hljs-comment">## 网站编译好的文件地址</span><br>​<br>    <span class="hljs-comment"># 网站路由</span><br>    location / &#123;<br>      alias <span class="hljs-regexp">/home/y</span>ahaha<span class="hljs-regexp">/think/</span>frontend/;<br>      try_files <span class="hljs-variable">$uri</span> <span class="hljs-variable">$uri</span><span class="hljs-regexp">/ /i</span>ndex.html;<br>    &#125;<br>​<br>    <span class="hljs-comment"># websocket api</span><br>    location <span class="hljs-regexp">/ws/</span>socket.io &#123;<br>      proxy_pass http:<span class="hljs-regexp">//</span><span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">8000</span>;<br>      proxy_http_version <span class="hljs-number">1.1</span>;<br>      proxy_connect_timeout <span class="hljs-number">600</span>s;<br>      proxy_read_timeout <span class="hljs-number">600</span>s;<br>      proxy_send_timeout <span class="hljs-number">600</span>s;<br>      proxy_set_header Upgrade <span class="hljs-variable">$http_upgrade</span>;<br>      proxy_set_header Connection <span class="hljs-string">&quot;Upgrade&quot;</span>;<br>      proxy_set_header Host <span class="hljs-variable">$host</span>;<br>      <span class="hljs-comment"># proxy_set_header Sec-WebSocket-Version 13;</span><br>      <span class="hljs-comment"># proxy_set_header Sec-WebSocket-Key $http_sec_websocket_key;</span><br>      proxy_set_header X-Real-IP <span class="hljs-variable">$remote_addr</span>;<br>      proxy_set_header X-Forwarded-For <span class="hljs-variable">$proxy_add_x_forwarded_for</span>;<br>​<br>      proxy_ssl_certificate <span class="hljs-regexp">/home/y</span>ahaha<span class="hljs-regexp">/think/</span>ssl/letsthink.top_bundle.crt;<br>      proxy_ssl_certificate_key <span class="hljs-regexp">/home/y</span>ahaha<span class="hljs-regexp">/think/</span>ssl/letsthink.top.key;<br>      proxy_ssl_session_reuse on;<br>      proxy_ssl_verify on;<br>      proxy_ssl_verify_depth <span class="hljs-number">2</span>;<br>    &#125;<br>  &#125;<br></code></pre></td></tr></table></figure><p>参考：<br><a href="https://mp.weixin.qq.com/s/Rbr3WIRCwGngDvFQyTeSHA">https://mp.weixin.qq.com/s/Rbr3WIRCwGngDvFQyTeSHA</a><br><a href="https://mp.weixin.qq.com/s/aN3-JHd-iPhHjUKQlc_Rzw">https://mp.weixin.qq.com/s/aN3-JHd-iPhHjUKQlc_Rzw</a><br><a href="https://pandagamebox.com/cloudflare-ssl-cdn.html">https://pandagamebox.com/cloudflare-ssl-cdn.html</a></p>]]></content>
    
    
    <categories>
      
      <category>全栈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>React, Fastapi</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>react和fastapi实时通信示例</title>
    <link href="/2023/11/13/React%E5%92%8Cfastapi%E5%AE%9E%E6%97%B6%E9%80%9A%E4%BF%A1%E7%A4%BA%E4%BE%8B/"/>
    <url>/2023/11/13/React%E5%92%8Cfastapi%E5%AE%9E%E6%97%B6%E9%80%9A%E4%BF%A1%E7%A4%BA%E4%BE%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="使用websocket打通-react-和-fastapi"><a href="#使用websocket打通-react-和-fastapi" class="headerlink" title="使用websocket打通 react 和 fastapi"></a>使用websocket打通 react 和 fastapi</h2><span id="more"></span><h4 id="前端代码"><a href="#前端代码" class="headerlink" title="前端代码"></a>前端代码</h4><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">import</span> React, &#123; useEffect, useState &#125; <span class="hljs-keyword">from</span> <span class="hljs-string">&quot;react&quot;</span>;<br><span class="hljs-keyword">import</span> io <span class="hljs-keyword">from</span> <span class="hljs-string">&quot;socket.io-client&quot;</span>;<br><br><br><span class="hljs-keyword">const</span> Monitor() = <span class="hljs-function">() =&gt;</span> &#123;<br>  <span class="hljs-keyword">const</span> [cpuUsage, setCpuUsage] = useState(<span class="hljs-string">&quot;&quot;</span>);<br>  <span class="hljs-keyword">const</span> socketRef = React.useRef(<span class="hljs-literal">null</span>); <span class="hljs-comment">// Socket引用</span><br>  <br><br>  useEffect(<span class="hljs-function">() =&gt;</span> &#123;<br>    socketRef.current = io(<span class="hljs-string">&quot;http://127.0.0.1:1080&quot;</span>); <span class="hljs-comment">// 替换为FastAPI服务器的地址</span><br><br>    socketRef.current.on(<span class="hljs-string">&quot;cpu_usage&quot;</span>, <span class="hljs-function">(<span class="hljs-params">data</span>) =&gt;</span> &#123; <span class="hljs-comment">// 监听 &quot;cpu_usage&quot; 事件</span><br>      setCpuUsage(data);<br>    &#125;);<br><br>    socketRef.current.on(<span class="hljs-string">&quot;connect&quot;</span>, <span class="hljs-function">() =&gt;</span> &#123;          <span class="hljs-comment">// 启动监控</span><br>      socketRef.current.emit(<span class="hljs-string">&quot;start_cpu_monitor&quot;</span>);<br>    &#125;);<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-function">() =&gt;</span> &#123;<br>      socketRef.current.emit(<span class="hljs-string">&quot;stop_cpu_monitor&quot;</span>);<br>      socketRef.current.disconnect(); <span class="hljs-comment">// 在组件卸载时关闭Socket连接</span><br>    &#125;;<br>  &#125;, []);<br><br>  <span class="hljs-keyword">return</span> (<br>    <span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">className</span>=<span class="hljs-string">&quot;child1-content&quot;</span>&gt;</span></span><br><span class="xml">      <span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span>CPU Usage: &#123;cpuUsage&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span></span><br><span class="xml">    <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span></span><br>  );<br>&#125;;<br><br><span class="hljs-keyword">export</span> <span class="hljs-keyword">default</span> Monitor;<br><br><br></code></pre></td></tr></table></figure><h4 id="后端代码-test-py"><a href="#后端代码-test-py" class="headerlink" title="后端代码 test.py"></a>后端代码 test.py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">import</span> socketio<br><span class="hljs-keyword">from</span> fastapi <span class="hljs-keyword">import</span> FastAPI<br><span class="hljs-keyword">from</span> fastapi.staticfiles <span class="hljs-keyword">import</span> StaticFiles<br><span class="hljs-keyword">import</span> psutil<br><br>app = FastAPI()<br><br>sio = socketio.AsyncServer(async_mode=<span class="hljs-string">&#x27;asgi&#x27;</span>, cors_allowed_origins=<span class="hljs-string">&#x27;*&#x27;</span>)<br>socket_app = socketio.ASGIApp(sio, static_files=&#123;<br>    <span class="hljs-string">&#x27;/&#x27;</span>: <span class="hljs-string">&#x27;./react-socketio/build&#x27;</span><br>&#125;)<br><br>app.mount(<span class="hljs-string">&quot;/&quot;</span>, socket_app)<br><br><br><span class="hljs-meta">@sio.event</span><br><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">connect</span>(<span class="hljs-params">sid, environ</span>):</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;connected&#x27;</span>, sid)<br>    cpu_percent = psutil.cpu_percent(interval=<span class="hljs-number">1</span>)  <span class="hljs-comment"># 获取初始CPU使用率</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Initial CPU Usage:&#x27;</span>, cpu_percent)  <span class="hljs-comment"># 打印初始CPU使用率</span><br>    <span class="hljs-keyword">await</span> sio.emit(<span class="hljs-string">&#x27;cpu_usage&#x27;</span>, cpu_percent)  <span class="hljs-comment"># 推送初始CPU使用率给前端</span><br><br><br><span class="hljs-meta">@sio.event</span><br><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">disconnect</span>(<span class="hljs-params">sid</span>):</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;disconnected&#x27;</span>, sid)<br><br><br><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">cpu_monitor</span>():</span><br>    <span class="hljs-keyword">while</span> running:<br>        cpu_percent = psutil.cpu_percent(interval=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">await</span> sio.emit(<span class="hljs-string">&#x27;cpu_usage&#x27;</span>, cpu_percent)<br>        <span class="hljs-keyword">await</span> sio.sleep(<span class="hljs-number">1</span>)<br><br><br><span class="hljs-meta">@sio.on(<span class="hljs-params"><span class="hljs-string">&#x27;start_cpu_monitor&#x27;</span></span>)</span><br><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start_cpu_monitor</span>(<span class="hljs-params">sid</span>):</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Starting CPU monitor...&#x27;</span>)<br>    <span class="hljs-keyword">global</span> running<br>    running = <span class="hljs-literal">True</span><br>    sio.start_background_task(cpu_monitor)  <span class="hljs-comment"># 后台任务用于持续获取CPU使用率</span><br><br><br><span class="hljs-meta">@sio.on(<span class="hljs-params"><span class="hljs-string">&#x27;stop_cpu_monitor&#x27;</span></span>)</span><br><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">stop_cpu_monitor</span>(<span class="hljs-params">sid</span>):</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Stopping CPU monitor...&#x27;</span>)<br>    <span class="hljs-keyword">global</span> running<br>    running = <span class="hljs-literal">False</span><br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    uvicorn.run(app, host=<span class="hljs-string">&quot;0.0.0.0&quot;</span>, port=<span class="hljs-number">8000</span>)<br><br></code></pre></td></tr></table></figure><p>后端启动命令</p><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs brainfuck"><span class="hljs-comment">uvicorn</span> <span class="hljs-comment">test:app</span> --<span class="hljs-comment">reload</span> --<span class="hljs-comment">host</span> <span class="hljs-comment">127</span><span class="hljs-string">.</span><span class="hljs-comment">0</span><span class="hljs-string">.</span><span class="hljs-comment">0</span><span class="hljs-string">.</span><span class="hljs-comment">1</span> --<span class="hljs-comment">port</span> <span class="hljs-comment">1080</span><br></code></pre></td></tr></table></figure><p>PS:上述后端代码中 socket_app 是挂载在根目录的，这样如果fastapi有其他路由，前端请求会404。所以要解决这个问题，socket_app 就不能挂载在根目录</p><p>修改后的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">import</span> socketio<br><span class="hljs-keyword">from</span> fastapi <span class="hljs-keyword">import</span> FastAPI, BackgroundTasks, Request<br><span class="hljs-keyword">from</span> fastapi.staticfiles <span class="hljs-keyword">import</span> StaticFiles<br><span class="hljs-keyword">import</span> psutil<br><br><br>app = FastAPI()<br>sio = socketio.AsyncServer(async_mode=<span class="hljs-string">&#x27;asgi&#x27;</span>, cors_allowed_origins=<span class="hljs-string">&#x27;*&#x27;</span>)<br>socket_app = socketio.ASGIApp(sio)<br><br>app.mount(<span class="hljs-string">&quot;/ws&quot;</span>, socket_app)<br><br><span class="hljs-meta">@sio.event</span><br><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">connect</span>(<span class="hljs-params">sid, environ</span>):</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;connected&#x27;</span>, sid)<br>    cpu_percent = psutil.cpu_percent(interval=<span class="hljs-number">1</span>)  <span class="hljs-comment"># 获取初始CPU使用率</span><br>    virtual_memory = psutil.virtual_memory()<br>    memory_percent = virtual_memory.percent<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Initial CPU Usage:&#x27;</span>, cpu_percent)  <span class="hljs-comment"># 打印初始CPU使用率</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Initial Memory Usage:&#x27;</span>, memory_percent)<br>    data = &#123;<br>        <span class="hljs-string">&#x27;cpu_percent&#x27;</span>: cpu_percent,<br>        <span class="hljs-string">&#x27;memory_percent&#x27;</span>: memory_percent<br>    &#125;<br>    <span class="hljs-keyword">await</span> sio.emit(<span class="hljs-string">&#x27;usage&#x27;</span>, data)  <span class="hljs-comment"># 推送初始CPU使用率给前端</span><br><br><br><span class="hljs-meta">@sio.event</span><br><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">disconnect</span>(<span class="hljs-params">sid</span>):</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;disconnected&#x27;</span>, sid)<br><br><br><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">monitor</span>():</span><br>    <span class="hljs-keyword">global</span> running<br>    <span class="hljs-keyword">while</span> running:<br>        cpu_percent = psutil.cpu_percent(interval=<span class="hljs-number">1</span>)<br>        virtual_memory = psutil.virtual_memory()<br>        memory_percent = virtual_memory.percent<br>        data = &#123;<br>        <span class="hljs-string">&#x27;cpu_percent&#x27;</span>: cpu_percent,<br>        <span class="hljs-string">&#x27;memory_percent&#x27;</span>: memory_percent<br>        &#125;<br>        <span class="hljs-keyword">await</span> sio.emit(<span class="hljs-string">&#x27;usage&#x27;</span>, data)<br>        <span class="hljs-keyword">await</span> sio.sleep(<span class="hljs-number">1</span>)<br><br><br><span class="hljs-meta">@sio.on(<span class="hljs-params"><span class="hljs-string">&#x27;start_monitor&#x27;</span></span>)</span><br><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start_monitor</span>(<span class="hljs-params">sid</span>):</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Starting System monitor...&#x27;</span>)<br>    <span class="hljs-keyword">global</span> running<br>    running = <span class="hljs-literal">True</span><br>    sio.start_background_task(monitor)  <span class="hljs-comment"># 后台任务用于持续获取CPU使用率</span><br><br><br><span class="hljs-meta">@sio.on(<span class="hljs-params"><span class="hljs-string">&#x27;stop_monitor&#x27;</span></span>)</span><br><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">stop_monitor</span>(<span class="hljs-params">sid</span>):</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Stopping System monitor...&#x27;</span>)<br>    <span class="hljs-keyword">global</span> running<br>    running = <span class="hljs-literal">False</span><br><br><br><span class="hljs-meta">@app.get(<span class="hljs-params"><span class="hljs-string">&quot;/aichat&quot;</span></span>)</span><br><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">aiChat</span>(<span class="hljs-params">request: Request</span>):</span><br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;message&quot;</span>: <span class="hljs-string">&quot;Hello, AI Chat!&quot;</span>&#125;<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    uvicorn.run(app, host=<span class="hljs-string">&quot;0.0.0.0&quot;</span>, port=<span class="hljs-number">8000</span>)<br><br></code></pre></td></tr></table></figure><p>前端连接代码：注意这里的路径是 <code>/ws/socket.io</code></p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">socketRef.current</span> = io(<span class="hljs-string">&quot;http://183.232.150.130:1080&quot;</span>, &#123;path:<span class="hljs-string">&#x27;/ws/socket.io&#x27;</span>, autoConnect: <span class="hljs-literal">true</span>&#125;)<span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure><p>参考：<a href="https://github.com/tiangolo/fastapi/issues/3666">https://github.com/tiangolo/fastapi/issues/3666</a></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-keyword">if</span> app.mount(<span class="hljs-string">&#x27;/ws&#x27;</span>) <span class="hljs-keyword">in</span><span class="hljs-built_in"> server</span><br><span class="hljs-built_in"></span>the<span class="hljs-built_in"> client </span>need sio.connect(url, <span class="hljs-attribute">socketio_path</span>=<span class="hljs-string">&#x27;/ws/docket.io&#x27;</span>)<br><br>So strange<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>全栈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>React, Fastapi, Websocket</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>3dmol.js在React中使用demo</title>
    <link href="/2023/11/03/3dmol-js%E5%9C%A8React%E4%B8%AD%E4%BD%BF%E7%94%A8demo/"/>
    <url>/2023/11/03/3dmol-js%E5%9C%A8React%E4%B8%AD%E4%BD%BF%E7%94%A8demo/</url>
    
    <content type="html"><![CDATA[<h2 id="3dmol-React-Demo"><a href="#3dmol-React-Demo" class="headerlink" title="3dmol React Demo"></a>3dmol React Demo</h2><span id="more"></span><h4 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h4><figure class="highlight dsconfig"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dsconfig"><span class="hljs-string">npx</span> <span class="hljs-built_in">create-react-app</span> <br></code></pre></td></tr></table></figure><h4 id="导入3dmol-js"><a href="#导入3dmol-js" class="headerlink" title="导入3dmol.js"></a>导入3dmol.js</h4><p>因为3dmol.js只是一个普通的js库，所以这里在index.html中引入，代码如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-meta">&lt;!DOCTYPE <span class="hljs-meta-keyword">html</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">html</span> <span class="hljs-attr">lang</span>=<span class="hljs-string">&quot;en&quot;</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">head</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">meta</span> <span class="hljs-attr">charset</span>=<span class="hljs-string">&quot;utf-8&quot;</span> /&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">link</span> <span class="hljs-attr">rel</span>=<span class="hljs-string">&quot;icon&quot;</span> <span class="hljs-attr">href</span>=<span class="hljs-string">&quot;%PUBLIC_URL%/favicon.ico&quot;</span> /&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">meta</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;viewport&quot;</span> <span class="hljs-attr">content</span>=<span class="hljs-string">&quot;width=device-width, initial-scale=1&quot;</span> /&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">meta</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;theme-color&quot;</span> <span class="hljs-attr">content</span>=<span class="hljs-string">&quot;#000000&quot;</span> /&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">meta</span></span><br><span class="hljs-tag">      <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;description&quot;</span></span><br><span class="hljs-tag">      <span class="hljs-attr">content</span>=<span class="hljs-string">&quot;Web site created using create-react-app&quot;</span></span><br><span class="hljs-tag">    /&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">link</span> <span class="hljs-attr">rel</span>=<span class="hljs-string">&quot;apple-touch-icon&quot;</span> <span class="hljs-attr">href</span>=<span class="hljs-string">&quot;%PUBLIC_URL%/logo192.png&quot;</span> /&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">link</span> <span class="hljs-attr">rel</span>=<span class="hljs-string">&quot;manifest&quot;</span> <span class="hljs-attr">href</span>=<span class="hljs-string">&quot;%PUBLIC_URL%/manifest.json&quot;</span> /&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;https://cdn.bootcdn.net/ajax/libs/3Dmol/2.0.1/3Dmol-min.min.js&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">title</span>&gt;</span>React App<span class="hljs-tag">&lt;/<span class="hljs-name">title</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">head</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">body</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">noscript</span>&gt;</span>You need to enable JavaScript to run this app.<span class="hljs-tag">&lt;/<span class="hljs-name">noscript</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;root&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">html</span>&gt;</span><br><br></code></pre></td></tr></table></figure><h4 id="编写APP-js-和-APP-css"><a href="#编写APP-js-和-APP-css" class="headerlink" title="编写APP.js 和 APP.css"></a>编写APP.js 和 APP.css</h4><p>APP.js</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">import</span> React, &#123; useRef, useEffect &#125;<span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;react&#x27;</span>;<br><span class="hljs-keyword">import</span> <span class="hljs-string">&#x27;./App.css&#x27;</span>;<br><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">App</span>(<span class="hljs-params"></span>) </span>&#123;<br>  <span class="hljs-keyword">const</span> containerRef = useRef(<span class="hljs-literal">null</span>);<br>  <span class="hljs-keyword">const</span> $3Dmol = <span class="hljs-built_in">window</span>.$3Dmol;<br><br>  useEffect(<span class="hljs-function">() =&gt;</span> &#123;<br>    <span class="hljs-keyword">const</span> element = containerRef.current;<br>    <span class="hljs-keyword">if</span> (element) &#123;<br>      <span class="hljs-keyword">let</span> viewer = $3Dmol.createViewer(element);<br><br>      $3Dmol.download(<span class="hljs-string">&quot;pdb:1MO8&quot;</span>, viewer, &#123; <span class="hljs-attr">multimodel</span>: <span class="hljs-literal">true</span>, <span class="hljs-attr">frames</span>: <span class="hljs-literal">true</span> &#125;, <span class="hljs-function"><span class="hljs-keyword">function</span> (<span class="hljs-params"></span>) </span>&#123;<br>        viewer.setStyle(&#123;&#125;, &#123; <span class="hljs-attr">cartoon</span>: &#123; <span class="hljs-attr">color</span>: <span class="hljs-string">&#x27;spectrum&#x27;</span> &#125; &#125;);<br>        viewer.render();<br>      &#125;);<br>    &#125;<br>  &#125;, []);<br><br>  <span class="hljs-keyword">return</span> (<br>    <span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">className</span>=<span class="hljs-string">&quot;App&quot;</span>&gt;</span></span><br><span class="xml">      <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">className</span>=<span class="hljs-string">&quot;display-box&quot;</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;protein-box&quot;</span> <span class="hljs-attr">ref</span>=<span class="hljs-string">&#123;containerRef&#125;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span></span><br><span class="xml">    <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span></span><br>  );<br>&#125;<br><br><span class="hljs-keyword">export</span> <span class="hljs-keyword">default</span> App;<br><br></code></pre></td></tr></table></figure><p>APP.css , 主要是 display-box 的样式设置</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-class">.App</span> &#123;<br>  <span class="hljs-attribute">text-align</span>: center;<br>&#125;<br><br><span class="hljs-selector-class">.App-logo</span> &#123;<br>  <span class="hljs-attribute">height</span>: <span class="hljs-number">40vmin</span>;<br>  <span class="hljs-attribute">pointer-events</span>: none;<br>&#125;<br><span class="hljs-selector-class">.display-box</span>&#123;<br>  <span class="hljs-attribute">height</span>: <span class="hljs-number">600px</span>;<br>  <span class="hljs-attribute">width</span>: <span class="hljs-number">800px</span>;<br>  <span class="hljs-attribute">position</span>: relative;<br>&#125;<br><br><span class="hljs-keyword">@media</span> (<span class="hljs-attribute">prefers-reduced-motion</span>: no-preference) &#123;<br>  <span class="hljs-selector-class">.App-logo</span> &#123;<br>    <span class="hljs-attribute">animation</span>: App-logo-spin infinite <span class="hljs-number">20s</span> linear;<br>  &#125;<br>&#125;<br><br><span class="hljs-selector-class">.App-header</span> &#123;<br>  <span class="hljs-attribute">background-color</span>: <span class="hljs-number">#282c34</span>;<br>  <span class="hljs-attribute">min-height</span>: <span class="hljs-number">100vh</span>;<br>  <span class="hljs-attribute">display</span>: flex;<br>  <span class="hljs-attribute">flex-direction</span>: column;<br>  <span class="hljs-attribute">align-items</span>: center;<br>  <span class="hljs-attribute">justify-content</span>: center;<br>  <span class="hljs-attribute">font-size</span>: <span class="hljs-built_in">calc</span>(<span class="hljs-number">10px</span> + <span class="hljs-number">2vmin</span>);<br>  <span class="hljs-attribute">color</span>: white;<br>&#125;<br><br><span class="hljs-selector-class">.App-link</span> &#123;<br>  <span class="hljs-attribute">color</span>: <span class="hljs-number">#61dafb</span>;<br>&#125;<br><br><span class="hljs-keyword">@keyframes</span> App-logo-spin &#123;<br>  <span class="hljs-selector-tag">from</span> &#123;<br>    <span class="hljs-attribute">transform</span>: <span class="hljs-built_in">rotate</span>(<span class="hljs-number">0deg</span>);<br>  &#125;<br>  <span class="hljs-selector-tag">to</span> &#123;<br>    <span class="hljs-attribute">transform</span>: <span class="hljs-built_in">rotate</span>(<span class="hljs-number">360deg</span>);<br>  &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h4 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h4><p>执行命令</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">npm <span class="hljs-builtin-name">run</span> start<br></code></pre></td></tr></table></figure><p>就可以在浏览器看到蛋白了。</p><p>完整代码仓库：<br><a href="https://github.com/shubihu/3dmol-react-example">https://github.com/shubihu/3dmol-react-example</a></p><p>参考：<a href="https://juejin.cn/post/7118732948328677389">https://juejin.cn/post/7118732948328677389</a></p>]]></content>
    
    
    <categories>
      
      <category>大前端</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3dmol, React</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python conda环境的小坑</title>
    <link href="/2023/10/16/Python-conda%E7%8E%AF%E5%A2%83%E7%9A%84%E5%B0%8F%E5%9D%91%EF%BC%8C%E4%BB%A4%E4%BA%BA%E4%B8%8D%E8%A7%A3%E7%9A%84%E5%8C%85%E5%AF%BC%E5%85%A5%E9%A1%BA%E5%BA%8F/"/>
    <url>/2023/10/16/Python-conda%E7%8E%AF%E5%A2%83%E7%9A%84%E5%B0%8F%E5%9D%91%EF%BC%8C%E4%BB%A4%E4%BA%BA%E4%B8%8D%E8%A7%A3%E7%9A%84%E5%8C%85%E5%AF%BC%E5%85%A5%E9%A1%BA%E5%BA%8F/</url>
    
    <content type="html"><![CDATA[<h2 id="令人不解的包导入顺序"><a href="#令人不解的包导入顺序" class="headerlink" title="令人不解的包导入顺序"></a>令人不解的包导入顺序</h2><span id="more"></span><p>这个坑就是conda环境的包导入顺序。具体就是：</p><p>在 Conda 环境中，包的版本决定了其加载的优先级。通常情况下，较高版本的包会优先加载，而不考虑其所在的位置（例如当前环境或家目录的 .local 目录）。<br>如果当前环境中的包版本较低，而家目录的 .local 目录中存在较高版本的包，那么 Python 解释器会优先加载 .local 目录中的较高版本包。这是因为 Python 解释器会根据版本号来决定使用哪个包，而不是根据包所在的位置。<br>这是妥妥的要抛弃低版本的东西啊。</p><p>我使用conda单独创建环境不就是想做隔离确保安全。好家伙直接一个版本号大小就打破了这生殖隔离！果然在隔离上还是容器靠谱点。</p><p>解决方法也有：</p><p>移除较高版本的包：如果 .local 目录中的包版本较高，并且你希望使用当前环境中的较低版本包，可以尝试在 .local 目录中删除较高版本的包文件。<br>简单粗暴，直接把高版本的删了！</p><p>但是我就是想保留我 .local 目录下较高版本的包呢。那就只能更改代码删除python的搜素路径。</p><figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs xquery"><span class="hljs-keyword">import</span> sys<br>paths_to_remove = <span class="hljs-built_in">[path</span> <span class="hljs-keyword">for</span><span class="hljs-built_in"> path</span> <span class="hljs-keyword">in</span> sys<span class="hljs-built_in">.path</span> <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;.local&#x27;</span> <span class="hljs-keyword">in</span><span class="hljs-built_in"> path</span>]<br><span class="hljs-keyword">for</span><span class="hljs-built_in"> path</span> <span class="hljs-keyword">in</span> paths_to_remove:<br>    sys<span class="hljs-built_in">.path</span><span class="hljs-built_in">.remove</span><span class="hljs-built_in">(path</span>)<br></code></pre></td></tr></table></figure><p>使用pip查看包的安装路径</p><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dart">pip <span class="hljs-keyword">show</span> xxx<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Conda</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Mac自动化——自动登陆公共Wi-Fi</title>
    <link href="/2023/09/15/Mac%E8%87%AA%E5%8A%A8%E5%8C%96%E2%80%94%E2%80%94%E8%87%AA%E5%8A%A8%E7%99%BB%E9%99%86%E5%85%AC%E5%85%B1Wi-Fi/"/>
    <url>/2023/09/15/Mac%E8%87%AA%E5%8A%A8%E5%8C%96%E2%80%94%E2%80%94%E8%87%AA%E5%8A%A8%E7%99%BB%E9%99%86%E5%85%AC%E5%85%B1Wi-Fi/</url>
    
    <content type="html"><![CDATA[<h2 id="适用场景：经常需要登陆同一个公共Wi-Fi且用户名和密码不变的"><a href="#适用场景：经常需要登陆同一个公共Wi-Fi且用户名和密码不变的" class="headerlink" title="适用场景：经常需要登陆同一个公共Wi-Fi且用户名和密码不变的"></a>适用场景：经常需要登陆同一个公共Wi-Fi且用户名和密码不变的</h2><span id="more"></span><p>一般情况登陆公共Wi-Fi后会弹出一个登陆界面供用户登陆，输入用户名和密码即可上网。</p><p>这里介绍两个自动化方法。还有一个是使用hammerspoon+lua+applescript（参考：<a href="https://www.jianshu.com/p/59e1334b0a5e%EF%BC%89%E3%80%82%E6%9C%80%E5%90%8E%E8%BF%99%E4%B8%AA%E4%B8%80%E7%9C%8B%E5%B0%B1%E5%BE%88%E9%BA%BB%E7%83%A6%E3%80%82">https://www.jianshu.com/p/59e1334b0a5e）。最后这个一看就很麻烦。</a></p><p>虽说是介绍两个其实根本上也算一个吧。主要都是使用脚本进行登陆。只是执行的方法不太一样。</p><p>这里有个前提，就是需要关闭Captive Network Assistant。原因如下：<br>当Captive Network Assistant弹出的时候，网络会被拦截，这个英语翻译成中文的意思强制网络助理。只要有这个弹窗在，网络都会被终止（没有实际性的原理，亲测是网络被拦截）<br>关闭方法：</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gradle">sudo defaults <span class="hljs-keyword">write</span> <span class="hljs-regexp">/Library/</span>Preferences<span class="hljs-regexp">/SystemConfiguration/</span>com.apple.captive.control Active -<span class="hljs-keyword">boolean</span> <span class="hljs-keyword">false</span><br></code></pre></td></tr></table></figure><p>关闭之后就没有什么阻止我们登陆了。</p><p>登陆脚本：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs powershell">wifiName=<span class="hljs-variable">$</span>(networksetup <span class="hljs-literal">-getairportnetwork</span> en0 | cut <span class="hljs-literal">-f2</span> <span class="hljs-literal">-d</span><span class="hljs-string">&#x27;:&#x27;</span>)<br><span class="hljs-comment"># echo $wifiName</span><br><span class="hljs-keyword">if</span> [ <span class="hljs-variable">$wifiName</span> = <span class="hljs-string">&quot;xxxx&quot;</span> ]; then<br>  <span class="hljs-comment"># 使用curl发送登陆请求</span><br>   <span class="hljs-built_in">curl</span> xxxx <br>fi<br></code></pre></td></tr></table></figure><p>保存后并添加执行权限。</p><h5 id="方法1-比较简单，就是更改上述脚本的默认打开方式为终端（必须是mac自带的终端）"><a href="#方法1-比较简单，就是更改上述脚本的默认打开方式为终端（必须是mac自带的终端）" class="headerlink" title="方法1: 比较简单，就是更改上述脚本的默认打开方式为终端（必须是mac自带的终端）"></a>方法1: 比较简单，就是更改上述脚本的默认打开方式为终端（必须是mac自带的终端）</h5><p>然后在系统设置-通用-登陆项里把该脚本添加到登陆时自动打卡。</p><p>这样设置之后登陆后便会自动打开终端执行登陆脚本了。不过有一点不完美的就是会多出个终端的窗口。</p><p>如何让脚本在后台默默把活干了。</p><h5 id="方法2：使用launchctl"><a href="#方法2：使用launchctl" class="headerlink" title="方法2：使用launchctl"></a>方法2：使用launchctl</h5><p>具体概念的东西可参考：<a href="https://www.jianshu.com/p/0886e1510bbb">https://www.jianshu.com/p/0886e1510bbb</a></p><ul><li>首先创建一个后缀为.plist的属性列表文件，例如com.example.myScript.plist，并添加如下内容：<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="hljs-meta">&lt;!DOCTYPE <span class="hljs-meta-keyword">plist</span> <span class="hljs-meta-keyword">PUBLIC</span> <span class="hljs-meta-string">&quot;-//Apple//DTD PLIST 1.0//EN&quot;</span> <span class="hljs-meta-string">&quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">plist</span> <span class="hljs-attr">version</span>=<span class="hljs-string">&quot;1.0&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">dict</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">key</span>&gt;</span>Label<span class="hljs-tag">&lt;/<span class="hljs-name">key</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">string</span>&gt;</span>com.example.myScript<span class="hljs-tag">&lt;/<span class="hljs-name">string</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">key</span>&gt;</span>ProgramArguments<span class="hljs-tag">&lt;/<span class="hljs-name">key</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">array</span>&gt;</span><br>          # 这里换成自己的脚本<br>        <span class="hljs-tag">&lt;<span class="hljs-name">string</span>&gt;</span>/path/to/your/script.sh<span class="hljs-tag">&lt;/<span class="hljs-name">string</span>&gt;</span> <br>    <span class="hljs-tag">&lt;/<span class="hljs-name">array</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">key</span>&gt;</span>RunAtLoad<span class="hljs-tag">&lt;/<span class="hljs-name">key</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">true</span>/&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dict</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">plist</span>&gt;</span><br></code></pre></td></tr></table></figure></li><li>将这个plist文件保存到~/Library/LaunchAgents目录下（用户级别）或/Library/LaunchAgents目录下（系统级别），然后执行命令：<figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arcade">launchctl load ~<span class="hljs-regexp">/Library/</span>LaunchAgents/com.example.myScript.plist<br></code></pre></td></tr></table></figure>下次登陆即可在后台自动登陆Wi-Fi了。</li></ul><p>另外：sleepwatcher貌似只能设置睡眠和唤醒后执行的任务，无法做开机登陆的任务。</p><p>参考：<br><a href="https://discussionschinese.apple.com/thread/44410">https://discussionschinese.apple.com/thread/44410</a><br><a href="https://www.jianshu.com/p/0886e1510bbb">https://www.jianshu.com/p/0886e1510bbb</a><br><a href="https://www.jianshu.com/p/59e1334b0a5e">https://www.jianshu.com/p/59e1334b0a5e</a><br><a href="https://fuzhii.com/2017/10/09/Mac-sleepwatcher/">https://fuzhii.com/2017/10/09/Mac-sleepwatcher/</a><br><a href="https://zhuanlan.zhihu.com/p/388287366">https://zhuanlan.zhihu.com/p/388287366</a></p>]]></content>
    
    
    <categories>
      
      <category>Mac</category>
      
    </categories>
    
    
    <tags>
      
      <tag>自动化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>v2ray一键搭建梯子</title>
    <link href="/2023/09/01/v2ray%E4%B8%80%E9%94%AE%E6%90%AD%E5%BB%BA%E6%A2%AF%E5%AD%90/"/>
    <url>/2023/09/01/v2ray%E4%B8%80%E9%94%AE%E6%90%AD%E5%BB%BA%E6%A2%AF%E5%AD%90/</url>
    
    <content type="html"><![CDATA[<h2 id="v2ray-Qv2ray"><a href="#v2ray-Qv2ray" class="headerlink" title="v2ray, Qv2ray"></a>v2ray, Qv2ray</h2><span id="more"></span><p>之前使用酸酸乳，但是每次切换代理的时候读会弹出通知，关也关不掉，就很烦！于是放弃酸酸乳，拥抱v2ray!</p><h4 id="服务端：v2ray安装"><a href="#服务端：v2ray安装" class="headerlink" title="服务端：v2ray安装"></a>服务端：v2ray安装</h4><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">sudo bash &lt;(wget -qO- -o- https:<span class="hljs-regexp">//gi</span>t.io/v2ray.sh)<br></code></pre></td></tr></table></figure><p>一键安装一键配置，都不用自己选择了。安装完后会生成配置信息。同时也会生成一个vmess链接。</p><h4 id="客户端：Qv2ray-安装"><a href="#客户端：Qv2ray-安装" class="headerlink" title="客户端：Qv2ray 安装"></a>客户端：Qv2ray 安装</h4><p>官网提供的客户端真是多彩多样。地址：<a href="https://www.v2ray.com/awesome/tools.html">https://www.v2ray.com/awesome/tools.html</a><br>我参考的这篇文章下的 Qv2ray， 地址：<a href="https://v2xtls.org/v2ray-mac%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8B%E8%BD%BD/">https://v2xtls.org/v2ray-mac%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8B%E8%BD%BD/</a><br>Qv2ray mac 地址： <a href="https://github.com/Qv2ray/Qv2ray/releases">https://github.com/Qv2ray/Qv2ray/releases</a><br>看这个项目在github上不在维护了，后期也可以试试官网提供的其他软件。<br>另外需要下载 v2ray 的核心模块，地址：<a href="https://github.com/v2ray/v2ray-core/releases">https://github.com/v2ray/v2ray-core/releases</a></p><p>下载完 v2ray core之后要把对应的路径配置到Qv2ray里。<br>配置方法为：Preferences ——&gt; Kernel Settings里分别配置 v2ray 的执行文件（下载后解压目录下的v2ray可执行文件） 和 v2ray assets的目录（下载后解压的目录）</p><p>最后把服务器端生成的 vmess链接 导入即可。</p><h4 id="开启bbr加速（虽然不知道有没有用）"><a href="#开启bbr加速（虽然不知道有没有用）" class="headerlink" title="开启bbr加速（虽然不知道有没有用）"></a>开启bbr加速（虽然不知道有没有用）</h4><p>参考：<a href="https://www.linuxv2ray.com/speedup/google-tcp-bbr-one-click-script-for-v2ray/">https://www.linuxv2ray.com/speedup/google-tcp-bbr-one-click-script-for-v2ray/</a></p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs awk">echo <span class="hljs-string">&#x27;net.core.default_qdisc=fq&#x27;</span> | sudo tee -a <span class="hljs-regexp">/etc/</span>sysctl.conf<br>echo <span class="hljs-string">&#x27;net.ipv4.tcp_congestion_control=bbr&#x27;</span> | sudo tee -a <span class="hljs-regexp">/etc/</span>sysctl.conf<br>sysctl -p<br>sysctl net.ipv4.tcp_available_congestion_control<br><br>lsmod | grep bbr   <span class="hljs-comment"># 检测 BBR 是否开启, 返回值有 tcp_bbr 模块说明 BBR 已经启动</span><br></code></pre></td></tr></table></figure><h4 id="v2ray-常用命令"><a href="#v2ray-常用命令" class="headerlink" title="v2ray 常用命令"></a>v2ray 常用命令</h4><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">v2ray</span> <span class="hljs-literal">info</span>     <span class="hljs-comment"># 查看 V2Ray 配置信息</span><br>v2ray qr       <span class="hljs-comment"># 生成 V2Ray 配置二维码链接</span><br>v2ray url      <span class="hljs-comment"># 生成 vmess URL 链接</span><br>v2ray help<br></code></pre></td></tr></table></figure><p>参考：<br><a href="https://v2xtls.org/qv2ray%e4%b8%8b%e8%bd%bd%e5%8f%8a%e4%bd%bf%e7%94%a8%e6%95%99%e7%a8%8b-v2ray-windows%e5%ae%a2%e6%88%b7%e7%ab%af-%e5%90%8c%e6%97%b6%e6%94%af%e6%8c%81ss-ssr-v2ray-trojan/">https://v2xtls.org/qv2ray%e4%b8%8b%e8%bd%bd%e5%8f%8a%e4%bd%bf%e7%94%a8%e6%95%99%e7%a8%8b-v2ray-windows%e5%ae%a2%e6%88%b7%e7%ab%af-%e5%90%8c%e6%97%b6%e6%94%af%e6%8c%81ss-ssr-v2ray-trojan/</a></p>]]></content>
    
    
    <categories>
      
      <category>TroubleShoot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>v2ray</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用gdb调试程序coredump</title>
    <link href="/2023/09/01/%E4%BD%BF%E7%94%A8gdb%E8%B0%83%E8%AF%95%E7%A8%8B%E5%BA%8Fcoredump/"/>
    <url>/2023/09/01/%E4%BD%BF%E7%94%A8gdb%E8%B0%83%E8%AF%95%E7%A8%8B%E5%BA%8Fcoredump/</url>
    
    <content type="html"><![CDATA[<h2 id="gdb调试"><a href="#gdb调试" class="headerlink" title="gdb调试"></a>gdb调试</h2><span id="more"></span><p>使用autogrid4处理数据的时候报错，coredump！根据GPT的指示解决了问题。简单记录一下。<br>要使用 gdb 调试 Autogrid4，可以按照以下步骤进行操作：</p><ul><li><p>安装 gdb：确保在您的系统上安装了 gdb。您可以通过在终端中运行适用于您的操作系统的相应安装命令来安装它。例如，在 Ubuntu 上，您可以运行 sudo apt-get install gdb 来安装 gdb。</p></li><li><p>获取可调试的 Autogrid4 可执行文件：如果您使用的是提供的二进制文件，请确保从 Autodock-GPU 获取了带有调试信息的版本。如果您可以编译 Autogrid4，可以使用适当的调试标志（如 -g）来生成带有调试信息的可执行文件。</p></li><li><p>启动 gdb：在终端中运行以下命令来启动 gdb 并加载 Autogrid4 可执行文件：</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs angelscript">gdb <span class="hljs-built_in">auto</span>grid4<br></code></pre></td></tr></table></figure></li><li><p>设置断点：您可以在代码中选择设置断点，以在特定的位置中断执行。例如，您可以使用 break 命令在某个函数或代码行上设置断点。例如，要在代码的第 98 行设置断点，可以运行：(这一步可以跳过)</p><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs kotlin"><span class="hljs-keyword">break</span> <span class="hljs-number">98</span><br></code></pre></td></tr></table></figure></li><li><p>运行程序：在 gdb 提示符下，您可以使用 run 命令来执行 Autogrid4。例如：(到这一步就已经报出很明显的错误了)</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-builtin-name">run</span> -p <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;PAIR&#125;</span>.gpf&quot;</span> -l <span class="hljs-variable">$&#123;PAIR&#125;</span><br></code></pre></td></tr></table></figure></li><li><p>调试过程中的命令：一旦程序在断点处停止，您可以使用命令如 continue（继续执行）、next（执行下一行）、print（打印变量内容）等来单步调试代码，观察变量的值和程序行为。</p></li><li><p>分析核心转储文件：如果程序发生核心转储并退出调试模式，您可以使用 gdb 分析核心转储文件以获取更多信息。在 gdb 中运行以下命令来加载核心转储文件：</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs angelscript">gdb <span class="hljs-built_in">auto</span>grid4 core<br></code></pre></td></tr></table></figure></li></ul><p>这些步骤将帮助您使用 gdb 调试 Autogrid4。调试过程中，您可以通过查阅 gdb 的文档或使用 help 命令来了解更多 gdb 的功能和命令。</p>]]></content>
    
    
    <categories>
      
      <category>Debug</category>
      
    </categories>
    
    
    <tags>
      
      <tag>gdb</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>github获取必应每日大图并推送到其他仓库</title>
    <link href="/2023/08/29/github%E8%8E%B7%E5%8F%96%E5%BF%85%E5%BA%94%E6%AF%8F%E6%97%A5%E5%A4%A7%E5%9B%BE%E5%B9%B6%E6%8E%A8%E9%80%81%E5%88%B0%E5%85%B6%E4%BB%96%E4%BB%93%E5%BA%93/"/>
    <url>/2023/08/29/github%E8%8E%B7%E5%8F%96%E5%BF%85%E5%BA%94%E6%AF%8F%E6%97%A5%E5%A4%A7%E5%9B%BE%E5%B9%B6%E6%8E%A8%E9%80%81%E5%88%B0%E5%85%B6%E4%BB%96%E4%BB%93%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><p>之前博客首页（虽然好久没更新了）的必应图片用的是他人的接口，有一天突然发现首页黑了，然后一看，果然，别人的东西终究是不安全，说寄就寄了。<br>最安全的办法就是自己实现，除非服务器寄了。计划白嫖github的服务器，github现已背靠微软，微软寄的可能性不大，所以放宽心使用好了。</p><h4 id="获取每日必应壁纸（代码很简单就几行，反正也是抄来的😎）"><a href="#获取每日必应壁纸（代码很简单就几行，反正也是抄来的😎）" class="headerlink" title="获取每日必应壁纸（代码很简单就几行，反正也是抄来的😎）"></a>获取每日必应壁纸（代码很简单就几行，反正也是抄来的😎）</h4><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs stylus">import re<br>import json<br>from datetime import datetime<br>from urllib<span class="hljs-selector-class">.parse</span> import urljoin<br><br>import requests<br><br>url = <span class="hljs-string">&#x27;https://cn.bing.com&#x27;</span><br><br>headers = &#123;<br>    <span class="hljs-string">&#x27;user-agent&#x27;</span>: <span class="hljs-string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36&#x27;</span><br>&#125;<br><br>res = requests<span class="hljs-selector-class">.get</span>(url, headers=headers)<br>res<span class="hljs-selector-class">.encoding</span> = res<span class="hljs-selector-class">.apparent_encoding</span><br>ret = re<span class="hljs-selector-class">.search</span>(<span class="hljs-string">&quot;var _model =(\&#123;.*?\&#125;);&quot;</span>, res.text)<br><span class="hljs-keyword">if</span> ret:<br>    data = json<span class="hljs-selector-class">.loads</span>(ret<span class="hljs-selector-class">.group</span>(<span class="hljs-number">1</span>))<br>    image_content = data<span class="hljs-selector-attr">[<span class="hljs-string">&#x27;MediaContents&#x27;</span>]</span><span class="hljs-selector-attr">[0]</span><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;ImageContent&#x27;</span>]</span><br><br>    image_url = urljoin(url, image_content<span class="hljs-selector-attr">[<span class="hljs-string">&#x27;Image&#x27;</span>]</span><span class="hljs-selector-attr">[<span class="hljs-string">&#x27;Url&#x27;</span>]</span>)<br>    r = requests<span class="hljs-selector-class">.get</span>(image_url)<br>    with open(<span class="hljs-string">&#x27;today.png&#x27;</span>, <span class="hljs-string">&#x27;wb&#x27;</span>) as f:<br>        f<span class="hljs-selector-class">.write</span>(r.<span class="hljs-attribute">content</span>)<br></code></pre></td></tr></table></figure><h4 id="使用github-action定时执行"><a href="#使用github-action定时执行" class="headerlink" title="使用github action定时执行"></a>使用github action定时执行</h4><p>在GitHub上执行Action有以下步骤：</p><ol><li>创建一个包含Workflow定义的YAML文件。这个文件将描述Action的触发条件、任务序列和执行环境等信息。</li><li>将YAML文件保存在你的代码仓库的<code>.github/workflows</code>目录下，确保文件名以<code>.yml</code>或<code>.yaml</code>结尾。</li><li>推送这个文件到你的GitHub仓库，触发一个版本控制操作。</li><li>GitHub会自动检测到新的Workflow文件，并根据你定义的触发条件启动Action运行。</li><li>在Action运行过程中，GitHub会根据你的定义，分配符合条件的执行环境，并执行定义的任务序列。</li><li>你可以在GitHub的Actions页面上查看Action运行的状态、日志和结果。<br>另外，你也可以手动在GitHub上执行Action。在你的仓库页面上，选择”Actions”标签，然后选择你想运行的Action，在Action页面上点击”Run workflow”按钮手动触发执行。<br>需要注意的是，GitHub Actions的执行需要满足一些条件，如正确的配置文件、权限设置和触发条件等。请参考GitHub的官方文档和使用指南以获取更详细的信息和指导。</li></ol><p>配置文件信息如下（名称可以随意取,另外就是必须放到项目根目录下的 .github/workflows/run.yml）</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">name:</span> <span class="hljs-string">Bing</span> <span class="hljs-string">Today</span> <span class="hljs-string">Img</span><br><br><span class="hljs-attr">on:</span><br>  <span class="hljs-attr">schedule:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">cron:</span> <span class="hljs-string">&#x27;0 21 * * *&#x27;</span>  <span class="hljs-comment"># 国际时间 21 点，估计北京时间 5点</span><br><br><span class="hljs-comment"># on:</span><br><span class="hljs-comment">#     push:</span><br><span class="hljs-comment">#         branches: [ main ]</span><br><br><br><span class="hljs-attr">jobs:</span><br>  <span class="hljs-attr">build:</span><br><br>    <span class="hljs-attr">runs-on:</span> <span class="hljs-string">ubuntu-latest</span><br><br>    <span class="hljs-attr">steps:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/checkout@v3</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Set</span> <span class="hljs-string">up</span> <span class="hljs-string">Python</span> <span class="hljs-number">3.10</span><br>      <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/setup-python@v3</span><br>      <span class="hljs-attr">with:</span><br>        <span class="hljs-attr">python-version:</span> <span class="hljs-string">&quot;3.10&quot;</span><br><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Install</span> <span class="hljs-string">dependencies</span><br>      <span class="hljs-attr">run:</span> <span class="hljs-string">|</span><br><span class="hljs-string">        python -m pip install --upgrade pip</span><br><span class="hljs-string">        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi</span><br><span class="hljs-string"></span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">run</span><br>      <span class="hljs-attr">run:</span> <span class="hljs-string">|</span><br><span class="hljs-string">        python bingTodayImg.py</span><br><span class="hljs-string"></span>    <br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">commit</span><br>      <span class="hljs-attr">run:</span> <span class="hljs-string">| </span><br><span class="hljs-string">        git config user.name github-actions</span><br><span class="hljs-string">        git config user.email github-actions@github.com</span><br><span class="hljs-string">        git add .</span><br><span class="hljs-string">        git commit -m &quot;generated&quot;</span><br><span class="hljs-string">        git push</span><br></code></pre></td></tr></table></figure><p>另外就是要设置下github-actions bot的权限，不然无法推送（没有权限）。设置方法为：在该仓库的Settings下找到Actions，对General下的Workflow permissions进行读写权限的勾选即可。</p><p>每日必应大图的接口地址为：<a href="https://raw.githubusercontent.com/shubihu/BingTodayImg/main/today.png">https://raw.githubusercontent.com/shubihu/BingTodayImg/main/today.png</a></p><h4 id="改款"><a href="#改款" class="headerlink" title="改款"></a>改款</h4><p>上述的接口地址国内不太好访问，本身博客也是在github上部署的，便想着直接把图片推送到博客的仓库。推送到其他仓库需要权限，权限设置方法如下：<br>token 的生成需要到这里：个人头像 -&gt; Settings -&gt; Developer settings -&gt; Personal access tokens，点击 Generate new token。这一步需要输入密码，然后我们可以选择所需权限去生成一个token。<br>为了安全考虑，这个token生成之后只会可见一次，因为后面的步骤会使用，所以我们需要做好保存。<br>注意这个 token 是用户级别的，它可以用于访问修改该账户名下的任意仓库。<br>为了让 Github Action 可以访问到这个token，需要给它做一个配置。配置路径是：在该仓库下的 Settings（注意这个是仓库下的设置而非个人下的设置） -&gt; Secrets -&gt; Actions 点击 New repository secret。<br>Name 的话可以命名为 ACCESS_TOKEN，Value 为上一步生成的访问 token。这里配置的任意内容都可以通过Github Action 访问到，且是加密的，创建之后只能看到 Name 看不到 Value。</p><p>改款后的配置信息：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># This workflow will install Python dependencies, run tests and lint with a single version of Python</span><br><span class="hljs-comment"># For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python</span><br><br><span class="hljs-attr">name:</span> <span class="hljs-string">Bing</span> <span class="hljs-string">Today</span> <span class="hljs-string">Img</span><br><br><span class="hljs-attr">on:</span><br>  <span class="hljs-attr">schedule:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">cron:</span> <span class="hljs-string">&#x27;0 21 * * *&#x27;</span>    <span class="hljs-comment"># 国际时间 21 点，估计北京时间 5点</span><br><br><span class="hljs-comment"># on:</span><br><span class="hljs-comment">#     push:</span><br><span class="hljs-comment">#         branches: [ main ]</span><br><br><br><span class="hljs-attr">jobs:</span><br>  <span class="hljs-attr">build:</span><br><br>    <span class="hljs-attr">runs-on:</span> <span class="hljs-string">ubuntu-latest</span><br><br>    <span class="hljs-attr">env:</span><br>          <span class="hljs-attr">ACCESS_TOKEN:</span> <span class="hljs-string">$&#123;&#123;</span> <span class="hljs-string">secrets.ACCESS_TOKEN</span> <span class="hljs-string">&#125;&#125;</span><br>          <br>    <span class="hljs-attr">steps:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/checkout@v3</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Set</span> <span class="hljs-string">up</span> <span class="hljs-string">Python</span> <span class="hljs-number">3.10</span><br>      <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/setup-python@v3</span><br>      <span class="hljs-attr">with:</span><br>        <span class="hljs-attr">python-version:</span> <span class="hljs-string">&quot;3.10&quot;</span><br><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Install</span> <span class="hljs-string">dependencies</span><br>      <span class="hljs-attr">run:</span> <span class="hljs-string">|</span><br><span class="hljs-string">        python -m pip install --upgrade pip</span><br><span class="hljs-string">        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi</span><br><span class="hljs-string"></span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">run</span><br>      <span class="hljs-attr">run:</span> <span class="hljs-string">|</span><br><span class="hljs-string">        python bingTodayImg.py</span><br><span class="hljs-string"></span>        <br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">commit</span><br>      <span class="hljs-attr">run:</span> <span class="hljs-string">| </span><br><span class="hljs-string">        git config user.name github-actions</span><br><span class="hljs-string">        git config user.email github-actions@github.com</span><br><span class="hljs-string">        git add today.png</span><br><span class="hljs-string">        git commit -m &quot;generated&quot;</span><br><span class="hljs-string">        git push</span><br><span class="hljs-string"></span><br>        <span class="hljs-string">git</span> <span class="hljs-string">config</span> <span class="hljs-string">--global</span> <span class="hljs-string">user.email</span> <span class="hljs-string">&quot;jrwjb@sina.com&quot;</span><br>        <span class="hljs-string">git</span> <span class="hljs-string">config</span> <span class="hljs-string">--global</span> <span class="hljs-string">user.name</span> <span class="hljs-string">&quot;shubihu&quot;</span><br>        <span class="hljs-string">git</span> <span class="hljs-string">clone</span> <span class="hljs-string">https://$&#123;ACCESS_TOKEN&#125;@github.com/shubihu/shubihu.github.io.git</span> <span class="hljs-string">repo</span><br>        <span class="hljs-string">cp</span> <span class="hljs-string">today.png</span> <span class="hljs-string">repo/</span><br>        <span class="hljs-string">cd</span> <span class="hljs-string">repo</span><br>        <span class="hljs-string">git</span> <span class="hljs-string">add</span> <span class="hljs-string">today.png</span><br>        <span class="hljs-string">git</span> <span class="hljs-string">commit</span> <span class="hljs-string">-m</span> <span class="hljs-string">&quot;Add today.png&quot;</span><br>        <span class="hljs-string">git</span> <span class="hljs-string">push</span><br></code></pre></td></tr></table></figure><p>另外博客仓库也添加了个Actions任务：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">name:</span> <span class="hljs-string">Get</span> <span class="hljs-string">Bing</span> <span class="hljs-string">Today</span> <span class="hljs-string">Img</span><br><br><span class="hljs-comment"># on:</span><br><span class="hljs-comment">#     push:</span><br><span class="hljs-comment">#         branches: [ main ]</span><br><br><span class="hljs-attr">on:</span><br>    <span class="hljs-attr">schedule:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">cron:</span> <span class="hljs-string">&#x27;0 */2 * * *&#x27;</span>  <span class="hljs-comment"># 每隔两个小时</span><br><br><span class="hljs-attr">jobs:</span><br>  <span class="hljs-attr">build:</span><br><br>    <span class="hljs-attr">runs-on:</span> <span class="hljs-string">ubuntu-latest</span><br><br>    <span class="hljs-attr">env:</span><br>          <span class="hljs-attr">ACCESS_TOKEN:</span> <span class="hljs-string">$&#123;&#123;</span> <span class="hljs-string">secrets.ACCESS_TOKEN</span> <span class="hljs-string">&#125;&#125;</span><br>          <br>    <span class="hljs-attr">steps:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/checkout@v3</span><br><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">commit</span><br>      <span class="hljs-attr">run:</span> <span class="hljs-string">| </span><br><span class="hljs-string">        if [[ ! -f &quot;today.png&quot; ]]; then</span><br><span class="hljs-string">            git config --global user.email &quot;jrwjb@sina.com&quot;</span><br><span class="hljs-string">            git config --global user.name &quot;shubihu&quot;</span><br><span class="hljs-string">            git clone https://$&#123;ACCESS_TOKEN&#125;@github.com/shubihu/BingTodayImg.git repo</span><br><span class="hljs-string">            cp repo/today.png ./</span><br><span class="hljs-string"></span>    <br>            <span class="hljs-string">git</span> <span class="hljs-string">config</span> <span class="hljs-string">user.name</span> <span class="hljs-string">github-actions</span><br>            <span class="hljs-string">git</span> <span class="hljs-string">config</span> <span class="hljs-string">user.email</span> <span class="hljs-string">github-actions@github.com</span><br>            <span class="hljs-string">git</span> <span class="hljs-string">add</span> <span class="hljs-string">today.png</span><br>            <span class="hljs-string">git</span> <span class="hljs-string">commit</span> <span class="hljs-string">-m</span> <span class="hljs-string">&quot;generated&quot;</span><br>            <span class="hljs-string">git</span> <span class="hljs-string">push</span><br>        <span class="hljs-string">fi</span><br><br></code></pre></td></tr></table></figure><p>这样就不完美解决了！</p><p>参考：<br><a href="https://mp.weixin.qq.com/s/oRXqNL48wZ0IbrfmNNOTGg">https://mp.weixin.qq.com/s/oRXqNL48wZ0IbrfmNNOTGg</a><br><a href="https://github.com/mouday/wallpaper-database/tree/main">https://github.com/mouday/wallpaper-database/tree/main</a><br><a href="https://github.com/licoded/BaiduFanyi_Crawler/issues/1">https://github.com/licoded/BaiduFanyi_Crawler/issues/1</a></p>]]></content>
    
    
    <categories>
      
      <category>CI/CD</category>
      
    </categories>
    
    
    <tags>
      
      <tag>github</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>快捷指令一键加入校园网</title>
    <link href="/2023/08/23/%E5%BF%AB%E6%8D%B7%E6%8C%87%E4%BB%A4%E4%B8%80%E9%94%AE%E5%8A%A0%E5%85%A5%E6%A0%A1%E5%9B%AD%E7%BD%91/"/>
    <url>/2023/08/23/%E5%BF%AB%E6%8D%B7%E6%8C%87%E4%BB%A4%E4%B8%80%E9%94%AE%E5%8A%A0%E5%85%A5%E6%A0%A1%E5%9B%AD%E7%BD%91/</url>
    
    <content type="html"><![CDATA[<h2 id="自动化冲浪"><a href="#自动化冲浪" class="headerlink" title="自动化冲浪"></a>自动化冲浪</h2><span id="more"></span><h4 id="前奏"><a href="#前奏" class="headerlink" title="前奏"></a>前奏</h4><p>因为在学校办公，用的网络是guest类型，每次冲浪前必须先登陆，电脑端还好，都有记忆功能，账号密码可以记住只需要点击上网即可。但是手机端就没那么方便了。<br>这里使用快捷指令实现快捷上网。<br>通过抓包发现以下参数可直接联网（仅用python做下测试）：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs powershell">import requests<br>url = <span class="hljs-string">&#x27;https://wificontroller.nic.sjtu.edu.cn/portal/logon.cgi&#x27;</span><br><span class="hljs-comment"># 处理post请求携带的参数(从抓包工具中获取)</span><br><span class="hljs-keyword">data</span> = &#123;<br>    <span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">2000</span>,<br>    <span class="hljs-string">&#x27;cmd&#x27;</span>: <span class="hljs-string">&#x27;authenticate&#x27;</span>,<br>    <span class="hljs-string">&#x27;mac&#x27;</span>: <span class="hljs-string">&#x27;&#x27;</span>,<br>    <span class="hljs-string">&#x27;ip&#x27;</span>:<span class="hljs-string">&#x27;&#x27;</span>,<br>    <span class="hljs-string">&#x27;essid&#x27;</span>:<span class="hljs-string">&#x27;&#x27;</span>,<br>    <span class="hljs-string">&#x27;url&#x27;</span>:<span class="hljs-string">&#x27;http://www.sjtu.edu.cn&#x27;</span>,<br>    <span class="hljs-string">&#x27;PtButton&#x27;</span>:<span class="hljs-string">&#x27;Logon&#x27;</span>,<br>    <span class="hljs-string">&#x27;PtUser&#x27;</span>:<span class="hljs-string">&#x27;xxxxxx&#x27;</span>,<br>    <span class="hljs-string">&#x27;PtPwd&#x27;</span>:<span class="hljs-string">&#x27;xxxxxx&#x27;</span>,<br>    <span class="hljs-string">&#x27;PtSubmit&#x27;</span>:<span class="hljs-string">&#x27;立即上网&#x27;</span><br>&#125;<br><br><span class="hljs-comment"># 自定义请求头信息，相关的头信息必须封装在字典结构中</span><br>headers = &#123;<br>    <span class="hljs-string">&#x27;User-Agent&#x27;</span>: <span class="hljs-string">&#x27;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36&#x27;</span>,<br>&#125;<br><br><span class="hljs-comment"># 2.发起基于ajax的post请求</span><br>requests.post(url=url,<span class="hljs-keyword">data</span>=<span class="hljs-keyword">data</span>,headers=headers)<br></code></pre></td></tr></table></figure><p>具体创建快捷指令的方法可参考：<br><a href="https://mp.weixin.qq.com/s?__biz=Mzg4OTEzMDcxNw==&amp;mid=2247484113&amp;idx=1&amp;sn=6db4b38a7004e922ab8de5420b8e15b1&amp;chksm=cff1d963f8865075b5e32c84f7ca44d3cf2238bacef444e6c12b1d603f5fa0daf5c385374f03&amp;token=14643316&amp;lang=zh_CN#rd">https://mp.weixin.qq.com/s?__biz=Mzg4OTEzMDcxNw==&amp;mid=2247484113&amp;idx=1&amp;sn=6db4b38a7004e922ab8de5420b8e15b1&amp;chksm=cff1d963f8865075b5e32c84f7ca44d3cf2238bacef444e6c12b1d603f5fa0daf5c385374f03&amp;token=14643316&amp;lang=zh_CN#rd</a></p><h4 id="后续：后来因为服务器端的ssl证书问题，上述快捷指令失效。"><a href="#后续：后来因为服务器端的ssl证书问题，上述快捷指令失效。" class="headerlink" title="后续：后来因为服务器端的ssl证书问题，上述快捷指令失效。"></a>后续：后来因为服务器端的ssl证书问题，上述快捷指令失效。</h4><p>于是新的折腾方法入下：<br>python测试方法几乎没变，只需要添加一个ssl验证为false即可</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import requests<br>url = <span class="hljs-string">&#x27;https://wificontroller.nic.sjtu.edu.cn/portal/logon.cgi&#x27;</span><br><span class="hljs-comment"># 处理post请求携带的参数(从抓包工具中获取)</span><br>data = &#123;<br>    <span class="hljs-string">&#x27;id&#x27;</span>: 2000,<br>    <span class="hljs-string">&#x27;cmd&#x27;</span>: <span class="hljs-string">&#x27;authenticate&#x27;</span>,<br>    <span class="hljs-string">&#x27;mac&#x27;</span>: <span class="hljs-string">&#x27;&#x27;</span>,<br>    <span class="hljs-string">&#x27;ip&#x27;</span>:<span class="hljs-string">&#x27;&#x27;</span>,<br>    <span class="hljs-string">&#x27;essid&#x27;</span>:<span class="hljs-string">&#x27;&#x27;</span>,<br>    <span class="hljs-string">&#x27;url&#x27;</span>:<span class="hljs-string">&#x27;http://www.sjtu.edu.cn&#x27;</span>,<br>    <span class="hljs-string">&#x27;PtButton&#x27;</span>:<span class="hljs-string">&#x27;Logon&#x27;</span>,<br>    <span class="hljs-string">&#x27;PtUser&#x27;</span>:<span class="hljs-string">&#x27;xxxxx&#x27;</span>,<br>    <span class="hljs-string">&#x27;PtPwd&#x27;</span>:<span class="hljs-string">&#x27;xxxx&#x27;</span>,<br>    <span class="hljs-string">&#x27;PtSubmit&#x27;</span>:<span class="hljs-string">&#x27;立即上网&#x27;</span><br>&#125;<br><br><span class="hljs-comment"># 自定义请求头信息，相关的头信息必须封装在字典结构中</span><br>headers = &#123;<br>    <span class="hljs-string">&#x27;User-Agent&#x27;</span>: <span class="hljs-string">&#x27;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36&#x27;</span>,<br>&#125;<br><br><span class="hljs-comment"># 2.发起基于ajax的post请求</span><br>response = requests.post(<span class="hljs-attribute">url</span>=url,data=data,headers=headers, <span class="hljs-attribute">verify</span>=<span class="hljs-literal">False</span>)<br><span class="hljs-builtin-name">print</span>(response.text)<br></code></pre></td></tr></table></figure><p>快捷指令的实现借助了第三方工具iSH,具体教程可以参考：<br><a href="https://blog.csdn.net/Qmj2333333/article/details/128910249">https://blog.csdn.net/Qmj2333333/article/details/128910249</a></p><p>这里可以用python脚本进行登陆也可以使用curl，curl命令如下, 使用 <code>-k</code> 设置禁用ssl验证：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">curl</span> -X POST -H <span class="hljs-string">&quot;User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36&quot;</span> -d <span class="hljs-string">&quot;id=2000&amp;cmd=authenticate&amp;mac=&amp;ip=&amp;essid=&amp;url=http://www.sjtu.edu.cn&amp;PtButton=Logon&amp;PtUser=xxxx&amp;PtPwd=xxxx&amp;PtSubmit=立即上网&quot;</span> -k <span class="hljs-string">&quot;https://wificontroller.nic.sjtu.edu.cn/portal/logon.cgi&quot;</span><br><br></code></pre></td></tr></table></figure><p>至此就可以无障碍冲浪了！</p>]]></content>
    
    
    <categories>
      
      <category>快捷指令</category>
      
    </categories>
    
    
    <tags>
      
      <tag>iphone</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>conda 安装包冲突解决</title>
    <link href="/2023/05/18/conda-%E5%AE%89%E8%A3%85%E5%8C%85%E5%86%B2%E7%AA%81%E8%A7%A3%E5%86%B3/"/>
    <url>/2023/05/18/conda-%E5%AE%89%E8%A3%85%E5%8C%85%E5%86%B2%E7%AA%81%E8%A7%A3%E5%86%B3/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><h4 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h4><p>使用conda install安装包的时候遇到下述问题：</p><figure class="highlight haml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs haml">The environment is inconsistent, please check the package plan carefully<br>The following packages are causing the inconsistency:<br><br>  -<span class="ruby"> <span class="hljs-symbol">https:</span>/<span class="hljs-regexp">/mirrors.njupt.edu.cn/anaconda</span><span class="hljs-regexp">/pkgs/main</span><span class="hljs-regexp">/linux-64::notebook==6.4.12=py39h06a4308_0</span></span><br><span class="hljs-regexp"><span class="ruby"></span></span>  -<span class="ruby"><span class="hljs-regexp"> defaults/linux</span>-<span class="hljs-number">64</span><span class="hljs-symbol">:</span><span class="hljs-symbol">:pandas=</span>=<span class="hljs-number">1.3</span>.<span class="hljs-number">5</span>=py39h8c16a72_0</span><br><span class="ruby"></span>  -<span class="ruby"> pytorch/linux-<span class="hljs-number">64</span><span class="hljs-symbol">:</span><span class="hljs-symbol">:torchvision=</span>=<span class="hljs-number">0.13</span>.<span class="hljs-number">0</span>=py39_cu116</span><br><span class="ruby"></span>  -<span class="ruby"> conda-forge/linux-<span class="hljs-number">64</span><span class="hljs-symbol">:</span><span class="hljs-symbol">:mamba=</span>=<span class="hljs-number">0.25</span>.<span class="hljs-number">0</span>=py39hfa8f2c8_1</span><br><span class="ruby"></span>  -<span class="ruby"> <span class="hljs-symbol">https:</span>/<span class="hljs-regexp">/mirrors.njupt.edu.cn/anaconda</span><span class="hljs-regexp">/pkgs/main</span><span class="hljs-regexp">/linux-64::jupyterlab==3.4.4=py39h06a4308_0</span></span><br><span class="hljs-regexp"><span class="ruby"></span></span>  -<span class="ruby"><span class="hljs-regexp"> conda-forge/noarch</span><span class="hljs-symbol">:</span><span class="hljs-symbol">:jupyterhub-base=</span>=<span class="hljs-number">2.3</span>.<span class="hljs-number">1</span>=pyhd8ed1ab_0</span><br><span class="ruby"></span>  -<span class="ruby"> pytorch/linux-<span class="hljs-number">64</span><span class="hljs-symbol">:</span><span class="hljs-symbol">:torchaudio=</span>=<span class="hljs-number">0.12</span>.<span class="hljs-number">0</span>=py39_cu116</span><br><span class="ruby"></span>  -<span class="ruby"> <span class="hljs-symbol">https:</span>/<span class="hljs-regexp">/mirrors.njupt.edu.cn/anaconda</span><span class="hljs-regexp">/pkgs/main</span><span class="hljs-regexp">/linux-64::nb_conda==2.2.1=py39h06a4308_1</span></span><br><span class="hljs-regexp"><span class="ruby"></span></span>  -<span class="ruby"><span class="hljs-regexp"> conda-forge/noarch</span><span class="hljs-symbol">:</span><span class="hljs-symbol">:distributed=</span>=<span class="hljs-number">2022.3</span>.<span class="hljs-number">0</span>=pyhd8ed1ab_0</span><br><span class="ruby"></span>  -<span class="ruby"> conda-forge/linux-<span class="hljs-number">64</span><span class="hljs-symbol">:</span><span class="hljs-symbol">:arrow-cpp=</span>=<span class="hljs-number">6.0</span>.<span class="hljs-number">1</span>=py39h964882e_6_cuda</span><br><span class="ruby"></span>  -<span class="ruby"> rapidsai/linux-<span class="hljs-number">64</span><span class="hljs-symbol">:</span><span class="hljs-symbol">:libcudf=</span>=<span class="hljs-number">22.04</span>.<span class="hljs-number">00</span>=cuda11_g8bf0520170_0</span><br><span class="ruby"></span>  -<span class="ruby"> conda-forge/linux-<span class="hljs-number">64</span><span class="hljs-symbol">:</span><span class="hljs-symbol">:pyarrow=</span>=<span class="hljs-number">6.0</span>.<span class="hljs-number">1</span>=py39h1ed2e5d_6_cuda</span><br></code></pre></td></tr></table></figure><p>然后导致包无法正常安装。之前试过conda回滚（当然没有试过回滚到最初的状态，即第一个版本）也没有解决问题。当然如果打算废弃环境的话就无所谓了，如果还想拯救一下的话可以进行删除这些包。</p><h4 id="删除冲突的包"><a href="#删除冲突的包" class="headerlink" title="删除冲突的包"></a>删除冲突的包</h4><p>如果只有几个冲突的话复制粘贴就可以了，如果比较多可以用命令行处理。比如使用awk, 先复制上面的内容到一个文件中packages.txt</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">awk</span> -F<span class="hljs-string">&#x27;::&#x27;</span> <span class="hljs-string">&#x27;&#123;print <span class="hljs-variable">$2</span>&#125;&#x27;</span> packages.txt | sed <span class="hljs-string">&#x27;:a;N;$!ba;s/\n/ /g&#x27;</span><br></code></pre></td></tr></table></figure><p>其中’:a;N;$!ba;’将所有行缓冲到模式空间中。最后，使用”s/\n/ /g”命令将每行的换行符替换为空格<br>处理后的冲突包如下(即上诉提示信息中<code>::</code>后面的部分, 包与包之间用空格隔开)</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">notebook</span>==<span class="hljs-number">6</span>.<span class="hljs-number">4</span>.<span class="hljs-number">12</span>=py<span class="hljs-number">39</span>h<span class="hljs-number">06</span>a<span class="hljs-number">4308</span>_<span class="hljs-number">0</span> pandas==<span class="hljs-number">1</span>.<span class="hljs-number">3</span>.<span class="hljs-number">5</span>=py<span class="hljs-number">39</span>h<span class="hljs-number">8</span>c<span class="hljs-number">16</span>a<span class="hljs-number">72</span>_<span class="hljs-number">0</span> torchvision==<span class="hljs-number">0</span>.<span class="hljs-number">13</span>.<span class="hljs-number">0</span>=py<span class="hljs-number">39</span>_cu<span class="hljs-number">116</span> mamba==<span class="hljs-number">0</span>.<span class="hljs-number">25</span>.<span class="hljs-number">0</span>=py<span class="hljs-number">39</span>hfa<span class="hljs-number">8</span>f<span class="hljs-number">2</span>c<span class="hljs-number">8</span>_<span class="hljs-number">1</span> jupyterlab==<span class="hljs-number">3</span>.<span class="hljs-number">4</span>.<span class="hljs-number">4</span>=py<span class="hljs-number">39</span>h<span class="hljs-number">06</span>a<span class="hljs-number">4308</span>_<span class="hljs-number">0</span> jupyterhub-base==<span class="hljs-number">2</span>.<span class="hljs-number">3</span>.<span class="hljs-number">1</span>=pyhd<span class="hljs-number">8</span>ed<span class="hljs-number">1</span>ab_<span class="hljs-number">0</span> torchaudio==<span class="hljs-number">0</span>.<span class="hljs-number">12</span>.<span class="hljs-number">0</span>=py<span class="hljs-number">39</span>_cu<span class="hljs-number">116</span> nb_conda==<span class="hljs-number">2</span>.<span class="hljs-number">2</span>.<span class="hljs-number">1</span>=py<span class="hljs-number">39</span>h<span class="hljs-number">06</span>a<span class="hljs-number">4308</span>_<span class="hljs-number">1</span> distributed==<span class="hljs-number">2022</span>.<span class="hljs-number">3</span>.<span class="hljs-number">0</span>=pyhd<span class="hljs-number">8</span>ed<span class="hljs-number">1</span>ab_<span class="hljs-number">0</span> arrow-cpp==<span class="hljs-number">6</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span>=py<span class="hljs-number">39</span>h<span class="hljs-number">964882</span>e_<span class="hljs-number">6</span>_cuda libcudf==<span class="hljs-number">22</span>.<span class="hljs-number">04</span>.<span class="hljs-number">00</span>=cuda<span class="hljs-number">11</span>_g<span class="hljs-number">8</span>bf<span class="hljs-number">0520170</span>_<span class="hljs-number">0</span> pyarrow==<span class="hljs-number">6</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span>=py<span class="hljs-number">39</span>h<span class="hljs-number">1</span>ed<span class="hljs-number">2</span>e<span class="hljs-number">5</span>d_<span class="hljs-number">6</span>_cuda<br></code></pre></td></tr></table></figure><p>删除命令：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">conda</span> remove notebook==<span class="hljs-number">6</span>.<span class="hljs-number">4</span>.<span class="hljs-number">12</span>=py<span class="hljs-number">39</span>h<span class="hljs-number">06</span>a<span class="hljs-number">4308</span>_<span class="hljs-number">0</span> pandas==<span class="hljs-number">1</span>.<span class="hljs-number">3</span>.<span class="hljs-number">5</span>=py<span class="hljs-number">39</span>h<span class="hljs-number">8</span>c<span class="hljs-number">16</span>a<span class="hljs-number">72</span>_<span class="hljs-number">0</span> torchvision==<span class="hljs-number">0</span>.<span class="hljs-number">13</span>.<span class="hljs-number">0</span>=py<span class="hljs-number">39</span>_cu<span class="hljs-number">116</span> mamba==<span class="hljs-number">0</span>.<span class="hljs-number">25</span>.<span class="hljs-number">0</span>=py<span class="hljs-number">39</span>hfa<span class="hljs-number">8</span>f<span class="hljs-number">2</span>c<span class="hljs-number">8</span>_<span class="hljs-number">1</span> jupyterlab==<span class="hljs-number">3</span>.<span class="hljs-number">4</span>.<span class="hljs-number">4</span>=py<span class="hljs-number">39</span>h<span class="hljs-number">06</span>a<span class="hljs-number">4308</span>_<span class="hljs-number">0</span> jupyterhub-base==<span class="hljs-number">2</span>.<span class="hljs-number">3</span>.<span class="hljs-number">1</span>=pyhd<span class="hljs-number">8</span>ed<span class="hljs-number">1</span>ab_<span class="hljs-number">0</span> torchaudio==<span class="hljs-number">0</span>.<span class="hljs-number">12</span>.<span class="hljs-number">0</span>=py<span class="hljs-number">39</span>_cu<span class="hljs-number">116</span> nb_conda==<span class="hljs-number">2</span>.<span class="hljs-number">2</span>.<span class="hljs-number">1</span>=py<span class="hljs-number">39</span>h<span class="hljs-number">06</span>a<span class="hljs-number">4308</span>_<span class="hljs-number">1</span> distributed==<span class="hljs-number">2022</span>.<span class="hljs-number">3</span>.<span class="hljs-number">0</span>=pyhd<span class="hljs-number">8</span>ed<span class="hljs-number">1</span>ab_<span class="hljs-number">0</span> arrow-cpp==<span class="hljs-number">6</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span>=py<span class="hljs-number">39</span>h<span class="hljs-number">964882</span>e_<span class="hljs-number">6</span>_cuda libcudf==<span class="hljs-number">22</span>.<span class="hljs-number">04</span>.<span class="hljs-number">00</span>=cuda<span class="hljs-number">11</span>_g<span class="hljs-number">8</span>bf<span class="hljs-number">0520170</span>_<span class="hljs-number">0</span> pyarrow==<span class="hljs-number">6</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span>=py<span class="hljs-number">39</span>h<span class="hljs-number">1</span>ed<span class="hljs-number">2</span>e<span class="hljs-number">5</span>d_<span class="hljs-number">6</span>_cuda<br></code></pre></td></tr></table></figure><p>删除包之后再执行安装命令应该就可以正常安装包了。</p>]]></content>
    
    
    <categories>
      
      <category>conda</category>
      
    </categories>
    
    
    <tags>
      
      <tag>conda</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于chatglm-6b的本地知识问答</title>
    <link href="/2023/05/08/%E5%9F%BA%E4%BA%8Echatglm-6b%E7%9A%84%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94/"/>
    <url>/2023/05/08/%E5%9F%BA%E4%BA%8Echatglm-6b%E7%9A%84%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94/</url>
    
    <content type="html"><![CDATA[<h2 id="langchain-chatglm-6b"><a href="#langchain-chatglm-6b" class="headerlink" title="langchain + chatglm-6b"></a>langchain + chatglm-6b</h2><span id="more"></span><h4 id="导包"><a href="#导包" class="headerlink" title="导包"></a>导包</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">import</span> os<br><span class="hljs-comment"># 设置CUDA_VISIBLE_DEVICES环境变量</span><br>os.environ[<span class="hljs-string">&#x27;CUDA_VISIBLE_DEVICES&#x27;</span>] = <span class="hljs-string">&#x27;0&#x27;</span><br><br><span class="hljs-keyword">from</span> llama_index <span class="hljs-keyword">import</span> StorageContext, load_index_from_storage, SimpleDirectoryReader, LangchainEmbedding, GPTListIndex, GPTVectorStoreIndex, PromptHelper, LLMPredictor, ServiceContext<br><span class="hljs-keyword">from</span> langchain.llms.base <span class="hljs-keyword">import</span> LLM<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Optional</span>, <span class="hljs-type">List</span>, Mapping, <span class="hljs-type">Any</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModel<br><span class="hljs-keyword">from</span> langchain.embeddings.huggingface <span class="hljs-keyword">import</span> HuggingFaceEmbeddings<br></code></pre></td></tr></table></figure><h4 id="加载chatglm-6b"><a href="#加载chatglm-6b" class="headerlink" title="加载chatglm-6b"></a>加载chatglm-6b</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;THUDM/chatglm-6b&quot;</span>, trust_remote_code=<span class="hljs-literal">True</span>)<br>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;THUDM/chatglm-6b&quot;</span>, trust_remote_code=<span class="hljs-literal">True</span>).half().cuda()<br>model = model.<span class="hljs-built_in">eval</span>()<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ChatGLM</span>(<span class="hljs-params">LLM</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_call</span>(<span class="hljs-params">self, prompt: <span class="hljs-built_in">str</span>, stop: <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]] = <span class="hljs-literal">None</span></span>) -&gt; <span class="hljs-built_in">str</span>:</span><br>        response, history = model.chat(tokenizer, prompt, history=[])<br>        <span class="hljs-comment"># only return newly generated tokens</span><br>        <span class="hljs-keyword">return</span> response<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_identifying_params</span>(<span class="hljs-params">self</span>) -&gt; Mapping[<span class="hljs-built_in">str</span>, <span class="hljs-type">Any</span>]:</span><br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;name_of_model&quot;</span>: <span class="hljs-string">&quot;chatglm-6b&quot;</span>&#125;<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_llm_type</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">str</span>:</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;ChatGLM&quot;</span><br></code></pre></td></tr></table></figure><h4 id="加载本地知识库，支持txt、pdf等格式，这里以txt为例，即把txt的文档放到docs目录下"><a href="#加载本地知识库，支持txt、pdf等格式，这里以txt为例，即把txt的文档放到docs目录下" class="headerlink" title="加载本地知识库，支持txt、pdf等格式，这里以txt为例，即把txt的文档放到docs目录下"></a>加载本地知识库，支持txt、pdf等格式，这里以txt为例，即把txt的文档放到docs目录下</h4><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">directory_path</span> = <span class="hljs-string">&quot;./docs&quot;</span><br><br><span class="hljs-attr">max_input_size</span> = <span class="hljs-number">4096</span><br><span class="hljs-attr">num_outputs</span> = <span class="hljs-number">2000</span><br><span class="hljs-attr">max_chunk_overlap</span> = <span class="hljs-number">20</span><br><span class="hljs-attr">chunk_size_limit</span> = <span class="hljs-number">600</span><br><span class="hljs-attr">prompt_helper</span> = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)<br><span class="hljs-attr">documents</span> = SimpleDirectoryReader(directory_path).load_data()<br></code></pre></td></tr></table></figure><h4 id="加载embedding模型-这里加载默认的huggingface-embedding-sentence-transformers-all-mpnet-base-v2"><a href="#加载embedding模型-这里加载默认的huggingface-embedding-sentence-transformers-all-mpnet-base-v2" class="headerlink" title="加载embedding模型, 这里加载默认的huggingface embedding(sentence-transformers/all-mpnet-base-v2)"></a>加载embedding模型, 这里加载默认的huggingface embedding(sentence-transformers/all-mpnet-base-v2)</h4><figure class="highlight isbl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs isbl"><span class="hljs-variable">embed_model</span> = <span class="hljs-function"><span class="hljs-title">LangchainEmbedding</span>(<span class="hljs-title">HuggingFaceEmbeddings</span>())</span><br><span class="hljs-variable">llm_predictor</span> = <span class="hljs-function"><span class="hljs-title">LLMPredictor</span>(<span class="hljs-variable">llm</span>=<span class="hljs-title">ChatGLM</span>())</span><br></code></pre></td></tr></table></figure><h4 id="本地知识向量化存储-默认存储在-storage"><a href="#本地知识向量化存储-默认存储在-storage" class="headerlink" title="本地知识向量化存储, 默认存储在 ./storage"></a>本地知识向量化存储, 默认存储在 <code>./storage</code></h4><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">service_context = <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">ServiceContext</span>.</span></span>from<span class="hljs-constructor">_defaults(<span class="hljs-params">embed_model</span>=<span class="hljs-params">embed_model</span>, <span class="hljs-params">llm_predictor</span>=<span class="hljs-params">llm_predictor</span>)</span><br>index = <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">GPTVectorStoreIndex</span>.</span></span>from<span class="hljs-constructor">_documents(<span class="hljs-params">documents</span>,<span class="hljs-params">service_context</span>=<span class="hljs-params">service_context</span>)</span><br>index.storage_context.persist<span class="hljs-literal">()</span><br></code></pre></td></tr></table></figure><h4 id="加载本地知识向量并提问"><a href="#加载本地知识向量并提问" class="headerlink" title="加载本地知识向量并提问"></a>加载本地知识向量并提问</h4><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">storage_context = <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">StorageContext</span>.</span></span>from<span class="hljs-constructor">_defaults(<span class="hljs-params">persist_dir</span>=&#x27;.<span class="hljs-operator">/</span><span class="hljs-params">storage</span>&#x27;)</span><br>index = load<span class="hljs-constructor">_index_from_storage(<span class="hljs-params">storage_context</span>, <span class="hljs-params">service_context</span>=<span class="hljs-params">service_context</span>)</span><br>query_engine = index.<span class="hljs-keyword">as</span><span class="hljs-constructor">_query_engine()</span><br>response = query_engine.query(<span class="hljs-string">&quot;&lt;What are the diseases associated with macrophage&gt;?&quot;</span>)<br>print(response.response)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>chatglm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GPU单卡多进程</title>
    <link href="/2023/04/26/GPU%E5%8D%95%E5%8D%A1%E5%A4%9A%E8%BF%9B%E7%A8%8B/"/>
    <url>/2023/04/26/GPU%E5%8D%95%E5%8D%A1%E5%A4%9A%E8%BF%9B%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><p>这里利用了清华开源的chatglm-6b模型对pubmed上的文献摘要进行总结式概括。<br>代码如下：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import os<br>import re<br><span class="hljs-comment"># 设置CUDA_VISIBLE_DEVICES环境变量</span><br>os.environ[<span class="hljs-string">&#x27;CUDA_VISIBLE_DEVICES&#x27;</span>] = <span class="hljs-string">&#x27;2&#x27;</span><br><span class="hljs-keyword">from</span> functools import partial<br><span class="hljs-keyword">from</span> transformers import AutoTokenizer, AutoModel<br>import pandas as pd<br>import torch<br><span class="hljs-keyword">from</span> torch.multiprocessing import<span class="hljs-built_in"> Pool</span><br><span class="hljs-built_in"></span><span class="hljs-keyword">from</span> tqdm import tqdm<br>import summarize<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    torch.multiprocessing.set_start_method(<span class="hljs-string">&#x27;spawn&#x27;</span>)<br>    df = pd.read_excel(<span class="hljs-string">&#x27;/data/database/pubmed/macrophage_disease.xlsx&#x27;</span>)<br>    <span class="hljs-builtin-name">print</span>(df.shape)<br>    tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;THUDM/chatglm-6b&quot;</span>, <span class="hljs-attribute">trust_remote_code</span>=<span class="hljs-literal">True</span>)<br>    model = AutoModel.from_pretrained(<span class="hljs-string">&quot;THUDM/chatglm-6b&quot;</span>, <span class="hljs-attribute">trust_remote_code</span>=<span class="hljs-literal">True</span>).half().cuda()<br>    model = model.eval()<br><br>    partial_process_data = partial(summarize.summarize_abstract, <span class="hljs-attribute">tokenizer</span>=tokenizer, <span class="hljs-attribute">model</span>=model)<br><br>    summary_ls = []<br>    with Pool(<span class="hljs-attribute">processes</span>=4) as pool:<br>        <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> tqdm(pool.imap(partial_process_data, df[<span class="hljs-string">&#x27;abstract&#x27;</span>]), <span class="hljs-attribute">total</span>=len(df[<span class="hljs-string">&#x27;abstract&#x27;</span>])):<br>            summary_ls.append(r)<br><br>    df[<span class="hljs-string">&#x27;summmary&#x27;</span>] = summary_ls<br>    <br>    df.to_csv(<span class="hljs-string">&#x27;pubmed_summary.txt&#x27;</span>, <span class="hljs-attribute">index</span>=<span class="hljs-literal">False</span>, <span class="hljs-attribute">sep</span>=<span class="hljs-string">&#x27;\t&#x27;</span>)<br></code></pre></td></tr></table></figure><p>另外summarize.py代码如下, summarize_abstract函数必须写到一个文件中：</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs csharp"><span class="hljs-function">def <span class="hljs-title">summarize_abstract</span>(<span class="hljs-params"><span class="hljs-keyword">abstract</span>, tokenizer, model</span>):</span><br><span class="hljs-function">        </span><br><span class="hljs-function">    # Remove non-alphanumeric characters <span class="hljs-keyword">and</span> extra whitespace</span><br><span class="hljs-function">    # <span class="hljs-keyword">abstract</span></span> = re.sub(r<span class="hljs-string">&#x27;[^a-zA-Z0-9\s]&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-keyword">abstract</span>).strip()<br>    prompt = f<span class="hljs-string">&quot;请用一句话总结以下摘要并且总结中必须要包含macrophage和相关的疾病,字数控制在50以内:&#123;abstract&#125;&quot;</span><br>    response, history = model.chat(tokenizer, prompt, history=[])<br>    <span class="hljs-keyword">return</span> response<br></code></pre></td></tr></table></figure><p>参考：<a href="https://blog.csdn.net/junjunzai123/article/details/126286131">https://blog.csdn.net/junjunzai123/article/details/126286131</a></p>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>单卡、多进程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python远程过程调用RPC小例子</title>
    <link href="/2023/03/17/%E8%BF%9C%E7%A8%8B%E8%BF%87%E7%A8%8B%E8%B0%83%E7%94%A8RPC%E5%B0%8F%E4%BE%8B%E5%AD%90/"/>
    <url>/2023/03/17/%E8%BF%9C%E7%A8%8B%E8%BF%87%E7%A8%8B%E8%B0%83%E7%94%A8RPC%E5%B0%8F%E4%BE%8B%E5%AD%90/</url>
    
    <content type="html"><![CDATA[<h2 id="RPC-demo"><a href="#RPC-demo" class="headerlink" title="RPC demo"></a>RPC demo</h2><span id="more"></span><h4 id="在B服务器上运行RPC服务"><a href="#在B服务器上运行RPC服务" class="headerlink" title="在B服务器上运行RPC服务"></a>在B服务器上运行RPC服务</h4><ul><li>服务端server.py代码：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># server.py</span><br><span class="hljs-keyword">import</span> Pyro4<br><br><span class="hljs-meta">@Pyro4.expose</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyServer</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">do_something</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;hello from server&quot;</span><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    daemon = Pyro4.Daemon(port=<span class="hljs-number">35721</span>)<br>    uri = daemon.register(MyServer, objectId=<span class="hljs-string">&quot;helloworld&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Ready. Object uri =&quot;</span>, uri)<br>    daemon.requestLoop()<br></code></pre></td></tr></table></figure></li><li>执行程序<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">python</span> server.<span class="hljs-keyword">py</span><br></code></pre></td></tr></table></figure></li></ul><h4 id="在A服务器上运行RPC客户端"><a href="#在A服务器上运行RPC客户端" class="headerlink" title="在A服务器上运行RPC客户端"></a>在A服务器上运行RPC客户端</h4><ul><li>客户端client.py代码<figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs axapta"><span class="hljs-meta"># client.py</span><br>import Pyro4<br><br><span class="hljs-meta"># 输入server 端的uri</span><br><span class="hljs-keyword">server</span> = Pyro4.Proxy(<span class="hljs-string">&quot;PYRO:helloworld@localhost:35721&quot;</span>)<br><br>result = <span class="hljs-keyword">server</span>.do_something()<br><span class="hljs-keyword">print</span>(result)<br></code></pre></td></tr></table></figure></li><li>执行程序<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">python</span> client.<span class="hljs-keyword">py</span><br></code></pre></td></tr></table></figure>正常输出：hello from server</li></ul><h4 id="其他方法（由chatgpt生成"><a href="#其他方法（由chatgpt生成" class="headerlink" title="其他方法（由chatgpt生成)"></a>其他方法（由chatgpt生成)</h4><ul><li><p>使用socket通信：可以在A服务器上编写一个Python程序，它将通过socket连接到B服务器，并发送需要执行的命令，B服务器将接收并执行该命令，并将结果返回给A服务器。</p></li><li><p>使用远程过程调用（RPC）：可以使用Python的RPC库，如Pyro或RPC4Django，以编写A服务器上的Python程序，它将调用B服务器上的Python程序。</p></li><li><p>使用Web服务：可以在B服务器上编写一个Python Web服务，使用Flask、Django等Web框架，以接收来自A服务器的HTTP请求，并返回结果。在A服务器上，可以使用Python的requests库或类似的HTTP客户端库发送HTTP请求并获取结果。</p></li><li><p>使用消息队列：可以使用消息队列，如RabbitMQ或Apache Kafka，以在A服务器和B服务器之间传递消息。在A服务器上，可以使用Python的pika或kafka-python库发送消息，而在B服务器上，可以使用相应的库来接收和处理消息。</p></li></ul><h5 id="使用socket通信"><a href="#使用socket通信" class="headerlink" title="使用socket通信"></a>使用socket通信</h5><ul><li>A服务器上的Python程序：<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">import <span class="hljs-built_in">socket</span><br><br>HOST = <span class="hljs-string">&#x27;B服务器IP地址&#x27;</span><br>PORT = B服务器监听的端口号<br><br><span class="hljs-comment"># 建立socket连接</span><br>s = <span class="hljs-built_in">socket</span>.<span class="hljs-built_in">socket</span>(<span class="hljs-built_in">socket</span>.AF_INET, <span class="hljs-built_in">socket</span>.SOCK_STREAM)<br>s.connect((HOST, PORT))<br><br><span class="hljs-comment"># 发送命令到B服务器</span><br>cmd = <span class="hljs-string">&#x27;python /path/to/python/program.py&#x27;</span><br>s.sendall(cmd.encode())<br><br><span class="hljs-comment"># 获取B服务器返回的结果</span><br>data = s.recv(<span class="hljs-number">1024</span>)<br>print(<span class="hljs-string">&#x27;Received:&#x27;</span>, data.decode())<br><br><span class="hljs-comment"># 关闭连接</span><br>s.<span class="hljs-built_in">close</span>()<br><br></code></pre></td></tr></table></figure></li><li>B服务器上的Python程序：<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">import subprocess<br><br><span class="hljs-keyword">while</span> True:<br>    <span class="hljs-comment"># 监听端口</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">socket</span>.<span class="hljs-built_in">socket</span>(<span class="hljs-built_in">socket</span>.AF_INET, <span class="hljs-built_in">socket</span>.SOCK_STREAM) <span class="hljs-keyword">as</span> s:<br>        s.bind((HOST, PORT))<br>        s.listen()<br>        conn, addr = s.accept()<br><br>        <span class="hljs-comment"># 接收来自A服务器的命令</span><br>        cmd = conn.recv(<span class="hljs-number">1024</span>).decode()<br><br>        <span class="hljs-comment"># 执行命令并返回结果</span><br>        <span class="hljs-built_in">result</span> = subprocess.run(cmd, <span class="hljs-built_in">shell</span>=True, capture_output=True)<br>        conn.sendall(<span class="hljs-built_in">result</span>.<span class="hljs-keyword">stdout</span>)<br><br></code></pre></td></tr></table></figure></li></ul><h5 id="使用Web服务"><a href="#使用Web服务" class="headerlink" title="使用Web服务"></a>使用Web服务</h5><ul><li>在B服务器上使用Flask框架创建Web服务：<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># app.py</span><br><span class="hljs-keyword">from</span> flask import Flask<br><br>app = Flask(__name__)<br><br>@app.route(<span class="hljs-string">&#x27;/do_something&#x27;</span>)<br>def do_something():<br>    return <span class="hljs-string">&quot;hello from server&quot;</span><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    app.<span class="hljs-builtin-name">run</span>(<span class="hljs-attribute">host</span>=<span class="hljs-string">&#x27;0.0.0.0&#x27;</span>, <span class="hljs-attribute">port</span>=5000)<br><br></code></pre></td></tr></table></figure></li><li>在A服务器上使用requests库发送HTTP请求：<figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs processing"><span class="hljs-keyword">import</span> requests<br><br>url = <span class="hljs-string">&#x27;B服务器IP地址:5000/do_something&#x27;</span><br>response = requests.<span class="hljs-built_in">get</span>(url)<br><br><span class="hljs-built_in">print</span>(response.<span class="hljs-built_in">text</span>)<br><br></code></pre></td></tr></table></figure></li></ul><h5 id="使用消息队列"><a href="#使用消息队列" class="headerlink" title="使用消息队列"></a>使用消息队列</h5><ul><li>在A服务器上使用pika库发送消息到消息队列：<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import pika<br><span class="hljs-built_in"></span><br><span class="hljs-built_in">connection </span>= pika.BlockingConnection(pika.ConnectionParameters(<span class="hljs-string">&#x27;localhost&#x27;</span>))<br>channel = connection.channel()<br><br>channel.queue_declare(<span class="hljs-attribute">queue</span>=<span class="hljs-string">&#x27;task_queue&#x27;</span>, <span class="hljs-attribute">durable</span>=<span class="hljs-literal">True</span>)<br><br>message = <span class="hljs-string">&#x27;python /path/to/python/program.py&#x27;</span><br>channel.basic_publish(<span class="hljs-attribute">exchange</span>=<span class="hljs-string">&#x27;&#x27;</span>,<br>                      <span class="hljs-attribute">routing_key</span>=<span class="hljs-string">&#x27;task_queue&#x27;</span>,<br>                      <span class="hljs-attribute">body</span>=message,<br>                      <span class="hljs-attribute">properties</span>=pika.BasicProperties(<br>                          <span class="hljs-attribute">delivery_mode</span>=2,  # make message persistent<br>                      ))<br><br><span class="hljs-builtin-name">print</span>(<span class="hljs-string">&quot; [x] Sent %r&quot;</span> % message)<br>connection.close()<br><br></code></pre></td></tr></table></figure></li><li>在B服务器上使用pika库接收消息并处理：<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">import</span> pika<br><span class="hljs-keyword">import</span> subprocess<br><br><span class="hljs-keyword">connection</span> = pika.BlockingConnection(pika.ConnectionParameters(<span class="hljs-string">&#x27;localhost&#x27;</span>))<br>channel = <span class="hljs-keyword">connection</span>.channel()<br><br>channel.queue_declare(queue=<span class="hljs-string">&#x27;task_queue&#x27;</span>,<br><br></code></pre></td></tr></table></figure></li></ul>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RPC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker打包python项目踩坑</title>
    <link href="/2023/03/15/Docker%E6%89%93%E5%8C%85python%E9%A1%B9%E7%9B%AE%E8%B8%A9%E5%9D%91/"/>
    <url>/2023/03/15/Docker%E6%89%93%E5%8C%85python%E9%A1%B9%E7%9B%AE%E8%B8%A9%E5%9D%91/</url>
    
    <content type="html"><![CDATA[<h2 id="Docker踩坑"><a href="#Docker踩坑" class="headerlink" title="Docker踩坑"></a>Docker踩坑</h2><span id="more"></span><h4 id="报错信息"><a href="#报错信息" class="headerlink" title="报错信息"></a>报错信息</h4><p>ERROR: No .egg-info directory found in /tmp/pip-pip-egg-info-lsnfgjec</p><ul><li>requirements.txt信息如下<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">colorama</span>==<span class="hljs-number">0</span>.<span class="hljs-number">4</span>.<span class="hljs-number">4</span><br><span class="hljs-attribute">Flask</span>==<span class="hljs-number">2</span>.<span class="hljs-number">1</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">Flask_Cors</span>==<span class="hljs-number">3</span>.<span class="hljs-number">0</span>.<span class="hljs-number">10</span><br><span class="hljs-attribute">Flask_Executor</span>==<span class="hljs-number">1</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">Flask_SocketIO</span>==<span class="hljs-number">5</span>.<span class="hljs-number">3</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">numpy</span>==<span class="hljs-number">1</span>.<span class="hljs-number">22</span>.<span class="hljs-number">4</span><br><span class="hljs-attribute">pandas</span>==<span class="hljs-number">1</span>.<span class="hljs-number">3</span>.<span class="hljs-number">5</span><br><span class="hljs-attribute">ProDy</span>==<span class="hljs-number">2</span>.<span class="hljs-number">3</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">redis</span>==<span class="hljs-number">3</span>.<span class="hljs-number">5</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">toml</span>==<span class="hljs-number">0</span>.<span class="hljs-number">10</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">ulid</span>==<span class="hljs-number">1</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">ulid_py</span>==<span class="hljs-number">1</span>.<span class="hljs-number">1</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">Werkzeug</span>==<span class="hljs-number">2</span>.<span class="hljs-number">2</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">yagmail</span>==<span class="hljs-number">0</span>.<span class="hljs-number">15</span>.<span class="hljs-number">293</span><br></code></pre></td></tr></table></figure></li><li>Dockerfile信息如下<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> python:<span class="hljs-number">3.9</span>-slim<br><br><span class="hljs-keyword">WORKDIR</span><span class="bash"> /frontend</span><br><span class="hljs-keyword">COPY</span><span class="bash"> requirements.txt requirements.txt</span><br><br><span class="hljs-comment">#RUN python -m pip install --quiet --upgrade pip -i https://pypi.tuna.tsinghua.edu.cn/simple --trusted-host pypi.tuna.tsinghua.edu.cn</span><br><span class="hljs-keyword">RUN</span><span class="bash"> python -m pip install -r requirements.txt</span><br><br><span class="hljs-keyword">ADD</span><span class="bash"> . .</span><br><br><span class="hljs-keyword">CMD</span><span class="bash"> [<span class="hljs-string">&quot;python&quot;</span>, <span class="hljs-string">&quot;fapp.py&quot;</span>]</span><br></code></pre></td></tr></table></figure>在以上两个文件的基础下build镜像<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">docker <span class="hljs-keyword">build </span>-t frontend:<span class="hljs-built_in">v1</span> .<br></code></pre></td></tr></table></figure>成功，，，报错。网上扒了好多信息大部分说是pip版本较低需要升级等等，测试了好多次，依然报错。不过build的时候发现一直卡在ProDy这个模块，于是想着就单独安装这一个模块试试。在各种尝试下发现是ProDy模块的版本问题，真的是巨坑。</li></ul><h4 id="成功编译"><a href="#成功编译" class="headerlink" title="成功编译"></a>成功编译</h4><ul><li>requirements.txt信息如下<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">colorama</span>==<span class="hljs-number">0</span>.<span class="hljs-number">4</span>.<span class="hljs-number">4</span><br><span class="hljs-attribute">Flask</span>==<span class="hljs-number">2</span>.<span class="hljs-number">1</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">Flask_Cors</span>==<span class="hljs-number">3</span>.<span class="hljs-number">0</span>.<span class="hljs-number">10</span><br><span class="hljs-attribute">Flask_Executor</span>==<span class="hljs-number">1</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">Flask_SocketIO</span>==<span class="hljs-number">5</span>.<span class="hljs-number">3</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">numpy</span>==<span class="hljs-number">1</span>.<span class="hljs-number">22</span>.<span class="hljs-number">4</span><br><span class="hljs-attribute">pandas</span>==<span class="hljs-number">1</span>.<span class="hljs-number">3</span>.<span class="hljs-number">5</span><br><span class="hljs-attribute">ProDy</span>==<span class="hljs-number">2</span>.<span class="hljs-number">4</span>.<span class="hljs-number">0</span>           # 升级到最新版本<br><span class="hljs-attribute">redis</span>==<span class="hljs-number">3</span>.<span class="hljs-number">5</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">toml</span>==<span class="hljs-number">0</span>.<span class="hljs-number">10</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">ulid</span>==<span class="hljs-number">1</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">ulid_py</span>==<span class="hljs-number">1</span>.<span class="hljs-number">1</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">Werkzeug</span>==<span class="hljs-number">2</span>.<span class="hljs-number">2</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">yagmail</span>==<span class="hljs-number">0</span>.<span class="hljs-number">15</span>.<span class="hljs-number">293</span><br></code></pre></td></tr></table></figure></li><li>Dockerfile信息如下<figure class="highlight hsp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs hsp">FROM python:<span class="hljs-number">3.9</span>-slim<br><br>WORKDIR /frontend<br>COPY requirements.txt requirements.txt<br><br><span class="hljs-keyword">RUN</span> apt update &amp;&amp; \<br>    apt install -y gcc g++<br><br><span class="hljs-meta">#RUN python -m pip install --quiet --upgrade pip -i https:<span class="hljs-comment">//pypi.tuna.tsinghua.edu.cn/simple --trusted-host pypi.tuna.tsinghua.edu.cn</span></span><br><span class="hljs-keyword">RUN</span> python -m pip install -r requirements.txt -i https:<span class="hljs-comment">//pypi.tuna.tsinghua.edu.cn/simple --trusted-host pypi.tuna.tsinghua.edu.cn</span><br><br><span class="hljs-meta">#ADD . .</span><br>COPY . .<br><br><span class="hljs-meta">#<span class="hljs-meta-keyword">CMD</span> [<span class="hljs-meta-string">&quot;python&quot;</span>, <span class="hljs-meta-string">&quot;fapp.py&quot;</span>]</span><br>ENTRYPOINT [<span class="hljs-string">&quot;python&quot;</span>, <span class="hljs-string">&quot;fapp.py&quot;</span>] <span class="hljs-meta"># ENTRYPOINT 指定了容器启动时要运行的命令，而 <span class="hljs-meta-keyword">CMD</span> 则是指定运行这个命令时的默认参数。默认参数可通过docker run命令后的参数来覆盖它</span><br></code></pre></td></tr></table></figure>在以上两个文件的基础下build镜像，测试中发现安装prody需要gcc和g++<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">docker <span class="hljs-keyword">build </span>-t frontend:<span class="hljs-built_in">v1</span> .<br></code></pre></td></tr></table></figure></li></ul><h4 id="运行容器"><a href="#运行容器" class="headerlink" title="运行容器"></a>运行容器</h4><ul><li>获取镜像的详细信息<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gradle">docker <span class="hljs-keyword">inspect</span> 镜像ID号<br></code></pre></td></tr></table></figure></li><li>交互式运行<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">docker</span> run -it -p <span class="hljs-number">5001</span>:<span class="hljs-number">5001</span> frontend:v<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure></li><li>交互式进入镜像<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">docker</span> run -it -p <span class="hljs-number">5001</span>:<span class="hljs-number">5001</span> frontend:v<span class="hljs-number">1</span> bash<br></code></pre></td></tr></table></figure></li><li>分离模式下运行 docker 容器<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">docker</span> run -d -p <span class="hljs-number">5001</span>:<span class="hljs-number">5001</span> --name saas frontend:v<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure></li><li>查看运行容器的ip<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">docker</span> inspect a<span class="hljs-number">7</span>a<span class="hljs-number">17666</span>fdd<span class="hljs-number">9</span> | grep -i ipaddress      # inspect后为容器id或容器name<br></code></pre></td></tr></table></figure></li><li>进入已经运行的容器<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">docker</span> exec -it a<span class="hljs-number">7</span>a<span class="hljs-number">17666</span>fdd<span class="hljs-number">9</span> bash        # 参数 -it 后为容器id, 另外使用attach也可进入，不过exit的时候容器会停止，而exec不会<br></code></pre></td></tr></table></figure></li><li>挂载数据卷,若添加多个数据卷,继续添加 -v 参数即可<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">docker run -it -p <span class="hljs-number">5001</span>:<span class="hljs-number">5001</span> --net=host --name saas -v <span class="hljs-regexp">/share/</span>saas<span class="hljs-regexp">/frontend:/</span>frontend frontend:v1<br></code></pre></td></tr></table></figure></li></ul><h4 id="容器连接宿主机redis"><a href="#容器连接宿主机redis" class="headerlink" title="容器连接宿主机redis"></a>容器连接宿主机redis</h4><p>Docker启动容器的网络模式如下</p><ul><li>Host : 容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口</li><li>Container : 创建的容器不会创建自己的网卡，配置自己的IP，而是和一个指定的容器共享IP、端口范围</li><li>None : 该模式关闭了容器的网络功能</li><li>Bridge : 默认为该模式，此模式会为每一个容器分配、设置IP等，并将容器连接到一个docker0虚拟网桥，通过docker0网桥以及iptables nat表配置与宿主机通信<br>使用host模式启动容器，以方便连接宿主机redis服务<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">docker <span class="hljs-builtin-name">run</span> -d -p 5001:5001 <span class="hljs-attribute">--net</span>=host --name saas frontend:v1<br></code></pre></td></tr></table></figure></li></ul><h4 id="docker常用命令"><a href="#docker常用命令" class="headerlink" title="docker常用命令"></a>docker常用命令</h4><ul><li>列出所有容器ID，包括停止的<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">docker ps -aq</span><br></code></pre></td></tr></table></figure></li><li>停止所有的container<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">docker stop <span class="hljs-constructor">$(<span class="hljs-params">docker</span> <span class="hljs-params">ps</span> -<span class="hljs-params">aq</span>)</span><br></code></pre></td></tr></table></figure></li><li>删除所有container<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">docker rm <span class="hljs-constructor">$(<span class="hljs-params">docker</span> <span class="hljs-params">ps</span> -<span class="hljs-params">aq</span>)</span><br></code></pre></td></tr></table></figure></li><li>删除tag为none的镜像<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">docker rmi <span class="hljs-constructor">$(<span class="hljs-params">docker</span> <span class="hljs-params">images</span> | <span class="hljs-params">grep</span> <span class="hljs-string">&quot;^&lt;none&gt;&quot;</span> | <span class="hljs-params">awk</span> <span class="hljs-string">&quot;&#123;print $3&#125;&quot;</span>)</span><br></code></pre></td></tr></table></figure></li><li>将镜像保存为本地文件<figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs fortran">docker <span class="hljs-keyword">save</span> -o 存储文件名 镜像ID号<br></code></pre></td></tr></table></figure></li><li>恢复镜像<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">docker load -<span class="hljs-selector-tag">i</span> 存储文件名<br></code></pre></td></tr></table></figure></li></ul><h4 id="常用-Dockerfile-操作指令"><a href="#常用-Dockerfile-操作指令" class="headerlink" title="常用 Dockerfile 操作指令"></a>常用 Dockerfile 操作指令</h4><ul><li>ARG—— 定义创建镜像过程中使用的变量 ，唯一一个可以在 FROM 之前定义 。</li><li>FROM——基于某个镜像， FROM前面只能有一个或多个ARG指令 。</li><li>MAINTAINER（已弃用） —— 镜像维护者姓名或邮箱地址 。</li><li>VOLUME —— 指定容器挂载点到宿主机自动生成的目录或其他容器</li><li>RUN——执行镜像里的命令，跟在 liunx 执行命令一样，只需要在前面加上 RUN 关键词就行。</li><li>COPY——复制本地（宿主机）上的文件到镜像。</li><li>ADD——复制并解压（宿主机）上的压缩文件到镜像。</li><li>ENV——设置环境变量。</li><li>WORKDIR —— 为 RUN、CMD、ENTRYPOINT、COPY 和 ADD 设置工作目录，就是切换目录 。</li><li>USER —— 为 RUN、CMD、和 ENTRYPOINT 执行命令指定运行用户。</li><li>EXPOSE —— 声明容器的服务端口（仅仅是声明） 。</li><li>CMD—— 容器启动后执行的命令 ，多个 CMD 只会执行最后一个，跟 ENTRYPOINT 的区别是，CMD 可以作为 ENTRYPOINT 的参数，且会被 yaml 文件里的 command 覆盖。</li><li>ENTRYPOINT—— 容器启动后执行的命令 ，多个只会执行最后一个。</li><li>HEALTHCHECH —— 健康检查 。</li><li>ONBUILD——它后面跟的是其它指令，比如 RUN, COPY 等，而这些指令，在当前镜像构建时并不会被执行。只有当以当前镜像为基础镜像，去构建下一级镜像的时候才会被执行。</li><li>LABEL——LABEL 指令用来给镜像添加一些元数据（metadata），以键值对的形式 ，替换 MAINTAINER。</li></ul><p>参考：<br>    <a href="https://mp.weixin.qq.com/s/fDBvrQl3P5wT9nP-hpQfcA">https://mp.weixin.qq.com/s/fDBvrQl3P5wT9nP-hpQfcA</a><br>    <a href="https://zhuanlan.zhihu.com/p/430989391">https://zhuanlan.zhihu.com/p/430989391</a><br>    <a href="https://www.cnblogs.com/orion-orion/p/16268011.html">https://www.cnblogs.com/orion-orion/p/16268011.html</a><br>    <a href="http://www.xiaomaidong.com/?p=1148">http://www.xiaomaidong.com/?p=1148</a><br>    <a href="https://mp.weixin.qq.com/s/jA3VZG068FlMGJbesj_MWA">https://mp.weixin.qq.com/s/jA3VZG068FlMGJbesj_MWA</a></p>]]></content>
    
    
    <categories>
      
      <category>TroubleShoot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>centos7安装openbabel踩坑</title>
    <link href="/2023/03/14/centos7%E5%AE%89%E8%A3%85openbabel%E8%B8%A9%E5%9D%91/"/>
    <url>/2023/03/14/centos7%E5%AE%89%E8%A3%85openbabel%E8%B8%A9%E5%9D%91/</url>
    
    <content type="html"><![CDATA[<h2 id="openbabel踩坑"><a href="#openbabel踩坑" class="headerlink" title="openbabel踩坑"></a>openbabel踩坑</h2><span id="more"></span><h4 id="源码安装报错，报错信息如下："><a href="#源码安装报错，报错信息如下：" class="headerlink" title="源码安装报错，报错信息如下："></a>源码安装报错，报错信息如下：</h4><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs vbnet">CMakeFiles/xtcformat.dir/xtcformat.cpp.o: <span class="hljs-keyword">In</span> <span class="hljs-keyword">function</span> `OpenBabel::XTCFormat::xdropen(XDR*, <span class="hljs-type">char</span> <span class="hljs-keyword">const</span>*, <span class="hljs-type">char</span> <span class="hljs-keyword">const</span>*)<span class="hljs-comment">&#x27;:</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>xd2): undefined reference <span class="hljs-keyword">to</span> `xdrstdio_create<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x11b): undefined reference <span class="hljs-keyword">to</span> `xdrstdio_create<span class="hljs-comment">&#x27;</span><br>CMakeFiles/xtcformat.dir/xtcformat.cpp.o: <span class="hljs-keyword">In</span> <span class="hljs-keyword">function</span> `OpenBabel::XTCFormat::xdr3dfcoord(XDR*, float*, int*, float*)<span class="hljs-comment">&#x27;:</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x888): undefined reference <span class="hljs-keyword">to</span> `xdr_int<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x8e6): undefined reference <span class="hljs-keyword">to</span> `xdr_float<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x951): undefined reference <span class="hljs-keyword">to</span> `xdr_int<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x961): undefined reference <span class="hljs-keyword">to</span> `xdr_int<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x971): undefined reference <span class="hljs-keyword">to</span> `xdr_int<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x981): undefined reference <span class="hljs-keyword">to</span> `xdr_int<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x991): undefined reference <span class="hljs-keyword">to</span> `xdr_int<span class="hljs-comment">&#x27;</span><br>CMakeFiles/xtcformat.dir/xtcformat.cpp.o:xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x9a1): more undefined references <span class="hljs-keyword">to</span> `xdr_int<span class="hljs-comment">&#x27; follow</span><br>CMakeFiles/xtcformat.dir/xtcformat.cpp.o: <span class="hljs-keyword">In</span> <span class="hljs-keyword">function</span> `OpenBabel::XTCFormat::xdr3dfcoord(XDR*, float*, int*, float*)<span class="hljs-comment">&#x27;:</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>xab7): undefined reference <span class="hljs-keyword">to</span> `xdr_opaque<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>xd33): undefined reference <span class="hljs-keyword">to</span> `xdr_int<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>xd5e): undefined reference <span class="hljs-keyword">to</span> `xdr_float<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>xd93): undefined reference <span class="hljs-keyword">to</span> `xdr_float<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>xd98): undefined reference <span class="hljs-keyword">to</span> `xdr_vector<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>xdb2): undefined reference <span class="hljs-keyword">to</span> `xdr_float<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x10ea): undefined reference <span class="hljs-keyword">to</span> `xdr_int<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x10fa): undefined reference <span class="hljs-keyword">to</span> `xdr_int<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x110a): undefined reference <span class="hljs-keyword">to</span> `xdr_int<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x111a): undefined reference <span class="hljs-keyword">to</span> `xdr_int<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x112a): undefined reference <span class="hljs-keyword">to</span> `xdr_int<span class="hljs-comment">&#x27;</span><br>CMakeFiles/xtcformat.dir/xtcformat.cpp.o:xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x113a): more undefined references <span class="hljs-keyword">to</span> `xdr_int<span class="hljs-comment">&#x27; follow</span><br>CMakeFiles/xtcformat.dir/xtcformat.cpp.o: <span class="hljs-keyword">In</span> <span class="hljs-keyword">function</span> `OpenBabel::XTCFormat::xdr3dfcoord(XDR*, float*, int*, float*)<span class="hljs-comment">&#x27;:</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x1b0c): undefined reference <span class="hljs-keyword">to</span> `xdr_opaque<span class="hljs-comment">&#x27;</span><br>CMakeFiles/xtcformat.dir/xtcformat.cpp.o: <span class="hljs-keyword">In</span> <span class="hljs-keyword">function</span> `OpenBabel::XTCFormat::ReadMolecule(OpenBabel::OBBase*, OpenBabel::OBConversion*)<span class="hljs-comment">&#x27;:</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x1d67): undefined reference <span class="hljs-keyword">to</span> `xdr_int<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x1d80): undefined reference <span class="hljs-keyword">to</span> `xdr_int<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x1da4): undefined reference <span class="hljs-keyword">to</span> `xdr_int<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x1db4): undefined reference <span class="hljs-keyword">to</span> `xdr_float<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x1dc4): undefined reference <span class="hljs-keyword">to</span> `xdr_float<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x1dd4): undefined reference <span class="hljs-keyword">to</span> `xdr_float<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x1de4): undefined reference <span class="hljs-keyword">to</span> `xdr_float<span class="hljs-comment">&#x27;</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x1df4): undefined reference <span class="hljs-keyword">to</span> `xdr_float<span class="hljs-comment">&#x27;</span><br>CMakeFiles/xtcformat.dir/xtcformat.cpp.o:xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>x1e04): more undefined references <span class="hljs-keyword">to</span> `xdr_float<span class="hljs-comment">&#x27; follow</span><br>CMakeFiles/xtcformat.dir/xtcformat.cpp.o: <span class="hljs-keyword">In</span> <span class="hljs-keyword">function</span> `OpenBabel::XTCFormat::xdr3dfcoord(XDR*, float*, int*, float*)<span class="hljs-comment">&#x27;:</span><br>xtcformat.cpp:(.<span class="hljs-keyword">text</span>+<span class="hljs-number">0</span>xd74): undefined reference <span class="hljs-keyword">to</span> `xdr_vector<span class="hljs-comment">&#x27;</span><br><span class="hljs-symbol">collect2:</span> <span class="hljs-keyword">error</span>: ld returned <span class="hljs-number">1</span> <span class="hljs-keyword">exit</span> status<br>make[<span class="hljs-number">2</span>]: *** [src/formats/CMakeFiles/xtcformat.dir/build.make:<span class="hljs-number">105</span>: <span class="hljs-keyword">lib</span>/xtcformat.so] <span class="hljs-keyword">Error</span> <span class="hljs-number">1</span><br>make[<span class="hljs-number">1</span>]: *** [CMakeFiles/Makefile2:<span class="hljs-number">4523</span>: src/formats/CMakeFiles/xtcformat.dir/all] <span class="hljs-keyword">Error</span> <span class="hljs-number">2</span><br>make[<span class="hljs-number">1</span>]: *** Waiting <span class="hljs-keyword">for</span> unfinished jobs....<br></code></pre></td></tr></table></figure><p>没找到解决方法。遂放弃。</p><h4 id="conda-安装"><a href="#conda-安装" class="headerlink" title="conda 安装"></a>conda 安装</h4><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">conda <span class="hljs-keyword">install</span> -y -c conda-forge openbabel<br></code></pre></td></tr></table></figure><p>安装还挺快。接下来绑定python<br>从pypi上下载openbabel的源码包（pip install直接安装会报错），下载地址<a href="https://pypi.org/project/openbabel/#files">https://pypi.org/project/openbabel/#files</a><br>解压后安装命令如下</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs awk">cd openbabel-<span class="hljs-number">3.1</span>.<span class="hljs-number">1.1</span><br><span class="hljs-comment"># -I 指定conda安装openbabel的include的路径，-L 指定conda安装openbabel的lib的路径</span><br>python setup.py build_ext -I<span class="hljs-variable">$CURR_DIR</span><span class="hljs-regexp">/envs/</span>Sdocking<span class="hljs-regexp">/include/</span>openbabel3<span class="hljs-regexp">/ -L$CURR_DIR/</span>envs<span class="hljs-regexp">/Sdocking/</span>lib<span class="hljs-regexp">/openbabel/</span><span class="hljs-number">3.1</span>.<span class="hljs-number">0</span><br><span class="hljs-comment"># --prefix指定安装路径，最好指定下，默认会安装到当前目录，后续执行 import openbabel的时候会报错找不到</span><br>python setup.py install --prefix=<span class="hljs-variable">$CURR_DIR</span><span class="hljs-regexp">/envs/</span>Sdocking<span class="hljs-regexp">/lib/</span>python3.<span class="hljs-number">7</span>/site-packages<br></code></pre></td></tr></table></figure><p>安装完确认是否安装成功</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-title">python</span> -c &#x27;<span class="hljs-keyword">import</span> openbabel&#x27;<br></code></pre></td></tr></table></figure><p>参考：<a href="https://blog.csdn.net/qq_32115939/article/details/120031684">https://blog.csdn.net/qq_32115939/article/details/120031684</a></p>]]></content>
    
    
    <categories>
      
      <category>TroubleShoot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>centos7</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>C++部署pytorch模型例子</title>
    <link href="/2023/03/08/C++%E9%83%A8%E7%BD%B2pytorch%E6%A8%A1%E5%9E%8B/"/>
    <url>/2023/03/08/C++%E9%83%A8%E7%BD%B2pytorch%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><h4 id="步骤1：将PyTorch模型转换为Torch脚本"><a href="#步骤1：将PyTorch模型转换为Torch脚本" class="headerlink" title="步骤1：将PyTorch模型转换为Torch脚本"></a>步骤1：将PyTorch模型转换为Torch脚本</h4><p>有两种将PyTorch模型转换为Torch脚本的方法。第一种称为跟踪，一种机制，其中通过使用示例输入对模型的结构进行一次评估，并记录这些 输入在模型中的流量，从而捕获模型的结构。这适用于有限使用控制流的模型。第二种方法是在模型中添加显式批注，以告知Torch Script编 译器可以根据Torch Script语言施加的约束直接解析和编译模型代码。<br>这里以第二种为例：</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> torch<br><span class="hljs-class"></span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-type">MyModule</span>(<span class="hljs-title">torch</span>.<span class="hljs-title">nn</span>.<span class="hljs-type">Module</span>):</span><br><span class="hljs-class">    def __init__(<span class="hljs-title">self</span>, <span class="hljs-type">N</span>, <span class="hljs-type">M</span>):</span><br><span class="hljs-class">        super(<span class="hljs-type">MyModule</span>, <span class="hljs-title">self</span>).__init__()</span><br><span class="hljs-class">        self.weight = torch.nn.<span class="hljs-type">Parameter</span>(<span class="hljs-title">torch</span>.<span class="hljs-title">rand</span>(<span class="hljs-type">N</span>, <span class="hljs-type">M</span>))</span><br><span class="hljs-class"></span><br><span class="hljs-class">    def forward(<span class="hljs-title">self</span>, <span class="hljs-title">input</span>):</span><br><span class="hljs-class">        if input.sum() &gt; 0:</span><br><span class="hljs-class">          output = self.weight.mv(<span class="hljs-title">input</span>)</span><br><span class="hljs-class">        else:</span><br><span class="hljs-class">          output = self.weight + input</span><br><span class="hljs-class">        return output</span><br><span class="hljs-class"></span><br><span class="hljs-class">my_module = <span class="hljs-type">MyModule</span>(10,20)</span><br><span class="hljs-class">sm = torch.jit.script(<span class="hljs-title">my_module</span>)</span><br><span class="hljs-class">sm.save(&#x27;<span class="hljs-title">model</span>.<span class="hljs-title">pt&#x27;</span>)</span><br></code></pre></td></tr></table></figure><p>保存上述代码为example-app.py, 运行后生成model.pt文件</p><h4 id="步骤2：在C-中加载脚本模块"><a href="#步骤2：在C-中加载脚本模块" class="headerlink" title="步骤2：在C++中加载脚本模块"></a>步骤2：在C++中加载脚本模块</h4><ul><li><p>编写一个example-app.cpp文件，内容如下</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;torch/script.h&gt;</span> <span class="hljs-comment">// One-stop header.</span></span><br><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;memory&gt;</span></span><br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* argv[])</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (argc != <span class="hljs-number">2</span>) &#123;<br>    std::cerr &lt;&lt; <span class="hljs-string">&quot;usage: example-app &lt;path-to-exported-script-module&gt;\n&quot;</span>;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>  &#125;<br><br><br>  torch::jit::script::Module <span class="hljs-keyword">module</span>;<br>  <span class="hljs-keyword">try</span> &#123;<br>    <span class="hljs-comment">// 使用以下命令从文件中反序列化脚本模块: torch::jit::load().</span><br>    <span class="hljs-keyword">module</span> = torch::jit::<span class="hljs-built_in">load</span>(argv[<span class="hljs-number">1</span>]);<br>  &#125;<br>  <span class="hljs-built_in"><span class="hljs-keyword">catch</span></span> (<span class="hljs-keyword">const</span> c10::Error&amp; e) &#123;<br>    std::cerr &lt;&lt; <span class="hljs-string">&quot;error loading the model\n&quot;</span>;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>  &#125;<br><br>  std::cout &lt;&lt; <span class="hljs-string">&quot;ok\n&quot;</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>&lt;torch/script.h&gt;</code>标头包含运行示例所需的LibTorch库中的所有相关包含。我们的应用程序接受序列化的PyTorch ScriptModule的文件路径 作为其唯一的命令行参数，然后使用<code>torch::jit::load()</code>函数继续对该模块进行反序列化，该函数将此文件路径作为输入。作为返回，我们 收到一个<code>Torch::jit::script::Module</code>对象。</p></li><li><p>编写 CMakeLists.txt，内容如下：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">cmake_minimum_required</span><span class="hljs-params">(VERSION <span class="hljs-number">3.15</span> FATAL_ERROR)</span></span><br><span class="hljs-function"><span class="hljs-title">project</span><span class="hljs-params">(example-app)</span></span><br><br><span class="hljs-function"><span class="hljs-title">set</span><span class="hljs-params">(CMAKE_CXX_STANDARD <span class="hljs-number">14</span>)</span></span><br><br><span class="hljs-comment">// 指定libtorch的安装目录，这里也可以使用cmake的时候指定，cmake参数:-DCMAKE_PREFIX_PATH</span><br><span class="hljs-function"><span class="hljs-title">set</span><span class="hljs-params">(Torch_DIR /share/apps/libtorch/libtorch-gpu/share/cmake/Torch)</span></span><br><span class="hljs-function"><span class="hljs-title">find_package</span><span class="hljs-params">(Torch REQUIRED)</span></span><br><br><span class="hljs-function"><span class="hljs-title">add_executable</span><span class="hljs-params">(example-app example-app.cpp)</span></span><br><span class="hljs-function"><span class="hljs-title">target_link_libraries</span><span class="hljs-params">(example-app <span class="hljs-string">&quot;$&#123;TORCH_LIBRARIES&#125;&quot;</span>)</span></span><br><span class="hljs-comment">// set_property(TARGET example-app PROPERTY CXX_STANDARD 11)</span><br></code></pre></td></tr></table></figure></li><li><p>构建应用程序</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">mkdir build<br><span class="hljs-keyword">cd</span> build<br><span class="hljs-string">//cmake</span> -DCMAKE_PREFIX_PATH=<span class="hljs-string">/path/to/libtorch</span> <span class="hljs-string">..</span><br>cmake <span class="hljs-string">..</span><br>make<br></code></pre></td></tr></table></figure></li><li><p>最后执行程序</p><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gams">./example-app <span class="hljs-keyword">model</span>.pt<br></code></pre></td></tr></table></figure><p>正常输出为ok</p></li></ul><p>参考：<a href="https://pytorch.panchuang.net/EigthSection/torchScript_in_C++/">https://pytorch.panchuang.net/EigthSection/torchScript_in_C++/</a></p>]]></content>
    
    
    <categories>
      
      <category>CPP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>torch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>centos7安装cudnn</title>
    <link href="/2023/03/08/centos7%E5%AE%89%E8%A3%85cudnn/"/>
    <url>/2023/03/08/centos7%E5%AE%89%E8%A3%85cudnn/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><h4 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h4><p>地址：<a href="https://developer.nvidia.com/rdp/cudnn-download">https://developer.nvidia.com/rdp/cudnn-download</a><br>cudnn需要注册登录才能下载，然后选择对应的版本进行下载，最开始我下载的是<code>Local Installer for RedHat/Centos 7.1 x84_64 (RPM)</code>，然后使用<code>sudo yum install</code>命令安装这个rpm包，最后发现不知道装哪了，也找不到cudnn的头文件。最后只能再下载另一个文件<code>Local Installer for Linux x86_64 (Tar)</code>，即这个tar包。<br>下载下来是个xz格式压缩包，首先解压：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">xz</span> -xzJf <span class="hljs-regexp">*.xz</span><br></code></pre></td></tr></table></figure><p>解压后会有两个目录：include 和 lib</p><h4 id="拷贝对应的文件到cuda下"><a href="#拷贝对应的文件到cuda下" class="headerlink" title="拷贝对应的文件到cuda下"></a>拷贝对应的文件到cuda下</h4><p>官网的命令如下：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">sudo cp cuda<span class="hljs-regexp">/include/</span>cudnn.h <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda/i</span>nclude<br>sudo cp cuda<span class="hljs-regexp">/lib64/</span>libcudnn* <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda/</span>lib64<br>sudo chmod a+r <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda/i</span>nclude<span class="hljs-regexp">/cudnn.h /u</span>sr<span class="hljs-regexp">/local/</span>cuda<span class="hljs-regexp">/lib64/</span>libcudnn*<br></code></pre></td></tr></table></figure><p>按照官网的方法会可能会有bug，可能现在新的cudnn版本信息没有包含在cudnn.h里，所以我这里把include下的文件都进行了拷贝</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">sudo cp cuda<span class="hljs-regexp">/include/</span>cudnn* <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda/i</span>nclude<br>sudo cp cuda<span class="hljs-regexp">/lib64/</span>libcudnn* <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda/</span>lib64<br>sudo chmod a+r <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda/i</span>nclude<span class="hljs-regexp">/cudnn* /u</span>sr<span class="hljs-regexp">/local/</span>cuda<span class="hljs-regexp">/lib64/</span>libcudnn*<br></code></pre></td></tr></table></figure><p>最后使用cmake进行编译使用libtorch的时候成功找到了cudnn。</p><p>参考：<a href="https://docs.nvidia.com/deeplearning/cudnn/archives/cudnn_764/cudnn-install/index.html#install-linux">https://docs.nvidia.com/deeplearning/cudnn/archives/cudnn_764/cudnn-install/index.html#install-linux</a><br>    <a href="http://zhaoxuhui.top/blog/2021/04/13/libtorch-installation-and-use.html">http://zhaoxuhui.top/blog/2021/04/13/libtorch-installation-and-use.html</a></p>]]></content>
    
    
    <categories>
      
      <category>cuda</category>
      
    </categories>
    
    
    <tags>
      
      <tag>cudnn</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>3dmol.js平移、缩放、旋转box</title>
    <link href="/2023/02/14/3dmol-js%E5%B9%B3%E7%A7%BB%E3%80%81%E7%BC%A9%E6%94%BE%E3%80%81%E6%97%8B%E8%BD%ACbox/"/>
    <url>/2023/02/14/3dmol-js%E5%B9%B3%E7%A7%BB%E3%80%81%E7%BC%A9%E6%94%BE%E3%80%81%E6%97%8B%E8%BD%ACbox/</url>
    
    <content type="html"><![CDATA[<h2 id="使用3dmol-js展示蛋白pocket-box-并对box进行平移旋转等"><a href="#使用3dmol-js展示蛋白pocket-box-并对box进行平移旋转等" class="headerlink" title="使用3dmol.js展示蛋白pocket(box), 并对box进行平移旋转等"></a>使用3dmol.js展示蛋白pocket(box), 并对box进行平移旋转等</h2><span id="more"></span><h5 id="首先添加蛋白和box"><a href="#首先添加蛋白和box" class="headerlink" title="首先添加蛋白和box"></a>首先添加蛋白和box</h5><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><code class="hljs nix">var <span class="hljs-attr">data</span> = reader.result;<br><span class="hljs-keyword">let</span> <span class="hljs-attr">element</span> = $(&#x27;<span class="hljs-comment">#protein-box&#x27;);  # html中的id标签</span><br>// <span class="hljs-keyword">let</span> <span class="hljs-attr">config</span> = &#123; backgroundColor : &#x27;<span class="hljs-comment">#E0F7FA&#x27;&#125;;</span><br><br>// <span class="hljs-attr">viewer</span> = $<span class="hljs-number">3</span>Dmol.createViewer( element, config );<br><span class="hljs-attr">viewer</span> = $<span class="hljs-number">3</span>Dmol.createViewer( element);<br>var <span class="hljs-attr">ligandData</span> = subLigandPdb(data);<br><span class="hljs-attr">ligandData</span> = pdbqtToPDB(ligandData);<br><br><span class="hljs-attr">pdbMol</span> = viewer.addModel( data, <span class="hljs-string">&quot;pdb&quot;</span> );                       <span class="hljs-comment">/* load data */</span>     <br>pdbMol.setStyle(&#123;&#125;, &#123;cartoon: &#123;color: &#x27;spectrum&#x27;&#125;&#125;);  <span class="hljs-comment">/* style all atoms */</span><br>// var <span class="hljs-attr">ligandMol</span> = viewer.addModel( ligandData, <span class="hljs-string">&quot;pdb&quot;</span>, &#123;<span class="hljs-string">&quot;keepH&quot;</span>: <span class="hljs-literal">true</span>&#125;);<br>// ligandMol.setStyle(&#123;&#125;,&#123;<span class="hljs-string">&quot;stick&quot;</span>: &#123; <span class="hljs-string">&quot;radius&quot;</span>: <span class="hljs-number">0.4</span> &#125;&#125;);<br><br>        <br>var <span class="hljs-attr">atoms</span> = viewer.selectedAtoms(&#123;&#125;);<br><span class="hljs-keyword">let</span> <span class="hljs-attr">len</span> = atoms.length;<br><span class="hljs-keyword">let</span> <span class="hljs-attr">xTot</span> = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">let</span> <span class="hljs-attr">yTot</span> = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">let</span> <span class="hljs-attr">zTot</span> = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">let</span> <span class="hljs-attr">minX</span> = <span class="hljs-number">1</span>e100;<br><span class="hljs-keyword">let</span> <span class="hljs-attr">minY</span> = <span class="hljs-number">1</span>e100;<br><span class="hljs-keyword">let</span> <span class="hljs-attr">minZ</span> = <span class="hljs-number">1</span>e100;<br><span class="hljs-keyword">let</span> <span class="hljs-attr">maxX</span> = -<span class="hljs-number">1</span>e100;<br><span class="hljs-keyword">let</span> <span class="hljs-attr">maxY</span> = -<span class="hljs-number">1</span>e100;<br><span class="hljs-keyword">let</span> <span class="hljs-attr">maxZ</span> = -<span class="hljs-number">1</span>e100;<br>for (var <span class="hljs-attr">i</span> = <span class="hljs-number">0</span>; i &lt; len; i++) &#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-attr">atom</span> = atoms[i];<br>    <span class="hljs-keyword">let</span> <span class="hljs-attr">x</span> = atom.x;<br>    <span class="hljs-keyword">let</span> <span class="hljs-attr">y</span> = atom.y;<br>    <span class="hljs-keyword">let</span> <span class="hljs-attr">z</span> = atom.z;<br>    xTot += x;<br>    yTot += y;<br>    zTot += z;<br>    <span class="hljs-keyword">if</span> (x &gt; maxX) &#123;<br>        <span class="hljs-attr">maxX</span> = x;<br>    &#125;<br>    <span class="hljs-keyword">if</span> (y &gt; maxY) &#123;<br>        <span class="hljs-attr">maxY</span> = y;<br>    &#125;<br>    <span class="hljs-keyword">if</span> (z &gt; maxZ) &#123;<br>        <span class="hljs-attr">maxZ</span> = z;<br>    &#125;<br>    <span class="hljs-keyword">if</span> (x &lt; minX) &#123;<br>        <span class="hljs-attr">minX</span> = x;<br>    &#125;<br>    <span class="hljs-keyword">if</span> (y &lt; minY) &#123;<br>        <span class="hljs-attr">minY</span> = y;<br>    &#125;<br>    <span class="hljs-keyword">if</span> (z &lt; minZ) &#123;<br>        <span class="hljs-attr">minZ</span> = z;<br>    &#125;<br>&#125;<br><span class="hljs-attr">centerX</span> = xTot / len;<br><span class="hljs-attr">centerY</span> = yTot / len;<br><span class="hljs-attr">centerZ</span> = zTot / len;<br><span class="hljs-attr">sizeX</span> = <span class="hljs-number">0.25</span> * (maxX - minX);<br><span class="hljs-attr">sizeY</span> = <span class="hljs-number">0.25</span> * (maxY - minY);<br><span class="hljs-attr">sizeZ</span> = <span class="hljs-number">0.25</span> * (maxZ - minZ);<br><br>//定义一些初始值<br><span class="hljs-attr">sizeWx</span> = sizeX;<br><span class="hljs-attr">sizeWx0</span> = sizeX;<br><span class="hljs-attr">sizeWy</span> = <span class="hljs-number">0</span>;<br><span class="hljs-attr">sizeWy0</span> = <span class="hljs-number">0</span>;<br><span class="hljs-attr">sizeWz</span> = <span class="hljs-number">0</span>;<br><span class="hljs-attr">sizeWz0</span> = <span class="hljs-number">0</span>;<br><span class="hljs-attr">sizeW</span> = sizeX;<br><span class="hljs-attr">rotateX</span> = <span class="hljs-number">0</span>;<br><span class="hljs-attr">sumX</span> = <span class="hljs-number">0</span>;<br><br><span class="hljs-attr">sizeHx</span> = <span class="hljs-number">0</span>;<br><span class="hljs-attr">sizeHx0</span> = <span class="hljs-number">0</span>;<br><span class="hljs-attr">sizeHy</span> = sizeY;<br><span class="hljs-attr">sizeHy0</span> = sizeY;<br><span class="hljs-attr">sizeHz</span> = <span class="hljs-number">0</span>;<br><span class="hljs-attr">sizeHz0</span> = <span class="hljs-number">0</span>;<br><span class="hljs-attr">sizeH</span> = sizeY;<br><span class="hljs-attr">rotateY</span> = <span class="hljs-number">0</span>;<br><span class="hljs-attr">sumY</span> = <span class="hljs-number">0</span>;<br><br><span class="hljs-attr">sizeDx</span> = <span class="hljs-number">0</span>;<br><span class="hljs-attr">sizeDx0</span> = <span class="hljs-number">0</span>;<br><span class="hljs-attr">sizeDy</span> = <span class="hljs-number">0</span>;<br><span class="hljs-attr">sizeDy0</span> = <span class="hljs-number">0</span>;<br><span class="hljs-attr">sizeDz</span> = sizeZ;<br><span class="hljs-attr">sizeDz0</span> = sizeZ;<br><span class="hljs-attr">sizeD</span>  = sizeZ;<br><span class="hljs-attr">rotateZ</span> = <span class="hljs-number">0</span>;<br><span class="hljs-attr">sumZ</span> = <span class="hljs-number">0</span>;<br><br>$(<span class="hljs-string">&quot;#CenterX&quot;</span>).val(centerX.toFixed(<span class="hljs-number">2</span>));<br>$(<span class="hljs-string">&quot;#rangeCenterX&quot;</span>).val(centerX);<br>$(<span class="hljs-string">&quot;#CenterY&quot;</span>).val(centerY.toFixed(<span class="hljs-number">2</span>));<br>$(<span class="hljs-string">&quot;#rangeCenterY&quot;</span>).val(centerY);<br>$(<span class="hljs-string">&quot;#CenterZ&quot;</span>).val(centerZ.toFixed(<span class="hljs-number">2</span>));<br>$(<span class="hljs-string">&quot;#rangeCenterZ&quot;</span>).val(centerZ);<br>$(&#x27;<span class="hljs-comment">#SizeX&#x27;).val(sizeX.toFixed(2));</span><br>$(<span class="hljs-string">&quot;#rangeSizeX&quot;</span>).val(sizeX);<br>$(&#x27;<span class="hljs-comment">#SizeY&#x27;).val(sizeY.toFixed(2));</span><br>$(<span class="hljs-string">&quot;#rangeSizeY&quot;</span>).val(sizeY);<br>$(&#x27;<span class="hljs-comment">#SizeZ&#x27;).val(sizeZ.toFixed(2));</span><br>$(<span class="hljs-string">&quot;#rangeSizeZ&quot;</span>).val(sizeZ);<br>$(<span class="hljs-string">&quot;#RotateX&quot;</span>).val(<span class="hljs-number">0</span>);<br>$(<span class="hljs-string">&quot;#rangeRotateX&quot;</span>).val(<span class="hljs-number">0</span>);<br>$(<span class="hljs-string">&quot;#RotateY&quot;</span>).val(<span class="hljs-number">0</span>);<br>$(<span class="hljs-string">&quot;#rangeRotateY&quot;</span>).val(<span class="hljs-number">0</span>);<br>$(<span class="hljs-string">&quot;#RotateZ&quot;</span>).val(<span class="hljs-number">0</span>);<br>$(<span class="hljs-string">&quot;#rangeRotateZ&quot;</span>).val(<span class="hljs-number">0</span>);<br><br><span class="hljs-attr">centerX0</span> = centerX;<br><span class="hljs-attr">centerY0</span> = centerY;<br><span class="hljs-attr">centerZ0</span> = centerZ;<br><br>viewer.addBox(&#123;center:&#123;x:centerX,y:centerY,z:centerZ&#125;,<br>    // dimensions: &#123;w: sizeW, h: sizeH, d: sizeD&#125;,<br>    dimensions:  &#123;&#x27;w&#x27;: &#123;&#x27;x&#x27;:sizeWx, &#x27;y&#x27;:sizeWy, &#x27;z&#x27;:sizeWz&#125;, <br>                  &#x27;h&#x27;: &#123;&#x27;x&#x27;:sizeHx, &#x27;y&#x27;:sizeHy, &#x27;z&#x27;:sizeHz&#125;,  <br>                  &#x27;d&#x27;: &#123;&#x27;x&#x27;:sizeDx, &#x27;y&#x27;:sizeDy, &#x27;z&#x27;:sizeDz&#125;&#125;, <br>    color:&#x27;yellow&#x27;, <br>    opacity: <span class="hljs-number">0.8</span>              <br>    &#125;);<br><br>viewer.addLine(&#123;color:&#x27;red&#x27;,start:&#123;x:centerX0,y:centerY0,z:centerZ0&#125;,end:&#123;x:centerX0+<span class="hljs-number">25</span>,y:centerY0,z:centerZ0&#125;&#125;);<br>viewer.addLine(&#123;color:&#x27;blue&#x27;,start:&#123;x:centerX0,y:centerY0,z:centerZ0&#125;,end:&#123;x:centerX0,y:centerY0+<span class="hljs-number">25</span>,z:centerZ0&#125;&#125;);<br>viewer.addLine(&#123;color:&#x27;green&#x27;,start:&#123;x:centerX0,y:centerY0,z:centerZ0&#125;,end:&#123;x:centerX0,y:centerY0,z:centerZ0+<span class="hljs-number">25</span>&#125;&#125;);<br><br>viewer.zoomTo();                                        <span class="hljs-comment">/* set camera */</span><br>viewer.render();                                      <span class="hljs-comment">/* render scene */</span><br>viewer.zoom(<span class="hljs-number">1.2</span>, <span class="hljs-number">1000</span>);    <br></code></pre></td></tr></table></figure><h5 id="更新box"><a href="#更新box" class="headerlink" title="更新box"></a>更新box</h5><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br></pre></td><td class="code"><pre><code class="hljs php"><span class="hljs-comment">// 更新box</span><br><span class="hljs-keyword">var</span> updateBox = <span class="hljs-function"><span class="hljs-keyword">function</span> (<span class="hljs-params"><span class="hljs-variable">$input</span></span>) </span>&#123;<br><span class="hljs-comment">/*拖动滑块的事件，内容可自行定义*/</span><br>    <span class="hljs-keyword">var</span> rangeSizeArray = [<span class="hljs-string">&#x27;rangeSizeX&#x27;</span>, <span class="hljs-string">&#x27;rangeSizeY&#x27;</span>, <span class="hljs-string">&#x27;rangeSizeZ&#x27;</span>]<br>    <span class="hljs-keyword">var</span> var_type = <span class="hljs-variable">$input</span>.id;<br>    <span class="hljs-keyword">if</span> (var_type===<span class="hljs-string">&#x27;rangeCenterX&#x27;</span>)<br>    &#123;<br>        centerX = Number(<span class="hljs-variable">$input</span>.value);<br>        $(<span class="hljs-string">&quot;#CenterX&quot;</span>).val(<span class="hljs-variable">$input</span>.value);<br>    &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (var_type===<span class="hljs-string">&#x27;rangeCenterY&#x27;</span>)<br>    &#123;<br>        centerY = Number(<span class="hljs-variable">$input</span>.value);<br>        $(<span class="hljs-string">&quot;#CenterY&quot;</span>).val(<span class="hljs-variable">$input</span>.value);<br>    &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (var_type===<span class="hljs-string">&#x27;rangeCenterZ&#x27;</span>)<br>    &#123;<br>        centerZ = Number(<span class="hljs-variable">$input</span>.value);<br>        $(<span class="hljs-string">&quot;#CenterZ&quot;</span>).val(<span class="hljs-variable">$input</span>.value);<br>    &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (rangeSizeArray.indexOf(var_type) !== -<span class="hljs-number">1</span>)<br>    &#123;   <br>        <span class="hljs-keyword">var</span> axisX = <span class="hljs-keyword">new</span> $<span class="hljs-number">3</span>Dmol.Vector3(<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>);   <span class="hljs-comment">// X 轴</span><br>        <span class="hljs-keyword">var</span> xDegree = Number($(<span class="hljs-string">&quot;#RotateX&quot;</span>).val());<br>        <span class="hljs-keyword">var</span> radianX = (Math.PI * xDegree) / <span class="hljs-number">180</span>;<br><br>        <span class="hljs-keyword">var</span> axisY = <span class="hljs-keyword">new</span> $<span class="hljs-number">3</span>Dmol.Vector3(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>);   <span class="hljs-comment">// Y 轴</span><br>        <span class="hljs-keyword">var</span> yDegree = Number($(<span class="hljs-string">&quot;#RotateY&quot;</span>).val());<br>        <span class="hljs-keyword">var</span> radianY = (Math.PI * yDegree) / <span class="hljs-number">180</span>;<br><br>        <span class="hljs-keyword">var</span> axisZ = <span class="hljs-keyword">new</span> $<span class="hljs-number">3</span>Dmol.Vector3(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>);   <span class="hljs-comment">// Z 轴</span><br>        <span class="hljs-keyword">var</span> zDegree = Number($(<span class="hljs-string">&quot;#RotateZ&quot;</span>).val());<br>        <span class="hljs-keyword">var</span> radianZ = (Math.PI * zDegree) / <span class="hljs-number">180</span>;<br><br>        <span class="hljs-keyword">if</span> (var_type===<span class="hljs-string">&#x27;rangeSizeX&#x27;</span> ) &#123;<br>            <span class="hljs-keyword">var</span> sizeW = Number(<span class="hljs-variable">$input</span>.value);<br>            <span class="hljs-keyword">var</span> vecW = <span class="hljs-keyword">new</span> $<span class="hljs-number">3</span>Dmol.Vector3(sizeW,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>);<br>            vecW.rotateAboutVector(axisX,radianX);<br>            vecW.rotateAboutVector(axisY,radianY);<br>            vecW.rotateAboutVector(axisZ,radianZ);<br><br>            sizeWx = vecW.x;<br>            sizeWy = vecW.y;<br>            sizeWz = vecW.z;<br><br>            sizeWx0 = sizeW;  <span class="hljs-comment"># 更新宽度大小初始值</span><br>            $(<span class="hljs-string">&quot;#SizeX&quot;</span>).val(<span class="hljs-variable">$input</span>.value);<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (var_type===<span class="hljs-string">&#x27;rangeSizeY&#x27;</span>) &#123;<br>            <span class="hljs-keyword">var</span> sizeH = Number(<span class="hljs-variable">$input</span>.value);                              <br>            <span class="hljs-keyword">var</span> vecH = <span class="hljs-keyword">new</span> $<span class="hljs-number">3</span>Dmol.Vector3(<span class="hljs-number">0</span>,sizeH,<span class="hljs-number">0</span>);<br>            vecH.rotateAboutVector(axisX,radianX);<br>            vecH.rotateAboutVector(axisY,radianY);<br>            vecH.rotateAboutVector(axisZ,radianZ);<br><br>            sizeHx = vecH.x;<br>            sizeHy = vecH.y;<br>            sizeHz = vecH.z;<br><br>            sizeHy0 = sizeH;  <span class="hljs-comment"># 更新高度大小初始值</span><br>            $(<span class="hljs-string">&quot;#SizeY&quot;</span>).val(<span class="hljs-variable">$input</span>.value);<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (var_type===<span class="hljs-string">&#x27;rangeSizeZ&#x27;</span>) &#123;<br>            <span class="hljs-keyword">var</span> sizeD = Number(<span class="hljs-variable">$input</span>.value);<br>            <span class="hljs-keyword">var</span> vecD = <span class="hljs-keyword">new</span> $<span class="hljs-number">3</span>Dmol.Vector3(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,sizeD);<br>            vecD.rotateAboutVector(axisX,radianX);<br>            vecD.rotateAboutVector(axisY,radianY);<br>            vecD.rotateAboutVector(axisZ,radianZ);<br><br>            sizeDx = vecD.x;<br>            sizeDy = vecD.y;<br>            sizeDz = vecD.z;<br><br>            sizeDz0 = sizeD; <span class="hljs-comment"># 更新深度大小初始值</span><br>            $(<span class="hljs-string">&quot;#SizeZ&quot;</span>).val(<span class="hljs-variable">$input</span>.value);<br>        &#125;<br>    &#125;<span class="hljs-keyword">else</span>&#123;<br>        <span class="hljs-comment">// 定义初始向量</span><br>        vecW = <span class="hljs-keyword">new</span> $<span class="hljs-number">3</span>Dmol.Vector3(sizeWx0,sizeWy0,sizeWz0);<br>        vecH = <span class="hljs-keyword">new</span> $<span class="hljs-number">3</span>Dmol.Vector3(sizeHx0,sizeHy0,sizeHz0);<br>        vecD = <span class="hljs-keyword">new</span> $<span class="hljs-number">3</span>Dmol.Vector3(sizeDx0,sizeDy0,sizeDz0);<br><br>        <span class="hljs-keyword">if</span> (var_type===<span class="hljs-string">&#x27;rangeRotateX&#x27;</span>)&#123;<br>            <span class="hljs-keyword">var</span> xDegree = Number(<span class="hljs-variable">$input</span>.value);<br>            <span class="hljs-keyword">var</span> yDegree = Number($(<span class="hljs-string">&quot;#RotateY&quot;</span>).val());<br>            <span class="hljs-keyword">var</span> zDegree = Number($(<span class="hljs-string">&quot;#RotateZ&quot;</span>).val());<br>            <span class="hljs-keyword">var</span> radianX = (Math.PI * xDegree) / <span class="hljs-number">180</span>;<br>            <span class="hljs-keyword">var</span> radianY = (Math.PI * yDegree) / <span class="hljs-number">180</span>;<br>            <span class="hljs-keyword">var</span> radianZ = (Math.PI * zDegree) / <span class="hljs-number">180</span>;<br>            $(<span class="hljs-string">&quot;#RotateX&quot;</span>).val(<span class="hljs-variable">$input</span>.value);<br>        &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (var_type===<span class="hljs-string">&#x27;rangeRotateY&#x27;</span>) &#123;<br>            <span class="hljs-keyword">var</span> xDegree = Number($(<span class="hljs-string">&quot;#RotateX&quot;</span>).val());<br>            <span class="hljs-keyword">var</span> yDegree = Number(<span class="hljs-variable">$input</span>.value);<br>            <span class="hljs-keyword">var</span> zDegree = Number($(<span class="hljs-string">&quot;#RotateZ&quot;</span>).val());<br>            <span class="hljs-keyword">var</span> radianX = (Math.PI * xDegree) / <span class="hljs-number">180</span>;<br>            <span class="hljs-keyword">var</span> radianY = (Math.PI * yDegree) / <span class="hljs-number">180</span>;<br>            <span class="hljs-keyword">var</span> radianZ = (Math.PI * zDegree) / <span class="hljs-number">180</span>;<br>            $(<span class="hljs-string">&quot;#RotateY&quot;</span>).val(<span class="hljs-variable">$input</span>.value);<br>        &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (var_type===<span class="hljs-string">&#x27;rangeRotateZ&#x27;</span>) &#123;<br>            <span class="hljs-keyword">var</span> xDegree = Number($(<span class="hljs-string">&quot;#RotateX&quot;</span>).val());<br>            <span class="hljs-keyword">var</span> yDegree = Number($(<span class="hljs-string">&quot;#RotateY&quot;</span>).val());<br>            <span class="hljs-keyword">var</span> zDegree = Number(<span class="hljs-variable">$input</span>.value);<br>            <span class="hljs-keyword">var</span> radianX = (Math.PI * xDegree) / <span class="hljs-number">180</span>;<br>            <span class="hljs-keyword">var</span> radianY = (Math.PI * yDegree) / <span class="hljs-number">180</span>;<br>            <span class="hljs-keyword">var</span> radianZ = (Math.PI * zDegree) / <span class="hljs-number">180</span>;<br>            $(<span class="hljs-string">&quot;#RotateZ&quot;</span>).val(<span class="hljs-variable">$input</span>.value);<br>        &#125;<br><br>        <span class="hljs-keyword">var</span> axisX = <span class="hljs-keyword">new</span> $<span class="hljs-number">3</span>Dmol.Vector3(<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>);   <span class="hljs-comment">// X 轴</span><br>        <span class="hljs-keyword">var</span> axisY = <span class="hljs-keyword">new</span> $<span class="hljs-number">3</span>Dmol.Vector3(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>);   <span class="hljs-comment">// Y 轴</span><br>        <span class="hljs-keyword">var</span> axisZ = <span class="hljs-keyword">new</span> $<span class="hljs-number">3</span>Dmol.Vector3(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>);   <span class="hljs-comment">// Z 轴</span><br><br>        vecW.rotateAboutVector(axisX,radianX);<br>        vecW.rotateAboutVector(axisY,radianY);<br>        vecW.rotateAboutVector(axisZ,radianZ);<br><br>        vecH.rotateAboutVector(axisX,radianX);<br>        vecH.rotateAboutVector(axisY,radianY);<br>        vecH.rotateAboutVector(axisZ,radianZ);<br><br>        vecD.rotateAboutVector(axisX,radianX);<br>        vecD.rotateAboutVector(axisY,radianY);<br>        vecD.rotateAboutVector(axisZ,radianZ);<br><br>        sizeWx = vecW.x;<br>        sizeWy = vecW.y;<br>        sizeWz = vecW.z;<br>        sizeHx = vecH.x;<br>        sizeHy = vecH.y;<br>        sizeHz = vecH.z;<br>        sizeDx = vecD.x;<br>        sizeDy = vecD.y;<br>        sizeDz = vecD.z;<br><br>    &#125;<br><br>    viewer.removeAllShapes();<br>    viewer.addBox(&#123;center:&#123;x:centerX,y:centerY,z:centerZ&#125;,<br>                <span class="hljs-comment">// dimensions: &#123;w: sizeW, h: sizeH, d: sizeD&#125;,</span><br>                dimensions:  &#123;<span class="hljs-string">&#x27;w&#x27;</span>: &#123;<span class="hljs-string">&#x27;x&#x27;</span>:sizeWx, <span class="hljs-string">&#x27;y&#x27;</span>:sizeWy, <span class="hljs-string">&#x27;z&#x27;</span>:sizeWz&#125;, <br>                              <span class="hljs-string">&#x27;h&#x27;</span>: &#123;<span class="hljs-string">&#x27;x&#x27;</span>:sizeHx, <span class="hljs-string">&#x27;y&#x27;</span>:sizeHy, <span class="hljs-string">&#x27;z&#x27;</span>:sizeHz&#125;,  <br>                              <span class="hljs-string">&#x27;d&#x27;</span>: &#123;<span class="hljs-string">&#x27;x&#x27;</span>:sizeDx, <span class="hljs-string">&#x27;y&#x27;</span>:sizeDy, <span class="hljs-string">&#x27;z&#x27;</span>:sizeDz&#125;&#125;,  <br>                color:<span class="hljs-string">&#x27;yellow&#x27;</span>, <br>                opacity: <span class="hljs-number">0.8</span>              <br>                &#125;);<br><br>    viewer.addLine(&#123;color:<span class="hljs-string">&#x27;red&#x27;</span>,start:&#123;x:centerX0,y:centerY0,z:centerZ0&#125;,end:&#123;x:centerX0+<span class="hljs-number">25</span>,y:centerY0,z:centerZ0&#125;&#125;);<br>    viewer.addLine(&#123;color:<span class="hljs-string">&#x27;blue&#x27;</span>,start:&#123;x:centerX0,y:centerY0,z:centerZ0&#125;,end:&#123;x:centerX0,y:centerY0+<span class="hljs-number">25</span>,z:centerZ0&#125;&#125;);<br>    viewer.addLine(&#123;color:<span class="hljs-string">&#x27;green&#x27;</span>,start:&#123;x:centerX0,y:centerY0,z:centerZ0&#125;,end:&#123;x:centerX0,y:centerY0,z:centerZ0+<span class="hljs-number">25</span>&#125;&#125;);<br><br>    viewer.render();<br><br>&#125;<br></code></pre></td></tr></table></figure><h5 id="使用滑块更新"><a href="#使用滑块更新" class="headerlink" title="使用滑块更新"></a>使用滑块更新</h5><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">$.fn.RangeSlider = <span class="hljs-keyword">function</span> (cfg) &#123;<br>    this.sliderCfg = &#123;<br>        min: cfg<span class="hljs-operator"> &amp;&amp; </span>!is<span class="hljs-constructor">NaN(<span class="hljs-params">parseFloat</span>(<span class="hljs-params">cfg</span>.<span class="hljs-params">min</span>)</span>) ? <span class="hljs-constructor">Number(<span class="hljs-params">cfg</span>.<span class="hljs-params">min</span>)</span> : null,<br>        max: cfg<span class="hljs-operator"> &amp;&amp; </span>!is<span class="hljs-constructor">NaN(<span class="hljs-params">parseFloat</span>(<span class="hljs-params">cfg</span>.<span class="hljs-params">max</span>)</span>) ? <span class="hljs-constructor">Number(<span class="hljs-params">cfg</span>.<span class="hljs-params">max</span>)</span> : null,<br>        step: cfg<span class="hljs-operator"> &amp;&amp; </span><span class="hljs-constructor">Number(<span class="hljs-params">cfg</span>.<span class="hljs-params">step</span>)</span> ? cfg.step : <span class="hljs-number">1</span>,<br>        callback: cfg<span class="hljs-operator"> &amp;&amp; </span>cfg.callback ? cfg.callback : null<br>    &#125;;<br><br>    var $input = <span class="hljs-constructor">$(<span class="hljs-params">this</span>)</span>;<br>    var min = this.sliderCfg.min;<br>    var max = this.sliderCfg.max;<br>    var step = this.sliderCfg.step;<br>    var callback = this.sliderCfg.callback;<br><br>    $input.attr(&#x27;min&#x27;, min)<br>        .attr(&#x27;max&#x27;, max)<br>        .attr(&#x27;step&#x27;, step);<br><br>    $input.bind(<span class="hljs-string">&quot;input&quot;</span>, <span class="hljs-keyword">function</span> (e) &#123;<br>        $input.attr(&#x27;value&#x27;, this.value);<br>        $input.css(&#x27;background-size&#x27;, this.value<span class="hljs-operator"> * </span><span class="hljs-number">100.0</span><span class="hljs-operator"> / </span>max + &#x27;% <span class="hljs-number">100</span>%&#x27;);<br><br>        <span class="hljs-keyword">if</span> ($.is<span class="hljs-constructor">Function(<span class="hljs-params">callback</span>)</span>) &#123;<br>            callback(this);<br>        &#125;<br>    &#125;);<br>&#125;;<br><br><span class="hljs-constructor">$(&#x27;#<span class="hljs-params">rangeCenterX</span>&#x27;)</span>.<span class="hljs-constructor">RangeSlider(&#123; <span class="hljs-params">min</span>: -50, <span class="hljs-params">max</span>: 100, <span class="hljs-params">step</span>: 0.1, <span class="hljs-params">callback</span>: <span class="hljs-params">updateBox</span> &#125;)</span>;<br><span class="hljs-constructor">$(&#x27;#<span class="hljs-params">rangeCenterY</span>&#x27;)</span>.<span class="hljs-constructor">RangeSlider(&#123; <span class="hljs-params">min</span>: -50, <span class="hljs-params">max</span>: 100, <span class="hljs-params">step</span>: 0.1, <span class="hljs-params">callback</span>: <span class="hljs-params">updateBox</span> &#125;)</span>;<br><span class="hljs-constructor">$(&#x27;#<span class="hljs-params">rangeCenterZ</span>&#x27;)</span>.<span class="hljs-constructor">RangeSlider(&#123; <span class="hljs-params">min</span>: -50, <span class="hljs-params">max</span>: 100, <span class="hljs-params">step</span>: 0.1, <span class="hljs-params">callback</span>: <span class="hljs-params">updateBox</span> &#125;)</span>;<br><br><span class="hljs-constructor">$(&#x27;#<span class="hljs-params">rangeSizeX</span>&#x27;)</span>.<span class="hljs-constructor">RangeSlider(&#123; <span class="hljs-params">min</span>: 0, <span class="hljs-params">max</span>: 100, <span class="hljs-params">step</span>: 0.1, <span class="hljs-params">callback</span>: <span class="hljs-params">updateBox</span> &#125;)</span>;<br><span class="hljs-constructor">$(&#x27;#<span class="hljs-params">rangeSizeY</span>&#x27;)</span>.<span class="hljs-constructor">RangeSlider(&#123; <span class="hljs-params">min</span>: 0, <span class="hljs-params">max</span>: 100, <span class="hljs-params">step</span>: 0.1, <span class="hljs-params">callback</span>: <span class="hljs-params">updateBox</span> &#125;)</span>;<br><span class="hljs-constructor">$(&#x27;#<span class="hljs-params">rangeSizeZ</span>&#x27;)</span>.<span class="hljs-constructor">RangeSlider(&#123; <span class="hljs-params">min</span>: 0, <span class="hljs-params">max</span>: 100, <span class="hljs-params">step</span>: 0.1, <span class="hljs-params">callback</span>: <span class="hljs-params">updateBox</span> &#125;)</span>;<br><br><span class="hljs-constructor">$(&#x27;#<span class="hljs-params">rangeRotateX</span>&#x27;)</span>.<span class="hljs-constructor">RangeSlider(&#123; <span class="hljs-params">min</span>: 0, <span class="hljs-params">max</span>: 180, <span class="hljs-params">step</span>: 0.1, <span class="hljs-params">callback</span>: <span class="hljs-params">updateBox</span> &#125;)</span>;<br><span class="hljs-constructor">$(&#x27;#<span class="hljs-params">rangeRotateY</span>&#x27;)</span>.<span class="hljs-constructor">RangeSlider(&#123; <span class="hljs-params">min</span>: 0, <span class="hljs-params">max</span>: 180, <span class="hljs-params">step</span>: 0.1, <span class="hljs-params">callback</span>: <span class="hljs-params">updateBox</span> &#125;)</span>;<br><span class="hljs-constructor">$(&#x27;#<span class="hljs-params">rangeRotateZ</span>&#x27;)</span>.<span class="hljs-constructor">RangeSlider(&#123; <span class="hljs-params">min</span>: 0, <span class="hljs-params">max</span>: 180, <span class="hljs-params">step</span>: 0.1, <span class="hljs-params">callback</span>: <span class="hljs-params">updateBox</span> &#125;)</span>;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>大前端</category>
      
    </categories>
    
    
    <tags>
      
      <tag>js,3dmol</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Flask异步任务</title>
    <link href="/2023/01/31/Flask%E5%BC%82%E6%AD%A5%E4%BB%BB%E5%8A%A1/"/>
    <url>/2023/01/31/Flask%E5%BC%82%E6%AD%A5%E4%BB%BB%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<h2 id="Flask-Executor实现异步"><a href="#Flask-Executor实现异步" class="headerlink" title="Flask-Executor实现异步"></a>Flask-Executor实现异步</h2><span id="more"></span><p>Flask 是 Python 中有名的轻量级同步 web 框架，在一些开发中，可能会遇到需要长时间处理的任务，此时就需要使用异步的方式来实现，让长时间任务在后台运行，先将本次请求的响应状态返回给前端，不让前端界面「卡顿」，当异步任务处理好后，如果需要返回状态，再将状态返回。</p><p>网上教程大多是针对 concurrent.futures 的 ThreadPoolExecutor(多线程)和ProcessPoolExecutor(多进程)实现，这里推荐使用<br>Flask-Executor。<br>官方文档介绍：Flask-Executor is a Flask extension that makes it easy to work with concurrent.futures in your application.</p><h5 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h5><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span> flask-executor<br></code></pre></td></tr></table></figure><h5 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h5><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs clean"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask<br><span class="hljs-keyword">from</span> flask_executor <span class="hljs-keyword">import</span> Executor<br><br>app = Flask(__name__)<br># app.config[<span class="hljs-string">&#x27;EXECUTOR_TYPE&#x27;</span>] = <span class="hljs-string">&#x27;process&#x27;</span><br>app.config[<span class="hljs-string">&#x27;EXECUTOR_TYPE&#x27;</span>] = <span class="hljs-string">&#x27;thread&#x27;</span><br>app.config[<span class="hljs-string">&#x27;EXECUTOR_MAX_WORKERS&#x27;</span>] = <span class="hljs-number">5</span><br>app.config[<span class="hljs-string">&#x27;EXECUTOR_PROPAGATE_EXCEPTIONS&#x27;</span>] = <span class="hljs-literal">True</span>   ## 方便debug<br>executor = Executor(app)<br></code></pre></td></tr></table></figure><h5 id="官方小例子："><a href="#官方小例子：" class="headerlink" title="官方小例子："></a>官方小例子：</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fib</span>(<span class="hljs-params">n</span>):</span><br>    <span class="hljs-keyword">if</span> n &lt;= <span class="hljs-number">2</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> fib(n-<span class="hljs-number">1</span>) + fib(n-<span class="hljs-number">2</span>)<br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/run_fib&#x27;</span></span>)</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run_fib</span>():</span><br>    executor.submit(fib, <span class="hljs-number">5</span>)<br>    executor.<span class="hljs-built_in">map</span>(fib, <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>))<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;OK&#x27;</span><br></code></pre></td></tr></table></figure><h5 id="收集异步任务信息"><a href="#收集异步任务信息" class="headerlink" title="收集异步任务信息"></a>收集异步任务信息</h5><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs less"><span class="hljs-variable">@app</span>.route(<span class="hljs-string">&#x27;/start-task&#x27;</span>)<br>def start_task():<br>    executor.submit_stored(<span class="hljs-string">&#x27;calc_power&#x27;</span>, pow, <span class="hljs-number">323</span>, <span class="hljs-number">1235</span>)<br>    return jsonify(&#123;<span class="hljs-string">&#x27;result&#x27;</span>:<span class="hljs-string">&#x27;success&#x27;</span>&#125;)<br><br><span class="hljs-variable">@app</span>.route(<span class="hljs-string">&#x27;/get-result&#x27;</span>)<br>def get_result():<br>    if not executor.futures.done(<span class="hljs-string">&#x27;calc_power&#x27;</span>):<br>        return jsonify(&#123;<span class="hljs-string">&#x27;status&#x27;</span>: executor.futures._state(<span class="hljs-string">&#x27;calc_power&#x27;</span>)&#125;)<br>    future = executor.futures.pop(<span class="hljs-string">&#x27;calc_power&#x27;</span>)<br>    return jsonify(&#123;<span class="hljs-string">&#x27;status&#x27;</span>: done, <span class="hljs-string">&#x27;result&#x27;</span>: future.result()&#125;)<br></code></pre></td></tr></table></figure><p>详细文档请查阅：<a href="https://flask-executor.readthedocs.io/en/latest/">https://flask-executor.readthedocs.io/en/latest/</a></p><h5 id="log"><a href="#log" class="headerlink" title="log"></a>log</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> logging<br><span class="hljs-keyword">from</span> logging.handlers <span class="hljs-keyword">import</span> TimedRotatingFileHandler<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Logger</span>:</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    自定义日志打印类，将日志保存到`../logs/`目录</span><br><span class="hljs-string">    设置日志等级和增加处理器，设置处理器为按照日期切分，最大保留30天</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-comment"># 创建Logger</span><br>        self.logger = logging.getLogger()<br>        self.logger.setLevel(logging.DEBUG)<br><br>        <span class="hljs-comment"># 终端Handler</span><br>        console_handler = logging.StreamHandler()<br>        console_handler.setLevel(logging.DEBUG)<br><br>        <span class="hljs-comment"># 文件Handler</span><br>        <span class="hljs-comment"># file_handler = logging.FileHandler(</span><br>        <span class="hljs-comment">#     filename=&#x27;./logs/app.log&#x27;,</span><br>        <span class="hljs-comment">#     mode=&#x27;a+&#x27;,</span><br>        <span class="hljs-comment">#     encoding=&#x27;UTF-8&#x27;</span><br>        <span class="hljs-comment"># )</span><br>        file_handler = TimedRotatingFileHandler(<span class="hljs-string">&#x27;./logs/app.log&#x27;</span>, when=<span class="hljs-string">&#x27;d&#x27;</span>, interval=<span class="hljs-number">1</span>, backupCount=<span class="hljs-number">30</span>,<br>                                                         encoding=<span class="hljs-string">&quot;utf8&quot;</span>, delay=<span class="hljs-literal">False</span>)<br>        file_handler.setLevel(logging.NOTSET)<br><br>        <span class="hljs-comment"># Formatter</span><br>        formatter = logging.Formatter(<br>            fmt=<span class="hljs-string">&#x27;%(asctime)s --- %(levelname)s - %(message)s&#x27;</span>,<br>            datefmt=<span class="hljs-string">&quot;%Y-%m-%d %H:%M:%S&quot;</span><br>        )<br><br>        console_handler.setFormatter(formatter)<br>        file_handler.setFormatter(formatter)<br><br>        <span class="hljs-comment"># 添加到Logger中</span><br>        self.logger.addHandler(file_handler)<br>        self.logger.addHandler(console_handler)<br></code></pre></td></tr></table></figure><ul><li>添加颜色<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> colorama <span class="hljs-keyword">import</span> Fore,Back,Style<br><br><span class="hljs-comment">#  前景色:白色  背景色:绿色</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">white_green</span>(<span class="hljs-params">s</span>):</span><br>    <span class="hljs-keyword">return</span> Fore.WHITE + Back.GREEN + s + Style.RESET_ALL<br><br> <span class="hljs-comment">#  前景色:白色  背景色:红色</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">white_red</span>(<span class="hljs-params">s</span>):</span><br>    <span class="hljs-keyword">return</span> Fore.WHITE + Back.RED + s + Style.RESET_ALL<br></code></pre></td></tr></table></figure></li><li>调用日志<figure class="highlight isbl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs isbl"><span class="hljs-variable">LOGGER</span> = <span class="hljs-function"><span class="hljs-title">Logger</span>()</span><br><span class="hljs-variable">LOGGER.logger.info</span>(<span class="hljs-function"><span class="hljs-title">white_green</span>(<span class="hljs-string">&#x27;hello&#x27;</span>))</span><br></code></pre></td></tr></table></figure></li></ul><h5 id="bug"><a href="#bug" class="headerlink" title="bug"></a>bug</h5><p>多线程操作sqlite:Recursive use of cursors not allowed</p><p>解决方案参考：<a href="https://blog.csdn.net/counsellor/article/details/43715007">https://blog.csdn.net/counsellor/article/details/43715007</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> threading<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">update</span>(<span class="hljs-params">database, projectId</span>):</span><br>    lock = threading.Lock()<br>    <span class="hljs-keyword">try</span>:<br>        lock.acquire(<span class="hljs-literal">True</span>)<br>        tmp_sql = <span class="hljs-string">&#x27;&#x27;&#x27;update tasks set complete = ? where projectId = ?&#x27;&#x27;&#x27;</span><br>        database.execute_sql(tmp_sql, (<span class="hljs-string">&#x27;Y&#x27;</span>, projectId))<br><br>        input_path = <span class="hljs-string">f&quot;static/project/<span class="hljs-subst">&#123;projectId&#125;</span>/result&quot;</span><br>        output_path = <span class="hljs-string">f&quot;static/project/<span class="hljs-subst">&#123;projectId&#125;</span>/result.zip&quot;</span><br>        zipDir(input_path, output_path)<br><br>        tmp_sql = <span class="hljs-string">&#x27;&#x27;&#x27;update tasks set result = ? where projectId = ?&#x27;&#x27;&#x27;</span><br>        database.execute_sql(tmp_sql, (output_path, projectId))<br>    <span class="hljs-keyword">finally</span>:<br>        lock.release()<br></code></pre></td></tr></table></figure><p>参考：<a href="https://blog.csdn.net/briblue/article/details/85220740">https://blog.csdn.net/briblue/article/details/85220740</a></p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Flask</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python从零生成PDF</title>
    <link href="/2023/01/13/Python%E4%BB%8E%E9%9B%B6%E7%94%9F%E6%88%90PDF/"/>
    <url>/2023/01/13/Python%E4%BB%8E%E9%9B%B6%E7%94%9F%E6%88%90PDF/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><p>使用的包为fpdf，可直接使用pip安装</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span> fpdf<br></code></pre></td></tr></table></figure><h5 id="中文字体下载"><a href="#中文字体下载" class="headerlink" title="中文字体下载"></a>中文字体下载</h5><p>该包默认是不支持中文的，如果想使用中文，需要下载中文字体，可在如下地址下载<br><a href="https://github.com/Haixing-Hu/latex-chinese-fonts">https://github.com/Haixing-Hu/latex-chinese-fonts</a></p><h5 id="简单使用"><a href="#简单使用" class="headerlink" title="简单使用"></a>简单使用</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-keyword">from</span> fpdf import FPDF<br><br>pdf = FPDF()<br>pdf.add_page()   # 这句必须<br>pdf.set_font(<span class="hljs-string">&#x27;Arial&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, 16)<br>pdf.cell(40, 10, <span class="hljs-string">&#x27;Hello World!&#x27;</span>)<br><span class="hljs-comment"># 添加中文</span><br>pdf.add_font(<span class="hljs-string">&#x27;STSong&#x27;</span>,<span class="hljs-string">&#x27;&#x27;</span>,<span class="hljs-string">&#x27;db/font/黑体/STHeiti.ttf&#x27;</span>,<span class="hljs-literal">True</span>) <br>pdf.set_font(<span class="hljs-string">&#x27;STSong&#x27;</span>,<span class="hljs-attribute">size</span>=25)<br>pdf.cell(0,20,<span class="hljs-string">&#x27;你好&#x27;</span>, <span class="hljs-attribute">ln</span>=1, <span class="hljs-attribute">align</span>=<span class="hljs-string">&#x27;C&#x27;</span>)<br><br><span class="hljs-comment"># 单行、多行插入</span><br>pdf.cell(0,10,<span class="hljs-string">&#x27;单行&#x27;</span>, <span class="hljs-attribute">ln</span>=1) #插入文本框，0表示文档整个横向长度，10是高度, ln是否换行<br>pdf.multi_cell(0,10,<span class="hljs-string">&#x27;多行&#x27;</span><span class="hljs-number">*100</span>)#多行插入<br><br><span class="hljs-comment"># 添加超链接</span><br>pdf.set_text_color(255,0,0) # 更改颜色<br>pdf.cell(0,10, <span class="hljs-attribute">txt</span>=<span class="hljs-string">&#x27;百度&#x27;</span>, <span class="hljs-attribute">link</span>=<span class="hljs-string">&#x27;www.baidu.com&#x27;</span>, <span class="hljs-attribute">ln</span>=1) # 插入链接<br><br>pdf.output(<span class="hljs-string">&#x27;tuto1.pdf&#x27;</span>, <span class="hljs-string">&#x27;F&#x27;</span>)<br></code></pre></td></tr></table></figure><p>参考：<br><a href="https://www.modb.pro/db/598830">https://www.modb.pro/db/598830</a><br><a href="https://pyfpdf.readthedocs.io/en/latest/Tutorial/index.html">https://pyfpdf.readthedocs.io/en/latest/Tutorial/index.html</a></p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pdf</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>微信公众号文章爬取</title>
    <link href="/2023/01/11/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%88%AC%E5%8F%96/"/>
    <url>/2023/01/11/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%E7%88%AC%E5%8F%96/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><p>每个公众号文章会有很多，所以这里只提取了最近发布的文章，时间可以自定义。<br>完整code如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> datetime<br><br><span class="hljs-comment">## 这里定义了爬取3天内的文章</span><br>earliest = datetime.datetime.now() + datetime.timedelta(-<span class="hljs-built_in">int</span>(<span class="hljs-number">3</span>))   <br>earliest = earliest.strftime(<span class="hljs-string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)<br>earliest = datetime.datetime.strptime(earliest, <span class="hljs-string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)<br>earliest = datetime.datetime.timestamp(earliest)<br>earliest<br><br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> re<br><span class="hljs-keyword">import</span> urllib3<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> os,sys<br><span class="hljs-keyword">from</span> selenium <span class="hljs-keyword">import</span> webdriver<br><span class="hljs-keyword">from</span> selenium.webdriver.common.by <span class="hljs-keyword">import</span> By<br><br>BASE_DIR = os.path.abspath(<span class="hljs-string">&quot;.&quot;</span>)<br><span class="hljs-comment"># sys.path.append(BASE_DIR)</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Wechat_Crawl</span>:</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,cookie_path</span>):</span><br>        self.cookie_path = cookie_path<br>        self.qurey = subscription_account<br>        self.url =  <span class="hljs-string">&#x27;https://mp.weixin.qq.com&#x27;</span><br>        self.search_url = <span class="hljs-string">&#x27;https://mp.weixin.qq.com/cgi-bin/searchbiz?&#x27;</span><br>        self.appmsg_url = <span class="hljs-string">&#x27;https://mp.weixin.qq.com/cgi-bin/appmsg?&#x27;</span><br>        self.header = &#123;<br>            <span class="hljs-string">&quot;HOST&quot;</span>: <span class="hljs-string">&quot;mp.weixin.qq.com&quot;</span>,<br>            <span class="hljs-string">&quot;User-Agent&quot;</span>: <span class="hljs-string">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36&quot;</span><br>        &#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">wechat_login</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        Login wechat by automatically inputing accounts and keywords and manully scanning QR code， and then you can</span><br><span class="hljs-string">        get the cookie information, save it in local file in order to simulate loginning and crawling……</span><br><span class="hljs-string">        :param __username:</span><br><span class="hljs-string">        :param __password:</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;浏览器将自动打开并跳转至微信公众号登录页面……&quot;</span>)<br>        time.sleep(<span class="hljs-number">1</span>)<br>        driver = webdriver.Chrome()<br>        driver.get(<span class="hljs-string">&quot;https://mp.weixin.qq.com/&quot;</span>)<br>        time.sleep(<span class="hljs-number">2</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;请拿手机扫码二维码登录公众号&quot;</span>)<br>        time.sleep(<span class="hljs-number">15</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;登录成功&quot;</span>)<br><br>        cookies = driver.get_cookies()<br>        info = &#123;&#125;<br>        <span class="hljs-keyword">for</span> cookie <span class="hljs-keyword">in</span> cookies:<br>            info[cookie[<span class="hljs-string">&#x27;name&#x27;</span>]] = cookie[<span class="hljs-string">&#x27;value&#x27;</span>]<br>        cookie_info = json.dumps(info)<br><span class="hljs-comment">#         print(cookie_info)</span><br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(cookie_path, <span class="hljs-string">&#x27;w+&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            f.write(cookie_info)<br>            f.flush()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;cookies已存入cookie.txt&quot;</span>,flush=<span class="hljs-literal">True</span>)<br>        driver.quit()<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_cookie</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(self.cookie_path, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            cookie = f.read()<br>        self.cookies = json.loads(cookie)<br><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_session</span>(<span class="hljs-params">self</span>):</span><br>        urllib3.disable_warnings()<br>        <span class="hljs-comment"># requests库urllib编写，是对urllib进行了封装，在urllib2版本对https的处理非常简单，只需要在请求的时候加上verify = False即可，</span><br>        <span class="hljs-comment"># 这个参数的意思是忽略https安全证书的验证，也就是不验证证书的可靠性，直接请求，这其实是不安全的，因为证书可以伪造，不验证的话就不</span><br>        <span class="hljs-comment"># 能保证数据的真实性。</span><br>        <span class="hljs-comment"># 在urllib3版本，官方强制验证https的安全证书，如果没有通过是不能通过请求的，虽然添加忽略验证的参数，但是依然会给出醒目的Warning</span><br>        <span class="hljs-comment"># urllib3.disable_warnings()可以禁用urllib3的警告。</span><br>        session = requests.Session()<br>        session.keep_alive = <span class="hljs-literal">False</span><br>        session.adapters.DEFAULT_RETRIES = <span class="hljs-number">511</span><br>        self.session = session<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_token</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        to get the token from the loginned page.</span><br><span class="hljs-string">        :param cookie_path:</span><br><span class="hljs-string">        :return: token</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        time.sleep(<span class="hljs-number">1</span>)<br>        response = self.session.get(url=self.url, cookies=self.cookies, verify=<span class="hljs-literal">False</span>)<br>        url = <span class="hljs-built_in">str</span>(response.url)<br>        pattern = <span class="hljs-string">r&#x27;token=([0-9]+)&#x27;</span><br>        self.token = re.findall(pattern,url)[<span class="hljs-number">0</span>]<br><br>        <span class="hljs-keyword">return</span> self.token<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_fakedid</span>(<span class="hljs-params">self, query</span>):</span><br>        query_id = &#123;<br>            <span class="hljs-string">&#x27;action&#x27;</span>: <span class="hljs-string">&#x27;search_biz&#x27;</span>,<br>            <span class="hljs-string">&#x27;token&#x27;</span>: self.token,<br>            <span class="hljs-string">&#x27;lang&#x27;</span>: <span class="hljs-string">&#x27;zh_CN&#x27;</span>,<br>            <span class="hljs-string">&#x27;f&#x27;</span>: <span class="hljs-string">&#x27;json&#x27;</span>,<br>            <span class="hljs-string">&#x27;ajax&#x27;</span>: <span class="hljs-string">&#x27;1&#x27;</span>,<br>            <span class="hljs-string">&#x27;random&#x27;</span>: random.random(),<br>            <span class="hljs-string">&#x27;query&#x27;</span>: query,<br>            <span class="hljs-string">&#x27;begin&#x27;</span>: <span class="hljs-string">&#x27;0&#x27;</span>,<br>            <span class="hljs-string">&#x27;count&#x27;</span>: <span class="hljs-string">&#x27;5&#x27;</span><br>        &#125;<br>        search_response = self.session.get(<br>            self.search_url,<br>            headers=self.header,<br>            cookies=self.cookies,<br>            params=query_id)<br>        lists = search_response.json()[<span class="hljs-string">&#x27;list&#x27;</span>][<span class="hljs-number">0</span>]<br><br>        self.fakeid = lists[<span class="hljs-string">&#x27;fakeid&#x27;</span>]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_args</span>(<span class="hljs-params">self, query</span>):</span><br>        self.get_cookie()<br>        self._session()<br>        self.get_token()<br>        self.get_fakedid(query)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_info</span>(<span class="hljs-params">self,output_path</span>):</span><br>        self.begin = <span class="hljs-number">0</span><br>        self.flag = <span class="hljs-literal">True</span><br>        <br>        self.data = &#123;<br>            <span class="hljs-string">&quot;token&quot;</span>: self.token,<br>            <span class="hljs-string">&quot;lang&quot;</span>: <span class="hljs-string">&quot;zh_CN&quot;</span>,<br>            <span class="hljs-string">&quot;f&quot;</span>: <span class="hljs-string">&quot;json&quot;</span>,<br>            <span class="hljs-string">&quot;ajax&quot;</span>: <span class="hljs-string">&quot;1&quot;</span>,<br>            <span class="hljs-string">&quot;action&quot;</span>: <span class="hljs-string">&quot;list_ex&quot;</span>,<br>            <span class="hljs-string">&quot;begin&quot;</span>: self.begin,<br>            <span class="hljs-string">&quot;count&quot;</span>: <span class="hljs-string">&quot;5&quot;</span>,<br>            <span class="hljs-string">&quot;query&quot;</span>: <span class="hljs-string">&quot;&quot;</span>,<br>            <span class="hljs-string">&quot;fakeid&quot;</span>: self.fakeid,<br>            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;9&quot;</span>,<br>        &#125;<br>        <br><span class="hljs-comment">#         print(self.data)</span><br><br>        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>            <span class="hljs-keyword">if</span> self.flag == <span class="hljs-literal">False</span>:<br>                <span class="hljs-keyword">break</span><br>            <span class="hljs-comment"># 随机暂停几秒，避免过快的请求导致过快的被查到</span><br>            time.sleep(random.randint(<span class="hljs-number">5</span>,<span class="hljs-number">10</span>))<br>            self.data[<span class="hljs-string">&#x27;begin&#x27;</span>] = self.begin * <span class="hljs-number">5</span><br>            res = requests.get(self.appmsg_url, cookies=self.cookies, headers=self.header, params=self.data)<br>            <span class="hljs-keyword">try</span>:<br>                json = res.json()<br>                count = json[<span class="hljs-string">&#x27;app_msg_cnt&#x27;</span>]<br><br>                <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> json[<span class="hljs-string">&quot;app_msg_list&quot;</span>]:<br>                    <span class="hljs-keyword">if</span> item[<span class="hljs-string">&#x27;create_time&#x27;</span>] &lt; earliest:<br>                        self.flag = <span class="hljs-literal">False</span><br>                        <span class="hljs-keyword">break</span><br>                    create_date = time.strftime(<span class="hljs-string">&quot;%Y-%m-%d&quot;</span>, time.localtime(item[<span class="hljs-string">&#x27;create_time&#x27;</span>]))<br><span class="hljs-comment">#                     print(create_date)</span><br>                    title = item[<span class="hljs-string">&#x27;title&#x27;</span>].replace(<span class="hljs-string">&quot;\n&quot;</span>, <span class="hljs-string">&quot;&quot;</span>)<br>                    link = item[<span class="hljs-string">&#x27;link&#x27;</span>]<br>                    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(output_path, <span class="hljs-string">&#x27;a+&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8-sig&#x27;</span>) <span class="hljs-keyword">as</span> fh:<br>                        article_info = <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;create_date&#125;</span>,<span class="hljs-subst">&#123;title&#125;</span>,<span class="hljs-subst">&#123;link&#125;</span>\n&#x27;</span><br>                        fh.write(article_info)<br>                        fh.flush()<br>                <br>                self.begin += <span class="hljs-number">1</span><br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;完成第<span class="hljs-subst">&#123;self.begin&#125;</span>页&#x27;</span>)<br><br>            <span class="hljs-keyword">except</span>:<br>                <span class="hljs-built_in">print</span>(res.json()[<span class="hljs-string">&#x27;base_resp&#x27;</span>][<span class="hljs-string">&#x27;err_msg&#x27;</span>])<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Try it again after two hours.&quot;</span>)<br>                <span class="hljs-keyword">break</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span>(<span class="hljs-params">self,query, output_path</span>):</span><br>        self.get_args(query)<br>        self.get_info(output_path)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-comment">## 可自定义需要爬取的公众号</span><br>    subscription_account_list = &#123;<span class="hljs-string">&#x27;医麦客&#x27;</span>:<span class="hljs-string">&#x27;eMedClub&#x27;</span>, <span class="hljs-string">&#x27;AIDD-Pro&#x27;</span>:<span class="hljs-string">&quot;AIDDPro&quot;</span>&#125;<br>    <br>    cookie_path = BASE_DIR + os.sep + <span class="hljs-string">&#x27;db&#x27;</span> + os.sep + <span class="hljs-string">&#x27;cookie.txt&#x27;</span><br>    wc = Wechat_Crawl(cookie_path)<br>    wc.wechat_login()<br>    <span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> subscription_account_list.items():<br>        output_path = BASE_DIR + os.sep + <span class="hljs-string">&#x27;db&#x27;</span> + os.sep + <span class="hljs-string">&#x27;data&#x27;</span> + os.sep + k + <span class="hljs-string">&#x27;.csv&#x27;</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;开始爬取公众号:&quot;</span>,k)<br>        wc.run(v, output_path)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;爬取完成:&quot;</span>, k)<br></code></pre></td></tr></table></figure><p>参考：<a href="https://cloud.tencent.com/developer/article/1506163">https://cloud.tencent.com/developer/article/1506163</a><br>     <a href="https://zhuanlan.zhihu.com/p/379062852">https://zhuanlan.zhihu.com/p/379062852</a></p><p>另外得到的公众号文章需要进一步处理，这里以某篇为例：</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs clean"><span class="hljs-keyword">import</span> lxml<br><span class="hljs-keyword">import</span> re<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<br><br>url = <span class="hljs-string">&#x27;https://mp.weixin.qq.com/s/v5NtX6xr2a2-lpDG2yvgLA&#x27;</span><br>page = requests.get(url)<br><br># 有些正文被隐藏<br>html = page.text.replace(<span class="hljs-string">&quot;data-src&quot;</span>, <span class="hljs-string">&quot;src&quot;</span>).replace(<span class="hljs-string">&#x27;style=&quot;visibility: hidden;&quot;&#x27;</span>,<span class="hljs-string">&quot;&quot;</span>)<br># html = re.sub(<span class="hljs-string">&quot;&lt;/html&gt;&quot;</span>,<span class="hljs-string">&quot;&quot;</span>,page.text,flags=re.S|re.IGNORECASE)+<span class="hljs-string">&quot;&lt;/html&gt;&quot;</span><br># soup = BeautifulSoup(page.content, <span class="hljs-string">&#x27;lxml&#x27;</span>)<br>soup = BeautifulSoup(html, <span class="hljs-string">&#x27;lxml&#x27;</span>)<br><br># 获取正文, 通过id或者<span class="hljs-keyword">class</span>获取<br># wb = soup.find(<span class="hljs-string">&#x27;div&#x27;</span>, &#123;<span class="hljs-string">&#x27;class&#x27;</span>: <span class="hljs-string">&quot;rich_media_content&quot;</span>&#125;)<br>wb = soup.find(<span class="hljs-string">&#x27;div&#x27;</span>, id=<span class="hljs-string">&#x27;js_content&#x27;</span>)<br><br>## 删除不需要的信息<br>tmp = <span class="hljs-number">0</span><br>for i, tag <span class="hljs-keyword">in</span> enumerate(wb.find_all(<span class="hljs-string">&#x27;section&#x27;</span>)):<br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;招聘信息&#x27;</span> <span class="hljs-keyword">in</span> tag.prettify():<br>        tmp = i<br>        break<br><br>for i, tag <span class="hljs-keyword">in</span> enumerate(wb.find_all(<span class="hljs-string">&#x27;section&#x27;</span>)):<br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;前言&#x27;</span> <span class="hljs-keyword">in</span> tag.prettify() and i&gt;=<span class="hljs-number">3</span>:<br>#         tag.extract()<br>        tag.decompose()<br>    <span class="hljs-keyword">if</span> i &gt;= tmp:<br>#         tag.extract()<br>        tag.decompose()<br>        <br># del_str = wb.find_all(<span class="hljs-string">&#x27;ol&#x27;</span>, &#123;<span class="hljs-string">&#x27;class&#x27;</span>: <span class="hljs-string">&quot;list-paddingleft-1&quot;</span>&#125;)[<span class="hljs-number">-1</span>].extract()<br>wb.find_all(<span class="hljs-string">&#x27;ol&#x27;</span>, &#123;<span class="hljs-string">&#x27;class&#x27;</span>: <span class="hljs-string">&quot;list-paddingleft-1&quot;</span>&#125;)[<span class="hljs-number">-1</span>].decompose()<br><br># 保存成html格式<br><span class="hljs-keyword">with</span> open(<span class="hljs-string">&#x27;AI药物周资讯.html&#x27;</span>,<span class="hljs-string">&quot;w&quot;</span>,encoding=<span class="hljs-string">&quot;utf-8-sig&quot;</span>)<span class="hljs-keyword">as</span> f:<br>    f.write(wb.prettify(formatter=<span class="hljs-string">&#x27;html&#x27;</span>))<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>爬虫</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>异质图链接预测</title>
    <link href="/2022/12/15/%E5%BC%82%E8%B4%A8%E5%9B%BE%E9%93%BE%E6%8E%A5%E9%A2%84%E6%B5%8B/"/>
    <url>/2022/12/15/%E5%BC%82%E8%B4%A8%E5%9B%BE%E9%93%BE%E6%8E%A5%E9%A2%84%E6%B5%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-title">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">import</span> copy<br><br><span class="hljs-title">from</span> torch_geometric.nn <span class="hljs-keyword">import</span> RGCNConv<br><span class="hljs-title">from</span> tqdm.notebook <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-title">from</span> torch_geometric.utils <span class="hljs-keyword">import</span> negative_sampling<br><span class="hljs-title">from</span> sklearn.metrics <span class="hljs-keyword">import</span> roc_auc_score<br><span class="hljs-title">from</span> torch_geometric.<span class="hljs-class"><span class="hljs-keyword">data</span> import <span class="hljs-type">HeteroData</span></span><br><span class="hljs-title">from</span> torch_geometric.datasets <span class="hljs-keyword">import</span> DBLP<br><br><br><span class="hljs-title">dataset</span> = <span class="hljs-type">DBLP</span>(root=&#x27;./<span class="hljs-type">DBLP&#x27;</span>)<br><span class="hljs-title">graph</span> = dataset[<span class="hljs-number">0</span>]<br><br></code></pre></td></tr></table></figure><p>HeteroData(<br>  author={<br>    x=[4057, 334],<br>    y=[4057],<br>    train_mask=[4057],<br>    val_mask=[4057],<br>    test_mask=[4057]<br>  },<br>  paper={ x=[14328, 4231] },<br>  term={ x=[7723, 50] },<br>  conference={ num_nodes=20 },<br>  (author, to, paper)={ edge_index=[2, 19645] },<br>  (paper, to, author)={ edge_index=[2, 19645] },<br>  (paper, to, term)={ edge_index=[2, 85810] },<br>  (paper, to, conference)={ edge_index=[2, 14328] },<br>  (term, to, paper)={ edge_index=[2, 85810] },<br>  (conference, to, paper)={ edge_index=[2, 14328] }<br>)</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># # 因为conference节点没有特征信息，所以将conference节点的特征初始化为1</span><br>graph[<span class="hljs-string">&#x27;conference&#x27;</span>].x = torch.ones(graph[<span class="hljs-string">&#x27;conference&#x27;</span>].num_nodes, 1)<br>graph<br><br>node_types, edge_types = graph.metadata()<br><span class="hljs-builtin-name">print</span>(<span class="hljs-string">&#x27;node_types:&#x27;</span>, node_types)<br><span class="hljs-builtin-name">print</span>(<span class="hljs-string">&#x27;edge_types:&#x27;</span>, edge_types)<br>num_relations = len(edge_types)<br><span class="hljs-builtin-name">print</span>(<span class="hljs-string">&#x27;num_relations:&#x27;</span>, num_relations)<br>init_sizes = [graph[x].x.shape[1] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> node_types]<br><span class="hljs-builtin-name">print</span>(init_sizes)<br>device = torch.device(<span class="hljs-string">&#x27;cpu&#x27;</span>)<br></code></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs routeros">train_data, val_data, test_data = T.RandomLinkSplit(<br>        <span class="hljs-attribute">num_val</span>=0.1,<br>        <span class="hljs-attribute">num_test</span>=0.1,<br>        <span class="hljs-attribute">is_undirected</span>=<span class="hljs-literal">True</span>,<br>        <span class="hljs-attribute">add_negative_train_samples</span>=<span class="hljs-literal">False</span>,<br>        <span class="hljs-attribute">disjoint_train_ratio</span>=0,<br>        edge_types=[(<span class="hljs-string">&#x27;author&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-string">&#x27;paper&#x27;</span>), (<span class="hljs-string">&#x27;paper&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-string">&#x27;term&#x27;</span>),<br>                    (<span class="hljs-string">&#x27;paper&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-string">&#x27;conference&#x27;</span>)],<br>        rev_edge_types=[(<span class="hljs-string">&#x27;paper&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-string">&#x27;author&#x27;</span>), (<span class="hljs-string">&#x27;term&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-string">&#x27;paper&#x27;</span>),<br>                        (<span class="hljs-string">&#x27;conference&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-string">&#x27;paper&#x27;</span>)]<br>    )(graph.to_homogeneous())<br>train_data<br></code></pre></td></tr></table></figure><p>Data(edge_index=[2, 191654], node_type=[26128], edge_type=[191654], edge_label=[95827], edge_label_index=[2, 95827])</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-title">def</span> negative_sample(<span class="hljs-class"><span class="hljs-keyword">data</span>):</span><br>    # 从训练集中采样与正边相同数量的负边<br>    neg_edge_index = negative_sampling(<br>        edge_index=<span class="hljs-class"><span class="hljs-keyword">data</span>.edge_index, num_nodes=<span class="hljs-keyword">data</span>.num_nodes,</span><br>        num_neg_samples=<span class="hljs-class"><span class="hljs-keyword">data</span>.edge_label_index.size(1), method=&#x27;sparse&#x27;)</span><br>    # print(neg_edge_index.size(<span class="hljs-number">1</span>))   # <span class="hljs-number">3642</span>条负边，即每次采样与训练集中正边数量一致的负边<br>    edge_label_index = torch.cat(<br>        [<span class="hljs-class"><span class="hljs-keyword">data</span>.edge_label_index, neg_edge_index],</span><br>        dim=<span class="hljs-number">-1</span>,<br>    )<br>    edge_label = torch.cat([<br>        <span class="hljs-class"><span class="hljs-keyword">data</span>.edge_label,</span><br>        <span class="hljs-class"><span class="hljs-keyword">data</span>.edge_label.new_zeros(<span class="hljs-title">neg_edge_index</span>.<span class="hljs-title">size</span>(1))</span><br>    ], dim=<span class="hljs-number">0</span>)<br><br>    return edge_label, edge_label_index<br></code></pre></td></tr></table></figure><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RGCN_LP</span>(<span class="hljs-title">nn</span>.<span class="hljs-title">Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, in_channels, hidden_channels, out_channels)</span></span>:<br>        <span class="hljs-keyword">super</span>(RGCN_LP, <span class="hljs-keyword">self</span>).__init__()<br>        <span class="hljs-keyword">self</span>.conv1 = RGCNConv(in_channels, hidden_channels,<br>                              num_relations=num_relations, num_bases=<span class="hljs-number">30</span>)<br>        <span class="hljs-keyword">self</span>.conv2 = RGCNConv(hidden_channels, out_channels,<br>                              num_relations=num_relations, num_bases=<span class="hljs-number">30</span>)<br>        <span class="hljs-keyword">self</span>.lins = torch.nn.ModuleList()<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(node_types)):<br>            lin = nn.Linear(init_sizes[i], in_channels)<br>            <span class="hljs-keyword">self</span>.lins.append(lin)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">trans_dimensions</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, g)</span></span>:<br>        data = copy.deepcopy(g)<br>        <span class="hljs-keyword">for</span> node_type, lin <span class="hljs-keyword">in</span> zip(node_types, <span class="hljs-keyword">self</span>.lins):<br>            data[node_type].x = lin(data[node_type].x)<br><br>        <span class="hljs-keyword">return</span> data<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">encode</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, data)</span></span>:<br>        data = <span class="hljs-keyword">self</span>.trans_dimensions(data)<br>        homogeneous_data = data.to_homogeneous()<br>        <span class="hljs-comment"># print(homogeneous_data)</span><br>        edge_index, edge_type = homogeneous_data.edge_index, homogeneous_data.edge_type<br>        <span class="hljs-comment"># print(edge_type)</span><br>        x = <span class="hljs-keyword">self</span>.conv1(homogeneous_data.x, edge_index, edge_type)<br>        x = <span class="hljs-keyword">self</span>.conv2(x, edge_index, edge_type)<br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">decode</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, z, edge_label_index)</span></span>:<br>        <span class="hljs-comment"># z所有节点的表示向量</span><br>        src = z[edge_label_index[<span class="hljs-number">0</span>]]<br>        dst = z[edge_label_index[<span class="hljs-number">1</span>]]<br>        <span class="hljs-comment"># print(dst.size())</span><br>        r = (src * dst).sum(dim=-<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># print(r.size())</span><br>        <span class="hljs-keyword">return</span> r<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, data, edge_label_index)</span></span>:<br>        z = <span class="hljs-keyword">self</span>.encode(data)<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">self</span>.decode(z, edge_label_index)<br></code></pre></td></tr></table></figure><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs css">def test(model, data):<br>    model.<span class="hljs-built_in">eval</span>()<br>    with torch.<span class="hljs-built_in">no_grad</span>():<br>        edge_label, edge_label_index = <span class="hljs-built_in">negative_sample</span>(data)<br>        out = <span class="hljs-built_in">model</span>(graph, edge_label_index).<span class="hljs-built_in">view</span>(-<span class="hljs-number">1</span>)<br>        model.<span class="hljs-built_in">train</span>()<br>    return <span class="hljs-built_in">roc_auc_score</span>(edge_label.<span class="hljs-built_in">cpu</span>().<span class="hljs-built_in">numpy</span>(), out.<span class="hljs-built_in">cpu</span>().<span class="hljs-built_in">numpy</span>())<br><br><br><br>model = <span class="hljs-built_in">RGCN_LP</span>(<span class="hljs-number">128</span>, <span class="hljs-number">64</span>, <span class="hljs-number">4</span>).<span class="hljs-built_in">to</span>(device)<br>optimizer = torch.optim.<span class="hljs-built_in">Adam</span>(params=model.<span class="hljs-built_in">parameters</span>(), lr=<span class="hljs-number">0.01</span>)<br>criterion = torch.nn.<span class="hljs-built_in">BCEWithLogitsLoss</span>().<span class="hljs-built_in">to</span>(device)<br>min_epochs = <span class="hljs-number">10</span><br>best_model = None<br>best_val_auc = <span class="hljs-number">0</span><br>final_test_auc = <span class="hljs-number">0</span><br>model.<span class="hljs-built_in">train</span>()<br>for epoch in <span class="hljs-built_in">range</span>(<span class="hljs-number">500</span>):<br>    optimizer.<span class="hljs-built_in">zero_grad</span>()<br>    edge_label, edge_label_index = <span class="hljs-built_in">negative_sample</span>(train_data)<br>    out = <span class="hljs-built_in">model</span>(graph, edge_label_index).<span class="hljs-built_in">view</span>(-<span class="hljs-number">1</span>)<br>    loss = <span class="hljs-built_in">criterion</span>(out, edge_label)<br>    loss.<span class="hljs-built_in">backward</span>()<br>    optimizer.<span class="hljs-built_in">step</span>()<br>    # validation<br>    val_auc = <span class="hljs-built_in">test</span>(model, val_data)<br>    # test_auc = <span class="hljs-built_in">test</span>(model, test_data)<br>    if epoch + <span class="hljs-number">1</span> &gt; min_epochs and val_auc &gt; best_val_auc:<br>        best_val_auc = val_auc<br>        # final_test_auc = test_auc<br>    if epoch % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch &#123;:03d&#125; train_loss &#123;:.8f&#125; val_auc &#123;:.4f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(epoch, loss.<span class="hljs-built_in">item</span>(), val_auc))<br>        # <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch &#123;:03d&#125; train_loss &#123;:.8f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(epoch, loss.<span class="hljs-built_in">item</span>()))<br><br></code></pre></td></tr></table></figure><p>参考：<a href="https://blog.csdn.net/circle2015/article/details/128004889">https://blog.csdn.net/circle2015/article/details/128004889</a><br>     <a href="https://blog.csdn.net/Cyril_KI/article/details/126186418?spm=1001.2014.3001.5502">https://blog.csdn.net/Cyril_KI/article/details/126186418?spm=1001.2014.3001.5502</a><br>     <a href="https://blog.csdn.net/Cyril_KI/article/details/126048682">https://blog.csdn.net/Cyril_KI/article/details/126048682</a><br>     <a href="https://zhuanlan.zhihu.com/p/354258797">https://zhuanlan.zhihu.com/p/354258797</a><br>     <a href="https://blog.csdn.net/PolarisRisingWar/article/details/128130870">https://blog.csdn.net/PolarisRisingWar/article/details/128130870</a><br>     <a href="https://blog.csdn.net/PolarisRisingWar/article/details/126980943">https://blog.csdn.net/PolarisRisingWar/article/details/126980943</a></p>]]></content>
    
    
    <categories>
      
      <category>图神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>异质图</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在线运行Vue项目</title>
    <link href="/2022/12/05/%E5%9C%A8%E7%BA%BF%E8%BF%90%E8%A1%8CVue%E9%A1%B9%E7%9B%AE/"/>
    <url>/2022/12/05/%E5%9C%A8%E7%BA%BF%E8%BF%90%E8%A1%8CVue%E9%A1%B9%E7%9B%AE/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><ul><li><p>在线运行Vue项目地址：<a href="https://stackblitz.com/">https://stackblitz.com/</a><br>注册登录即可，也可直接使用github账户登录。选择Vue3后就直接进入环境了。虽然显示可以直接导入github仓库，不过测试导入不显示，可能还有bug吧</p></li><li><p>按照参考的方法使用<br><a href="https://stackblitz.com/github">https://stackblitz.com/github</a> + 名称/仓库（Jeff-Bee/knowledgeGraph）即 <a href="https://stackblitz.com/github/Jeff-Bee/knowledgeGraph">https://stackblitz.com/github/Jeff-Bee/knowledgeGraph</a></p></li><li><p>进去后会自动安装依赖，如果没安装成功，在终端重新执行安装命令</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">npm <span class="hljs-keyword">install</span><br></code></pre></td></tr></table></figure></li><li><p>启动项目</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">npm <span class="hljs-builtin-name">run</span> serve<br></code></pre></td></tr></table></figure></li></ul><p>参考：<br><a href="https://cloud.tencent.com/developer/article/1429246">https://cloud.tencent.com/developer/article/1429246</a></p>]]></content>
    
    
    <categories>
      
      <category>大前端</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Vue</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>监控cpu使用率可视化</title>
    <link href="/2022/11/03/%E7%9B%91%E6%8E%A7cpu%E4%BD%BF%E7%94%A8%E7%8E%87%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    <url>/2022/11/03/%E7%9B%91%E6%8E%A7cpu%E4%BD%BF%E7%94%A8%E7%8E%87%E5%8F%AF%E8%A7%86%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><p>可视化使用的echarts</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">var</span> <span class="hljs-string">myChart</span> <span class="hljs-string">=</span> <span class="hljs-string">echarts.init(document.getElementById(&#x27;main&#x27;));</span><br><span class="hljs-string">var</span> <span class="hljs-string">data</span> <span class="hljs-string">=</span> <span class="hljs-string">parseInt(res.data);</span><br><span class="hljs-string">//</span> <span class="hljs-string">指定图表的配置项和数据</span><br><span class="hljs-string">var</span> <span class="hljs-string">option</span> <span class="hljs-string">=</span> &#123;<br>  <span class="hljs-attr">dark:</span> <span class="hljs-literal">true</span>,<br>  <span class="hljs-attr">backgroundColor:</span> <span class="hljs-string">&#x27;#001122&#x27;</span>,<br>  <span class="hljs-attr">series:</span> [<br>    &#123;<br>      <span class="hljs-attr">type:</span> <span class="hljs-string">&#x27;gauge&#x27;</span>,<br>      <span class="hljs-attr">progress:</span> &#123;<br>        <span class="hljs-attr">show:</span> <span class="hljs-literal">false</span>,<br>        <span class="hljs-attr">width:</span> <span class="hljs-number">5</span>,<br>        <span class="hljs-attr">itemStyle:</span> &#123;<br>          <span class="hljs-attr">color:</span> &#123;<br>            <span class="hljs-attr">type:</span> <span class="hljs-string">&#x27;radial&#x27;</span>,<br>            <span class="hljs-attr">global:</span> <span class="hljs-literal">true</span>,<br>            <span class="hljs-string">//</span> <span class="hljs-attr">x:</span> <span class="hljs-number">1</span>,<br>            <span class="hljs-string">//</span> <span class="hljs-attr">y:</span> <span class="hljs-number">0.5</span>,<br>            <span class="hljs-string">//</span> <span class="hljs-attr">r:</span> <span class="hljs-number">0.5</span>,<br>            <span class="hljs-attr">colorStops:</span> [<br>              &#123;<br>                <span class="hljs-attr">offset:</span> <span class="hljs-number">0</span>,<br>                <span class="hljs-attr">color:</span> <span class="hljs-string">&#x27;transparent&#x27;</span>,<br>              &#125;,<br>              &#123;<br>                <span class="hljs-attr">offset:</span> <span class="hljs-number">0.7</span>,<br>                <span class="hljs-attr">color:</span> <span class="hljs-string">&#x27;transparent&#x27;</span>,<br>              &#125;,<br>              &#123;<br>                <span class="hljs-attr">offset:</span> <span class="hljs-number">0.95</span>,<br>                <span class="hljs-attr">color:</span> <span class="hljs-string">&#x27;rgba(150, 200, 255, 0.5)&#x27;</span>,<br>              &#125;,<br>              &#123;<br>                <span class="hljs-attr">offset:</span> <span class="hljs-number">0.98</span>,<br>                <span class="hljs-attr">color:</span> <span class="hljs-string">&#x27;rgba(230, 250, 255, 0.9)&#x27;</span>,<br>              &#125;,<br>              &#123;<br>                <span class="hljs-attr">offset:</span> <span class="hljs-number">1</span>,<br>                <span class="hljs-attr">color:</span> <span class="hljs-string">&#x27;rgba(255,255,255,1)&#x27;</span>,<br>              &#125;,<br>            ],<br>          &#125;,<br>        &#125;,<br>      &#125;,<br>      <span class="hljs-attr">axisLine:</span> &#123;<br>        <span class="hljs-attr">lineStyle:</span> &#123;<br>          <span class="hljs-attr">width:</span> <span class="hljs-number">2</span>,<br>          <span class="hljs-attr">color:</span> [<br>            [<span class="hljs-number">0.8</span>, <span class="hljs-string">&#x27;#fff&#x27;</span>],<br>            [<span class="hljs-number">1</span>, <span class="hljs-string">&#x27;red&#x27;</span>],<br>          ],<br>        &#125;,<br>      &#125;,<br>      <span class="hljs-attr">axisTick:</span> &#123;<br>        <span class="hljs-attr">lineStyle:</span> &#123;<br>            <span class="hljs-attr">color:</span> <span class="hljs-string">&#x27;#fff&#x27;</span>,<br>          &#125;,<br>      &#125;,<br>      <span class="hljs-attr">splitLine:</span> &#123;<br>        <span class="hljs-attr">length:</span> <span class="hljs-number">15</span>,<br>        <span class="hljs-attr">lineStyle:</span> &#123;<br>          <span class="hljs-attr">width:</span> <span class="hljs-number">2</span>,<br>          <span class="hljs-attr">color:</span> <span class="hljs-string">&#x27;#999&#x27;</span><br>        &#125;<br>      &#125;,<br>      <span class="hljs-attr">axisLabel:</span> &#123;<br>        <span class="hljs-attr">color:</span> <span class="hljs-string">&#x27;#fff&#x27;</span>,<br>        <span class="hljs-attr">fontSize:</span> <span class="hljs-number">20</span>,<br>      &#125;,<br>      <span class="hljs-attr">anchor:</span> &#123;<br>        <span class="hljs-attr">show:</span> <span class="hljs-literal">true</span>,<br>        <span class="hljs-attr">size:</span> <span class="hljs-number">60</span>,<br>        <span class="hljs-attr">showAbove:</span> <span class="hljs-literal">true</span>,<br>        <span class="hljs-attr">itemStyle:</span> &#123;<br>          <span class="hljs-attr">color:</span> <span class="hljs-string">&#x27;#001122&#x27;</span>,<br>          <span class="hljs-attr">opacity:</span> <span class="hljs-number">0.9</span>,<br>          <span class="hljs-attr">borderColor:</span> <span class="hljs-string">&#x27;rgba(255,255,255,0.8)&#x27;</span>,<br>          <span class="hljs-attr">borderWidth:</span> <span class="hljs-number">1</span>,<br>          <span class="hljs-attr">shadowBlur:</span> <span class="hljs-number">30</span>,<br>          <span class="hljs-attr">shadowColor:</span> <span class="hljs-string">&#x27;rgba(255, 255, 255, 0.5)&#x27;</span>,<br>        &#125;,<br>      &#125;,<br>      <span class="hljs-attr">pointer:</span> &#123;<br>        <span class="hljs-attr">offsetCenter:</span> [<span class="hljs-number">0</span>, <span class="hljs-string">&#x27;20%&#x27;</span>],<br>        <span class="hljs-attr">icon:</span> <span class="hljs-string">&#x27;path://M2090.36389,615.30999 L2090.36389,615.30999 C2091.48372,615.30999 2092.40383,616.194028 2092.44859,617.312956 L2096.90698,728.755929 C2097.05155,732.369577 2094.2393,735.416212 2090.62566,735.56078 C2090.53845,735.564269 2090.45117,735.566014 2090.36389,735.566014 L2090.36389,735.566014 C2086.74736,735.566014 2083.81557,732.63423 2083.81557,729.017692 C2083.81557,728.930412 2083.81732,728.84314 2083.82081,728.755929 L2088.2792,617.312956 C2088.32396,616.194028 2089.24407,615.30999 2090.36389,615.30999 Z&#x27;</span>,<br>        <span class="hljs-attr">length:</span> <span class="hljs-string">&#x27;110%&#x27;</span>,<br>        <span class="hljs-attr">itemStyle:</span> &#123;<br>          <span class="hljs-attr">color:</span> <span class="hljs-string">&#x27;rgba(255,255,255,0.9)&#x27;</span>,<br>        &#125;,<br>      &#125;,<br>      <span class="hljs-attr">title:</span> &#123;<br>        <span class="hljs-attr">show:</span> <span class="hljs-literal">false</span><br>      &#125;,<br>      <span class="hljs-attr">detail:</span> &#123;<br>        <span class="hljs-attr">valueAnimation:</span> <span class="hljs-literal">true</span>,<br>          <span class="hljs-string">//</span> <span class="hljs-attr">formatter:</span> <span class="hljs-string">&#x27;&#123;value&#125;\n&#123;unit|km / h&#125;&#x27;</span>,<br>          <span class="hljs-attr">offsetCenter:</span> [<span class="hljs-number">0</span>, <span class="hljs-string">&#x27;50%&#x27;</span>],<br>          <span class="hljs-attr">rich:</span> &#123;<br>            <span class="hljs-attr">unit:</span> &#123;<br>              <span class="hljs-attr">lineHeight:</span> <span class="hljs-number">80</span>,<br>              <span class="hljs-attr">color:</span> <span class="hljs-string">&#x27;#fff&#x27;</span>,<br>              <span class="hljs-attr">fontSize:</span> <span class="hljs-number">30</span>,<br>            &#125;,<br>          &#125;,<br>          <span class="hljs-attr">fontSize:</span> <span class="hljs-number">50</span>,<br>          <span class="hljs-attr">color:</span> <span class="hljs-string">&#x27;#fff&#x27;</span>,<br>      &#125;,<br>      <span class="hljs-attr">data:</span> [<br>        &#123;<br>          <span class="hljs-attr">value:</span> <span class="hljs-string">data</span><br>        &#125;<br>      ]<br>    &#125;<br>  ]<br>&#125;<span class="hljs-string">;</span><br><br><span class="hljs-string">//</span> <span class="hljs-string">使用刚指定的配置项和数据显示图表。</span><br><span class="hljs-string">myChart.setOption(option);</span><br><span class="hljs-string">&#125;);</span><br></code></pre></td></tr></table></figure><p>完整代码见：<a href="https://github.com/shubihu/Tools/tree/master/cpuMonitor">https://github.com/shubihu/Tools/tree/master/cpuMonitor</a></p><h3 id="抄代码参考"><a href="#抄代码参考" class="headerlink" title="抄代码参考"></a>抄代码参考</h3><p><a href="https://blog.csdn.net/joson1234567890/article/details/106572536">https://blog.csdn.net/joson1234567890/article/details/106572536</a><br><a href="https://www.delftstack.com/zh/howto/python/get-cpu-usage-in-python/">https://www.delftstack.com/zh/howto/python/get-cpu-usage-in-python/</a></p>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>R包magick安装的坑</title>
    <link href="/2022/10/09/R%E5%8C%85magick%E5%AE%89%E8%A3%85%E7%9A%84%E5%9D%91/"/>
    <url>/2022/10/09/R%E5%8C%85magick%E5%AE%89%E8%A3%85%E7%9A%84%E5%9D%91/</url>
    
    <content type="html"><![CDATA[<h2 id="Magick"><a href="#Magick" class="headerlink" title="Magick"></a>Magick</h2><span id="more"></span><p>安装magick遇到的问题记录一下，毕竟花了好多时间。<br>问题1:</p><figure class="highlight smali"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs smali">Configuration failed to find the Magick++ library. Try installing:<br> - deb: libmagick++-dev (Debian, Ubuntu)<br> - rpm: ImageMagick-c++-devel (Fedora, CentOS, RHEL)<br> - csw: imagemagick_dev (Solaris)<br> - brew imagemagick@6 (MacOS)<br>For Ubuntu versions Trusty (14.04)<span class="hljs-built_in"> and </span>Xenial (16.04) use our PPA:<br>   sudo<span class="hljs-built_in"> add-apt-repository </span>-y ppa:cran/imagemagick<br>   sudo apt-get update<br>   sudo apt-get install -y libmagick++-dev<br>If Magick++ is already installed,<span class="hljs-built_in"> check </span>that &#x27;pkg-config&#x27; is in your<br>PATH<span class="hljs-built_in"> and </span>PKG_CONFIG_PATH contains a Magick++.pc file. If pkg-config<br>is unavailable you can set INCLUDE_DIR<span class="hljs-built_in"> and </span>LIB_DIR manually via:<br>R CMD INSTALL --configure-vars=&#x27;INCLUDE_DIR=... LIB_DIR=...&#x27;<br></code></pre></td></tr></table></figure><p>解决方法：按照对应的系统安装 ImageMagick</p><p>这个问题好解决，但是事情往往没这么简单。</p><h5 id="终极问题："><a href="#终极问题：" class="headerlink" title="终极问题："></a>终极问题：</h5><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gradle">Error: <span class="hljs-keyword">package</span> or namespace load failed <span class="hljs-keyword">for</span> ‘magick’ in dyn.load(<span class="hljs-keyword">file</span>, DLLpath = DLLpath, ...):<br> unable to load shared object <span class="hljs-string">&#x27;/share/apps/R/R-4.2.1/library/00LOCK-magick/00new/magick/libs/magick.so&#x27;</span>:<br>  <span class="hljs-regexp">/share/</span>apps<span class="hljs-regexp">/R/</span>R-<span class="hljs-number">4.2</span>.<span class="hljs-number">1</span><span class="hljs-regexp">/library/</span><span class="hljs-number">00</span>LOCK-magick<span class="hljs-regexp">/00new/m</span>agick<span class="hljs-regexp">/libs/m</span>agick.so: undefined symbol: _ZN6Magick5Image5writeEPNS_4BlobERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEm<br></code></pre></td></tr></table></figure><p>就这个问题网上找了好多办法都没解决，也可能是之前自己搜的关键词不对，最开始检索的错误信息（Error: package or namespace load failed for ‘magick’ in dyn.load(file, DLLpath = DLLpath, …)），挖了半天一直试错。最后通过检索（magick.so: undefined symbol: _ZN6Magick5Image5wri)找到了解决方法。</p><p>解决方法(如果没有该目录请提前创建)：</p><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arcade">echo <span class="hljs-string">&quot;CXX11=/usr/bin/g++&quot;</span> &gt; ~<span class="hljs-regexp">/.R/</span>Makevars<br></code></pre></td></tr></table></figure><p>这个方法还是在github上的一个issue上看到的，按方法中所说应该是g++版本的问题，更改编译的g++即可。<br>地址如下：<br><a href="https://github.com/ropensci/magick/issues/300">https://github.com/ropensci/magick/issues/300</a></p><p>最后的安装命令（下载的源码进行安装的，应该也可以直接安装不用提前下载源码）</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs lasso">install.packages(<span class="hljs-string">&quot;magick_2.7.3.tar.gz&quot;</span>,repos=<span class="hljs-built_in">NULL</span>,<span class="hljs-keyword">type</span>=<span class="hljs-string">&quot;source&quot;</span>)<br></code></pre></td></tr></table></figure><h6 id="其他错误：usr-bin-ld-cannot-find-错误解决方法"><a href="#其他错误：usr-bin-ld-cannot-find-错误解决方法" class="headerlink" title="其他错误：usr/bin/ld: cannot find 错误解决方法"></a>其他错误：usr/bin/ld: cannot find 错误解决方法</h6><p>通常在软件编译时出现的usr/bin/ld: cannot find -lxxx的错误，主要的原因是库文件并没有导入的ld检索目录中。<br>其中xxx即表示函式库文件名称，如上例的：libc.so、libltdl.so、libXtst.so。<br>其命名规则是：lib+库名(即xxx)+.so。<br>会发生这样的原因有以下三种情形：<br>1 系统没有安装相对应的lib<br>2 相对应的lib版本不对<br>3 lib(.so档)的symbolic link 不正确，没有连结到正确的函式库文件(.so)</p><p>解决方式：<br>1。确认库文件是否存在，比如-l123, 在/usr/lib, /usr/local/lib,或者其他自定义的lib下有无lib123.so, 如果只是存在lib123.so.1,<br>   那么可以通过ln -sv lib123.so.1   lib123.so，建立一个连接重建lib123.so.<br>2。检查/etc/ld.so.conf中的库文件路径是否正确，如果库文件不是使用系统路径，/usr/lib, /usr/local/lib, 那么必须在文件中加入。<br>3。ldconfig 重建ld.so.cache文件，ld的库文件检索目录存放文件。尤其刚刚编译安装的软件，必须运行ldconfig，才能将新安装的库文件导入ld.so.cache</p>]]></content>
    
    
    <categories>
      
      <category>TroubleShoot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TroubleShoot</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>英伟达(nvida)驱动安装的坑</title>
    <link href="/2022/09/02/%E8%8B%B1%E4%BC%9F%E8%BE%BE-nvida-%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85%E7%9A%84%E5%9D%91/"/>
    <url>/2022/09/02/%E8%8B%B1%E4%BC%9F%E8%BE%BE-nvida-%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85%E7%9A%84%E5%9D%91/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><p>本来服务器上的驱动没有问题的，因为之前的cudatookits是通过conda安装的，现在需要管理员在全局安装。<br>cudatoolkits下载 <a href="https://developer.nvidia.com/cuda-toolkit-archive">https://developer.nvidia.com/cuda-toolkit-archive</a><br>根据自己的系统选择对应的文件下载。注意：这里尽量选择runfile文件下载，因为runfile文件安装的时候可以进行选择哪些安装哪些不安装，如果选择rpm包下载安装可能就是全家桶了，包括显卡驱动。我就是下的rpm包安装的(没留神下成最新的版本了)，然后驱动就更新了，随之显卡就悲催的不能用了。<br>没办法只能重新安装驱动<br>查看显卡版本</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">cat <span class="hljs-regexp">/proc/</span>driver<span class="hljs-regexp">/nvidia/</span>version<br></code></pre></td></tr></table></figure><p>下载驱动 <a href="http://www.nvidia.com/Download/Find.aspx">http://www.nvidia.com/Download/Find.aspx</a><br>选择和显卡版本一致的驱动版本，我这里的版本和安装命令如下，另外kernel的目录3.10.0-1062.18.1.el7.x86_64改成自己的</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># NVIDIA-Linux-x86_64-515.57.run</span><br><span class="hljs-attribute">chmod</span> +x NVIDIA-Linux-x<span class="hljs-number">86</span>_<span class="hljs-number">64</span>-<span class="hljs-number">515</span>.<span class="hljs-number">57</span>.run<br><span class="hljs-attribute">sudo</span> ./NVIDIA-Linux-x<span class="hljs-number">86</span>_<span class="hljs-number">64</span>-<span class="hljs-number">515</span>.<span class="hljs-number">57</span>.run --kernel-source-path=/usr/src/kernels/<span class="hljs-number">3</span>.<span class="hljs-number">10</span>.<span class="hljs-number">0</span>-<span class="hljs-number">1062</span>.<span class="hljs-number">18</span>.<span class="hljs-number">1</span>.el<span class="hljs-number">7</span>.x<span class="hljs-number">86</span>_<span class="hljs-number">64</span> -k $(uname -r)<br></code></pre></td></tr></table></figure><p>以为一切很顺利，然后就报错了。</p><h5 id="第一个坑"><a href="#第一个坑" class="headerlink" title="第一个坑"></a>第一个坑</h5><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs awk">ERROR: You appear to be running an X server; please <span class="hljs-keyword">exit</span> X before            <br>         installing.  For further details, please see the section INSTALLING   <br>         THE NVIDIA DRIVER <span class="hljs-keyword">in</span> the README available on the Linux driver         <br>         download page at www.nvidia.com.<br></code></pre></td></tr></table></figure><p>网上扒了半天扒了一个有效的方法：<a href="https://unix.stackexchange.com/questions/25668/how-to-close-x-server-to-avoid-errors-while-updating-nvidia-driver">https://unix.stackexchange.com/questions/25668/how-to-close-x-server-to-avoid-errors-while-updating-nvidia-driver</a></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">sudo</span> init <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><h5 id="第二个坑"><a href="#第二个坑" class="headerlink" title="第二个坑"></a>第二个坑</h5><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs applescript">ERROR: An NVIDIA kernel module &#x27;nvidia-uvm&#x27; appears <span class="hljs-keyword">to</span> already be loaded <span class="hljs-keyword">in</span> your kernel.  This may be because <span class="hljs-keyword">it</span> <span class="hljs-keyword">is</span> <br><span class="hljs-keyword">in</span> use (<span class="hljs-keyword">for</span> example, <span class="hljs-keyword">by</span> an X server, a CUDA program, <span class="hljs-keyword">or</span> <span class="hljs-keyword">the</span> NVIDIA Persistence Daemon), <span class="hljs-keyword">but</span> this may also happen <span class="hljs-keyword">if</span> <br>your kernel was configured <span class="hljs-keyword">without</span> support <span class="hljs-keyword">for</span> module unloading.  Please be sure <span class="hljs-keyword">to</span> <span class="hljs-keyword">exit</span> any programs <span class="hljs-keyword">that</span> may be us<br>ing <span class="hljs-keyword">the</span> GPU(s) <span class="hljs-keyword">before</span> attempting <span class="hljs-keyword">to</span> upgrade your driver.  If no GPU-based programs are <span class="hljs-built_in">running</span>, you know <span class="hljs-keyword">that</span> your k<br>ernel supports module unloading, <span class="hljs-keyword">and</span> you still receive this message, <span class="hljs-keyword">then</span> an <span class="hljs-keyword">error</span> may have occurred <span class="hljs-keyword">that</span> has corrup<br>ted an NVIDIA kernel module&#x27;s usage <span class="hljs-built_in">count</span>, <span class="hljs-keyword">for</span> which <span class="hljs-keyword">the</span> simplest remedy <span class="hljs-keyword">is</span> <span class="hljs-keyword">to</span> reboot your computer.<br></code></pre></td></tr></table></figure><p>解决方法参考 <a href="https://www.cnblogs.com/1016391912pm/p/16494815.html">https://www.cnblogs.com/1016391912pm/p/16494815.html</a></p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># 查看显卡上的进程 </span><br>lsof <span class="hljs-regexp">/dev/</span>nvidia*<br><span class="hljs-comment"># kill 掉所有进程</span><br>kill -<span class="hljs-number">9</span> xxx<br></code></pre></td></tr></table></figure><p>再次运行安装显卡驱动命令终于可以往下进行了。</p><p>参考：<a href="https://www.cnblogs.com/gollong/p/12655424.html">https://www.cnblogs.com/gollong/p/12655424.html</a><br>    <a href="https://www.cnblogs.com/shenggang/p/12133220.html">https://www.cnblogs.com/shenggang/p/12133220.html</a><br>    <a href="https://eipi10.cn/deep-learning/2019/11/28/centos_cuda_cudnn/">https://eipi10.cn/deep-learning/2019/11/28/centos_cuda_cudnn/</a></p>]]></content>
    
    
    <categories>
      
      <category>TroubleShoot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TroubleShoot</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>jupyterhub踩坑</title>
    <link href="/2022/08/30/jupyterhub%E8%B8%A9%E5%9D%91/"/>
    <url>/2022/08/30/jupyterhub%E8%B8%A9%E5%9D%91/</url>
    
    <content type="html"><![CDATA[<h2 id="坑"><a href="#坑" class="headerlink" title="坑"></a>坑</h2><span id="more"></span><h5 id="安装Jupyterhub"><a href="#安装Jupyterhub" class="headerlink" title="安装Jupyterhub"></a>安装Jupyterhub</h5><p>使用 conda 安装，另外官网提供了pip安装方法，参考：<a href="https://jupyterhub.readthedocs.io/en/latest/quickstart.html#prerequisites">https://jupyterhub.readthedocs.io/en/latest/quickstart.html#prerequisites</a></p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">conda <span class="hljs-keyword">install </span>-c conda-forge <span class="hljs-keyword">jupyterhub </span> <span class="hljs-comment"># installs jupyterhub and proxy</span><br>conda <span class="hljs-keyword">install </span><span class="hljs-keyword">jupyterlab </span>notebook  <span class="hljs-comment"># needed if running the notebook servers in the same environment</span><br></code></pre></td></tr></table></figure><p>测试安装是否成功</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">jupyterhub -h</span><br><span class="hljs-attribute">configurable-http-proxy -h</span><br></code></pre></td></tr></table></figure><h5 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h5><p>使用sudo权限启动，这样可以多用户使用jupyter</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs verilog">jupyterhub --<span class="hljs-keyword">generate</span>-<span class="hljs-keyword">config</span> #生成配置文件<br>sudo jupyterhub<br></code></pre></td></tr></table></figure><p>如果有坑，就需要对配置文件进行修改<br>我这里遇到的坑也是对conda升级造成的，即 conda update conda, 所以没啥事还是不要升级的好。</p><h5 id="conda-版本回退"><a href="#conda-版本回退" class="headerlink" title="conda 版本回退"></a>conda 版本回退</h5><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ada">conda list <span class="hljs-comment">--revisions</span><br></code></pre></td></tr></table></figure><p>可以显示之前所有的安装版本，以及相应的时间，然后选择一个正常的版本进行回退(我这里选择第16个版本)</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ada">conda install <span class="hljs-comment">--revision 16</span><br></code></pre></td></tr></table></figure><p>参考：<a href="https://chowdera.com/2022/01/202201151540272854.html">https://chowdera.com/2022/01/202201151540272854.html</a></p><h5 id="各种坑"><a href="#各种坑" class="headerlink" title="各种坑"></a>各种坑</h5><p>最开始一直遇到的问题是<br>    Spawn failed:Server at xxxxxxxxx respond in 30 seconds<br>经过不断测试（一天过去了）<br>配置文件里添加了个参数，如下，倒是可以运行了，但是后来发现这个参数是给到root权限了，所以坚决去掉，不然太危险了。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">c<span class="hljs-selector-class">.Spawner</span><span class="hljs-selector-class">.args</span> = <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;--allow-root&#x27;</span>]</span><br></code></pre></td></tr></table></figure><p>后来在 <a href="https://github.com/jupyterhub/jupyterhub/issues/294">https://github.com/jupyterhub/jupyterhub/issues/294</a> 这里找到了答案<br>原来是用户家目录的 .jupyter 目录惹的祸， 删除或者改个名字就OK了。</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">rm -rf ~<span class="hljs-string">/.jupyter</span><br></code></pre></td></tr></table></figure><p>当然了坑不止这一个，总之一言难尽，最后整体一个配置如下：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">c.PAMAuthenticator.encoding</span> = <span class="hljs-string">&#x27;utf8&#x27;</span><br><span class="hljs-attr">c.LocalAuthenticator.create_system_users</span> = <span class="hljs-literal">True</span><br><span class="hljs-attr">c.Authenticator.admin_users</span> = &#123;<span class="hljs-string">&#x27;dg&#x27;</span>&#125;<br><span class="hljs-attr">c.Authenticator.allowed_users</span> = &#123;<span class="hljs-string">&#x27;dg&#x27;</span>&#125;<br><span class="hljs-attr">c.JupyterHub.authenticator_class</span> = <span class="hljs-string">&#x27;dummyauthenticator.DummyAuthenticator&#x27;</span><br><span class="hljs-comment">#c.JupyterHub.authenticator_class = &#x27;jupyterhub.auth.DummyAuthenticator&#x27;</span><br><span class="hljs-comment">#c.JupyterHub.spawner_class = &#x27;jupyterhub.spawner.SimpleLocalProcessSpawner&#x27;</span><br><span class="hljs-attr">c.LocalProcessSpawner.shell_cmd</span> = [<span class="hljs-string">&quot;bash&quot;</span>, <span class="hljs-string">&quot;-l&quot;</span>, <span class="hljs-string">&quot;-c&quot;</span>]<br><span class="hljs-attr">c.Spawner.notebook_dir</span> = <span class="hljs-string">&#x27;/share/home/&#123;username&#125;&#x27;</span><br><span class="hljs-attr">c.LabBuildApp.minimize</span> = <span class="hljs-literal">False</span><br><span class="hljs-attr">c.LabBuildApp.dev_build</span> = <span class="hljs-literal">False</span><br><br><span class="hljs-comment">### 这几项应该没啥用 ###</span><br><span class="hljs-comment">#c.Spawner.cmd=[&#x27;jupyterhub-singleuser&#x27;]</span><br><span class="hljs-comment">#c.JupyterHub.admin_access = True</span><br><span class="hljs-comment">#c.PAMAuthenticator.open_sessions = False</span><br></code></pre></td></tr></table></figure><p>参考：<a href="https://www.cnblogs.com/childheart/p/15570915.html">https://www.cnblogs.com/childheart/p/15570915.html</a></p><p>另外关于conda</p><h4 id="切换不同的镜像站点时记得清除缓存"><a href="#切换不同的镜像站点时记得清除缓存" class="headerlink" title="切换不同的镜像站点时记得清除缓存"></a>切换不同的镜像站点时记得清除缓存</h4><p>删除索引缓存、锁定文件、未使用过的包和tar包</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">conda clean -<span class="hljs-selector-tag">a</span><br></code></pre></td></tr></table></figure><p>当从一个站点切换到另一个站点的时候记得运行一下上面这个命令，否则即使更新了~/.condarc，软件还是会从之前的站点下载。</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>jupyter</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python + Selenium爬取drugbank药物靶点信息</title>
    <link href="/2022/08/19/Python-Selenium%E7%88%AC%E5%8F%96drugbank%E8%8D%AF%E7%89%A9%E9%9D%B6%E7%82%B9%E4%BF%A1%E6%81%AF/"/>
    <url>/2022/08/19/Python-Selenium%E7%88%AC%E5%8F%96drugbank%E8%8D%AF%E7%89%A9%E9%9D%B6%E7%82%B9%E4%BF%A1%E6%81%AF/</url>
    
    <content type="html"><![CDATA[<h2 id="Selenium爬虫"><a href="#Selenium爬虫" class="headerlink" title="Selenium爬虫"></a>Selenium爬虫</h2><span id="more"></span><p>为什么要使用selenium来进行爬取，因为有的网站有反爬机制，平常的requests等无法爬取。<br>Selenium可使用pip进行安装</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span> selenium<br></code></pre></td></tr></table></figure><p>这里使用chrome浏览器进行爬取，所以需要下载对应版本的chromedriver，下载地址如下<br><a href="https://chromedriver.storage.googleapis.com/index.html">https://chromedriver.storage.googleapis.com/index.html</a></p><p>在drugbank网站输入一个drugID或者drug的名字即可查到该药物的相关信息，根据自己的需求进行提取。我主要是需要靶点的信息即targets。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> selenium <span class="hljs-keyword">import</span> webdriver<br><span class="hljs-keyword">from</span> selenium.webdriver.common.by <span class="hljs-keyword">import</span> By<br><br><span class="hljs-comment"># 下载的chromedriver地址</span><br>chromedriver = <span class="hljs-string">r&#x27;/Users/xxx/Desktop/drugbank-spider/chromedriver&#x27;</span><br>os.environ[<span class="hljs-string">&#x27;webdriver.chrome.driver&#x27;</span>] = chromedriver<br>driver = webdriver.Chrome(chromedriver)<br><br><span class="hljs-comment"># 使用代码爬虫的时候只能输入drugID,如果有很多个drugID，网址信息只需要改变drugID即可</span><br>drugID = <span class="hljs-string">&#x27;DB00635&#x27;</span><br>site = <span class="hljs-string">&#x27;https://go.drugbank.com/drugs/&#x27;</span> + drugID<br>driver.get(site)<br></code></pre></td></tr></table></figure><p>运行代码会打开一个chrome窗口显示对应的drug的信息，就如同自己输入一样。<br>如果想获取或者保存整个网页的源代码，可通过如下代码</p><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sqf"><span class="hljs-built_in">driver</span>.page_source<br></code></pre></td></tr></table></figure><p>如果只是想获取某一部分信息，就需要进行提取了。<br>在网页上选中自己感兴趣的信息点击右键，选择检查就可以直接定位到html中。<br>在 WebDriver 中现在有两种用法，find_element()和find_elements()。需要通过参数传入定位方式和定位语句。<br>比如这里通过ID定位查找元素</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">driver.find_element(<span class="hljs-keyword">By</span>.ID, <span class="hljs-string">&#x27;uniprot-id&#x27;</span>)<br>#获取文本内容需要加个.text即可，如下<br>driver.find_element(<span class="hljs-keyword">By</span>.ID, <span class="hljs-string">&#x27;uniprot-id&#x27;</span>).text<br></code></pre></td></tr></table></figure><p>find_elements()查到的信息是个列表<br>比如通过class 名字进行定位查找（targets信息)</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs less"><span class="hljs-selector-tag">driver</span><span class="hljs-selector-class">.find_elements</span>(By.CLASS_NAME, <span class="hljs-string">&#x27;col-md-7&#x27;</span>)<br># 这里<span class="hljs-selector-tag">targets</span>的信息如下(如果targets有多个，可能位置索引就会变，而不是<span class="hljs-number">8</span>了)<br><span class="hljs-selector-tag">driver</span><span class="hljs-selector-class">.find_elements</span>(By.CLASS_NAME, <span class="hljs-string">&#x27;col-md-7&#x27;</span>)<span class="hljs-selector-attr">[8]</span><span class="hljs-selector-class">.text</span><br></code></pre></td></tr></table></figure><p>以上获取的是所有class名字为col-md-7 的所有内容，还需要手动确认列表中哪一项是自己需要的。当然了，以这种方式获取可能会存在bug，因为不能保证自己需要的信息一定在列表中的某一固定位置。</p><p>以下是定位方式与 By 中的属性对应清单：</p><table><thead><tr><th>定位方式</th><th>By</th></tr></thead><tbody><tr><td>id</td><td>By.ID</td></tr><tr><td>name</td><td>By.NAME</td></tr><tr><td>class_name</td><td>By.CLASS_NAME</td></tr><tr><td>tag_name</td><td>By.TAG_NAME</td></tr><tr><td>link_text</td><td>By.LINK_TEXT</td></tr><tr><td>partial_link_text</td><td>By.PARTIAL_LINK_TEXT</td></tr><tr><td>css_selector</td><td>By.CSS_SELECTOR</td></tr><tr><td>xpath</td><td>By.XPATH</td></tr></tbody></table><p>顺便贴一下另一个数据库网站（药智数据，应该是这个公司自己整理的数据库，只对人民币玩家开放，所以只能不厚道了）的代码</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># 该公司的数据库可输入drug的名字进行查询</span><br><span class="hljs-attribute">drugName</span> = &#x27;Esmolol&#x27;<br><span class="hljs-attribute">site</span> = &#x27;https://db.yaozh.com/targets?durg_name=&#x27; + drugName + &#x27;&amp;type=%E<span class="hljs-number">5</span>%<span class="hljs-number">85</span>%A<span class="hljs-number">8</span>%E<span class="hljs-number">9</span>%<span class="hljs-number">83</span>%A<span class="hljs-number">8</span>&amp;durg_targets=&amp;groups=%E<span class="hljs-number">5</span>%<span class="hljs-number">85</span>%A<span class="hljs-number">8</span>%E<span class="hljs-number">9</span>%<span class="hljs-number">83</span>%A<span class="hljs-number">8</span>&amp;durg_indication=&amp;cas=&#x27;<br><span class="hljs-attribute">driver</span> = webdriver.Chrome(chromedriver)<br><span class="hljs-attribute">driver</span>.get(site)<br><span class="hljs-comment">#th = driver.find_elements(By.TAG_NAME, &#x27;th&#x27;)</span><br><span class="hljs-attribute">td</span> = driver.find_elements(By.TAG_NAME, &#x27;td&#x27;)<br><span class="hljs-attribute">target</span> = td[<span class="hljs-number">3</span>].text<br><span class="hljs-attribute">driver</span>.close()<br><br></code></pre></td></tr></table></figure><p>最后就是使用脚本批量爬取的时候电脑需要一直开机，而且会一直自动打开关闭chrome窗口，所以在爬取的时候就无法进行其他工作。<br>在网上找了下无头操作（即不显示窗口），但是结果却（头是没了，结果也没了），，，可能还是有bug，不过也好，在爬取的时候正好摸个鱼休息休息也不错。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">from selenium.webdriver.chrome.options import Options<br>chrome_options = <span class="hljs-constructor">Options()</span><br>chrome_options.add<span class="hljs-constructor">_argument(&#x27;--<span class="hljs-params">headless</span>&#x27;)</span><br>driver = webdriver.<span class="hljs-constructor">Chrome(<span class="hljs-params">chromedriver</span>, <span class="hljs-params">chrome_options</span> = <span class="hljs-params">chrome_options</span>)</span><br></code></pre></td></tr></table></figure><p>参考：<a href="https://blog.csdn.net/minzhung/category_9416023.html">https://blog.csdn.net/minzhung/category_9416023.html</a></p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>爬虫</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Rstudio Server设置公共库</title>
    <link href="/2022/08/16/Rstudio-Server%E8%AE%BE%E7%BD%AE%E5%85%AC%E5%85%B1%E5%BA%93/"/>
    <url>/2022/08/16/Rstudio-Server%E8%AE%BE%E7%BD%AE%E5%85%AC%E5%85%B1%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><p>在网页版登录远程Rstudio后输入命令</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"><span class="hljs-title">.libPaths()</span><br></code></pre></td></tr></table></figure><p>显示当前环境的R安装包路径，为了方便大家共享安装包可以设置一个公共路径，当然最简单的方法就是直接在当前环境进行设置，如</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs less"><span class="hljs-selector-class">.libPaths</span>(<span class="hljs-string">&quot;/share/apps/R/R-4.2.1/library&quot;</span>)<br></code></pre></td></tr></table></figure><p>但是这就带来一个问题，就是每个用户都要手动进行设置，如果Rstudio server 和 session 重启，可能就需要重新设置，虽然也不是很麻烦，但有可能会忘。</p><p>如何一劳永逸的解决这个问题。<br>编辑 /etc/rstudio/rsession.conf</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">r-libs-user=<span class="hljs-regexp">/share/</span>apps<span class="hljs-regexp">/R/</span>R-<span class="hljs-number">4.2</span>.<span class="hljs-number">1</span>/library<br></code></pre></td></tr></table></figure><p>这里踩了很多坑，不太确定是不是只需要设置这个文件就可以了，设置完重启 rstudio server 和网页版的session</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">sudo systemctl <span class="hljs-keyword">restart</span> rstudio-<span class="hljs-keyword">server</span>.service<br></code></pre></td></tr></table></figure><p>这里只是设置了rsession的环境，但是如果在服务器上使用 Rscript 运行 R 脚本可能找不到刚才设置的库路径，这里需要在设置一下服务器上的R库路径<br>编辑 /etc/profile 写入以下代码（随意选择一个就可以）</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-builtin-name">export</span> <span class="hljs-attribute">R_LIBS</span>=<span class="hljs-string">&quot;/usr/local/hdf5-1.8.17/lib:/share/apps/R/R-4.2.1/library:<span class="hljs-variable">$R_LIBS</span>&quot;</span><br></code></pre></td></tr></table></figure><p>保存退出后使用source 命令重新加载</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gradle"><span class="hljs-keyword">source</span> <span class="hljs-regexp">/etc/</span>profile<br></code></pre></td></tr></table></figure><p>如果使用以上方法已经可以解决Rsession里的libPath，那就不用往下看了。如果没有就接着设置其他文件<br>编辑 /etc/rstudio/rserver.conf 添加以下代码</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs elixir">rsession-ld-library-path=<span class="hljs-regexp">/usr/local</span><span class="hljs-regexp">/hdf5-1.8.17/lib</span><span class="hljs-symbol">:/share/apps/R/R-</span><span class="hljs-number">4.2</span>.<span class="hljs-number">1</span>/library<br></code></pre></td></tr></table></figure><p>编辑 /share/apps/R/R-4.2.1/src/gnuwin32/fixed/etc/Rprofile.site 添加以下代码  这个文件每个人的目录应该不一样，可以使用 locate Rprofile.site 查找自己的目录</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs less"><span class="hljs-selector-class">.libPaths</span>(<span class="hljs-string">&quot;/share/apps/R/R-4.2.1/library&quot;</span>)<br></code></pre></td></tr></table></figure><p>终端执行命令</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs arduino">sudo rstudio-server test-config<br>sudo ldconfig<br></code></pre></td></tr></table></figure><p>所有配置设置完后重启 rstudio server 和网页版的session<br>如果这些还没解决，，，，，，黔驴也有技穷的时候呀。</p><p>hdf5r包安装参考：<br><a href="https://codeleading.com/article/76914236347/">https://codeleading.com/article/76914236347/</a><br><a href="https://blog.csdn.net/qq_36608036/article/details/106537556">https://blog.csdn.net/qq_36608036/article/details/106537556</a></p>]]></content>
    
    
    <categories>
      
      <category>R</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rstudio</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>jupyterhub配置conda环境</title>
    <link href="/2022/08/15/jupyterhub%E9%85%8D%E7%BD%AEconda%E7%8E%AF%E5%A2%83/"/>
    <url>/2022/08/15/jupyterhub%E9%85%8D%E7%BD%AEconda%E7%8E%AF%E5%A2%83/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><p>JupyterHub是一个支持多用户的Notebook服务器，用于创建、管理和代理多个Jupyter Notebook实例。<br>jupyter notebook 配置conda环境可参考 <a href="https://shixiangwang.github.io/blog/4-jupyter-notebook-conda/">https://shixiangwang.github.io/blog/4-jupyter-notebook-conda/</a></p><p>使用jupyterhub 配置conda环境与使用jupyter notebook 配置conda环境大体一致。<br>如果是管理员使用jupyterhub配置的conda环境，其它用户都可以使用，如果是普通用户自己配置的conda环境，则只能该用户自己使用。<br>1、首先使用conda创建环境</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">conda</span> create -n py<span class="hljs-number">38</span> python=<span class="hljs-number">3</span>.<span class="hljs-number">8</span><br></code></pre></td></tr></table></figure><p>2、环境建好以后进入环境</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">source</span> activate py<span class="hljs-number">38</span><br></code></pre></td></tr></table></figure><p>3、进入环境后安装和配置ipykernel</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs gradle">conda install -c conda-forge ipykernel<br>python -m ipykernel install --name=py38 --prefix=<span class="hljs-regexp">/home/</span>xxx/.local<br># --prefix 指定安装路径<br># 管理员可安装到 <span class="hljs-regexp">/usr/</span>local 下或者其他自定义路径<br># 比如 <span class="hljs-regexp">/share/</span>apps<span class="hljs-regexp">/miniconda3/</span>envs<span class="hljs-regexp">/py38/</span><br></code></pre></td></tr></table></figure><p>现在打开jupyterhub进入自己的lab就可以看到多了一个conda的kernel。<br>参考：<a href="https://jupyterhub.readthedocs.io/en/stable/reference/config-user-env.html">https://jupyterhub.readthedocs.io/en/stable/reference/config-user-env.html</a></p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>jupyter</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深度学习炼丹踩坑</title>
    <link href="/2022/07/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%82%BC%E4%B8%B9%E8%B8%A9%E5%9D%91/"/>
    <url>/2022/07/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%82%BC%E4%B8%B9%E8%B8%A9%E5%9D%91/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><h4 id="GPU显存"><a href="#GPU显存" class="headerlink" title="GPU显存"></a>GPU显存</h4><p>使用GPU进行炼丹的时候，发现了些ghost进程，如图中所示<br><img src="/img/article/DL1.jpg"><br>这些进程不仅占用了大量的GPU显存，而且使用 ps 查询该进程的时候竟然都查不到。<br>好在互联网上查到了解决的办法</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">sudo fuser -v <span class="hljs-regexp">/dev/</span>nvidia*<br></code></pre></td></tr></table></figure><p>使用该命令查询出所有在GPU显卡上的进程，然后kill掉已经不存在的进程即可释放显存。</p><h4 id="learning-rate"><a href="#learning-rate" class="headerlink" title="learning rate"></a>learning rate</h4><p>在网上找了张图<br><img src="/img/article/DL2.jpg"><br>LR在优化算法中更新网络权重的幅度大小，同时也是深度学习中需要调的第一大参数了吧。一般学习率从0.1或0.01开始尝试，如果太大loss会很震荡甚至直接NA，太小了收敛就会很慢。学习率一般要随着训练进行衰减。衰减系数设0.1，0.3，0.5均可，衰减时机，可以是验证集准确率不再上升时，或固定训练多少个周期以后自动进行衰减。当然了也可以一个学习率走到底（不衰减）。</p><h4 id="batch-size"><a href="#batch-size" class="headerlink" title="batch size"></a>batch size</h4><p>深度学习中一直都有一些参数有着玄学般的存在，比如 random seed = 42，batch size 设置为 2 的倍数，或者 8 的倍数等等。但是最近有大佬对 batch size 这个玄学问题做了实验，结果呢就是也不用非要按 2 的倍数这样去设置。既然玄学被打破那就随心好了，在GPU显存允许的范围内可以尽量设置大点，这样可以节约不少时间。当然了也不能盲目的使用一个大的batch size，如果模型效果不好，该改还是要改的，毕竟玄学终究是玄学。</p><h4 id="optimizer"><a href="#optimizer" class="headerlink" title="optimizer"></a>optimizer</h4><p>目前的优化器有 Adagrad, Adadelta, RMSprop, Adam等，这么多该怎么选呢，整体来讲，Adam是最好的选择，也就是像我这样的小白直接无脑 Adam 就好了。大佬请随意。</p><p>当然了还有一些其他的参数，比如 weight decay, epoch, drop out 等等，epoch 主要就是训练的轮数，只要没过拟合，loss没收敛，那epoch就只能往大了改。如果过拟合了就可以增加 weight decay, drop out的参数，或者使用其他的正则化或者减少过拟合的方法。</p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>DL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>neo4j中节点及关系的查询、删除等</title>
    <link href="/2022/03/01/neo4j%E4%B8%AD%E9%87%8D%E5%A4%8D%E8%8A%82%E7%82%B9%E5%8F%8A%E5%85%B3%E7%B3%BB%E7%9A%84%E6%9F%A5%E6%89%BE%E3%80%81%E5%88%A0%E9%99%A4/"/>
    <url>/2022/03/01/neo4j%E4%B8%AD%E9%87%8D%E5%A4%8D%E8%8A%82%E7%82%B9%E5%8F%8A%E5%85%B3%E7%B3%BB%E7%9A%84%E6%9F%A5%E6%89%BE%E3%80%81%E5%88%A0%E9%99%A4/</url>
    
    <content type="html"><![CDATA[<h2 id="Neo4j-查询、删除"><a href="#Neo4j-查询、删除" class="headerlink" title="Neo4j 查询、删除"></a>Neo4j 查询、删除</h2><span id="more"></span><figure class="highlight hsp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs hsp">MATCH (n)-[r]-(m) <span class="hljs-keyword">RETURN</span> * <span class="hljs-keyword">LIMIT</span> <span class="hljs-number">100</span>  等价于 MATCH p=()--() <span class="hljs-keyword">RETURN</span> p <span class="hljs-keyword">LIMIT</span> <span class="hljs-number">100</span><br></code></pre></td></tr></table></figure><p>n和m代表节点，r代表relationship关系<br>(n)-[r]-(m)代表一种模式，即n节点和m节点由r关系联系起来<br>MATCH (n)-[r]-(m) RETURN的意思是查询并返回所有与(n)-[r]-(m)模式匹配的节点和关系。<br>* LIMIT 100是限制条件，意思是仅需返回前100个匹配到的结果（节点和关系）。</p><h5 id="查询重复节点"><a href="#查询重复节点" class="headerlink" title="查询重复节点"></a>查询重复节点</h5><p>可以分为以下步骤解决：</p><ul><li><p> 1、先查看下某个标签下的节点总数</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">match</span> (n:PERSON) <span class="hljs-keyword">return</span> <span class="hljs-built_in">count</span>(n)<br></code></pre></td></tr></table></figure></li><li><p> 2、比较总数和去重后总数，可判断是否存在相同name的节点</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">match</span> (n:PERSON) <span class="hljs-keyword">return</span> <span class="hljs-built_in">count</span>(<span class="hljs-keyword">distinct</span> n.name)<br></code></pre></td></tr></table></figure></li></ul><p>若执行步骤1和步骤2，得到的数量相同，则证明没有重复的节点</p><ul><li><p> 3、若重复节点较少，可通过设置id条件进行删除</p></li><li><p> 4、若重复节点较多，可用apoc来进行操作(需要安装apoc插件，地址：<a href="https://github.com/neo4j-contrib/neo4j-apoc-procedures/releases">https://github.com/neo4j-contrib/neo4j-apoc-procedures/releases</a>)</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">MATCH (n:Tag) <br><span class="hljs-keyword">WITH</span> n.name <span class="hljs-keyword">AS</span> <span class="hljs-type">name</span>, <br>    COLLECT(n) <span class="hljs-keyword">AS</span> nodelist, <br>    COUNT(*) <span class="hljs-keyword">AS</span> count <br><span class="hljs-keyword">WHERE</span> count &gt; <span class="hljs-number">1</span> <br><span class="hljs-keyword">CALL</span> apoc.refactor.mergeNodes(nodelist) YIELD node <br><span class="hljs-keyword">RETURN</span> node<br></code></pre></td></tr></table></figure></li></ul><h5 id="查询重复关系"><a href="#查询重复关系" class="headerlink" title="查询重复关系"></a>查询重复关系</h5><ul><li><p>查询</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">MATCH (<span class="hljs-keyword">a</span>)-[r]-(b) <br><span class="hljs-keyword">with</span> count(type(r)) <span class="hljs-keyword">as</span> <span class="hljs-built_in">num</span>,<span class="hljs-keyword">a</span>,b <br>where <span class="hljs-built_in">num</span> &gt;= <span class="hljs-number">2</span> <span class="hljs-literal">return</span> <span class="hljs-built_in">num</span>,<span class="hljs-keyword">a</span>,b LIMIT <span class="hljs-number">25</span><br></code></pre></td></tr></table></figure></li><li><p>删除</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs less"><span class="hljs-selector-tag">MATCH</span> (a)<span class="hljs-selector-tag">-</span><span class="hljs-selector-attr">[r]</span><span class="hljs-selector-tag">-</span>(b) <br><span class="hljs-selector-tag">WITH</span> <span class="hljs-selector-tag">a</span>, <span class="hljs-selector-tag">b</span>, <span class="hljs-selector-tag">TAIL</span> (COLLECT (r)) <span class="hljs-selector-tag">as</span> <span class="hljs-selector-tag">rr</span> <br><span class="hljs-selector-tag">WHERE</span> <span class="hljs-selector-tag">size</span>(rr)&gt;<span class="hljs-selector-tag">0</span> <br><span class="hljs-selector-tag">FOREACH</span> (r IN rr | DELETE r)<br></code></pre></td></tr></table></figure></li><li><p>修改节点的 label ，可以先新加 label ，再删除旧的的label</p><figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs oxygene">match (n:<span class="hljs-keyword">old</span>) <span class="hljs-keyword">set</span> n:<span class="hljs-keyword">NEW</span> <span class="hljs-keyword">remove</span> n:<span class="hljs-keyword">old</span><br></code></pre></td></tr></table></figure></li><li><p>修改关系的 label</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs less"><span class="hljs-selector-tag">MATCH</span> (<span class="hljs-attribute">n</span>:drug)<span class="hljs-selector-tag">-</span><span class="hljs-selector-attr">[r:indication]</span><span class="hljs-selector-tag">-</span>(<span class="hljs-attribute">m</span>:disease)<br><span class="hljs-selector-tag">CREATE</span> (n)<span class="hljs-selector-tag">-</span><span class="hljs-selector-attr">[r2:drug_disease]</span><span class="hljs-selector-tag">-</span>&gt;(m)<br><span class="hljs-selector-tag">DELETE</span> <span class="hljs-selector-tag">r</span><br></code></pre></td></tr></table></figure></li><li><p>删除某个节点及对应的关系</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">MATCH (n:Disease)-[r]-() <span class="hljs-keyword">where</span> n.name=&quot;&#123;f&#125;&quot; <span class="hljs-keyword">DELETE</span> n,r<br></code></pre></td></tr></table></figure></li><li><p>节点添加属性</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">MATCH (n &#123; <span class="hljs-type">name</span>: <span class="hljs-string">&#x27;Andres&#x27;</span> &#125;) <span class="hljs-keyword">SET</span> n.surname = <span class="hljs-string">&#x27;Taylor&#x27;</span> <span class="hljs-keyword">RETURN</span> n.name, n.surname<br></code></pre></td></tr></table></figure></li><li><p>关系添加属性</p><figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sas">MATCH p=()-[r:`尾部`]-&gt;() <span class="hljs-meta">SET</span> r=&#123;<span class="hljs-meta">title</span>:<span class="hljs-string">&quot;尾部&quot;</span>&#125; <span class="hljs-meta">RETURN</span> p<br></code></pre></td></tr></table></figure></li></ul><h5 id="查询某节点深度关系"><a href="#查询某节点深度关系" class="headerlink" title="查询某节点深度关系"></a>查询某节点深度关系</h5><p>变长路径的模式</p><ul><li><p>(a)-[*2]-&gt;(b) : 表示路径长度为2， 起始节点是a，终止节点是b；</p></li><li><p>(a)-[*3..5]-&gt;(b) : 表示路径长度最小为2，最大为5， 起始节点是a，终止节点是b；</p></li><li><p>(a)-[*..5]-&gt;(b) : 表示路径长度最大为5， 起始节点是a，终止节点是b；</p></li><li><p>(a)-[*3..]-&gt;(b) : 表示路径长度最小为3， 起始节点是a，终止节点是b；</p></li><li><p>(a)-[*]-&gt;(b) : 表示不限制路径长度， 起始节点是a，终止节点是b；</p></li></ul><ul><li><p>所有深度</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">match(n:TargetGene&#123;name:<span class="hljs-string">&#x27;TOP2A&#x27;</span>&#125;)-[r*]-(m) <span class="hljs-built_in">return</span> n,r,m <span class="hljs-built_in">limit</span> 100  <span class="hljs-comment">## 某节点的所有关系</span><br>match p=()--() <span class="hljs-built_in">return</span> p <span class="hljs-built_in">limit</span> 25   <span class="hljs-comment">## 所有节点所有关系</span><br></code></pre></td></tr></table></figure></li><li><p>一级深度（某节点关联的一级所有节点及关系）</p><figure class="highlight rsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs rsl"><span class="hljs-built_in">match</span> p=(n:TargetGene&#123;name:<span class="hljs-string">&#x27;TOP2A&#x27;</span>&#125;) -[]-() <span class="hljs-keyword">return</span> p    <span class="hljs-meta">## [] 前后的 - 代表关系的方向，如果没有箭头表示所有方向(中括号[]可省略)</span><br><span class="hljs-built_in">match</span>(n:TargetGene&#123;name:<span class="hljs-string">&#x27;TOP2A&#x27;</span>&#125;)-[r]-(m) <span class="hljs-keyword">return</span> n,r,m  <span class="hljs-meta">## 与上条命令效果相同</span><br><br><span class="hljs-built_in">match</span> p=(n:TargetGene&#123;name:<span class="hljs-string">&#x27;TOP2A&#x27;</span>&#125;) -[]-&gt;() <span class="hljs-keyword">return</span> p   <span class="hljs-meta">##  表示TOP2A指向外部的所有节点及关系</span><br><span class="hljs-built_in">match</span> p=(n:TargetGene&#123;name:<span class="hljs-string">&#x27;TOP2A&#x27;</span>&#125;) &lt;-[]-() <span class="hljs-keyword">return</span> p   <span class="hljs-meta">##  表示指向TOP2A的所有节点及关系</span><br></code></pre></td></tr></table></figure></li><li><p>指定深度</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">match</span><span class="hljs-params">(n:TargetGene&#123;name:<span class="hljs-string">&#x27;TOP2A&#x27;</span>&#125;)</span></span>-<span class="hljs-selector-attr">[r*..3]</span>-(m) return n,r,m limit <span class="hljs-number">100</span><br></code></pre></td></tr></table></figure></li></ul><h5 id="查询某两个节点是否有关系"><a href="#查询某两个节点是否有关系" class="headerlink" title="查询某两个节点是否有关系"></a>查询某两个节点是否有关系</h5><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">match (:节点标签<span class="hljs-number">1</span>&#123;<span class="hljs-type">name</span>:<span class="hljs-string">&#x27;xx&#x27;</span>&#125;)-[r]-(:节点标签<span class="hljs-number">2</span>&#123;<span class="hljs-type">name</span>:<span class="hljs-string">&#x27;xx&#x27;</span>&#125;) <span class="hljs-keyword">return</span> r,<span class="hljs-keyword">type</span>(r)<br></code></pre></td></tr></table></figure><ul><li><p>查询深度关系（r*3表示3级）</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">match p=(n:TargetGene&#123;<span class="hljs-type">name</span>:<span class="hljs-string">&#x27;MIR7-1&#x27;</span>&#125;)-[r*<span class="hljs-number">3</span>]-(m:Disease&#123;<span class="hljs-type">name</span>:<span class="hljs-string">&#x27;breast cancer&#x27;</span>&#125;) <span class="hljs-keyword">return</span> p<br></code></pre></td></tr></table></figure></li><li><p>使用where进行查询</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs applescript">match p=(n:TargetGene)-[r*<span class="hljs-number">3</span>]-(m:Disease) <span class="hljs-keyword">where</span> n.<span class="hljs-built_in">name</span>=<span class="hljs-string">&quot;MIR7-1&quot;</span> <span class="hljs-keyword">and</span> m.<span class="hljs-built_in">name</span>=<span class="hljs-string">&quot;breast cancer&quot;</span> <span class="hljs-literal">return</span> p<br></code></pre></td></tr></table></figure></li><li><p>使用正则忽略大小写  <del>“(?i)strings”  其语法为 : =</del> “regexp”  区分大小写的模糊匹配; =~”(?i)regexp” 不区分大小写的模糊匹配</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs applescript">match p=(n:TargetGene)-[r*<span class="hljs-number">3</span>]-(m:Disease) <span class="hljs-keyword">where</span> n.<span class="hljs-built_in">name</span>=~<span class="hljs-string">&quot;(?i)mir7-1&quot;</span> <span class="hljs-keyword">and</span> m.<span class="hljs-built_in">name</span>=<span class="hljs-string">&quot;breast cancer&quot;</span> <span class="hljs-literal">return</span> p<br></code></pre></td></tr></table></figure></li><li><p>最短路径查询<br>方法一：</p><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs lisp">match p=shortestPath((<span class="hljs-name">n</span><span class="hljs-symbol">:TargetGene</span>&#123;name:<span class="hljs-string">&quot;MIR7-1&quot;</span>&#125;)-[r*]-(<span class="hljs-name">m</span><span class="hljs-symbol">:Disease</span>&#123;name:<span class="hljs-string">&quot;breast cancer&quot;</span>&#125;))  return p<br></code></pre></td></tr></table></figure><p>方法二：<br>加入了忽略大小写</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs applescript">match (n:TargetGene),(m:Disease) <span class="hljs-keyword">where</span> n.<span class="hljs-built_in">name</span>=~<span class="hljs-string">&quot;(?i)mir7-1&quot;</span> <span class="hljs-keyword">and</span> m.<span class="hljs-built_in">name</span>=<span class="hljs-string">&quot;breast cancer&quot;</span><br><span class="hljs-keyword">with</span> n,m match p=shortestpath((n)-[r*]-(m)) <span class="hljs-literal">return</span> p;<br></code></pre></td></tr></table></figure></li><li><p>查询多个药物与某个疾病的最短路径</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs coq"><span class="hljs-keyword">match</span> (m:Drug), (n:Disease) <span class="hljs-keyword">where</span> m.name=~&#x27;(?i)DOXYLAMINE|<span class="hljs-type">FESOTERODINE</span>|<span class="hljs-type">TROPICAMIDE</span>|<span class="hljs-type">Dexmedetomidine</span>&#x27; and n.name=~&#x27;(?i)Systemic sclerosis&#x27; <span class="hljs-built_in">with</span> n,m <span class="hljs-keyword">match</span> p=shortestpath((n)-[r*]-(m)) <span class="hljs-keyword">return</span> p<br></code></pre></td></tr></table></figure></li></ul><h5 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h5><ul><li><p>通过 name 属性  删除这一个节点</p><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs excel"><span class="hljs-built_in">MATCH</span> (<span class="hljs-symbol">n:TE</span>ST1&#123;<span class="hljs-built_in">na</span><span class="hljs-symbol">me:</span>&#x27;temp&#x27;&#125;) delete <span class="hljs-built_in">n</span><br></code></pre></td></tr></table></figure></li><li><p>通过 id 属性 删除这一个节点</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">MATCH (<span class="hljs-built_in">r</span>) <span class="hljs-built_in">WHERE</span> id(<span class="hljs-built_in">r</span>) = <span class="hljs-number">492</span> DELETE <span class="hljs-built_in">r</span><br></code></pre></td></tr></table></figure></li><li><p>删除一个节点及其所有的关系</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">MATCH (<span class="hljs-built_in">r</span>) <span class="hljs-built_in">WHERE</span> id(<span class="hljs-built_in">r</span>) = <span class="hljs-number">493</span> DETACH DELETE <span class="hljs-built_in">r</span><br></code></pre></td></tr></table></figure></li><li><p>删除所有节点和所有的关系</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">MATCH (<span class="hljs-built_in">r</span>) DETACH DELETE <span class="hljs-built_in">r</span><br></code></pre></td></tr></table></figure></li><li><p>删除一个标签中所有的节点</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs less"><span class="hljs-selector-tag">MATCH</span> (<span class="hljs-attribute">r</span>:Loc) <span class="hljs-selector-tag">DETACH</span> <span class="hljs-selector-tag">DELETE</span> <span class="hljs-selector-tag">r</span><br></code></pre></td></tr></table></figure></li><li><p>删除标签</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs clean">:schema    ### 查询标签所对应的索引<br></code></pre></td></tr></table></figure></li></ul><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs n1ql"><span class="hljs-keyword">drop</span> <span class="hljs-keyword">index</span> 索引名字<br></code></pre></td></tr></table></figure><p>参考：<a href="https://python.iitter.com/other/191720.html">https://python.iitter.com/other/191720.html</a></p>]]></content>
    
    
    <categories>
      
      <category>Neo4j</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Neo4j</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>cpp学习笔记03</title>
    <link href="/2022/03/01/cpp%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B003/"/>
    <url>/2022/03/01/cpp%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B003/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span><span class="hljs-meta-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span><span class="hljs-meta-string">&lt;string&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><br><br><span class="hljs-comment">//圆周长</span><br><span class="hljs-keyword">const</span> <span class="hljs-keyword">double</span> pi = <span class="hljs-number">3.14</span>;<br><br><br><span class="hljs-comment">// struct 默认权限为 公共 public</span><br><span class="hljs-comment">// class 默认权限为 私有 private</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">C1</span></span><br><span class="hljs-class">&#123;</span><br>    <span class="hljs-keyword">int</span> m1; <span class="hljs-comment">// 默认私有</span><br>&#125;;<br><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">C2</span></span><br><span class="hljs-class">&#123;</span><br>    <span class="hljs-keyword">int</span> m2; <span class="hljs-comment">// 默认公共 </span><br>&#125;;<br><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Circle</span></span><br><span class="hljs-class">&#123;</span><br>    <span class="hljs-comment">//访问权限：公共权限public、保护权限protected、私有权限private</span><br>    <span class="hljs-comment">//公共权限</span><br><span class="hljs-keyword">public</span>:   <span class="hljs-comment">//类内外都可访问</span><br>    <span class="hljs-comment">//类中属性和行为统一称为成员</span><br>    <span class="hljs-comment">// 属性  成员属性 成员变量</span><br>    <span class="hljs-keyword">int</span> r;<br><br>    <span class="hljs-comment">//行为  成员行为 成员函数</span><br>    <span class="hljs-function"><span class="hljs-keyword">double</span> <span class="hljs-title">calculate</span><span class="hljs-params">()</span></span><br><span class="hljs-function">    </span>&#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">2</span> * pi * r;<br>    &#125;<br><br><span class="hljs-keyword">protected</span>:  <span class="hljs-comment">//类内可访问，类外不可    子类可访问</span><br>    <span class="hljs-keyword">int</span> r1;<br><br><br><span class="hljs-keyword">private</span>:   <span class="hljs-comment">// 类内可访问，类外不可   子类不可访问</span><br>    <span class="hljs-keyword">int</span> r2;<br>    <br>&#125;;<br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">char</span> <span class="hljs-keyword">const</span> *argv[])</span></span><br><span class="hljs-function"></span>&#123;<br>    Circle c1;<br>    c1.r = <span class="hljs-number">10</span>;<br><br>    cout &lt;&lt; c1.<span class="hljs-built_in">calculate</span>() &lt;&lt; endl;<br><br>    <br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>CPP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CPP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>cpp学习笔记02</title>
    <link href="/2022/03/01/cpp%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B002/"/>
    <url>/2022/03/01/cpp%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B002/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span><span class="hljs-meta-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span><span class="hljs-meta-string">&lt;string&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><br><br><span class="hljs-comment">//值传递, 形参不会修饰实参</span><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">swap1</span><span class="hljs-params">(<span class="hljs-keyword">int</span> a, <span class="hljs-keyword">int</span> b)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">int</span> tmp = a;<br>    a = b;<br>    b = tmp;<br><br>&#125;<br><br><span class="hljs-comment">//地址传递，形参会修饰实参</span><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">swap2</span><span class="hljs-params">(<span class="hljs-keyword">int</span> *a, <span class="hljs-keyword">int</span> *b)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">int</span> tmp = *a;<br>    *a = *b;<br>    *b = tmp;<br>&#125;<br><br><span class="hljs-comment">//常量引用，用来修饰形参，防止误操作</span><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">showValue</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> &amp;val)</span></span><br><span class="hljs-function"></span>&#123;<br>    cout &lt;&lt; val &lt;&lt; endl; <span class="hljs-comment">// val的值无法修改</span><br>&#125;<br><br><br><span class="hljs-comment">//引用的本质是指针常量</span><br><span class="hljs-comment">//引用传递，形参会修饰实参</span><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">swap3</span><span class="hljs-params">(<span class="hljs-keyword">int</span> &amp;a, <span class="hljs-keyword">int</span> &amp;b)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">int</span> tmp = a;<br>    a = b;<br>    b = tmp;<br>&#125;<br><br><span class="hljs-comment">// 不要返回局部变量的引用</span><br><span class="hljs-comment">// int&amp; test1()</span><br><span class="hljs-comment">// &#123;</span><br><span class="hljs-comment">//  int a = 10; // 局部变量存放在栈区</span><br><span class="hljs-comment">//  // return a; // 返回引用会带来隐患</span><br><span class="hljs-comment">// &#125;</span><br><br><span class="hljs-comment">// 函数的调用可以作为左值</span><br><span class="hljs-function"><span class="hljs-keyword">int</span>&amp; <span class="hljs-title">test2</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span> a = <span class="hljs-number">10</span>; <span class="hljs-comment">// 静态变量存放在全局区</span><br>    <span class="hljs-keyword">return</span> a; <br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">char</span> <span class="hljs-keyword">const</span> *argv[])</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-comment">//引用的基本使用</span><br>    <span class="hljs-comment">//作用：给变量起别名</span><br>    <span class="hljs-comment">//语法：数据类型 &amp;别名 = 原名</span><br>    <span class="hljs-keyword">int</span> a = <span class="hljs-number">10</span>;<br>    <span class="hljs-comment">// 创建引用</span><br>    <span class="hljs-keyword">int</span> &amp;b = a;   <span class="hljs-comment">// 引用初始化(必须)，初始化后不可改变，b的值也是10</span><br><br>    <span class="hljs-keyword">int</span> &amp;aa = <span class="hljs-built_in">test2</span>();<br>    <span class="hljs-built_in">test2</span>() = <span class="hljs-number">100</span>;       <span class="hljs-comment">// 函数的调用可以作为左值</span><br>    cout &lt;&lt; aa &lt;&lt; endl;<br><br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs csharp"><span class="hljs-meta">#include&lt;iostream&gt;</span><br><span class="hljs-meta">#include&lt;string&gt;</span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> <span class="hljs-title">std</span>;<br><br><span class="hljs-comment">//声明和实现只能有一个有默认参数,即如果函数声明有默认参数，函数实现就不能有默认参数，反之亦然</span><br><span class="hljs-comment">//函数声明</span><br><span class="hljs-function"><span class="hljs-built_in">int</span> <span class="hljs-title">func1</span>(<span class="hljs-params"><span class="hljs-built_in">int</span> a, <span class="hljs-built_in">int</span> b=<span class="hljs-number">10</span></span>)</span>;<br><br><span class="hljs-comment">//函数实现</span><br><span class="hljs-function"><span class="hljs-built_in">int</span> <span class="hljs-title">func1</span>(<span class="hljs-params"><span class="hljs-built_in">int</span> a, <span class="hljs-built_in">int</span> b</span>)</span><br>&#123;<br>    <span class="hljs-keyword">return</span> a + b<br>&#125;<br><br><span class="hljs-comment">// 占位参数</span><br><span class="hljs-function"><span class="hljs-built_in">int</span> <span class="hljs-title">func2</span>(<span class="hljs-params"><span class="hljs-built_in">int</span> a, <span class="hljs-built_in">int</span></span>)  <span class="hljs-comment">// 第二个 int 为占位符，占位符也可有默认值, 如 int func2(int a, int = 10);</span></span><br>&#123;<br>    <span class="hljs-keyword">return</span> a<br>&#125;<br><br><span class="hljs-comment">//函数重载</span><br><span class="hljs-comment">//同一个作用域下</span><br><span class="hljs-comment">//函数名称相同</span><br><span class="hljs-comment">//函数参数类型不同，或者个数不同，或者顺序不同</span><br><span class="hljs-comment">// 函数的返回值不可以做为函数重载的条件</span><br><br><span class="hljs-comment">//引用做为重载条件</span><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">func3</span>(<span class="hljs-params"><span class="hljs-built_in">int</span> &amp;a</span>)</span><br>&#123;<br>    cout &lt;&lt; <span class="hljs-string">&#x27;&#x27;</span> &lt;&lt; endl;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">func3</span>(<span class="hljs-params"><span class="hljs-keyword">const</span> <span class="hljs-built_in">int</span> &amp;a</span>)</span><br>&#123;<br>    cout &lt;&lt; <span class="hljs-string">&#x27;const&#x27;</span> &lt;&lt; endl;<br>&#125;<br><br><br><span class="hljs-function"><span class="hljs-built_in">int</span> <span class="hljs-title">main</span>(<span class="hljs-params"><span class="hljs-built_in">int</span> argc, <span class="hljs-built_in">char</span> <span class="hljs-keyword">const</span> *argv[]</span>)</span><br>&#123;<br>    func3(<span class="hljs-number">10</span>); <span class="hljs-comment">// 运行 func3(const int &amp;a), 因为 int &amp;a = 10 不合法</span><br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>CPP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CPP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>cpp学习笔记01</title>
    <link href="/2022/03/01/cpp%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001/"/>
    <url>/2022/03/01/cpp%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span><span class="hljs-meta-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span><span class="hljs-meta-string">&lt;string&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><br><br><span class="hljs-comment">// 函数分文件</span><br><span class="hljs-comment">// 1、创建 .h 后缀名的头文件</span><br><span class="hljs-comment">// 2、创建 .cpp 后缀名的源文件</span><br><span class="hljs-comment">// 3、在头文件中写函数的声明</span><br><span class="hljs-comment">// 4、在源文件中写函数定义</span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;swap.h&quot;</span></span><br><br><span class="hljs-comment">//常量定义方式</span><br><span class="hljs-comment">//1、 #define 宏常量</span><br><span class="hljs-comment">//2、 const 修饰的变量</span><br><br><span class="hljs-comment">//1、 #define 定义常量</span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> Day 7</span><br><br><span class="hljs-comment">// struct 自定义数据结构关键字，结构体指针通过 -&gt; 获取属性数据</span><br><br><span class="hljs-comment">//栈区数据(局部变量、形参等)由编译器管理，堆区数据(new关键字开辟内存存放数据，可使用delete删除)由程序员管理</span><br><br><span class="hljs-comment">// 使用new创建数据：new返回的是 该数据类型的指针</span><br><span class="hljs-keyword">int</span> *p = <span class="hljs-keyword">new</span> <span class="hljs-built_in"><span class="hljs-keyword">int</span></span>(<span class="hljs-number">10</span>);<br><br><span class="hljs-comment">// 函数声明：可以提前告诉编译器函数的存在, 声明可以多次，定义只有一次</span><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">max</span><span class="hljs-params">(<span class="hljs-keyword">int</span> a, <span class="hljs-keyword">int</span> b)</span></span>;<br><br><span class="hljs-comment">// 函数：值传递不修改实参，地址传递修改实参</span><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">swap1</span><span class="hljs-params">(<span class="hljs-keyword">int</span> a, <span class="hljs-keyword">int</span> b)</span></span>; <span class="hljs-comment">// 值传递</span><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">swap2</span><span class="hljs-params">(<span class="hljs-keyword">int</span> *p1, <span class="hljs-keyword">int</span> *p2)</span></span>; <span class="hljs-comment">// 地址传递 swap2(&amp;a, &amp;b)</span><br><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">bubbleSort</span><span class="hljs-params">(<span class="hljs-keyword">int</span> arr[], <span class="hljs-keyword">int</span> len)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; len - <span class="hljs-number">1</span>; i++)<br>    &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; len -i <span class="hljs-number">-1</span>; j++)<br>        &#123;<br>            <span class="hljs-keyword">if</span> (arr[j] &gt; arr[j+<span class="hljs-number">1</span>])<br>            &#123;<br>                <span class="hljs-keyword">int</span> tmp = arr[j];<br>                arr[j] = arr[j+<span class="hljs-number">1</span>];<br>                arr[j+<span class="hljs-number">1</span>] = tmp;<br>            &#125;<br>                <br>        &#125;<br>    &#125;<br>&#125;<br><br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">char</span> <span class="hljs-keyword">const</span> *argv[])</span></span><br><span class="hljs-function"></span>&#123;   <br>    <span class="hljs-comment">//2、 const 修饰的变量</span><br>    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> month = <span class="hljs-number">12</span>;  <span class="hljs-comment">// const 修饰的变量也是常量</span><br>    cout &lt;&lt; Day &lt;&lt; month &lt;&lt; endl;<br><br>    <span class="hljs-comment">// int a = 10;</span><br>    <span class="hljs-comment">// sizeof 计算内存大小</span><br>    <span class="hljs-comment">// cout &lt;&lt; sizeof(a) &lt;&lt; endl;</span><br><br>    <span class="hljs-comment">// 默认情况小数显示6位有效数字</span><br>    <span class="hljs-keyword">float</span> f = <span class="hljs-number">3.14f</span>; <span class="hljs-comment">// 默认双精度，数字后加f为单精度</span><br><br>    <span class="hljs-comment">//字符型变量用于显示单个字符</span><br>    <span class="hljs-keyword">char</span> c = <span class="hljs-string">&#x27;a&#x27;</span>; <span class="hljs-comment">// 只能单引号</span><br>    cout &lt;&lt; (<span class="hljs-keyword">int</span>)c &lt;&lt; endl; <span class="hljs-comment">// (int) 转换 c 为 ascii 值</span><br><br>    cout &lt;&lt; <span class="hljs-string">&quot;aa\tbb&quot;</span> &lt;&lt; endl;<br><br>    <span class="hljs-comment">// c 风格字符串  chat 字符串名 []</span><br>    <span class="hljs-keyword">char</span> str1[] = <span class="hljs-string">&quot;hello&quot;</span>;<br>    <span class="hljs-comment">// c++ 风格字符串</span><br>    string str2 = <span class="hljs-string">&quot;hello&quot;</span>;<br>    cout &lt;&lt; str1 &lt;&lt; <span class="hljs-string">&quot;\t&quot;</span> &lt;&lt; str2 &lt;&lt;endl;<br><br>    <span class="hljs-comment">// 两个整数相除结果还是整数（向下取整）</span><br>    cout &lt;&lt; <span class="hljs-number">10</span> / <span class="hljs-number">20</span> &lt;&lt; endl;<br>    <span class="hljs-comment">// % 取膜运算（取余数）</span><br><br>    <span class="hljs-comment">// 三目运算符</span><br>    <span class="hljs-comment">// 表达式1 ？表达式2 ：表达式3  1真 执行2 ,否则 执行3</span><br>    <span class="hljs-comment">// c++ 中 三目运算符返回的是变量，可以继续赋值</span><br>    <span class="hljs-keyword">int</span> a = <span class="hljs-number">10</span>; <span class="hljs-keyword">int</span> b = <span class="hljs-number">20</span>;<br>    (a &gt; b ? a : b) = <span class="hljs-number">100</span>; <span class="hljs-comment">// 对 b 重新赋值 100</span><br><br>    <span class="hljs-comment">// goto 语句</span><br>    <span class="hljs-comment">// 如果goto的标记存在，则直接跳转到标记处</span><br>    <span class="hljs-keyword">goto</span> FLAG;<br>    cout &lt;&lt; <span class="hljs-string">&quot;跳过了&quot;</span> &lt;&lt; endl; <span class="hljs-comment">// 该语句不执行</span><br>    FLAG:<br>    cout &lt;&lt; <span class="hljs-string">&quot;执行&quot;</span> &lt;&lt; endl;<br><br>    <span class="hljs-comment">// 数据类型 数组名[数组长度];</span><br>    <span class="hljs-keyword">int</span> arr[<span class="hljs-number">2</span>] = &#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>&#125;;  <span class="hljs-comment">// 数组名 arr 是常量，不可进行赋值操作，如 arr = 10</span><br><br>    <span class="hljs-comment">// 二维数组</span><br>    <span class="hljs-comment">// 1、数据类型 数组名[行数][列数];</span><br>    <span class="hljs-comment">// 2、数据类型 数组名[行数][列数] = &#123;&#123;数据1，数据2&#125;, &#123;数据3，数据4&#125;&#125;;</span><br>    <span class="hljs-comment">// 3、数据类型 数组名[行数][列数] = &#123;数据1，数据2, 数据3，数据4&#125;;</span><br>    <span class="hljs-comment">// 4、数据类型 数组名[][列数] = &#123;数据1，数据2, 数据3，数据4&#125;;</span><br><br>    <span class="hljs-comment">// 指针定义：数据类型 * 指针变量名;</span><br>    <span class="hljs-comment">// 让指针记录变量的地址</span><br>    <span class="hljs-keyword">int</span> g = <span class="hljs-number">10</span>;<br>    <span class="hljs-keyword">int</span> *p = &amp;g; <span class="hljs-comment">// 等同于下面两行代码</span><br>    <span class="hljs-comment">// int *p;</span><br>    <span class="hljs-comment">// p = &amp;g;</span><br><br>    <span class="hljs-comment">// 指针前加 * 号代表 解引用</span><br>    cout &lt;&lt; *p &lt;&lt; endl;<br>    *p = <span class="hljs-number">100</span>; <span class="hljs-comment">// 可以进行赋值修改变量的值</span><br>    cout &lt;&lt; g &lt;&lt; endl;<br><br>    <span class="hljs-comment">// 空指针：指针变量指向内存中编号为0的空间</span><br>    <span class="hljs-comment">// 用途：初始化变量</span><br>    <span class="hljs-comment">// 注：空指针不可以进行访问(0-255内存编号为系统占用)</span><br>    <span class="hljs-keyword">int</span> *p1 = <span class="hljs-literal">NULL</span>;<br><br>    <span class="hljs-comment">// 野指针：指向非法的内存空间</span><br><br>    <span class="hljs-comment">// const修饰指针 </span><br>    <span class="hljs-comment">// 常量指针:指针的指向可以修改，指针指的值不可以修改</span><br>    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> *p2 = &amp;a;  <span class="hljs-comment">// *n = 20 错误， n = &amp;b; 正确</span><br><br>    <span class="hljs-comment">// 指针常量：指针的指向不可以修改，指针指的值可以修改</span><br>    <span class="hljs-keyword">int</span> * <span class="hljs-keyword">const</span> p3 = &amp;a;<br><br>    <span class="hljs-comment">// const修饰指针，又修饰常量： 指针的指向不可以修改，指针指的值不可以修改</span><br>    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> * <span class="hljs-keyword">const</span> p4 = &amp;a;<br><br>    <span class="hljs-comment">// 指针和数组</span><br>    <span class="hljs-keyword">int</span> arr2[<span class="hljs-number">2</span>] = &#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>&#125;;<br>    <span class="hljs-keyword">int</span> *p5 = arr2; <span class="hljs-comment">// arr2 数组首地址</span><br><br>    cout &lt;&lt; *p5 &lt;&lt; endl; <span class="hljs-comment">//可获取arr第一个值</span><br>    p5++;<br>    cout &lt;&lt; *p5 &lt;&lt; endl; <span class="hljs-comment">//可获取arr第2个值</span><br>    <br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">max</span><span class="hljs-params">(<span class="hljs-keyword">int</span> a, <span class="hljs-keyword">int</span> b)</span></span>&#123;<br>    <span class="hljs-keyword">return</span> a &gt; b ? a : b;<br>&#125;<br><br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>CPP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CPP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>图数据库neo4j-Echarts可视化</title>
    <link href="/2022/02/23/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93neo4j-Echarts%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    <url>/2022/02/23/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93neo4j-Echarts%E5%8F%AF%E8%A7%86%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h2 id="Neo4j-Flask-Echarts"><a href="#Neo4j-Flask-Echarts" class="headerlink" title="Neo4j Flask Echarts"></a>Neo4j Flask Echarts</h2><span id="more"></span><h5 id="安装-Neo4j"><a href="#安装-Neo4j" class="headerlink" title="安装 Neo4j"></a>安装 Neo4j</h5><p>Neo4j依赖Java环境，所以需要先安装JDK， JDK下载地址如下：</p><ul><li><a href="https://www.oracle.com/java/technologies/downloads/">https://www.oracle.com/java/technologies/downloads/</a><br>最新版的Neo4j需要java11版本以上，所以按需求安装对应的版本即可。</li></ul><p>Neo4j下载地址如下：</p><ul><li><a href="https://neo4j.com/download-center/#community">https://neo4j.com/download-center/#community</a></li></ul><p>社区版是免费的，所以选择社区版安装最新版即可。<br>另：Neo4j 插件 apoc 安装地址如下（插件根据需求安装）：</p><ul><li><a href="https://github.com/neo4j-contrib/neo4j-apoc-procedures/releases">https://github.com/neo4j-contrib/neo4j-apoc-procedures/releases</a></li></ul><p>插件这里有个小坑，就是版本之间的依赖，如果Neo4j下载的是最新版，插件也最好选择最新版进行安装。<br>下载完后直接放在 neo4j-community-4.4.4/plugins 目录下，并且需要在配置文件里进行设置。</p><h5 id="启动-Neo4j"><a href="#启动-Neo4j" class="headerlink" title="启动 Neo4j"></a>启动 Neo4j</h5><p>如果是桌面端直接运行程序即可，如果是server端配置好环境后运行 neo4j start 即可启动，停止运行命令：neo4j stop<br>启动后可以在浏览器输入 <a href="http://localhost:7474/">http://localhost:7474/</a> 进入数据库，初始用户名和密码均是：neo4j，第一次进入需要修改密码，自行修改即可。<br>另外neo4j自带的数据库为 system 和 neo4j。如果想创建一个新的数据库需要在配置文件里修改，配置文件地址为：</p><ul><li>neo4j-community-4.4.4/conf/neo4j.conf</li></ul><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">修改默认数据库<br><span class="hljs-meta">#The name of the default database</span><br><span class="hljs-meta">#dbms.default_database=neo4j</span><br>dbms.default_database=test<br><br>修改插件配置<br># A comma separated list <span class="hljs-keyword">of</span> <span class="hljs-keyword">procedures</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">user</span> defined <span class="hljs-keyword">functions</span> that are allowed<br># <span class="hljs-keyword">full</span> <span class="hljs-keyword">access</span> <span class="hljs-keyword">to</span> the <span class="hljs-keyword">database</span> through unsupported/insecure <span class="hljs-type">internal</span> APIs.<br><span class="hljs-meta">#dbms.security.procedures.unrestricted=my.extensions.example,my.procedures.*</span><br>dbms.<span class="hljs-keyword">security</span>.<span class="hljs-keyword">procedures</span>.unrestricted=apoc.*<br><br>修改免密登陆（测试需求）<br># Whether requests <span class="hljs-keyword">to</span> Neo4j are authenticated.<br># <span class="hljs-keyword">To</span> <span class="hljs-keyword">disable</span> authentication, uncomment this <span class="hljs-type">line</span><br>dbms.<span class="hljs-keyword">security</span>.auth_enabled=<span class="hljs-keyword">false</span><br></code></pre></td></tr></table></figure><p>其它配置有需求再进行修改。</p><h5 id="Neo4j-节点和关系创建"><a href="#Neo4j-节点和关系创建" class="headerlink" title="Neo4j 节点和关系创建"></a>Neo4j 节点和关系创建</h5><ul><li>参考教程：<a href="https://www.w3cschool.cn/neo4j/">https://www.w3cschool.cn/neo4j/</a></li><li>python方法</li></ul><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-comment">## pip install py2neo </span><br>from py2neo <span class="hljs-built_in">import</span> *<br><br><span class="hljs-comment"># 连接neo4j数据库，输入地址、用户名、密码</span><br><span class="hljs-attr">graph</span> = Graph(<span class="hljs-string">&quot;bolt://localhost:7687&quot;</span>, <span class="hljs-attr">auth=(&#x27;neo4j&#x27;,&#x27;neo4j&#x27;))</span><br>graph.delete_all() <span class="hljs-comment">#清除neo4j中原有的结点等所有信息</span><br><br><span class="hljs-comment"># 随机生成100个节点</span><br><span class="hljs-attr">N</span> = <span class="hljs-number">100</span><br><span class="hljs-attr">node_ls</span> = []<br>for i <span class="hljs-keyword">in</span> range(N):<br><span class="hljs-attr">random_name</span> = <span class="hljs-string">&quot;P&quot;</span>+str(round(random.random()*N*<span class="hljs-number">2</span>))<br><span class="hljs-attr">random_age</span> = round(random.random()*<span class="hljs-number">15</span>)<br><span class="hljs-attr">node</span> = Node(<span class="hljs-string">&quot;Person&quot;</span>, <span class="hljs-attr">name=random_name,</span> <span class="hljs-attr">age=random_age)</span><br>node_ls.append(node)<br><br><span class="hljs-attr">subgraph</span> = Subgraph(node_ls, [])    <span class="hljs-comment">## [] 代表关系为空</span><br><span class="hljs-attr">tx</span> = graph.begin() <br>tx.create(subgraph)<br>graph.commit(tx)<br></code></pre></td></tr></table></figure><p>详情可参考：<a href="https://mp.weixin.qq.com/s/1DnMHOx6jPi0j0GhZwNPqw">https://mp.weixin.qq.com/s/1DnMHOx6jPi0j0GhZwNPqw</a></p><h5 id="Echarts可视化"><a href="#Echarts可视化" class="headerlink" title="Echarts可视化"></a>Echarts可视化</h5><p>neo4j本身有自己的可视化系统，比如browser、Bloom等，但是blowser面向开发者，Bloom又是收费的，所以只能自己动手了。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment">## 主要就是 option的设置</span><br><span class="hljs-string">var</span> <span class="hljs-string">categories</span> <span class="hljs-string">=</span> [&#123;<span class="hljs-string">name:&quot;DrugName&quot;</span>&#125;,&#123;<span class="hljs-string">name:&quot;TargetGene&quot;</span>&#125;,&#123;<span class="hljs-string">name:&quot;DiseaseLabel&quot;</span>&#125;]<span class="hljs-string">;</span><br><br><span class="hljs-string">option</span> <span class="hljs-string">=</span> &#123;<br>    <span class="hljs-string">//</span> <span class="hljs-string">color:</span>[<span class="hljs-string">&#x27;#5470c6&#x27;</span>, <span class="hljs-string">&#x27;#91cc75&#x27;</span>, <span class="hljs-string">&#x27;#fac858&#x27;</span>, <span class="hljs-string">&#x27;#ee6666&#x27;</span>, <span class="hljs-string">&#x27;#73c0de&#x27;</span>, <span class="hljs-string">&#x27;#3ba272&#x27;</span>, <span class="hljs-string">&#x27;#fc8452&#x27;</span>, <span class="hljs-string">&#x27;#9a60b4&#x27;</span>, <span class="hljs-string">&#x27;#ea7ccc&#x27;</span>],<br>    <span class="hljs-attr">tooltip:</span> &#123;<br>     <span class="hljs-attr">trigger:</span> <span class="hljs-string">&#x27;item&#x27;</span>,<br>     <span class="hljs-attr">triggerOn:</span> <span class="hljs-string">&#x27;mousemove&#x27;</span>,<br>         <span class="hljs-string">enterable:true</span>,<span class="hljs-string">//鼠标是否可进入提示框浮层中</span><br>          <span class="hljs-string">formatter:formatterHover</span>,<span class="hljs-string">//修改鼠标悬停显示的内容</span><br>    &#125;,<br>    <span class="hljs-string">color:</span>[<span class="hljs-string">&quot;#c12e34&quot;</span>, <span class="hljs-string">&quot;#e6b600&quot;</span>, <span class="hljs-string">&quot;#0098d9&quot;</span>,],<br>    <span class="hljs-string">textStyle:</span>&#123;<br>        <span class="hljs-attr">fontFamily:</span> <span class="hljs-string">&quot;sans-serif&quot;</span>,<br>        <span class="hljs-attr">fontSize:</span> <span class="hljs-number">12</span>,<br>        <span class="hljs-attr">fontStyle:</span> <span class="hljs-string">&quot;normal&quot;</span>,<br>        <span class="hljs-attr">fontWeight:</span> <span class="hljs-string">&quot;normal&quot;</span>,<br>    &#125;,<br>    <span class="hljs-attr">legend:</span> &#123;<br>        <span class="hljs-attr">data:</span> [<span class="hljs-string">&#x27;DrugName&#x27;</span>, <span class="hljs-string">&#x27;TargetGene&#x27;</span>, <span class="hljs-string">&#x27;DiseaseLabel&#x27;</span>] <span class="hljs-string">//此处的数据必须和关系网类别中name相对应</span>  <br>    &#125;,<br>    <span class="hljs-attr">series:</span> [&#123;<br>        <span class="hljs-attr">type:</span> <span class="hljs-string">&#x27;graph&#x27;</span>,<br>        <span class="hljs-attr">layout:</span> <span class="hljs-string">&#x27;force&#x27;</span>,     <span class="hljs-comment"># 力导图</span><br>        <span class="hljs-attr">animation:</span> <span class="hljs-literal">false</span>,<br>        <span class="hljs-attr">symbolSize:</span> <span class="hljs-number">25</span>,<br>        <span class="hljs-attr">label:</span> &#123;<br>            <span class="hljs-attr">normal:</span> &#123;<br>                <span class="hljs-attr">show:</span> <span class="hljs-literal">false</span>,<br>                <span class="hljs-attr">position:</span> <span class="hljs-string">&#x27;right&#x27;</span>,<br>                <span class="hljs-attr">textStyle:</span> &#123;<br>                    <span class="hljs-attr">fontSize:</span> <span class="hljs-number">10</span><br>                &#125;,<br>            &#125;,<br>        &#125;,<br>        <span class="hljs-attr">labelLayout:</span> &#123;<br>            <span class="hljs-attr">hideOverlap:</span> <span class="hljs-literal">true</span><br>        &#125;,<br>        <span class="hljs-attr">draggable:</span> <span class="hljs-literal">true</span>,<br>        <span class="hljs-attr">roam:</span> <span class="hljs-literal">true</span>,<br>        <span class="hljs-attr">focusNodeAdjacency:</span> <span class="hljs-literal">true</span>,<br>        <span class="hljs-attr">force:</span> &#123;<br>            <span class="hljs-attr">edgeLength:</span> <span class="hljs-number">80</span>, <span class="hljs-string">//连线的长度</span>  <br>            <span class="hljs-attr">repulsion:</span> <span class="hljs-number">100</span>, <span class="hljs-string">//子节点之间的间距</span>  <br>            <span class="hljs-string">//</span> <span class="hljs-attr">gravity:</span> <span class="hljs-number">0.2</span><br>        &#125;,<br>        <span class="hljs-attr">categories:</span> <span class="hljs-string">categories</span>,<br>        <span class="hljs-attr">data:</span> <span class="hljs-string">data.nodes</span>,<br>        <span class="hljs-attr">edges:</span> <span class="hljs-string">data.edges</span>,<br><br>        <span class="hljs-attr">edgeSymbol:</span> [<span class="hljs-string">&#x27;circle&#x27;</span>, <span class="hljs-string">&#x27;arrow&#x27;</span>],<br>        <span class="hljs-attr">edgeSymbolSize:</span> [<span class="hljs-number">4</span>, <span class="hljs-number">4</span>],<br>        <span class="hljs-attr">edgeLabel:</span> &#123;<br>            <span class="hljs-attr">normal:</span> &#123;<br>                <span class="hljs-attr">show:</span> <span class="hljs-literal">false</span>,<br>                <span class="hljs-attr">formatter:</span> <span class="hljs-string">function</span> <span class="hljs-string">(x)</span> &#123;<br>                    <span class="hljs-string">return</span> <span class="hljs-string">x.data.relationship;</span><br>                &#125;,<br>                <span class="hljs-attr">textStyle:</span> &#123;<br>                    <span class="hljs-attr">fontSize:</span> <span class="hljs-number">10</span><br>                &#125;<br>            &#125;<br>        &#125;,<br>        <span class="hljs-attr">lineStyle:</span> &#123;<br>            <span class="hljs-attr">normal:</span> &#123;<br>                <span class="hljs-attr">width:</span> <span class="hljs-number">2</span>,<br>                <span class="hljs-attr">color:</span> <span class="hljs-string">&#x27;#4b565b&#x27;</span>,<br>            &#125;<br>        &#125;,<br>    &#125;]<br>&#125;<span class="hljs-string">;</span><br></code></pre></td></tr></table></figure><p>剩下的就是把 data 和 edges 的数据传人即可。<br>同样可以用python进行请求获取</p><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs kotlin"><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> json<br><br>login_url = <span class="hljs-string">&#x27;http://localhost:7474/db/data/transaction/commit&#x27;</span><br>headers = &#123;<span class="hljs-string">&#x27;Content-Type&#x27;</span>:<span class="hljs-string">&#x27;application/json&#x27;</span>&#125;<br>name_pwd = &#123;<span class="hljs-string">&#x27;username&#x27;</span>:<span class="hljs-string">&#x27;neo4j&#x27;</span>,<br>      <span class="hljs-string">&#x27;password&#x27;</span>:<span class="hljs-string">&#x27;neo4j&#x27;</span>,<br>      &#125;<br><br><br>def request_result(login_url, query_cql, headers):<br><br>    nodes, edges = [], []<br><br>    query_json = &#123;<br>        <span class="hljs-string">&quot;statements&quot;</span> : [ &#123;<br>        <span class="hljs-string">&quot;statement&quot;</span> : query_cql,<br>        <span class="hljs-string">&quot;resultDataContents&quot;</span> : [ <span class="hljs-string">&quot;row&quot;</span>, <span class="hljs-string">&quot;graph&quot;</span> ]<br>        &#125;]<br>    &#125;<br><br>    response = requests.post(url=login_url, json= query_json, headers=headers)<br>    print(response.status_code) <br><br>    result = json.loads(response.text)[<span class="hljs-string">&#x27;results&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;data&#x27;</span>]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(result)):<br>        <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> result[i][<span class="hljs-string">&#x27;graph&#x27;</span>][<span class="hljs-string">&#x27;nodes&#x27;</span>]:<br>            <span class="hljs-keyword">if</span> n not <span class="hljs-keyword">in</span> nodes:<br>                nodes.append(n)<br><br>        <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> result[i][<span class="hljs-string">&#x27;graph&#x27;</span>][<span class="hljs-string">&#x27;relationships&#x27;</span>]:<br>            <span class="hljs-keyword">if</span> r not <span class="hljs-keyword">in</span> edges:<br>                edges.append(r)<br><br>    <span class="hljs-keyword">return</span> nodes, edges<br><br><br>def query_all():<br>    query_cql = <span class="hljs-string">&#x27;match p=()--&gt;() return p&#x27;</span><br><br>    nodes, edges = request_result(login_url, query_cql, headers)<br>    <br>    <span class="hljs-keyword">return</span> nodes, edges<br><br><br>## 修改成 Echarts 需要的格式<br>def buildNodes(nodeRecord):<br>    <span class="hljs-keyword">data</span> = &#123;<span class="hljs-string">&quot;id&quot;</span>: str(nodeRecord[<span class="hljs-string">&#x27;id&#x27;</span>]), <span class="hljs-string">&quot;label&quot;</span>: next(iter(nodeRecord[<span class="hljs-string">&#x27;labels&#x27;</span>]))&#125;<br>    <span class="hljs-keyword">data</span>.update(nodeRecord[<span class="hljs-string">&#x27;properties&#x27;</span>])<br><br>    tradeNames = <span class="hljs-keyword">data</span>.<span class="hljs-keyword">get</span>(<span class="hljs-string">&#x27;TradeNames&#x27;</span>)<br>    <span class="hljs-keyword">if</span> tradeNames and len(tradeNames) &gt; <span class="hljs-number">20</span>:<br>        tradeNames = tradeNames[:<span class="hljs-number">20</span>] + <span class="hljs-string">&#x27;...&#x27;</span><br>        <span class="hljs-keyword">data</span>[<span class="hljs-string">&#x27;TradeNames&#x27;</span>] = tradeNames<br><br>    <span class="hljs-keyword">data</span>[<span class="hljs-string">&#x27;category&#x27;</span>] = category_dict.<span class="hljs-keyword">get</span>(<span class="hljs-keyword">data</span>[<span class="hljs-string">&#x27;label&#x27;</span>])<br>    # newdata = &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-keyword">data</span>[<span class="hljs-string">&#x27;name&#x27;</span>], <span class="hljs-string">&#x27;category&#x27;</span>: category_dict.<span class="hljs-keyword">get</span>(<span class="hljs-keyword">data</span>[<span class="hljs-string">&#x27;label&#x27;</span>])&#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">data</span><br><br>def buildEdges(relationRecord):<br>    <span class="hljs-keyword">data</span> = &#123;<span class="hljs-string">&quot;source&quot;</span>: str(relationRecord[<span class="hljs-string">&#x27;startNode&#x27;</span>]), <br>            <span class="hljs-string">&quot;target&quot;</span>: str(relationRecord[<span class="hljs-string">&#x27;endNode&#x27;</span>]), <br>            <span class="hljs-string">&quot;relationship&quot;</span>: relationRecord[<span class="hljs-string">&#x27;type&#x27;</span>]&#125;<br>    # <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;links&quot;</span>: <span class="hljs-keyword">data</span>&#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">data</span><br><br><br>nodes, edges = query_all()<br>nodes = [buildNodes(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> nodes]<br>edges = [buildEdges(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> edges]<br><br></code></pre></td></tr></table></figure><p>整体前端框架参考</p><ul><li><a href="https://github.com/chizhu/KGQA_HLM">https://github.com/chizhu/KGQA_HLM</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Neo4j</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记17-时间序列数据建模流程范例</title>
    <link href="/2022/02/09/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/"/>
    <url>/2022/02/09/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017-%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="时间序列数据"><a href="#时间序列数据" class="headerlink" title="时间序列数据"></a>时间序列数据</h2><span id="more"></span><p>本文基于中国2020年3月之前的疫情数据，建立时间序列RNN模型，对中国的新冠肺炎疫情结束时间进行预测。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> datetime<br><span class="hljs-keyword">import</span> importlib <br><span class="hljs-keyword">import</span> torchkeras<br><br><span class="hljs-meta">#打印时间</span><br><span class="hljs-title">def</span> printbar():<br>    nowtime = datetime.datetime.now().strftime(&#x27;%<span class="hljs-type">Y</span>-%m-%d %<span class="hljs-type">H</span>:%<span class="hljs-type">M</span>:%<span class="hljs-type">S&#x27;</span>)<br>    print(<span class="hljs-string">&quot;\n&quot;</span>+<span class="hljs-string">&quot;==========&quot;</span>*<span class="hljs-number">8</span> + <span class="hljs-string">&quot;%s&quot;</span>%nowtime)<br><br><span class="hljs-meta">#mac系统上pytorch和matplotlib在jupyter中同时跑需要更改环境变量</span><br><span class="hljs-title">os</span>.environ[<span class="hljs-string">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>]=<span class="hljs-string">&quot;TRUE&quot;</span> <br></code></pre></td></tr></table></figure><h4 id="一，准备数据"><a href="#一，准备数据" class="headerlink" title="一，准备数据"></a>一，准备数据</h4><p>本文的数据集取自tushare，获取该数据集的方法参考了以下文章。</p><ul><li>《<a href="https://zhuanlan.zhihu.com/p/109556102%E3%80%8B">https://zhuanlan.zhihu.com/p/109556102》</a></li></ul><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-built_in">import</span> numpy as np<br><span class="hljs-built_in">import</span> pandas as pd <br><span class="hljs-built_in">import</span> matplotlib.pyplot as plt<br><br><br>%matplotlib inline<br>%config InlineBackend.<span class="hljs-attr">figure_format</span> = &#x27;svg&#x27;<br><br><span class="hljs-attr">df</span> = pd.read_csv(<span class="hljs-string">&quot;/home/kesci/input/data6936/data/covid-19.csv&quot;</span>,<span class="hljs-attr">sep</span> = <span class="hljs-string">&quot;\t&quot;</span>)<br>df.plot(<span class="hljs-attr">x</span> = <span class="hljs-string">&quot;date&quot;</span>,<span class="hljs-attr">y</span> = [<span class="hljs-string">&quot;confirmed_num&quot;</span>,<span class="hljs-string">&quot;cured_num&quot;</span>,<span class="hljs-string">&quot;dead_num&quot;</span>],<span class="hljs-attr">figsize=(10,6))</span><br>plt.xticks(<span class="hljs-attr">rotation=60)</span><br><br><span class="hljs-attr">dfdata</span> = df.set_index(<span class="hljs-string">&quot;date&quot;</span>)<br><span class="hljs-attr">dfdiff</span> = dfdata.diff(<span class="hljs-attr">periods=1).dropna()</span><br><span class="hljs-attr">dfdiff</span> = dfdiff.reset_index(<span class="hljs-string">&quot;date&quot;</span>)<br><br>dfdiff.plot(<span class="hljs-attr">x</span> = <span class="hljs-string">&quot;date&quot;</span>,<span class="hljs-attr">y</span> = [<span class="hljs-string">&quot;confirmed_num&quot;</span>,<span class="hljs-string">&quot;cured_num&quot;</span>,<span class="hljs-string">&quot;dead_num&quot;</span>],<span class="hljs-attr">figsize=(10,6))</span><br>plt.xticks(<span class="hljs-attr">rotation=60)</span><br><span class="hljs-attr">dfdiff</span> = dfdiff.drop(<span class="hljs-string">&quot;date&quot;</span>,<span class="hljs-attr">axis</span> = <span class="hljs-number">1</span>).astype(<span class="hljs-string">&quot;float32&quot;</span>)<br></code></pre></td></tr></table></figure><p>下面我们通过继承torch.utils.data.Dataset实现自定义时间序列数据集。</p><p>torch.utils.data.Dataset是一个抽象类，用户想要加载自定义的数据只需要继承这个类，并且覆写其中的两个方法即可：</p><ul><li>__len__:实现len(dataset)返回整个数据集的大小。</li><li>__getitem__:用来获取一些索引的数据，使dataset[i]返回数据集中第i个样本。<br>不覆写这两个方法会直接返回错误。</li></ul><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> torch <br><span class="hljs-title">from</span> torch <span class="hljs-keyword">import</span> nn <br><span class="hljs-title">from</span> torch.utils.<span class="hljs-class"><span class="hljs-keyword">data</span> import <span class="hljs-type">Dataset</span>,<span class="hljs-type">DataLoader</span>,<span class="hljs-type">TensorDataset</span></span><br><br><br><span class="hljs-meta">#用某日前8天窗口数据作为输入预测该日数据</span><br><span class="hljs-type">WINDOW_SIZE</span> = <span class="hljs-number">8</span><br><span class="hljs-class"></span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-type">Covid19Dataset</span>(<span class="hljs-type">Dataset</span>):</span><br><span class="hljs-class">        </span><br><span class="hljs-class">    def __len__(<span class="hljs-title">self</span>):</span><br><span class="hljs-class">        return len(<span class="hljs-title">dfdiff</span>) - <span class="hljs-type">WINDOW_SIZE</span></span><br><span class="hljs-class">    </span><br><span class="hljs-class">    def __getitem__(<span class="hljs-title">self</span>,<span class="hljs-title">i</span>):</span><br><span class="hljs-class">        x = dfdiff.loc[i:i+<span class="hljs-type">WINDOW_SIZE</span>-1,:]</span><br><span class="hljs-class">        feature = torch.tensor(<span class="hljs-title">x</span>.<span class="hljs-title">values</span>)</span><br><span class="hljs-class">        y = dfdiff.loc[i+<span class="hljs-type">WINDOW_SIZE</span>,:]</span><br><span class="hljs-class">        label = torch.tensor(<span class="hljs-title">y</span>.<span class="hljs-title">values</span>)</span><br><span class="hljs-class">        return (<span class="hljs-title">feature</span>,<span class="hljs-title">label</span>)</span><br><span class="hljs-class">    </span><br><span class="hljs-class">ds_train = <span class="hljs-type">Covid19Dataset</span>()</span><br><span class="hljs-class"></span><br><span class="hljs-class">#数据较小，可以将全部训练数据放入到一个batch中，提升性能</span><br><span class="hljs-class">dl_train = <span class="hljs-type">DataLoader</span>(<span class="hljs-title">ds_train</span>,<span class="hljs-title">batch_size</span> = 38)</span><br></code></pre></td></tr></table></figure><h4 id="二，定义模型"><a href="#二，定义模型" class="headerlink" title="二，定义模型"></a>二，定义模型</h4><p>使用Pytorch通常有三种方式构建模型：使用nn.Sequential按层顺序构建模型，继承nn.Module基类构建自定义模型，继承nn.Module基类构建模型并辅助应用模型容器进行封装。</p><p>此处选择第二种方式构建模型。</p><p>由于接下来使用类形式的训练循环，我们进一步将模型封装成torchkeras中的Model类来获得类似Keras中高阶模型接口的功能。</p><p>Model类实际上继承自nn.Module类。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> torch<br><span class="hljs-title">from</span> torch <span class="hljs-keyword">import</span> nn <br><span class="hljs-keyword">import</span> importlib <br><span class="hljs-keyword">import</span> torchkeras <br><br><span class="hljs-title">torch</span>.random.seed()<br><span class="hljs-class"></span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-type">Block</span>(<span class="hljs-title">nn</span>.<span class="hljs-type">Module</span>):</span><br><span class="hljs-class">    def __init__(<span class="hljs-title">self</span>):</span><br><span class="hljs-class">        super(<span class="hljs-type">Block</span>,<span class="hljs-title">self</span>).__init__()</span><br><span class="hljs-class">    </span><br><span class="hljs-class">    def forward(<span class="hljs-title">self</span>,<span class="hljs-title">x</span>,<span class="hljs-title">x_input</span>):</span><br><span class="hljs-class">        x_out = torch.max((1+<span class="hljs-title">x</span>)*x_input[:,-1,:],torch.tensor(0.0))</span><br><span class="hljs-class">        return x_out</span><br><span class="hljs-class">    </span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-type">Net</span>(<span class="hljs-title">nn</span>.<span class="hljs-type">Module</span>):</span><br><span class="hljs-class">    def __init__(<span class="hljs-title">self</span>):</span><br><span class="hljs-class">        super(<span class="hljs-type">Net</span>, <span class="hljs-title">self</span>).__init__()</span><br><span class="hljs-class">        # 3层lstm</span><br><span class="hljs-class">        self.lstm = nn.<span class="hljs-type">LSTM</span>(<span class="hljs-title">input_size</span> = 3,<span class="hljs-title">hidden_size</span> = 3,<span class="hljs-title">num_layers</span> = 5,<span class="hljs-title">batch_first</span> = <span class="hljs-type">True</span>)</span><br><span class="hljs-class">        self.linear = nn.<span class="hljs-type">Linear</span>(3,3)</span><br><span class="hljs-class">        self.block = <span class="hljs-type">Block</span>()</span><br><span class="hljs-class">        </span><br><span class="hljs-class">    def forward(<span class="hljs-title">self</span>,<span class="hljs-title">x_input</span>):</span><br><span class="hljs-class">        x = self.lstm(<span class="hljs-title">x_input</span>)[0][:,-1,:]</span><br><span class="hljs-class">        x = self.linear(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        y = self.block(<span class="hljs-title">x</span>,<span class="hljs-title">x_input</span>)</span><br><span class="hljs-class">        return y</span><br><span class="hljs-class">        </span><br><span class="hljs-class">net = <span class="hljs-type">Net</span>()</span><br><span class="hljs-class">model = torchkeras.<span class="hljs-type">Model</span>(<span class="hljs-title">net</span>)</span><br><span class="hljs-class">print(<span class="hljs-title">model</span>)</span><br><span class="hljs-class"></span><br><span class="hljs-class">model.summary(<span class="hljs-title">input_shape</span>=(8,3),input_dtype = torch.<span class="hljs-type">FloatTensor</span>)</span><br></code></pre></td></tr></table></figure><h4 id="三，训练模型"><a href="#三，训练模型" class="headerlink" title="三，训练模型"></a>三，训练模型</h4><p>训练Pytorch通常需要用户编写自定义训练循环，训练循环的代码风格因人而异。</p><p>有3类典型的训练循环代码风格：脚本形式训练循环，函数形式训练循环，类形式训练循环。</p><p>此处介绍一种类形式的训练循环。</p><p>我们仿照Keras定义了一个高阶的模型接口Model,实现 fit, validate，predict, summary 方法，相当于用户自定义高阶API。</p><p>注：循环神经网络调试较为困难，需要设置多个不同的学习率多次尝试，以取得较好的效果。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">def</span> mspe(y_pred,y_true):<br>    <span class="hljs-attribute">err_percent</span> = (y_true - y_pred)**<span class="hljs-number">2</span>/(torch.max(y_true**<span class="hljs-number">2</span>,torch.tensor(<span class="hljs-number">1</span>e-<span class="hljs-number">7</span>)))<br>    <span class="hljs-attribute">return</span> torch.mean(err_percent)<br><br><span class="hljs-attribute">model</span>.compile(loss_func = mspe,optimizer = torch.optim.Adagrad(model.parameters(),lr = <span class="hljs-number">0</span>.<span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">dfhistory</span> = model.fit(<span class="hljs-number">100</span>,dl_train,log_step_freq=<span class="hljs-number">10</span>)<br></code></pre></td></tr></table></figure><h4 id="四，评估模型"><a href="#四，评估模型" class="headerlink" title="四，评估模型"></a>四，评估模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">%matplotlib inline<br>%config InlineBackend.figure_format = <span class="hljs-string">&#x27;svg&#x27;</span><br><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_metric</span>(<span class="hljs-params">dfhistory, metric</span>):</span><br>    train_metrics = dfhistory[metric]<br>    epochs = <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(train_metrics) + <span class="hljs-number">1</span>)<br>    plt.plot(epochs, train_metrics, <span class="hljs-string">&#x27;bo--&#x27;</span>)<br>    plt.title(<span class="hljs-string">&#x27;Training &#x27;</span>+ metric)<br>    plt.xlabel(<span class="hljs-string">&quot;Epochs&quot;</span>)<br>    plt.ylabel(metric)<br>    plt.legend([<span class="hljs-string">&quot;train_&quot;</span>+metric])<br>    plt.show()<br><br>plot_metric(dfhistory,<span class="hljs-string">&quot;loss&quot;</span>)<br><br></code></pre></td></tr></table></figure><h4 id="五，使用模型"><a href="#五，使用模型" class="headerlink" title="五，使用模型"></a>五，使用模型</h4><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">#使用dfresult记录现有数据以及此后预测的疫情数据<br>dfresult = dfdiff<span class="hljs-selector-attr">[[<span class="hljs-string">&quot;confirmed_num&quot;</span>,<span class="hljs-string">&quot;cured_num&quot;</span>,<span class="hljs-string">&quot;dead_num&quot;</span>]</span>]<span class="hljs-selector-class">.copy</span>()<br>dfresult<span class="hljs-selector-class">.tail</span>()<br></code></pre></td></tr></table></figure><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs css">#预测此后<span class="hljs-number">500</span>天的新增走势,将其结果添加到dfresult中<br>for <span class="hljs-selector-tag">i</span> in range(<span class="hljs-number">500</span>):<br>    arr_input = torch.<span class="hljs-built_in">unsqueeze</span>(torch.<span class="hljs-built_in">from_numpy</span>(dfresult.values[-<span class="hljs-number">38</span>:,:]),axis=<span class="hljs-number">0</span>)<br>    arr_predict = model.<span class="hljs-built_in">forward</span>(arr_input)<br><br>    dfpredict = pd.<span class="hljs-built_in">DataFrame</span>(torch.<span class="hljs-built_in">floor</span>(arr_predict).data.<span class="hljs-built_in">numpy</span>(),<br>                columns = dfresult.columns)<br>    dfresult = dfresult.<span class="hljs-built_in">append</span>(dfpredict,ignore_index=True)<br></code></pre></td></tr></table></figure><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs vala">dfresult.query(<span class="hljs-string">&quot;confirmed_num==0&quot;</span>).head()<br><br><span class="hljs-meta"># 第50天开始新增确诊降为0，第45天对应3月10日，也就是5天后，即预计3月15日新增确诊降为0</span><br><span class="hljs-meta"># 注：该预测偏乐观</span><br></code></pre></td></tr></table></figure><h4 id="六，保存模型"><a href="#六，保存模型" class="headerlink" title="六，保存模型"></a>六，保存模型</h4><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"># 保存模型参数<br><br>torch.save(model.net.state<span class="hljs-constructor">_dict()</span>, <span class="hljs-string">&quot;./data/model_parameter.pkl&quot;</span>)<br><br>net_clone = <span class="hljs-constructor">Net()</span><br>net_clone.load<span class="hljs-constructor">_state_dict(<span class="hljs-params">torch</span>.<span class="hljs-params">load</span>(<span class="hljs-string">&quot;./data/model_parameter.pkl&quot;</span>)</span>)<br>model_clone = torchkeras.<span class="hljs-constructor">Model(<span class="hljs-params">net_clone</span>)</span><br>model_clone.compile(loss_func = mspe)<br><br># 评估模型<br>model_clone.evaluate(dl_train)<br></code></pre></td></tr></table></figure><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记16-文本数据建模流程范例</title>
    <link href="/2022/02/09/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/"/>
    <url>/2022/02/09/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="文本数据"><a href="#文本数据" class="headerlink" title="文本数据"></a>文本数据</h2><span id="more"></span><h4 id="一，准备数据"><a href="#一，准备数据" class="headerlink" title="一，准备数据"></a>一，准备数据</h4><p>imdb数据集的目标是根据电影评论的文本内容预测评论的情感标签。</p><p>训练集有20000条电影评论文本，测试集有5000条电影评论文本，其中正面评论和负面评论都各占一半。</p><p>文本数据预处理较为繁琐，包括中文切词（本示例不涉及），构建词典，编码转换，序列填充，构建数据管道等等。</p><p>在torch中预处理文本数据一般使用torchtext或者自定义Dataset，torchtext功能非常强大，可以构建文本分类，序列标注，问答模型，机器翻译等NLP任务的数据集。</p><p>下面仅演示使用它来构建文本分类数据集的方法。</p><p>较完整的教程可以参考以下知乎文章：《pytorch学习笔记—Torchtext》</p><ul><li><a href="https://zhuanlan.zhihu.com/p/65833208">https://zhuanlan.zhihu.com/p/65833208</a></li></ul><p>torchtext常见API一览</p><ul><li>torchtext.data.Example : 用来表示一个样本，数据和标签</li><li>torchtext.vocab.Vocab: 词汇表，可以导入一些预训练词向量</li><li>torchtext.data.Datasets: 数据集类，__getitem__返回 Example实例, torchtext.data.TabularDataset是其子类。</li><li>torchtext.data.Field : 用来定义字段的处理方法（文本字段，标签字段）创建 Example时的 预处理，batch 时的一些处理操作。</li><li>torchtext.data.Iterator: 迭代器，用来生成 batch</li><li>torchtext.datasets: 包含了常见的数据集.</li></ul><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd <br><span class="hljs-title">from</span> collections <span class="hljs-keyword">import</span> OrderedDict<br><span class="hljs-keyword">import</span> re,string<br><span class="hljs-type">MAX_WORDS</span> = <span class="hljs-number">10000</span>  # 仅考虑最高频的<span class="hljs-number">10000</span>个词<br><span class="hljs-type">MAX_LEN</span> = <span class="hljs-number">200</span>  # 每个样本保留<span class="hljs-number">200</span>个词的长度<br><span class="hljs-type">BATCH_SIZE</span> = <span class="hljs-number">20</span> <br><span class="hljs-title">train_data_path</span> = &#x27;/home/kesci/input/data6936/<span class="hljs-class"><span class="hljs-keyword">data</span>/imdb/train.tsv&#x27;</span><br><span class="hljs-title">test_data_path</span> = &#x27;/home/kesci/input/data6936/<span class="hljs-class"><span class="hljs-keyword">data</span>/imdb/test.tsv&#x27;</span><br><span class="hljs-title">train_token_path</span> = &#x27;/home/kesci/input/data6936/<span class="hljs-class"><span class="hljs-keyword">data</span>/imdb/train_token.tsv&#x27;</span><br><span class="hljs-title">test_token_path</span> =  &#x27;/home/kesci/input/data6936/<span class="hljs-class"><span class="hljs-keyword">data</span>/imdb/test_token.tsv&#x27;</span><br><span class="hljs-title">train_samples_path</span> = &#x27;/home/kesci/input/data6936/<span class="hljs-class"><span class="hljs-keyword">data</span>/imdb/train_samples/&#x27;</span><br><span class="hljs-title">test_samples_path</span> =  &#x27;/home/kesci/input/data6936/<span class="hljs-class"><span class="hljs-keyword">data</span>/imdb/test_samples/&#x27;</span><br></code></pre></td></tr></table></figure><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs applescript"><span class="hljs-comment">##构建词典</span><br><br>word_count_dict = &#123;&#125;<br><br><span class="hljs-comment">#清洗文本</span><br>def clean_text(<span class="hljs-built_in">text</span>):<br>    lowercase = <span class="hljs-built_in">text</span>.lower().replace(<span class="hljs-string">&quot;\n&quot;</span>,<span class="hljs-string">&quot; &quot;</span>)<br>    stripped_html = re.sub(&#x27;&lt;br /&gt;&#x27;, &#x27; &#x27;,lowercase)<br>    cleaned_punctuation = re.sub(&#x27;[%s]&#x27;%re.escape(<span class="hljs-built_in">string</span>.punctuation),&#x27;&#x27;,stripped_html)<br><span class="hljs-built_in">    return</span> cleaned_punctuation<br><br><span class="hljs-keyword">with</span> open(train_data_path,<span class="hljs-string">&quot;r&quot;</span>,encoding = &#x27;utf<span class="hljs-number">-8</span>&#x27;) <span class="hljs-keyword">as</span> f:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<br>        label,<span class="hljs-built_in">text</span> = line.split(<span class="hljs-string">&quot;\t&quot;</span>)<br>        cleaned_text = clean_text(<span class="hljs-built_in">text</span>)<br>        <span class="hljs-keyword">for</span> <span class="hljs-built_in">word</span> <span class="hljs-keyword">in</span> cleaned_text.split(<span class="hljs-string">&quot; &quot;</span>):<br>            word_count_dict[<span class="hljs-built_in">word</span>] = word_count_dict.<span class="hljs-keyword">get</span>(<span class="hljs-built_in">word</span>,<span class="hljs-number">0</span>)+<span class="hljs-number">1</span> <br><br>df_word_dict = pd.DataFrame(pd.Series(word_count_dict,<span class="hljs-built_in">name</span> = <span class="hljs-string">&quot;count&quot;</span>))<br>df_word_dict = df_word_dict.sort_values(<span class="hljs-keyword">by</span> = <span class="hljs-string">&quot;count&quot;</span>,ascending =False)<br><br>df_word_dict = df_word_dict[<span class="hljs-number">0</span>:MAX_WORDS<span class="hljs-number">-2</span>] <span class="hljs-comment">#  </span><br>df_word_dict[<span class="hljs-string">&quot;word_id&quot;</span>] = range(<span class="hljs-number">2</span>,MAX_WORDS) <span class="hljs-comment">#编号0和1分别留给未知词&lt;unkown&gt;和填充&lt;padding&gt;</span><br><br>word_id_dict = df_word_dict[<span class="hljs-string">&quot;word_id&quot;</span>].to_dict()<br><br>df_word_dict.head(<span class="hljs-number">10</span>)<br></code></pre></td></tr></table></figure><p>利用构建好的词典，将文本转换成token序号。</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver"><span class="hljs-comment">#转换token</span><br><br><span class="hljs-comment"># 填充文本</span><br>def pad(data_list,pad_length):<br>    padded_list = data_list.copy()<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(data_list)&gt; pad_length:<br>         padded_list = data_list[-pad_length:]<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(data_list)&lt; pad_length:<br>         padded_list = [<span class="hljs-number">1</span>]*(pad_length-<span class="hljs-built_in">len</span>(data_list))+data_list<br>    <span class="hljs-literal">return</span> padded_list<br><br>def text_to_token(text_file,token_file):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(text_file,<span class="hljs-string">&quot;r&quot;</span>,encoding = <span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> fin,\<br>      <span class="hljs-built_in">open</span>(token_file,<span class="hljs-string">&quot;w&quot;</span>,encoding = <span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> fout:<br>        <span class="hljs-keyword">for</span> <span class="hljs-built_in">line</span> <span class="hljs-keyword">in</span> fin:<br>            label,<span class="hljs-keyword">text</span> = <span class="hljs-built_in">line</span>.<span class="hljs-built_in">split</span>(<span class="hljs-string">&quot;\t&quot;</span>)<br>            cleaned_text = clean_text(<span class="hljs-keyword">text</span>)<br>            word_token_list = [word_id_dict.<span class="hljs-built_in">get</span>(<span class="hljs-built_in">word</span>, <span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> <span class="hljs-built_in">word</span> <span class="hljs-keyword">in</span> cleaned_text.<span class="hljs-built_in">split</span>(<span class="hljs-string">&quot; &quot;</span>)]<br>            pad_list = pad(word_token_list,MAX_LEN)<br>            out_line = label+<span class="hljs-string">&quot;\t&quot;</span>+<span class="hljs-string">&quot; &quot;</span>.join([str(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> pad_list])<br>            fout.<span class="hljs-built_in">write</span>(out_line+<span class="hljs-string">&quot;\n&quot;</span>)<br>        <br>text_to_token(train_data_path,train_token_path)<br>text_to_token(test_data_path,test_token_path)<br></code></pre></td></tr></table></figure><p>接着将token文本按照样本分割，每个文件存放一个样本的数据。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"># 分割样本<br>import os<br><br><span class="hljs-keyword">if</span> not os.path.exists(train_samples_path):<br>    os.mkdir(train_samples_path)<br>    <br><span class="hljs-keyword">if</span> not os.path.exists(test_samples_path):<br>    os.mkdir(test_samples_path)<br>    <br>    <br>def split<span class="hljs-constructor">_samples(<span class="hljs-params">token_path</span>,<span class="hljs-params">samples_dir</span>)</span>:<br>    <span class="hljs-keyword">with</span> <span class="hljs-keyword">open</span>(token_path,<span class="hljs-string">&quot;r&quot;</span>,encoding = &#x27;utf-<span class="hljs-number">8</span>&#x27;) <span class="hljs-keyword">as</span> fin:<br>        i = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> fin:<br>            <span class="hljs-keyword">with</span> <span class="hljs-keyword">open</span>(samples_dir+<span class="hljs-string">&quot;%d.txt&quot;</span>%i,<span class="hljs-string">&quot;w&quot;</span>,encoding = <span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> fout:<br>                fout.write(line)<br>            i = i+<span class="hljs-number">1</span><br><br>split<span class="hljs-constructor">_samples(<span class="hljs-params">train_token_path</span>,<span class="hljs-params">train_samples_path</span>)</span><br>split<span class="hljs-constructor">_samples(<span class="hljs-params">test_token_path</span>,<span class="hljs-params">test_samples_path</span>)</span><br></code></pre></td></tr></table></figure><p>创建数据集Dataset, 从文件名称列表中读取文件内容</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset,DataLoader <br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">imdbDataset</span>(<span class="hljs-params">Dataset</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,samples_dir</span>):</span><br>        self.samples_dir = samples_dir<br>        self.samples_paths = os.listdir(samples_dir)<br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.samples_paths)<br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span>(<span class="hljs-params">self,index</span>):</span><br>        path = self.samples_dir + self.samples_paths[index]<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(path,<span class="hljs-string">&quot;r&quot;</span>,encoding = <span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>            line = f.readline()<br>            label,tokens = line.split(<span class="hljs-string">&quot;\t&quot;</span>)<br>            label = torch.tensor([<span class="hljs-built_in">float</span>(label)],dtype = torch.<span class="hljs-built_in">float</span>)<br>            feature = torch.tensor([<span class="hljs-built_in">int</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> tokens.split(<span class="hljs-string">&quot; &quot;</span>)],dtype = torch.long)<br>            <span class="hljs-keyword">return</span>  (feature,label)<br>ds_train = imdbDataset(train_samples_path)<br>ds_test = imdbDataset(test_samples_path)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(ds_train))<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(ds_test))<br><br>dl_train = DataLoader(ds_train,batch_size = BATCH_SIZE,shuffle = <span class="hljs-literal">True</span>,num_workers=<span class="hljs-number">4</span>)<br>dl_test = DataLoader(ds_test,batch_size = BATCH_SIZE,num_workers=<span class="hljs-number">4</span>)<br><br><span class="hljs-keyword">for</span> features,labels <span class="hljs-keyword">in</span> dl_train:<br>    <span class="hljs-built_in">print</span>(features)<br>    <span class="hljs-built_in">print</span>(labels)<br>    <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure><h4 id="二，定义模型"><a href="#二，定义模型" class="headerlink" title="二，定义模型"></a>二，定义模型</h4><p>使用Pytorch通常有三种方式构建模型：使用nn.Sequential按层顺序构建模型，继承nn.Module基类构建自定义模型，继承nn.Module基类构建模型并辅助应用模型容器(nn.Sequential,nn.ModuleList,nn.ModuleDict)进行封装。</p><p>此处选择使用第三种方式进行构建。</p><p>由于接下来使用类形式的训练循环，我们将模型封装成torchkeras.Model类来获得类似Keras中高阶模型接口的功能。</p><p>Model类实际上继承自nn.Module类。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">import torch<br>from torch import nn <br>import torchkeras<br><br>torch.random.seed<span class="hljs-literal">()</span><br>import torch<br>from torch import nn <br><br><span class="hljs-keyword">class</span> <span class="hljs-constructor">Net(<span class="hljs-params">torchkeras</span>.Model)</span>:<br>    <br>    def <span class="hljs-constructor">__init__(<span class="hljs-params">self</span>)</span>:<br>        super(Net, self).<span class="hljs-constructor">__init__()</span><br>        <br>        #设置padding_idx参数后将在训练过程中将填充的token始终赋值为<span class="hljs-number">0</span>向量<br>        self.embedding = nn.<span class="hljs-constructor">Embedding(<span class="hljs-params">num_embeddings</span> = MAX_WORDS,<span class="hljs-params">embedding_dim</span> = 3,<span class="hljs-params">padding_idx</span> = 1)</span><br>        self.conv = nn.<span class="hljs-constructor">Sequential()</span><br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;conv_1&quot;</span>,<span class="hljs-params">nn</span>.Conv1d(<span class="hljs-params">in_channels</span> = 3,<span class="hljs-params">out_channels</span> = 16,<span class="hljs-params">kernel_size</span> = 5)</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;pool_1&quot;</span>,<span class="hljs-params">nn</span>.MaxPool1d(<span class="hljs-params">kernel_size</span> = 2)</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;relu_1&quot;</span>,<span class="hljs-params">nn</span>.ReLU()</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;conv_2&quot;</span>,<span class="hljs-params">nn</span>.Conv1d(<span class="hljs-params">in_channels</span> = 16,<span class="hljs-params">out_channels</span> = 128,<span class="hljs-params">kernel_size</span> = 2)</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;pool_2&quot;</span>,<span class="hljs-params">nn</span>.MaxPool1d(<span class="hljs-params">kernel_size</span> = 2)</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;relu_2&quot;</span>,<span class="hljs-params">nn</span>.ReLU()</span>)<br>        <br>        self.dense = nn.<span class="hljs-constructor">Sequential()</span><br>        self.dense.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;flatten&quot;</span>,<span class="hljs-params">nn</span>.Flatten()</span>)<br>        self.dense.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;linear&quot;</span>,<span class="hljs-params">nn</span>.Linear(6144,1)</span>)<br>        self.dense.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;sigmoid&quot;</span>,<span class="hljs-params">nn</span>.Sigmoid()</span>)<br>        <br>    def forward(self,x):<br>        x = self.embedding(x).transpose(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)<br>        x = self.conv(x)<br>        y = self.dense(x)<br>        return y<br>        <br><br>model = <span class="hljs-constructor">Net()</span><br>print(model)<br><br>model.summary(input_shape = (<span class="hljs-number">200</span>,),input_dtype = torch.LongTensor)<br></code></pre></td></tr></table></figure><h4 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h4><p>训练Pytorch通常需要用户编写自定义训练循环，训练循环的代码风格因人而异。</p><p>有3类典型的训练循环代码风格：脚本形式训练循环，函数形式训练循环，类形式训练循环。</p><p>此处介绍一种类形式的训练循环。</p><p>我们仿照Keras定义了一个高阶的模型接口Model,实现 fit, validate，predict, summary 方法，相当于用户自定义高阶API。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"># 准确率<br>def accuracy(y_pred,y_true):<br>    y_pred = torch.where(y_pred&gt;<span class="hljs-number">0.5</span>,torch.ones<span class="hljs-constructor">_like(<span class="hljs-params">y_pred</span>,<span class="hljs-params">dtype</span> = <span class="hljs-params">torch</span>.<span class="hljs-params">float32</span>)</span>,<br>                      torch.zeros<span class="hljs-constructor">_like(<span class="hljs-params">y_pred</span>,<span class="hljs-params">dtype</span> = <span class="hljs-params">torch</span>.<span class="hljs-params">float32</span>)</span>)<br>    acc = torch.mean(<span class="hljs-number">1</span>-torch.abs(y_true-y_pred))<br>    return acc<br><br>model.compile(loss_func = nn.<span class="hljs-constructor">BCELoss()</span>,optimizer= torch.optim.<span class="hljs-constructor">Adagrad(<span class="hljs-params">model</span>.<span class="hljs-params">parameters</span>()</span>,lr = <span class="hljs-number">0.02</span>),<br>             metrics_dict=&#123;<span class="hljs-string">&quot;accuracy&quot;</span>:accuracy&#125;)<br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># 有时候模型训练过程中不收敛，需要多试几次</span><br><span class="hljs-attribute">dfhistory</span> = model.fit(<span class="hljs-number">20</span>,dl_train,dl_val=dl_test,log_step_freq= <span class="hljs-number">200</span>)<br></code></pre></td></tr></table></figure><h4 id="四，评估模型"><a href="#四，评估模型" class="headerlink" title="四，评估模型"></a>四，评估模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python">%matplotlib inline<br>%config InlineBackend.figure_format = <span class="hljs-string">&#x27;svg&#x27;</span><br><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_metric</span>(<span class="hljs-params">dfhistory, metric</span>):</span><br>    train_metrics = dfhistory[metric]<br>    val_metrics = dfhistory[<span class="hljs-string">&#x27;val_&#x27;</span>+metric]<br>    epochs = <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(train_metrics) + <span class="hljs-number">1</span>)<br>    plt.plot(epochs, train_metrics, <span class="hljs-string">&#x27;bo--&#x27;</span>)<br>    plt.plot(epochs, val_metrics, <span class="hljs-string">&#x27;ro-&#x27;</span>)<br>    plt.title(<span class="hljs-string">&#x27;Training and validation &#x27;</span>+ metric)<br>    plt.xlabel(<span class="hljs-string">&quot;Epochs&quot;</span>)<br>    plt.ylabel(metric)<br>    plt.legend([<span class="hljs-string">&quot;train_&quot;</span>+metric, <span class="hljs-string">&#x27;val_&#x27;</span>+metric])<br>    plt.show()<br><br>plot_metric(dfhistory,<span class="hljs-string">&quot;loss&quot;</span>)<br>plot_metric(dfhistory,<span class="hljs-string">&quot;accuracy&quot;</span>)<br><br><span class="hljs-comment"># 评估</span><br>model.evaluate(dl_test)<br></code></pre></td></tr></table></figure><h4 id="五，使用模型"><a href="#五，使用模型" class="headerlink" title="五，使用模型"></a>五，使用模型</h4><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gams"><span class="hljs-keyword">model</span>.predict(dl_test)<br></code></pre></td></tr></table></figure><h4 id="六，保存模型"><a href="#六，保存模型" class="headerlink" title="六，保存模型"></a>六，保存模型</h4><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"># 保存模型参数<br><br>torch.save(model.state<span class="hljs-constructor">_dict()</span>, <span class="hljs-string">&quot;./data/model_parameter.pkl&quot;</span>)<br><br>model_clone = <span class="hljs-constructor">Net()</span><br>model_clone.load<span class="hljs-constructor">_state_dict(<span class="hljs-params">torch</span>.<span class="hljs-params">load</span>(<span class="hljs-string">&quot;./data/model_parameter.pkl&quot;</span>)</span>)<br><br>model_clone.compile(loss_func = nn.<span class="hljs-constructor">BCELoss()</span>,optimizer= torch.optim.<span class="hljs-constructor">Adagrad(<span class="hljs-params">model</span>.<span class="hljs-params">parameters</span>()</span>,lr = <span class="hljs-number">0.02</span>),<br>             metrics_dict=&#123;<span class="hljs-string">&quot;accuracy&quot;</span>:accuracy&#125;)<br><br># 评估模型<br>model_clone.evaluate(dl_test)<br></code></pre></td></tr></table></figure><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记15-图片数据建模流程范例</title>
    <link href="/2022/02/08/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015-%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/"/>
    <url>/2022/02/08/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015-%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="图片数据"><a href="#图片数据" class="headerlink" title="图片数据"></a>图片数据</h2><span id="more"></span><figure class="highlight cos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs cos">import os<br>import datetime<br><br>#打印时间<br>def printbar():<br>    nowtime = datetime.datetime.now().strftime(&#x27;<span class="hljs-built_in">%Y</span>-<span class="hljs-built_in">%m</span>-<span class="hljs-built_in">%d</span> <span class="hljs-built_in">%H</span>:<span class="hljs-built_in">%M</span>:<span class="hljs-built_in">%S</span>&#x27;)<br>    <span class="hljs-keyword">print</span>(<span class="hljs-string">&quot;\n&quot;</span>+<span class="hljs-string">&quot;==========&quot;</span>*<span class="hljs-number">8</span> + <span class="hljs-string">&quot;%s&quot;</span><span class="hljs-built_in">%nowtime</span>)<br><br>#mac系统上pytorch和matplotlib在jupyter中同时跑需要更改环境变量<br>os.environ[<span class="hljs-string">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>]=<span class="hljs-string">&quot;TRUE&quot;</span> <br></code></pre></td></tr></table></figure><h4 id="一，准备数据"><a href="#一，准备数据" class="headerlink" title="一，准备数据"></a>一，准备数据</h4><p>cifar2数据集为cifar10数据集的子集，只包括前两种类别airplane和automobile。</p><p>训练集有airplane和automobile图片各5000张，测试集有airplane和automobile图片各1000张。</p><p>cifar2任务的目标是训练一个模型来对飞机airplane和机动车automobile两种图片进行分类。</p><p>在Pytorch中构建图片数据管道通常有两种方法。</p><p>第一种是使用 torchvision中的datasets.ImageFolder来读取图片然后用 DataLoader来并行加载。</p><p>第二种是通过继承 torch.utils.data.Dataset 实现用户自定义读取逻辑然后用 DataLoader来并行加载。</p><p>第二种方法是读取用户自定义数据集的通用方法，既可以读取图片数据集，也可以读取文本数据集。</p><p>本篇我们介绍第一种方法。</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-built_in">import</span> torch <br>from torch <span class="hljs-built_in">import</span> nn<br>from torch.utils.data <span class="hljs-built_in">import</span> Dataset,DataLoader<br>from torchvision <span class="hljs-built_in">import</span> transforms,datasets <br><br><br><span class="hljs-attr">transform_train</span> = transforms.Compose(<br>    [transforms.ToTensor()])<br><span class="hljs-attr">transform_valid</span> = transforms.Compose(<br>    [transforms.ToTensor()])<br><br><br><span class="hljs-attr">ds_train</span> = datasets.ImageFolder(<span class="hljs-string">&quot;/home/kesci/input/data6936/data/cifar2/train/&quot;</span>,<br>            <span class="hljs-attr">transform</span> = transform_train,<span class="hljs-attr">target_transform=</span> lambda t:torch.tensor([t]).float())<br><span class="hljs-attr">ds_valid</span> = datasets.ImageFolder(<span class="hljs-string">&quot;/home/kesci/input/data6936/data/cifar2/test/&quot;</span>,<br>            <span class="hljs-attr">transform</span> = transform_train,<span class="hljs-attr">target_transform=</span> lambda t:torch.tensor([t]).float())<br><br>print(ds_train.class_to_idx)<br></code></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">dl_train = <span class="hljs-constructor">DataLoader(<span class="hljs-params">ds_train</span>,<span class="hljs-params">batch_size</span> = 50,<span class="hljs-params">shuffle</span> = True,<span class="hljs-params">num_workers</span>=3)</span><br>dl_valid = <span class="hljs-constructor">DataLoader(<span class="hljs-params">ds_valid</span>,<span class="hljs-params">batch_size</span> = 50,<span class="hljs-params">shuffle</span> = True,<span class="hljs-params">num_workers</span>=3)</span><br></code></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">%matplotlib inline<br>%config <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">InlineBackend</span>.</span></span>figure_format = &#x27;svg&#x27;<br><br>#查看部分样本<br>from matplotlib import pyplot <span class="hljs-keyword">as</span> plt <br><br>plt.figure(figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">8</span>)) <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">9</span>):<br>    img,label = ds_train<span class="hljs-literal">[<span class="hljs-identifier">i</span>]</span><br>    img = img.permute(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>)<br>    ax=plt.subplot(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>,i+<span class="hljs-number">1</span>)<br>    ax.imshow(img.numpy<span class="hljs-literal">()</span>)<br>    ax.set<span class="hljs-constructor">_title(<span class="hljs-string">&quot;label = %d&quot;</span>%<span class="hljs-params">label</span>.<span class="hljs-params">item</span>()</span>)<br>    ax.set<span class="hljs-constructor">_xticks([])</span><br>    ax.set<span class="hljs-constructor">_yticks([])</span> <br>plt.show<span class="hljs-literal">()</span><br></code></pre></td></tr></table></figure><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs processing"># Pytorch的图片默认顺序是 Batch,Channel,Width,Height<br><span class="hljs-keyword">for</span> x,y in dl_train:<br>    <span class="hljs-built_in">print</span>(x.<span class="hljs-built_in">shape</span>,y.<span class="hljs-built_in">shape</span>) <br>    <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure><h4 id="二，定义模型"><a href="#二，定义模型" class="headerlink" title="二，定义模型"></a>二，定义模型</h4><p>使用Pytorch通常有三种方式构建模型：使用nn.Sequential按层顺序构建模型，继承nn.Module基类构建自定义模型，继承nn.Module基类构建模型并辅助应用模型容器(nn.Sequential,nn.ModuleList,nn.ModuleDict)进行封装。</p><p>此处选择通过继承nn.Module基类构建自定义模型。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment">#测试AdaptiveMaxPool2d的效果</span><br><span class="hljs-attribute">pool</span> = nn.AdaptiveMaxPool<span class="hljs-number">2</span>d((<span class="hljs-number">1</span>,<span class="hljs-number">1</span>))<br><span class="hljs-attribute">t</span> = torch.randn(<span class="hljs-number">10</span>,<span class="hljs-number">8</span>,<span class="hljs-number">32</span>,<span class="hljs-number">32</span>)<br><span class="hljs-attribute">pool</span>(t).shape <br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">class</span> Net(nn.Module):<br>    <br>    <span class="hljs-attribute">def</span> __init__(self):<br>        <span class="hljs-attribute">super</span>(Net, self).__init__()<br>        <span class="hljs-attribute">self</span>.conv<span class="hljs-number">1</span> = nn.Conv<span class="hljs-number">2</span>d(in_channels=<span class="hljs-number">3</span>,out_channels=<span class="hljs-number">32</span>,kernel_size = <span class="hljs-number">3</span>)<br>        <span class="hljs-attribute">self</span>.pool = nn.MaxPool<span class="hljs-number">2</span>d(kernel_size = <span class="hljs-number">2</span>,stride = <span class="hljs-number">2</span>)<br>        <span class="hljs-attribute">self</span>.conv<span class="hljs-number">2</span> = nn.Conv<span class="hljs-number">2</span>d(in_channels=<span class="hljs-number">32</span>,out_channels=<span class="hljs-number">64</span>,kernel_size = <span class="hljs-number">5</span>)<br>        <span class="hljs-attribute">self</span>.dropout = nn.Dropout<span class="hljs-number">2</span>d(p = <span class="hljs-number">0</span>.<span class="hljs-number">1</span>)<br>        <span class="hljs-attribute">self</span>.adaptive_pool = nn.AdaptiveMaxPool<span class="hljs-number">2</span>d((<span class="hljs-number">1</span>,<span class="hljs-number">1</span>))<br>        <span class="hljs-attribute">self</span>.flatten = nn.Flatten()<br>        <span class="hljs-attribute">self</span>.linear<span class="hljs-number">1</span> = nn.Linear(<span class="hljs-number">64</span>,<span class="hljs-number">32</span>)<br>        <span class="hljs-attribute">self</span>.relu = nn.ReLU()<br>        <span class="hljs-attribute">self</span>.linear<span class="hljs-number">2</span> = nn.Linear(<span class="hljs-number">32</span>,<span class="hljs-number">1</span>)<br>        <span class="hljs-attribute">self</span>.sigmoid = nn.Sigmoid()<br>        <br>    <span class="hljs-attribute">def</span> forward(self,x):<br>        <span class="hljs-attribute">x</span> = self.conv<span class="hljs-number">1</span>(x)<br>        <span class="hljs-attribute">x</span> = self.pool(x)<br>        <span class="hljs-attribute">x</span> = self.conv<span class="hljs-number">2</span>(x)<br>        <span class="hljs-attribute">x</span> = self.pool(x)<br>        <span class="hljs-attribute">x</span> = self.dropout(x)<br>        <span class="hljs-attribute">x</span> = self.adaptive_pool(x)<br>        <span class="hljs-attribute">x</span> = self.flatten(x)<br>        <span class="hljs-attribute">x</span> = self.linear<span class="hljs-number">1</span>(x)<br>        <span class="hljs-attribute">x</span> = self.relu(x)<br>        <span class="hljs-attribute">x</span> = self.linear<span class="hljs-number">2</span>(x)<br>        <span class="hljs-attribute">y</span> = self.sigmoid(x)<br>        <span class="hljs-attribute">return</span> y<br>        <br><span class="hljs-attribute">net</span> = Net()<br><span class="hljs-attribute">print</span>(net)<br><br><span class="hljs-attribute">import</span> torchkeras<br><span class="hljs-attribute">torchkeras</span>.summary(net,input_shape= (<span class="hljs-number">3</span>,<span class="hljs-number">32</span>,<span class="hljs-number">32</span>))<br></code></pre></td></tr></table></figure><h4 id="三，训练模型"><a href="#三，训练模型" class="headerlink" title="三，训练模型"></a>三，训练模型</h4><p>Pytorch通常需要用户编写自定义训练循环，训练循环的代码风格因人而异。</p><p>有3类典型的训练循环代码风格：脚本形式训练循环，函数形式训练循环，类形式训练循环。</p><p>此处介绍一种较通用的函数形式训练循环。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs stylus">import pandas as pd <br>from sklearn<span class="hljs-selector-class">.metrics</span> import roc_auc_score<br><br>model = net<br>model<span class="hljs-selector-class">.optimizer</span> = torch<span class="hljs-selector-class">.optim</span><span class="hljs-selector-class">.SGD</span>(model<span class="hljs-selector-class">.parameters</span>(),lr = <span class="hljs-number">0.01</span>)<br>model<span class="hljs-selector-class">.loss_func</span> = torch<span class="hljs-selector-class">.nn</span><span class="hljs-selector-class">.BCELoss</span>()<br>model<span class="hljs-selector-class">.metric_func</span> = lambda y_pred,y_true: roc_auc_score(y_true<span class="hljs-selector-class">.data</span><span class="hljs-selector-class">.numpy</span>(),y_pred<span class="hljs-selector-class">.data</span><span class="hljs-selector-class">.numpy</span>())<br>model<span class="hljs-selector-class">.metric_name</span> = <span class="hljs-string">&quot;auc&quot;</span><br></code></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">def train<span class="hljs-constructor">_step(<span class="hljs-params">model</span>,<span class="hljs-params">features</span>,<span class="hljs-params">labels</span>)</span>:<br>    <br>    # 训练模式，dropout层发生作用<br>    model.train<span class="hljs-literal">()</span><br>    <br>    # 梯度清零<br>    model.optimizer.zero<span class="hljs-constructor">_grad()</span><br>    <br>    # 正向传播求损失<br>    predictions = model(features)<br>    loss = model.loss<span class="hljs-constructor">_func(<span class="hljs-params">predictions</span>,<span class="hljs-params">labels</span>)</span><br>    metric = model.metric<span class="hljs-constructor">_func(<span class="hljs-params">predictions</span>,<span class="hljs-params">labels</span>)</span><br><br>    # 反向传播求梯度<br>    loss.backward<span class="hljs-literal">()</span><br>    model.optimizer.step<span class="hljs-literal">()</span><br><br>    return loss.item<span class="hljs-literal">()</span>,metric.item<span class="hljs-literal">()</span><br><br>def valid<span class="hljs-constructor">_step(<span class="hljs-params">model</span>,<span class="hljs-params">features</span>,<span class="hljs-params">labels</span>)</span>:<br>    <br>    # 预测模式，dropout层不发生作用<br>    model.eval<span class="hljs-literal">()</span><br>    # 关闭梯度计算<br>    <span class="hljs-keyword">with</span> torch.no<span class="hljs-constructor">_grad()</span>:<br>        predictions = model(features)<br>        loss = model.loss<span class="hljs-constructor">_func(<span class="hljs-params">predictions</span>,<span class="hljs-params">labels</span>)</span><br>        metric = model.metric<span class="hljs-constructor">_func(<span class="hljs-params">predictions</span>,<span class="hljs-params">labels</span>)</span><br>    <br>    return loss.item<span class="hljs-literal">()</span>, metric.item<span class="hljs-literal">()</span><br><br><br># 测试train_step效果<br>features,labels = next(iter(dl_train))<br>train<span class="hljs-constructor">_step(<span class="hljs-params">model</span>,<span class="hljs-params">features</span>,<span class="hljs-params">labels</span>)</span><br></code></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs routeros">def train_model(model,epochs,dl_train,dl_valid,log_step_freq):<br><br>    metric_name = model.metric_name<br>    dfhistory = pd.DataFrame(columns = [<span class="hljs-string">&quot;epoch&quot;</span>,<span class="hljs-string">&quot;loss&quot;</span>,metric_name,<span class="hljs-string">&quot;val_loss&quot;</span>,<span class="hljs-string">&quot;val_&quot;</span>+metric_name]) <br>    <span class="hljs-builtin-name">print</span>(<span class="hljs-string">&quot;Start Training...&quot;</span>)<br>    nowtime = datetime.datetime.now().strftime(<span class="hljs-string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)<br>    <span class="hljs-builtin-name">print</span>(<span class="hljs-string">&quot;==========&quot;</span><span class="hljs-number">*8</span> + <span class="hljs-string">&quot;%s&quot;</span>%nowtime)<br><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(1,epochs+1):  <br><br>        # 1，训练循环-------------------------------------------------<br>        loss_sum = 0.0<br>        metric_sum = 0.0<br>        <span class="hljs-keyword">step</span> = 1<br><br>        <span class="hljs-keyword">for</span> <span class="hljs-keyword">step</span>, (features,labels) <span class="hljs-keyword">in</span> enumerate(dl_train, 1):<br><br>            loss,metric = train_step(model,features,labels)<br><br>            # 打印batch级别日志<br>            loss_sum += loss<br>            metric_sum += metric<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">step</span>%log_step_freq == 0:   <br>                <span class="hljs-builtin-name">print</span>((<span class="hljs-string">&quot;[step = %d] loss: %.3f, &quot;</span>+metric_name+<span class="hljs-string">&quot;: %.3f&quot;</span>) %<br>                      (<span class="hljs-keyword">step</span>, loss_sum/<span class="hljs-keyword">step</span>, metric_sum/<span class="hljs-keyword">step</span>))<br><br>        # 2，验证循环-------------------------------------------------<br>        val_loss_sum = 0.0<br>        val_metric_sum = 0.0<br>        val_step = 1<br><br>        <span class="hljs-keyword">for</span> val_step, (features,labels) <span class="hljs-keyword">in</span> enumerate(dl_valid, 1):<br><br>            val_loss,val_metric = valid_step(model,features,labels)<br><br>            val_loss_sum += val_loss<br>            val_metric_sum += val_metric<br><br>        # 3，记录日志-------------------------------------------------<br>        <span class="hljs-builtin-name">info</span> = (epoch, loss_sum/<span class="hljs-keyword">step</span>, metric_sum/<span class="hljs-keyword">step</span>, <br>                val_loss_sum/val_step, val_metric_sum/val_step)<br>        dfhistory.loc[epoch-1] = <span class="hljs-builtin-name">info</span><br><br>        # 打印epoch级别日志<br>        <span class="hljs-builtin-name">print</span>((<span class="hljs-string">&quot;\nEPOCH = %d, loss = %.3f,&quot;</span>+ metric_name + \<br>              <span class="hljs-string">&quot;  = %.3f, val_loss = %.3f, &quot;</span>+<span class="hljs-string">&quot;val_&quot;</span>+ metric_name+<span class="hljs-string">&quot; = %.3f&quot;</span>) <br>              %info)<br>        nowtime = datetime.datetime.now().strftime(<span class="hljs-string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)<br>        <span class="hljs-builtin-name">print</span>(<span class="hljs-string">&quot;\n&quot;</span>+<span class="hljs-string">&quot;==========&quot;</span><span class="hljs-number">*8</span> + <span class="hljs-string">&quot;%s&quot;</span>%nowtime)<br><br>    <span class="hljs-builtin-name">print</span>(<span class="hljs-string">&#x27;Finished Training...&#x27;</span>)<br>    <br>    return dfhistory<br></code></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">epochs = <span class="hljs-number">20</span><br><br>dfhistory = train<span class="hljs-constructor">_model(<span class="hljs-params">model</span>,<span class="hljs-params">epochs</span>,<span class="hljs-params">dl_train</span>,<span class="hljs-params">dl_valid</span>,<span class="hljs-params">log_step_freq</span> = 50)</span><br><br></code></pre></td></tr></table></figure><h4 id="四，评估模型"><a href="#四，评估模型" class="headerlink" title="四，评估模型"></a>四，评估模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python">%matplotlib inline<br>%config InlineBackend.figure_format = <span class="hljs-string">&#x27;svg&#x27;</span><br><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_metric</span>(<span class="hljs-params">dfhistory, metric</span>):</span><br>    train_metrics = dfhistory[metric]<br>    val_metrics = dfhistory[<span class="hljs-string">&#x27;val_&#x27;</span>+metric]<br>    epochs = <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(train_metrics) + <span class="hljs-number">1</span>)<br>    plt.plot(epochs, train_metrics, <span class="hljs-string">&#x27;bo--&#x27;</span>)<br>    plt.plot(epochs, val_metrics, <span class="hljs-string">&#x27;ro-&#x27;</span>)<br>    plt.title(<span class="hljs-string">&#x27;Training and validation &#x27;</span>+ metric)<br>    plt.xlabel(<span class="hljs-string">&quot;Epochs&quot;</span>)<br>    plt.ylabel(metric)<br>    plt.legend([<span class="hljs-string">&quot;train_&quot;</span>+metric, <span class="hljs-string">&#x27;val_&#x27;</span>+metric])<br>    plt.show()<br><br><br>plot_metric(dfhistory,<span class="hljs-string">&quot;loss&quot;</span>)<br>plot_metric(dfhistory,<span class="hljs-string">&quot;auc&quot;</span>)<br></code></pre></td></tr></table></figure><h4 id="五，使用模型"><a href="#五，使用模型" class="headerlink" title="五，使用模型"></a>五，使用模型</h4><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs css">def predict(model,<span class="hljs-selector-tag">dl</span>):<br>    model.<span class="hljs-built_in">eval</span>()<br>    with torch.<span class="hljs-built_in">no_grad</span>():<br>        result = torch.<span class="hljs-built_in">cat</span>([model.<span class="hljs-built_in">forward</span>(t[<span class="hljs-number">0</span>]) for t in dl])<br>    <span class="hljs-built_in">return</span>(result.data)<br><br><br>#预测概率<br>y_pred_probs = <span class="hljs-built_in">predict</span>(model,dl_valid)<br>y_pred_probs<br><br>#预测类别<br>y_pred = torch.<span class="hljs-built_in">where</span>(y_pred_probs&gt;<span class="hljs-number">0.5</span>,<br>        torch.<span class="hljs-built_in">ones_like</span>(y_pred_probs),torch.<span class="hljs-built_in">zeros_like</span>(y_pred_probs))<br>y_pred<br></code></pre></td></tr></table></figure><h4 id="六，保存模型"><a href="#六，保存模型" class="headerlink" title="六，保存模型"></a>六，保存模型</h4><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">print(model.state<span class="hljs-constructor">_dict()</span>.keys<span class="hljs-literal">()</span>)<br><br># 保存模型参数<br><br>torch.save(model.state<span class="hljs-constructor">_dict()</span>, <span class="hljs-string">&quot;./data/model_parameter.pkl&quot;</span>)<br><br>net_clone = <span class="hljs-constructor">Net()</span><br>net_clone.load<span class="hljs-constructor">_state_dict(<span class="hljs-params">torch</span>.<span class="hljs-params">load</span>(<span class="hljs-string">&quot;./data/model_parameter.pkl&quot;</span>)</span>)<br><br>predict(net_clone,dl_valid)<br></code></pre></td></tr></table></figure><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记14-结构化数据建模流程范例</title>
    <link href="/2022/02/08/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014-%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/"/>
    <url>/2022/02/08/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014-%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="结构化数据"><a href="#结构化数据" class="headerlink" title="结构化数据"></a>结构化数据</h2><span id="more"></span><figure class="highlight cos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs cos">import os<br>import datetime<br><br>#打印时间<br>def printbar():<br>    nowtime = datetime.datetime.now().strftime(&#x27;<span class="hljs-built_in">%Y</span>-<span class="hljs-built_in">%m</span>-<span class="hljs-built_in">%d</span> <span class="hljs-built_in">%H</span>:<span class="hljs-built_in">%M</span>:<span class="hljs-built_in">%S</span>&#x27;)<br>    <span class="hljs-keyword">print</span>(<span class="hljs-string">&quot;\n&quot;</span>+<span class="hljs-string">&quot;==========&quot;</span>*<span class="hljs-number">8</span> + <span class="hljs-string">&quot;%s&quot;</span><span class="hljs-built_in">%nowtime</span>)<br><br>#mac系统上pytorch和matplotlib在jupyter中同时跑需要更改环境变量<br>os.environ[<span class="hljs-string">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>]=<span class="hljs-string">&quot;TRUE&quot;</span> <br></code></pre></td></tr></table></figure><h4 id="一，准备数据"><a href="#一，准备数据" class="headerlink" title="一，准备数据"></a>一，准备数据</h4><p>titanic数据集的目标是根据乘客信息预测他们在Titanic号撞击冰山沉没后能否生存。</p><p>结构化数据一般会使用Pandas中的DataFrame进行预处理。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">import numpy <span class="hljs-keyword">as</span> np <br>import pandas <span class="hljs-keyword">as</span> pd <br>import matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>import torch <br>from torch import nn <br>from torch.utils.data import Dataset,DataLoader,TensorDataset<br><br>dftrain_raw = pd.read<span class="hljs-constructor">_csv(&#x27;<span class="hljs-operator">/</span><span class="hljs-params">home</span><span class="hljs-operator">/</span><span class="hljs-params">kesci</span><span class="hljs-operator">/</span><span class="hljs-params">input</span><span class="hljs-operator">/</span><span class="hljs-params">data6936</span><span class="hljs-operator">/</span><span class="hljs-params">data</span><span class="hljs-operator">/</span><span class="hljs-params">titanic</span><span class="hljs-operator">/</span><span class="hljs-params">train</span>.<span class="hljs-params">csv</span>&#x27;)</span><br>dftest_raw = pd.read<span class="hljs-constructor">_csv(&#x27;<span class="hljs-operator">/</span><span class="hljs-params">home</span><span class="hljs-operator">/</span><span class="hljs-params">kesci</span><span class="hljs-operator">/</span><span class="hljs-params">input</span><span class="hljs-operator">/</span><span class="hljs-params">data6936</span><span class="hljs-operator">/</span><span class="hljs-params">data</span><span class="hljs-operator">/</span><span class="hljs-params">titanic</span><span class="hljs-operator">/</span><span class="hljs-params">test</span>.<span class="hljs-params">csv</span>&#x27;)</span><br>dftrain_raw.head(<span class="hljs-number">10</span>)<br></code></pre></td></tr></table></figure><p>利用Pandas的数据可视化功能我们可以简单地进行探索性数据分析EDA（Exploratory Data Analysis）。</p><p>label分布情况</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">%matplotlib inline<br>%config InlineBackend.figure_format = &#x27;png&#x27;<br>ax = dftrain_raw[&#x27;Survived&#x27;]<span class="hljs-string">.value_counts</span><span class="hljs-params">()</span><span class="hljs-string">.plot</span><span class="hljs-params">(<span class="hljs-attr">kind</span> = &#x27;bar&#x27;,</span><br><span class="hljs-params">     <span class="hljs-attr">figsize</span> = (12,8)</span>,fontsize=15,rot = 0)<br>ax.<span class="hljs-keyword">set</span>_ylabel<span class="hljs-params">(&#x27;Counts&#x27;,<span class="hljs-attr">fontsize</span> = 15)</span><br>ax.<span class="hljs-keyword">set</span>_xlabel<span class="hljs-params">(&#x27;Survived&#x27;,<span class="hljs-attr">fontsize</span> = 15)</span><br>plt.show<span class="hljs-params">()</span><br></code></pre></td></tr></table></figure><p>数据预处理</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs prolog">def preprocessing(dfdata):<br><br>    dfresult= pd.<span class="hljs-symbol">DataFrame</span>()<br><br>    #<span class="hljs-symbol">Pclass</span><br>    dfPclass = pd.get_dummies(dfdata[<span class="hljs-string">&#x27;Pclass&#x27;</span>])<br>    dfPclass.columns = [<span class="hljs-string">&#x27;Pclass_&#x27;</span> +str(x) for x in dfPclass.columns ]<br>    dfresult = pd.concat([dfresult,dfPclass],axis = <span class="hljs-number">1</span>)<br><br>    #<span class="hljs-symbol">Sex</span><br>    dfSex = pd.get_dummies(dfdata[<span class="hljs-string">&#x27;Sex&#x27;</span>])<br>    dfresult = pd.concat([dfresult,dfSex],axis = <span class="hljs-number">1</span>)<br><br>    #<span class="hljs-symbol">Age</span><br>    dfresult[<span class="hljs-string">&#x27;Age&#x27;</span>] = dfdata[<span class="hljs-string">&#x27;Age&#x27;</span>].fillna(<span class="hljs-number">0</span>)<br>    dfresult[<span class="hljs-string">&#x27;Age_null&#x27;</span>] = pd.isna(dfdata[<span class="hljs-string">&#x27;Age&#x27;</span>]).astype(<span class="hljs-string">&#x27;int32&#x27;</span>)<br><br>    #<span class="hljs-symbol">SibSp</span>,<span class="hljs-symbol">Parch</span>,<span class="hljs-symbol">Fare</span><br>    dfresult[<span class="hljs-string">&#x27;SibSp&#x27;</span>] = dfdata[<span class="hljs-string">&#x27;SibSp&#x27;</span>]<br>    dfresult[<span class="hljs-string">&#x27;Parch&#x27;</span>] = dfdata[<span class="hljs-string">&#x27;Parch&#x27;</span>]<br>    dfresult[<span class="hljs-string">&#x27;Fare&#x27;</span>] = dfdata[<span class="hljs-string">&#x27;Fare&#x27;</span>]<br><br>    #<span class="hljs-symbol">Carbin</span><br>    dfresult[<span class="hljs-string">&#x27;Cabin_null&#x27;</span>] =  pd.isna(dfdata[<span class="hljs-string">&#x27;Cabin&#x27;</span>]).astype(<span class="hljs-string">&#x27;int32&#x27;</span>)<br><br>    #<span class="hljs-symbol">Embarked</span><br>    dfEmbarked = pd.get_dummies(dfdata[<span class="hljs-string">&#x27;Embarked&#x27;</span>],dummy_na=<span class="hljs-symbol">True</span>)<br>    dfEmbarked.columns = [<span class="hljs-string">&#x27;Embarked_&#x27;</span> + str(x) for x in dfEmbarked.columns]<br>    dfresult = pd.concat([dfresult,dfEmbarked],axis = <span class="hljs-number">1</span>)<br><br>    return(dfresult)<br><br>x_train = preprocessing(dftrain_raw).values<br>y_train = dftrain_raw[[<span class="hljs-string">&#x27;Survived&#x27;</span>]].values<br><br>x_test = preprocessing(dftest_raw).values<br>y_test = dftest_raw[[<span class="hljs-string">&#x27;Survived&#x27;</span>]].values<br><br>print(<span class="hljs-string">&quot;x_train.shape =&quot;</span>, x_train.shape )<br>print(<span class="hljs-string">&quot;x_test.shape =&quot;</span>, x_test.shape )<br><br>print(<span class="hljs-string">&quot;y_train.shape =&quot;</span>, y_train.shape )<br>print(<span class="hljs-string">&quot;y_test.shape =&quot;</span>, y_test.shape )<br></code></pre></td></tr></table></figure><p>进一步使用DataLoader和TensorDataset封装成可以迭代的数据管道。</p><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs lisp">dl_train = DataLoader(<span class="hljs-name">TensorDataset</span>(<span class="hljs-name">torch</span>.tensor(<span class="hljs-name">x_train</span>).float(),torch.tensor(<span class="hljs-name">y_train</span>).float()),<br>                     shuffle = True, batch_size = <span class="hljs-number">8</span>)<br>dl_valid = DataLoader(<span class="hljs-name">TensorDataset</span>(<span class="hljs-name">torch</span>.tensor(<span class="hljs-name">x_test</span>).float(),torch.tensor(<span class="hljs-name">y_test</span>).float()),<br>                     shuffle = False, batch_size = <span class="hljs-number">8</span>)<br></code></pre></td></tr></table></figure><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs maxima"># 测试数据管道<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">features</span>,<span class="hljs-built_in">labels</span> <span class="hljs-keyword">in</span> dl_train:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">features</span>,<span class="hljs-built_in">labels</span>)<br>    <span class="hljs-built_in">break</span><br></code></pre></td></tr></table></figure><h4 id="二，定义模型"><a href="#二，定义模型" class="headerlink" title="二，定义模型"></a>二，定义模型</h4><p>使用Pytorch通常有三种方式构建模型：使用nn.Sequential按层顺序构建模型，继承nn.Module基类构建自定义模型，继承nn.Module基类构建模型并辅助应用模型容器进行封装。</p><p>此处选择使用最简单的nn.Sequential，按层顺序模型。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs css">def create_net():<br>    net = nn.<span class="hljs-built_in">Sequential</span>()<br>    net.<span class="hljs-built_in">add_module</span>(<span class="hljs-string">&quot;linear1&quot;</span>,nn.<span class="hljs-built_in">Linear</span>(<span class="hljs-number">15</span>,<span class="hljs-number">20</span>))<br>    net.<span class="hljs-built_in">add_module</span>(<span class="hljs-string">&quot;relu1&quot;</span>,nn.<span class="hljs-built_in">ReLU</span>())<br>    net.<span class="hljs-built_in">add_module</span>(<span class="hljs-string">&quot;linear2&quot;</span>,nn.<span class="hljs-built_in">Linear</span>(<span class="hljs-number">20</span>,<span class="hljs-number">15</span>))<br>    net.<span class="hljs-built_in">add_module</span>(<span class="hljs-string">&quot;relu2&quot;</span>,nn.<span class="hljs-built_in">ReLU</span>())<br>    net.<span class="hljs-built_in">add_module</span>(<span class="hljs-string">&quot;linear3&quot;</span>,nn.<span class="hljs-built_in">Linear</span>(<span class="hljs-number">15</span>,<span class="hljs-number">1</span>))<br>    net.<span class="hljs-built_in">add_module</span>(<span class="hljs-string">&quot;sigmoid&quot;</span>,nn.<span class="hljs-built_in">Sigmoid</span>())<br>    return net<br>    <br>net = <span class="hljs-built_in">create_net</span>()<br><span class="hljs-built_in">print</span>(net)<br></code></pre></td></tr></table></figure><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">from</span> torchkeras <span class="hljs-keyword">import</span> <span class="hljs-keyword">summary</span><br><span class="hljs-keyword">summary</span>(net,input_shape=(<span class="hljs-number">15</span>,))<br></code></pre></td></tr></table></figure><h4 id="三，训练模型"><a href="#三，训练模型" class="headerlink" title="三，训练模型"></a>三，训练模型</h4><p>Pytorch通常需要用户编写自定义训练循环，训练循环的代码风格因人而异。</p><p>有3类典型的训练循环代码风格：脚本形式训练循环，函数形式训练循环，类形式训练循环。</p><p>此处介绍一种较通用的脚本形式。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">from sklearn.metrics import accuracy_score<br><br>loss_func = nn.<span class="hljs-constructor">BCELoss()</span><br>optimizer = torch.optim.<span class="hljs-constructor">Adam(<span class="hljs-params">params</span>=<span class="hljs-params">net</span>.<span class="hljs-params">parameters</span>()</span>,lr = <span class="hljs-number">0.01</span>)<br>metric_func = lambda y_pred,y_true: accuracy<span class="hljs-constructor">_score(<span class="hljs-params">y_true</span>.<span class="hljs-params">data</span>.<span class="hljs-params">numpy</span>()</span>,y_pred.data.numpy<span class="hljs-literal">()</span>&gt;<span class="hljs-number">0.5</span>)<br>metric_name = <span class="hljs-string">&quot;accuracy&quot;</span><br></code></pre></td></tr></table></figure><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><code class="hljs maxima">epochs = <span class="hljs-number">10</span><br>log_step_freq = <span class="hljs-number">30</span><br><br>dfhistory = pd.DataFrame(<span class="hljs-built_in">columns</span> = [<span class="hljs-string">&quot;epoch&quot;</span>,<span class="hljs-string">&quot;loss&quot;</span>,metric_name,<span class="hljs-string">&quot;val_loss&quot;</span>,<span class="hljs-string">&quot;val_&quot;</span>+metric_name]) <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Start Training...&quot;</span>)<br>nowtime = datetime.datetime.now().strftime(&#x27;%Y-<span class="hljs-built_in">%m</span>-%d %H:%M:%S&#x27;)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;==========&quot;</span>*<span class="hljs-number">8</span> + <span class="hljs-string">&quot;%s&quot;</span>%nowtime)<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,epochs+<span class="hljs-number">1</span>):  <br><br>    # <span class="hljs-number">1</span>，训练循环-------------------------------------------------<br>    net.train()<br>    loss_sum = <span class="hljs-number">0.0</span><br>    metric_sum = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">step</span> = <span class="hljs-number">1</span><br>    <br>    <span class="hljs-keyword">for</span> <span class="hljs-keyword">step</span>, (<span class="hljs-built_in">features</span>,<span class="hljs-built_in">labels</span>) <span class="hljs-keyword">in</span> enumerate(dl_train, <span class="hljs-number">1</span>):<br>    <br>        # 梯度清零<br>        optimizer.zero_grad()<br><br>        # 正向传播求损失<br>        predictions = net(<span class="hljs-built_in">features</span>)<br>        loss = loss_func(predictions,<span class="hljs-built_in">labels</span>)<br>        metric = metric_func(predictions,<span class="hljs-built_in">labels</span>)<br>        <br>        # 反向传播求梯度<br>        loss.backward()<br>        optimizer.<span class="hljs-keyword">step</span>()<br><br>        # 打印<span class="hljs-built_in">batch</span>级别日志<br>        loss_sum += loss.item()<br>        metric_sum += metric.item()<br>        <span class="hljs-keyword">if</span> step%log_step_freq == <span class="hljs-number">0</span>:   <br>            <span class="hljs-built_in">print</span>((<span class="hljs-string">&quot;[step = %d] loss: %.3f, &quot;</span>+metric_name+<span class="hljs-string">&quot;: %.3f&quot;</span>) <span class="hljs-symbol">%</span><br>                  (<span class="hljs-keyword">step</span>, loss_sum/<span class="hljs-keyword">step</span>, metric_sum/<span class="hljs-keyword">step</span>))<br>            <br>    # <span class="hljs-number">2</span>，验证循环-------------------------------------------------<br>    net.<span class="hljs-built_in">eval</span>()<br>    val_loss_sum = <span class="hljs-number">0.0</span><br>    val_metric_sum = <span class="hljs-number">0.0</span><br>    val_step = <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">for</span> val_step, (<span class="hljs-built_in">features</span>,<span class="hljs-built_in">labels</span>) <span class="hljs-keyword">in</span> enumerate(dl_valid, <span class="hljs-number">1</span>):<br>        # 关闭梯度计算<br>        with torch.no_grad():<br>            predictions = net(<span class="hljs-built_in">features</span>)<br>            val_loss = loss_func(predictions,<span class="hljs-built_in">labels</span>)<br>            val_metric = metric_func(predictions,<span class="hljs-built_in">labels</span>)<br>        val_loss_sum += val_loss.item()<br>        val_metric_sum += val_metric.item()<br><br>    # <span class="hljs-number">3</span>，记录日志-------------------------------------------------<br>    info = (epoch, loss_sum/<span class="hljs-keyword">step</span>, metric_sum/<span class="hljs-keyword">step</span>, <br>            val_loss_sum/val_step, val_metric_sum/val_step)<br>    dfhistory.loc[epoch-<span class="hljs-number">1</span>] = info<br>    <br>    # 打印epoch级别日志<br>    <span class="hljs-built_in">print</span>((<span class="hljs-string">&quot;\nEPOCH = %d, loss = %.3f,&quot;</span>+ metric_name + \<br>          <span class="hljs-string">&quot;  = %.3f, val_loss = %.3f, &quot;</span>+<span class="hljs-string">&quot;val_&quot;</span>+ metric_name+<span class="hljs-string">&quot; = %.3f&quot;</span>) <br>          %info)<br>    nowtime = datetime.datetime.now().strftime(&#x27;%Y-<span class="hljs-built_in">%m</span>-%d %H:%M:%S&#x27;)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\n&quot;</span>+<span class="hljs-string">&quot;==========&quot;</span>*<span class="hljs-number">8</span> + <span class="hljs-string">&quot;%s&quot;</span>%nowtime)<br>        <br><span class="hljs-built_in">print</span>(&#x27;Finished Training...&#x27;)<br></code></pre></td></tr></table></figure><h4 id="四，评估模型"><a href="#四，评估模型" class="headerlink" title="四，评估模型"></a>四，评估模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python">%matplotlib inline<br>%config InlineBackend.figure_format = <span class="hljs-string">&#x27;svg&#x27;</span><br><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_metric</span>(<span class="hljs-params">dfhistory, metric</span>):</span><br>    train_metrics = dfhistory[metric]<br>    val_metrics = dfhistory[<span class="hljs-string">&#x27;val_&#x27;</span>+metric]<br>    epochs = <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(train_metrics) + <span class="hljs-number">1</span>)<br>    plt.plot(epochs, train_metrics, <span class="hljs-string">&#x27;bo--&#x27;</span>)<br>    plt.plot(epochs, val_metrics, <span class="hljs-string">&#x27;ro-&#x27;</span>)<br>    plt.title(<span class="hljs-string">&#x27;Training and validation &#x27;</span>+ metric)<br>    plt.xlabel(<span class="hljs-string">&quot;Epochs&quot;</span>)<br>    plt.ylabel(metric)<br>    plt.legend([<span class="hljs-string">&quot;train_&quot;</span>+metric, <span class="hljs-string">&#x27;val_&#x27;</span>+metric])<br>    plt.show()<br><br>plot_metric(dfhistory,<span class="hljs-string">&quot;loss&quot;</span>)<br>plot_metric(dfhistory,<span class="hljs-string">&quot;accuracy&quot;</span>)<br></code></pre></td></tr></table></figure><h4 id="五，使用模型"><a href="#五，使用模型" class="headerlink" title="五，使用模型"></a>五，使用模型</h4><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs stylus">#预测概率<br>y_pred_probs = net(torch<span class="hljs-selector-class">.tensor</span>(x_test<span class="hljs-selector-attr">[0:10]</span>)<span class="hljs-selector-class">.float</span>())<span class="hljs-selector-class">.data</span><br>y_pred_probs<br><br>#预测类别<br>y_pred = torch<span class="hljs-selector-class">.where</span>(y_pred_probs&gt;<span class="hljs-number">0.5</span>,<br>        torch<span class="hljs-selector-class">.ones_like</span>(y_pred_probs),torch<span class="hljs-selector-class">.zeros_like</span>(y_pred_probs))<br>y_pred<br></code></pre></td></tr></table></figure><h4 id="六，保存模型"><a href="#六，保存模型" class="headerlink" title="六，保存模型"></a>六，保存模型</h4><p>Pytorch 有两种保存模型的方式，都是通过调用pickle序列化方法实现的。</p><p>第一种方法只保存模型参数。</p><p>第二种方法保存完整模型。</p><p>推荐使用第一种，第二种方法可能在切换设备和目录的时候出现各种问题。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(net.state_dict()</span></span><span class="hljs-selector-class">.keys</span>())<br></code></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"># 保存模型参数<br><br>torch.save(net.state<span class="hljs-constructor">_dict()</span>, <span class="hljs-string">&quot;./data/net_parameter.pkl&quot;</span>)<br><br>net_clone = create<span class="hljs-constructor">_net()</span><br>net_clone.load<span class="hljs-constructor">_state_dict(<span class="hljs-params">torch</span>.<span class="hljs-params">load</span>(<span class="hljs-string">&quot;./data/net_parameter.pkl&quot;</span>)</span>)<br><br>net_clone.forward(torch.tensor(x_test<span class="hljs-literal">[<span class="hljs-number">0</span>:<span class="hljs-number">10</span>]</span>).<span class="hljs-built_in">float</span><span class="hljs-literal">()</span>).data<br></code></pre></td></tr></table></figure><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记13-使用GPU训练模型</title>
    <link href="/2022/02/07/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"/>
    <url>/2022/02/07/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><p>训练过程的耗时主要来自于两个部分，一部分来自数据准备，另一部分来自参数迭代。</p><p>当数据准备过程还是模型训练时间的主要瓶颈时，我们可以使用更多进程来准备数据。</p><p>当参数迭代过程成为训练时间的主要瓶颈时，我们通常的方法是应用GPU来进行加速。</p><p>Pytorch中使用GPU加速模型非常简单，只要将模型和数据移动到GPU上。核心代码只有以下几行。</p><figure class="highlight monkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs monkey"><span class="hljs-meta"># 定义模型  </span><br>...   <br><br>device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)  <br>model.<span class="hljs-keyword">to</span>(device)<span class="hljs-meta"> # 移动模型到cuda  </span><span class="hljs-meta"></span><br><span class="hljs-meta"></span><br><span class="hljs-meta"># 训练模型  </span><br>...  <br><br>features = features.<span class="hljs-keyword">to</span>(device)<span class="hljs-meta"> # 移动数据到cuda  </span><br>labels = labels.<span class="hljs-keyword">to</span>(device)<span class="hljs-meta"> # 或者  labels = labels.cuda() <span class="hljs-meta-keyword">if</span> torch.cuda.is_available() <span class="hljs-meta-keyword">else</span> labels  </span><br>...<br></code></pre></td></tr></table></figure><p>如果要使用多个GPU训练模型，也非常简单。只需要在将模型设置为数据并行风格模型。<br>则模型移动到GPU上之后，会在每一个GPU上拷贝一个副本，并把数据平分到各个GPU上进行训练。核心代码如下。</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs maxima"># 定义模型  <br>...   <br><br><span class="hljs-keyword">if</span> torch.cuda.device_count() &gt; <span class="hljs-number">1</span>:  <br>    model = nn.DataParallel(model) # 包装为并行风格模型  <br><br># 训练模型  <br>...  <br><span class="hljs-built_in">features</span> = <span class="hljs-built_in">features</span>.to(device) # 移动数据到cuda  <br><span class="hljs-built_in">labels</span> = <span class="hljs-built_in">labels</span>.to(device) # 或者 <span class="hljs-built_in">labels</span> = <span class="hljs-built_in">labels</span>.cuda() <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-built_in">labels</span>  <br></code></pre></td></tr></table></figure><h4 id="一些和GPU有关的基本操作汇总"><a href="#一些和GPU有关的基本操作汇总" class="headerlink" title="一些和GPU有关的基本操作汇总"></a>一些和GPU有关的基本操作汇总</h4><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import torch <br><span class="hljs-keyword">from</span> torch import nn <br><br><span class="hljs-comment"># 1，查看gpu信息</span><br>if_cuda = torch.cuda.is_available()<br><span class="hljs-builtin-name">print</span>(<span class="hljs-string">&quot;if_cuda=&quot;</span>,if_cuda)<br><br>gpu_count = torch.cuda.device_count()<br><span class="hljs-builtin-name">print</span>(<span class="hljs-string">&quot;gpu_count=&quot;</span>,gpu_count)<br><br><br><span class="hljs-comment"># 2，将张量在gpu和cpu间移动</span><br>tensor = torch.rand((100,100))<br>tensor_gpu = tensor.<span class="hljs-keyword">to</span>(<span class="hljs-string">&quot;cuda:0&quot;</span>) # 或者 tensor_gpu = tensor.cuda()<br><span class="hljs-builtin-name">print</span>(tensor_gpu.device)<br><span class="hljs-builtin-name">print</span>(tensor_gpu.is_cuda)<br><br>tensor_cpu = tensor_gpu.<span class="hljs-keyword">to</span>(<span class="hljs-string">&quot;cpu&quot;</span>) # 或者 tensor_cpu = tensor_gpu.cpu() <br><span class="hljs-builtin-name">print</span>(tensor_cpu.device)<br><br><span class="hljs-comment"># 3，将模型中的全部张量移动到gpu上</span><br>net = nn.Linear(2,1)<br><span class="hljs-builtin-name">print</span>(next(net.parameters()).is_cuda)<br>net.<span class="hljs-keyword">to</span>(<span class="hljs-string">&quot;cuda:0&quot;</span>) # 将模型中的全部参数张量依次到GPU上，注意，无需重新赋值为 net = net.<span class="hljs-keyword">to</span>(<span class="hljs-string">&quot;cuda:0&quot;</span>)<br><span class="hljs-comment">#查看模型是否已经移动到GPU上</span><br><span class="hljs-builtin-name">print</span>(<span class="hljs-string">&quot;if on cuda:&quot;</span>,next(net.parameters()).is_cuda)<br><span class="hljs-comment">#print(next(net.parameters()).is_cuda)</span><br><span class="hljs-builtin-name">print</span>(next(net.parameters()).device)<br><br><span class="hljs-comment"># 4，创建支持多个gpu数据并行的模型</span><br>linear = nn.Linear(2,1)<br><span class="hljs-builtin-name">print</span>(next(linear.parameters()).device)<br><br>model = nn.DataParallel(linear)<br><span class="hljs-builtin-name">print</span>(model.device_ids)<br><span class="hljs-builtin-name">print</span>(next(model.module.parameters()).device) <br><br><span class="hljs-comment">#注意保存参数时要指定保存model.module的参数</span><br>torch.save(model.module.state_dict(), <span class="hljs-string">&quot;model_parameter.pkl&quot;</span>) <br><br>linear = nn.Linear(2,1)<br>linear.load_state_dict(torch.load(<span class="hljs-string">&quot;model_parameter.pkl&quot;</span>)) <br><br><br><span class="hljs-comment"># 5，清空cuda缓存</span><br><br><span class="hljs-comment"># 该方法在cuda超内存时十分有用</span><br>torch.cuda.empty_cache()<br></code></pre></td></tr></table></figure><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记12-训练模型的3种方法</title>
    <link href="/2022/02/07/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/"/>
    <url>/2022/02/07/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><h4 id="〇，准备数据"><a href="#〇，准备数据" class="headerlink" title="〇，准备数据"></a>〇，准备数据</h4><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import torch <br><span class="hljs-keyword">from</span> torch import nn <br><span class="hljs-keyword">from</span> torchkeras import summary,Model <br><br>import torchvision <br><span class="hljs-keyword">from</span> torchvision import transforms<br><br>transform = transforms.Compose([transforms.ToTensor()])<br><br>ds_train = torchvision.datasets.MNIST(<span class="hljs-attribute">root</span>=<span class="hljs-string">&quot;/home/kesci/input/data6936/data/minist/&quot;</span>,train=True,download=True,transform=transform)<br>ds_valid = torchvision.datasets.MNIST(<span class="hljs-attribute">root</span>=<span class="hljs-string">&quot;/home/kesci/input/data6936/data/minist/&quot;</span>,train=False,download=True,transform=transform)<br><br>dl_train =  torch.utils.data.DataLoader(ds_train, <span class="hljs-attribute">batch_size</span>=128, <span class="hljs-attribute">shuffle</span>=<span class="hljs-literal">True</span>, <span class="hljs-attribute">num_workers</span>=4)<br>dl_valid =  torch.utils.data.DataLoader(ds_valid, <span class="hljs-attribute">batch_size</span>=128, <span class="hljs-attribute">shuffle</span>=<span class="hljs-literal">False</span>, <span class="hljs-attribute">num_workers</span>=4)<br><br><span class="hljs-builtin-name">print</span>(len(ds_train))<br><span class="hljs-builtin-name">print</span>(len(ds_valid))<br></code></pre></td></tr></table></figure><figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs sas"><span class="hljs-name">%matplotlib</span> inline<br><span class="hljs-name">%config</span> InlineBackend.figure_format = <span class="hljs-string">&#x27;svg&#x27;</span><br><br>#查看部分样本<br><span class="hljs-meta">from</span> matplotlib import pyplot <span class="hljs-meta">as</span> plt <br><br>plt.figure(figsize=(8,8)) <br>for i <span class="hljs-meta">in</span><span class="hljs-meta"> range(</span>9):<br>    img,<span class="hljs-meta">label</span> = ds_train[i]<br>    img = torch.squeeze(img)<br>    ax=plt.subplot(3,3,i+1)<br>    ax.imshow(img.numpy())<br>    ax.set_title(<span class="hljs-string">&quot;label = %d&quot;</span><span class="hljs-built_in">%label</span>)<br>    ax.set_xticks([])<br>    ax.set_yticks([]) <br>plt.show()<br></code></pre></td></tr></table></figure><h4 id="一，脚本风格"><a href="#一，脚本风格" class="headerlink" title="一，脚本风格"></a>一，脚本风格</h4><p>脚本风格的训练循环最为常见。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">net = nn.<span class="hljs-constructor">Sequential()</span><br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;conv1&quot;</span>,<span class="hljs-params">nn</span>.Conv2d(<span class="hljs-params">in_channels</span>=1,<span class="hljs-params">out_channels</span>=32,<span class="hljs-params">kernel_size</span> = 3)</span>)<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;pool1&quot;</span>,<span class="hljs-params">nn</span>.MaxPool2d(<span class="hljs-params">kernel_size</span> = 2,<span class="hljs-params">stride</span> = 2)</span>)<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;conv2&quot;</span>,<span class="hljs-params">nn</span>.Conv2d(<span class="hljs-params">in_channels</span>=32,<span class="hljs-params">out_channels</span>=64,<span class="hljs-params">kernel_size</span> = 5)</span>)<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;pool2&quot;</span>,<span class="hljs-params">nn</span>.MaxPool2d(<span class="hljs-params">kernel_size</span> = 2,<span class="hljs-params">stride</span> = 2)</span>)<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;dropout&quot;</span>,<span class="hljs-params">nn</span>.Dropout2d(<span class="hljs-params">p</span> = 0.1)</span>)<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;adaptive_pool&quot;</span>,<span class="hljs-params">nn</span>.AdaptiveMaxPool2d((1,1)</span>))<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;flatten&quot;</span>,<span class="hljs-params">nn</span>.Flatten()</span>)<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;linear1&quot;</span>,<span class="hljs-params">nn</span>.Linear(64,32)</span>)<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;relu&quot;</span>,<span class="hljs-params">nn</span>.ReLU()</span>)<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;linear2&quot;</span>,<span class="hljs-params">nn</span>.Linear(32,10)</span>)<br><br>print(net)<br></code></pre></td></tr></table></figure><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> datetime<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd <br><span class="hljs-title">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<br><br><span class="hljs-title">def</span> accuracy(y_pred,y_true):<br>    y_pred_cls = torch.argmax(nn.<span class="hljs-type">Softmax</span>(dim=<span class="hljs-number">1</span>)(y_pred),dim=<span class="hljs-number">1</span>).<span class="hljs-class"><span class="hljs-keyword">data</span></span><br>    return accuracy_score(y_true,y_pred_cls)<br><br><span class="hljs-title">loss_func</span> = nn.<span class="hljs-type">CrossEntropyLoss</span>()<br><span class="hljs-title">optimizer</span> = torch.optim.<span class="hljs-type">Adam</span>(params=net.parameters(),lr = <span class="hljs-number">0.01</span>)<br><span class="hljs-title">metric_func</span> = accuracy<br><span class="hljs-title">metric_name</span> = <span class="hljs-string">&quot;accuracy&quot;</span><br></code></pre></td></tr></table></figure><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><code class="hljs maxima">epochs = <span class="hljs-number">3</span><br>log_step_freq = <span class="hljs-number">100</span><br><br>dfhistory = pd.DataFrame(<span class="hljs-built_in">columns</span> = [<span class="hljs-string">&quot;epoch&quot;</span>,<span class="hljs-string">&quot;loss&quot;</span>,metric_name,<span class="hljs-string">&quot;val_loss&quot;</span>,<span class="hljs-string">&quot;val_&quot;</span>+metric_name]) <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Start Training...&quot;</span>)<br>nowtime = datetime.datetime.now().strftime(&#x27;%Y-<span class="hljs-built_in">%m</span>-%d %H:%M:%S&#x27;)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;==========&quot;</span>*<span class="hljs-number">8</span> + <span class="hljs-string">&quot;%s&quot;</span>%nowtime)<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,epochs+<span class="hljs-number">1</span>):  <br><br>    # <span class="hljs-number">1</span>，训练循环-------------------------------------------------<br>    net.train()<br>    loss_sum = <span class="hljs-number">0.0</span><br>    metric_sum = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">step</span> = <span class="hljs-number">1</span><br>    <br>    <span class="hljs-keyword">for</span> <span class="hljs-keyword">step</span>, (<span class="hljs-built_in">features</span>,<span class="hljs-built_in">labels</span>) <span class="hljs-keyword">in</span> enumerate(dl_train, <span class="hljs-number">1</span>):<br>    <br>        # 梯度清零<br>        optimizer.zero_grad()<br><br>        # 正向传播求损失<br>        predictions = net(<span class="hljs-built_in">features</span>)<br>        loss = loss_func(predictions,<span class="hljs-built_in">labels</span>)<br>        metric = metric_func(predictions,<span class="hljs-built_in">labels</span>)<br>        <br>        # 反向传播求梯度<br>        loss.backward()<br>        optimizer.<span class="hljs-keyword">step</span>()<br><br>        # 打印<span class="hljs-built_in">batch</span>级别日志<br>        loss_sum += loss.item()<br>        metric_sum += metric.item()<br>        <span class="hljs-keyword">if</span> step%log_step_freq == <span class="hljs-number">0</span>:   <br>            <span class="hljs-built_in">print</span>((<span class="hljs-string">&quot;[step = %d] loss: %.3f, &quot;</span>+metric_name+<span class="hljs-string">&quot;: %.3f&quot;</span>) <span class="hljs-symbol">%</span><br>                  (<span class="hljs-keyword">step</span>, loss_sum/<span class="hljs-keyword">step</span>, metric_sum/<span class="hljs-keyword">step</span>))<br>            <br>    # <span class="hljs-number">2</span>，验证循环-------------------------------------------------<br>    net.<span class="hljs-built_in">eval</span>()<br>    val_loss_sum = <span class="hljs-number">0.0</span><br>    val_metric_sum = <span class="hljs-number">0.0</span><br>    val_step = <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">for</span> val_step, (<span class="hljs-built_in">features</span>,<span class="hljs-built_in">labels</span>) <span class="hljs-keyword">in</span> enumerate(dl_valid, <span class="hljs-number">1</span>):<br>        with torch.no_grad():<br>            predictions = net(<span class="hljs-built_in">features</span>)<br>            val_loss = loss_func(predictions,<span class="hljs-built_in">labels</span>)<br>            val_metric = metric_func(predictions,<span class="hljs-built_in">labels</span>)<br><br>        val_loss_sum += val_loss.item()<br>        val_metric_sum += val_metric.item()<br><br>    # <span class="hljs-number">3</span>，记录日志-------------------------------------------------<br>    info = (epoch, loss_sum/<span class="hljs-keyword">step</span>, metric_sum/<span class="hljs-keyword">step</span>, <br>            val_loss_sum/val_step, val_metric_sum/val_step)<br>    dfhistory.loc[epoch-<span class="hljs-number">1</span>] = info<br>    <br>    # 打印epoch级别日志<br>    <span class="hljs-built_in">print</span>((<span class="hljs-string">&quot;\nEPOCH = %d, loss = %.3f,&quot;</span>+ metric_name + \<br>          <span class="hljs-string">&quot;  = %.3f, val_loss = %.3f, &quot;</span>+<span class="hljs-string">&quot;val_&quot;</span>+ metric_name+<span class="hljs-string">&quot; = %.3f&quot;</span>) <br>          %info)<br>    nowtime = datetime.datetime.now().strftime(&#x27;%Y-<span class="hljs-built_in">%m</span>-%d %H:%M:%S&#x27;)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\n&quot;</span>+<span class="hljs-string">&quot;==========&quot;</span>*<span class="hljs-number">8</span> + <span class="hljs-string">&quot;%s&quot;</span>%nowtime)<br>        <br><span class="hljs-built_in">print</span>(&#x27;Finished Training...&#x27;)<br></code></pre></td></tr></table></figure><h4 id="二，函数风格"><a href="#二，函数风格" class="headerlink" title="二，函数风格"></a>二，函数风格</h4><p>该风格在脚本形式上作了简单的函数封装。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-type">Net</span>(<span class="hljs-title">nn</span>.<span class="hljs-type">Module</span>):</span><br><span class="hljs-class">    def __init__(<span class="hljs-title">self</span>):</span><br><span class="hljs-class">        super(<span class="hljs-type">Net</span>, <span class="hljs-title">self</span>).__init__()</span><br><span class="hljs-class">        self.layers = nn.<span class="hljs-type">ModuleList</span>([</span><br><span class="hljs-class">            <span class="hljs-title">nn</span>.<span class="hljs-type">Conv2d</span>(<span class="hljs-title">in_channels</span>=1,<span class="hljs-title">out_channels</span>=32,<span class="hljs-title">kernel_size</span> = 3),</span><br><span class="hljs-class">            nn.<span class="hljs-type">MaxPool2d</span>(<span class="hljs-title">kernel_size</span> = 2,<span class="hljs-title">stride</span> = 2),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Conv2d</span>(<span class="hljs-title">in_channels</span>=32,<span class="hljs-title">out_channels</span>=64,<span class="hljs-title">kernel_size</span> = 5),</span><br><span class="hljs-class">            nn.<span class="hljs-type">MaxPool2d</span>(<span class="hljs-title">kernel_size</span> = 2,<span class="hljs-title">stride</span> = 2),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Dropout2d</span>(<span class="hljs-title">p</span> = 0.1),</span><br><span class="hljs-class">            nn.<span class="hljs-type">AdaptiveMaxPool2d</span>((1,1)),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Flatten</span>(),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Linear</span>(64,32),</span><br><span class="hljs-class">            nn.<span class="hljs-type">ReLU</span>(),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Linear</span>(32,10)]</span><br><span class="hljs-class">        )</span><br><span class="hljs-class">    def forward(<span class="hljs-title">self</span>,<span class="hljs-title">x</span>):</span><br><span class="hljs-class">        for layer in self.layers:</span><br><span class="hljs-class">            x = layer(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        return x</span><br><span class="hljs-class">net = <span class="hljs-type">Net</span>()</span><br><span class="hljs-class">print(<span class="hljs-title">net</span>)</span><br></code></pre></td></tr></table></figure><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> datetime<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd <br><span class="hljs-title">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<br><br><span class="hljs-title">def</span> accuracy(y_pred,y_true):<br>    y_pred_cls = torch.argmax(nn.<span class="hljs-type">Softmax</span>(dim=<span class="hljs-number">1</span>)(y_pred),dim=<span class="hljs-number">1</span>).<span class="hljs-class"><span class="hljs-keyword">data</span></span><br>    return accuracy_score(y_true,y_pred_cls)<br><br><span class="hljs-title">model</span> = net<br><span class="hljs-title">model</span>.optimizer = torch.optim.<span class="hljs-type">SGD</span>(model.parameters(),lr = <span class="hljs-number">0.01</span>)<br><span class="hljs-title">model</span>.loss_func = nn.<span class="hljs-type">CrossEntropyLoss</span>()<br><span class="hljs-title">model</span>.metric_func = accuracy<br><span class="hljs-title">model</span>.metric_name = <span class="hljs-string">&quot;accuracy&quot;</span><br></code></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">def train<span class="hljs-constructor">_step(<span class="hljs-params">model</span>,<span class="hljs-params">features</span>,<span class="hljs-params">labels</span>)</span>:<br>    <br>    # 训练模式，dropout层发生作用<br>    model.train<span class="hljs-literal">()</span><br>    <br>    # 梯度清零<br>    model.optimizer.zero<span class="hljs-constructor">_grad()</span><br>    <br>    # 正向传播求损失<br>    predictions = model(features)<br>    loss = model.loss<span class="hljs-constructor">_func(<span class="hljs-params">predictions</span>,<span class="hljs-params">labels</span>)</span><br>    metric = model.metric<span class="hljs-constructor">_func(<span class="hljs-params">predictions</span>,<span class="hljs-params">labels</span>)</span><br><br>    # 反向传播求梯度<br>    loss.backward<span class="hljs-literal">()</span><br>    model.optimizer.step<span class="hljs-literal">()</span><br><br>    return loss.item<span class="hljs-literal">()</span>,metric.item<span class="hljs-literal">()</span><br><br>@torch.no<span class="hljs-constructor">_grad()</span><br>def valid<span class="hljs-constructor">_step(<span class="hljs-params">model</span>,<span class="hljs-params">features</span>,<span class="hljs-params">labels</span>)</span>:<br>    <br>    # 预测模式，dropout层不发生作用<br>    model.eval<span class="hljs-literal">()</span><br>    <br>    predictions = model(features)<br>    loss = model.loss<span class="hljs-constructor">_func(<span class="hljs-params">predictions</span>,<span class="hljs-params">labels</span>)</span><br>    metric = model.metric<span class="hljs-constructor">_func(<span class="hljs-params">predictions</span>,<span class="hljs-params">labels</span>)</span><br>    <br>    return loss.item<span class="hljs-literal">()</span>, metric.item<span class="hljs-literal">()</span><br><br><br># 测试train_step效果<br>features,labels = next(iter(dl_train))<br>train<span class="hljs-constructor">_step(<span class="hljs-params">model</span>,<span class="hljs-params">features</span>,<span class="hljs-params">labels</span>)</span><br></code></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs routeros">def train_model(model,epochs,dl_train,dl_valid,log_step_freq):<br><br>    metric_name = model.metric_name<br>    dfhistory = pd.DataFrame(columns = [<span class="hljs-string">&quot;epoch&quot;</span>,<span class="hljs-string">&quot;loss&quot;</span>,metric_name,<span class="hljs-string">&quot;val_loss&quot;</span>,<span class="hljs-string">&quot;val_&quot;</span>+metric_name]) <br>    <span class="hljs-builtin-name">print</span>(<span class="hljs-string">&quot;Start Training...&quot;</span>)<br>    nowtime = datetime.datetime.now().strftime(<span class="hljs-string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)<br>    <span class="hljs-builtin-name">print</span>(<span class="hljs-string">&quot;==========&quot;</span><span class="hljs-number">*8</span> + <span class="hljs-string">&quot;%s&quot;</span>%nowtime)<br><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(1,epochs+1):  <br><br>        # 1，训练循环-------------------------------------------------<br>        loss_sum = 0.0<br>        metric_sum = 0.0<br>        <span class="hljs-keyword">step</span> = 1<br><br>        <span class="hljs-keyword">for</span> <span class="hljs-keyword">step</span>, (features,labels) <span class="hljs-keyword">in</span> enumerate(dl_train, 1):<br><br>            loss,metric = train_step(model,features,labels)<br><br>            # 打印batch级别日志<br>            loss_sum += loss<br>            metric_sum += metric<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">step</span>%log_step_freq == 0:   <br>                <span class="hljs-builtin-name">print</span>((<span class="hljs-string">&quot;[step = %d] loss: %.3f, &quot;</span>+metric_name+<span class="hljs-string">&quot;: %.3f&quot;</span>) %<br>                      (<span class="hljs-keyword">step</span>, loss_sum/<span class="hljs-keyword">step</span>, metric_sum/<span class="hljs-keyword">step</span>))<br><br>        # 2，验证循环-------------------------------------------------<br>        val_loss_sum = 0.0<br>        val_metric_sum = 0.0<br>        val_step = 1<br><br>        <span class="hljs-keyword">for</span> val_step, (features,labels) <span class="hljs-keyword">in</span> enumerate(dl_valid, 1):<br><br>            val_loss,val_metric = valid_step(model,features,labels)<br><br>            val_loss_sum += val_loss<br>            val_metric_sum += val_metric<br><br>        # 3，记录日志-------------------------------------------------<br>        <span class="hljs-builtin-name">info</span> = (epoch, loss_sum/<span class="hljs-keyword">step</span>, metric_sum/<span class="hljs-keyword">step</span>, <br>                val_loss_sum/val_step, val_metric_sum/val_step)<br>        dfhistory.loc[epoch-1] = <span class="hljs-builtin-name">info</span><br><br>        # 打印epoch级别日志<br>        <span class="hljs-builtin-name">print</span>((<span class="hljs-string">&quot;\nEPOCH = %d, loss = %.3f,&quot;</span>+ metric_name + \<br>              <span class="hljs-string">&quot;  = %.3f, val_loss = %.3f, &quot;</span>+<span class="hljs-string">&quot;val_&quot;</span>+ metric_name+<span class="hljs-string">&quot; = %.3f&quot;</span>) <br>              %info)<br>        nowtime = datetime.datetime.now().strftime(<span class="hljs-string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)<br>        <span class="hljs-builtin-name">print</span>(<span class="hljs-string">&quot;\n&quot;</span>+<span class="hljs-string">&quot;==========&quot;</span><span class="hljs-number">*8</span> + <span class="hljs-string">&quot;%s&quot;</span>%nowtime)<br><br>    <span class="hljs-builtin-name">print</span>(<span class="hljs-string">&#x27;Finished Training...&#x27;</span>)<br>    return dfhistory<br></code></pre></td></tr></table></figure><h4 id="三，类风格"><a href="#三，类风格" class="headerlink" title="三，类风格"></a>三，类风格</h4><p>此处使用torchkeras中定义的模型接口构建模型，并调用compile方法和fit方法训练模型。</p><p>使用该形式训练模型非常简洁明了。推荐使用该形式。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> torchkeras <br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-type">CnnModel</span>(<span class="hljs-title">nn</span>.<span class="hljs-type">Module</span>):</span><br><span class="hljs-class">    def __init__(<span class="hljs-title">self</span>):</span><br><span class="hljs-class">        super().__init__()</span><br><span class="hljs-class">        self.layers = nn.<span class="hljs-type">ModuleList</span>([</span><br><span class="hljs-class">            <span class="hljs-title">nn</span>.<span class="hljs-type">Conv2d</span>(<span class="hljs-title">in_channels</span>=1,<span class="hljs-title">out_channels</span>=32,<span class="hljs-title">kernel_size</span> = 3),</span><br><span class="hljs-class">            nn.<span class="hljs-type">MaxPool2d</span>(<span class="hljs-title">kernel_size</span> = 2,<span class="hljs-title">stride</span> = 2),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Conv2d</span>(<span class="hljs-title">in_channels</span>=32,<span class="hljs-title">out_channels</span>=64,<span class="hljs-title">kernel_size</span> = 5),</span><br><span class="hljs-class">            nn.<span class="hljs-type">MaxPool2d</span>(<span class="hljs-title">kernel_size</span> = 2,<span class="hljs-title">stride</span> = 2),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Dropout2d</span>(<span class="hljs-title">p</span> = 0.1),</span><br><span class="hljs-class">            nn.<span class="hljs-type">AdaptiveMaxPool2d</span>((1,1)),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Flatten</span>(),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Linear</span>(64,32),</span><br><span class="hljs-class">            nn.<span class="hljs-type">ReLU</span>(),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Linear</span>(32,10)]</span><br><span class="hljs-class">        )</span><br><span class="hljs-class">    def forward(<span class="hljs-title">self</span>,<span class="hljs-title">x</span>):</span><br><span class="hljs-class">        for layer in self.layers:</span><br><span class="hljs-class">            x = layer(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        return x</span><br><span class="hljs-class">model = torchkeras.<span class="hljs-type">Model</span>(<span class="hljs-type">CnnModel</span>())</span><br><span class="hljs-class">print(<span class="hljs-title">model</span>)</span><br></code></pre></td></tr></table></figure><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-tag">from</span> sklearn<span class="hljs-selector-class">.metrics</span> import accuracy_score<br><br>def accuracy(y_pred,y_true):<br>    y_pred_cls = torch.<span class="hljs-built_in">argmax</span>(nn.<span class="hljs-built_in">Softmax</span>(dim=<span class="hljs-number">1</span>)(y_pred),dim=<span class="hljs-number">1</span>).data<br>    return <span class="hljs-built_in">accuracy_score</span>(y_true.<span class="hljs-built_in">numpy</span>(),y_pred_cls.<span class="hljs-built_in">numpy</span>())<br><br>model.<span class="hljs-built_in">compile</span>(loss_func = nn.<span class="hljs-built_in">CrossEntropyLoss</span>(),<br>             optimizer= torch.optim.<span class="hljs-built_in">Adam</span>(model.<span class="hljs-built_in">parameters</span>(),lr = <span class="hljs-number">0.02</span>),<br>             metrics_dict=&#123;<span class="hljs-string">&quot;accuracy&quot;</span>:accuracy&#125;)<br></code></pre></td></tr></table></figure><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-attr">dfhistory</span> = model.fit(<span class="hljs-number">3</span>,<span class="hljs-attr">dl_train</span> = dl_train, <span class="hljs-attr">dl_val=dl_valid,</span> <span class="hljs-attr">log_step_freq=100)</span> <br></code></pre></td></tr></table></figure><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记11-构建模型的3种方法</title>
    <link href="/2022/02/07/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/"/>
    <url>/2022/02/07/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><p>可以使用以下3种方式构建模型：</p><ul><li><p>1，继承nn.Module基类构建自定义模型。</p></li><li><p>2，使用nn.Sequential按层顺序构建模型。</p></li><li><p>3，继承nn.Module基类构建模型并辅助应用模型容器进行封装(nn.Sequential,nn.ModuleList,nn.ModuleDict)。</p></li></ul><p>其中 第1种方式最为常见，第2种方式最简单，第3种方式最为灵活也较为复杂。</p><p>推荐使用第1种方式构建模型。</p><h4 id="一，继承nn-Module基类构建自定义模型"><a href="#一，继承nn-Module基类构建自定义模型" class="headerlink" title="一，继承nn.Module基类构建自定义模型"></a>一，继承nn.Module基类构建自定义模型</h4><p>以下是继承nn.Module基类构建自定义模型的一个范例。模型中的用到的层一般在__init__函数中定义，然后在forward方法中定义模型的正向传播逻辑。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> torch <br><span class="hljs-title">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-title">from</span> torchkeras <span class="hljs-keyword">import</span> summary<br><span class="hljs-class"></span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-type">Net</span>(<span class="hljs-title">nn</span>.<span class="hljs-type">Module</span>):</span><br><span class="hljs-class">    </span><br><span class="hljs-class">    def __init__(<span class="hljs-title">self</span>):</span><br><span class="hljs-class">        super(<span class="hljs-type">Net</span>, <span class="hljs-title">self</span>).__init__()</span><br><span class="hljs-class">        self.conv1 = nn.<span class="hljs-type">Conv2d</span>(<span class="hljs-title">in_channels</span>=3,<span class="hljs-title">out_channels</span>=32,<span class="hljs-title">kernel_size</span> = 3)</span><br><span class="hljs-class">        self.pool1 = nn.<span class="hljs-type">MaxPool2d</span>(<span class="hljs-title">kernel_size</span> = 2,<span class="hljs-title">stride</span> = 2)</span><br><span class="hljs-class">        self.conv2 = nn.<span class="hljs-type">Conv2d</span>(<span class="hljs-title">in_channels</span>=32,<span class="hljs-title">out_channels</span>=64,<span class="hljs-title">kernel_size</span> = 5)</span><br><span class="hljs-class">        self.pool2 = nn.<span class="hljs-type">MaxPool2d</span>(<span class="hljs-title">kernel_size</span> = 2,<span class="hljs-title">stride</span> = 2)</span><br><span class="hljs-class">        self.dropout = nn.<span class="hljs-type">Dropout2d</span>(<span class="hljs-title">p</span> = 0.1)</span><br><span class="hljs-class">        self.adaptive_pool = nn.<span class="hljs-type">AdaptiveMaxPool2d</span>((1,1))</span><br><span class="hljs-class">        self.flatten = nn.<span class="hljs-type">Flatten</span>()</span><br><span class="hljs-class">        self.linear1 = nn.<span class="hljs-type">Linear</span>(64,32)</span><br><span class="hljs-class">        self.relu = nn.<span class="hljs-type">ReLU</span>()</span><br><span class="hljs-class">        self.linear2 = nn.<span class="hljs-type">Linear</span>(32,1)</span><br><span class="hljs-class">        self.sigmoid = nn.<span class="hljs-type">Sigmoid</span>()</span><br><span class="hljs-class">        </span><br><span class="hljs-class">    def forward(<span class="hljs-title">self</span>,<span class="hljs-title">x</span>):</span><br><span class="hljs-class">        x = self.conv1(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        x = self.pool1(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        x = self.conv2(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        x = self.pool2(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        x = self.dropout(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        x = self.adaptive_pool(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        x = self.flatten(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        x = self.linear1(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        x = self.relu(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        x = self.linear2(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        y = self.sigmoid(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        return y</span><br><span class="hljs-class">        </span><br><span class="hljs-class">net = <span class="hljs-type">Net</span>()</span><br><span class="hljs-class">print(<span class="hljs-title">net</span>)</span><br></code></pre></td></tr></table></figure><h4 id="二，使用nn-Sequential按层顺序构建模型"><a href="#二，使用nn-Sequential按层顺序构建模型" class="headerlink" title="二，使用nn.Sequential按层顺序构建模型"></a>二，使用nn.Sequential按层顺序构建模型</h4><p>使用nn.Sequential按层顺序构建模型无需定义forward方法。仅仅适合于简单的模型。</p><p>以下是使用nn.Sequential搭建模型的一些等价方法。</p><h5 id="1，利用add-module方法"><a href="#1，利用add-module方法" class="headerlink" title="1，利用add_module方法"></a>1，利用add_module方法</h5><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">net = nn.<span class="hljs-constructor">Sequential()</span><br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;conv1&quot;</span>,<span class="hljs-params">nn</span>.Conv2d(<span class="hljs-params">in_channels</span>=3,<span class="hljs-params">out_channels</span>=32,<span class="hljs-params">kernel_size</span> = 3)</span>)<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;pool1&quot;</span>,<span class="hljs-params">nn</span>.MaxPool2d(<span class="hljs-params">kernel_size</span> = 2,<span class="hljs-params">stride</span> = 2)</span>)<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;conv2&quot;</span>,<span class="hljs-params">nn</span>.Conv2d(<span class="hljs-params">in_channels</span>=32,<span class="hljs-params">out_channels</span>=64,<span class="hljs-params">kernel_size</span> = 5)</span>)<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;pool2&quot;</span>,<span class="hljs-params">nn</span>.MaxPool2d(<span class="hljs-params">kernel_size</span> = 2,<span class="hljs-params">stride</span> = 2)</span>)<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;dropout&quot;</span>,<span class="hljs-params">nn</span>.Dropout2d(<span class="hljs-params">p</span> = 0.1)</span>)<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;adaptive_pool&quot;</span>,<span class="hljs-params">nn</span>.AdaptiveMaxPool2d((1,1)</span>))<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;flatten&quot;</span>,<span class="hljs-params">nn</span>.Flatten()</span>)<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;linear1&quot;</span>,<span class="hljs-params">nn</span>.Linear(64,32)</span>)<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;relu&quot;</span>,<span class="hljs-params">nn</span>.ReLU()</span>)<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;linear2&quot;</span>,<span class="hljs-params">nn</span>.Linear(32,1)</span>)<br>net.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;sigmoid&quot;</span>,<span class="hljs-params">nn</span>.Sigmoid()</span>)<br><br>print(net)<br></code></pre></td></tr></table></figure><h5 id="2，利用变长参数"><a href="#2，利用变长参数" class="headerlink" title="2，利用变长参数"></a>2，利用变长参数</h5><p>这种方式构建时不能给每个层指定名称。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs stylus">net = nn<span class="hljs-selector-class">.Sequential</span>(<br>    nn<span class="hljs-selector-class">.Conv2d</span>(in_channels=<span class="hljs-number">3</span>,out_channels=<span class="hljs-number">32</span>,kernel_size = <span class="hljs-number">3</span>),<br>    nn<span class="hljs-selector-class">.MaxPool2d</span>(kernel_size = <span class="hljs-number">2</span>,stride = <span class="hljs-number">2</span>),<br>    nn<span class="hljs-selector-class">.Conv2d</span>(in_channels=<span class="hljs-number">32</span>,out_channels=<span class="hljs-number">64</span>,kernel_size = <span class="hljs-number">5</span>),<br>    nn<span class="hljs-selector-class">.MaxPool2d</span>(kernel_size = <span class="hljs-number">2</span>,stride = <span class="hljs-number">2</span>),<br>    nn<span class="hljs-selector-class">.Dropout2d</span>(<span class="hljs-selector-tag">p</span> = <span class="hljs-number">0.1</span>),<br>    nn<span class="hljs-selector-class">.AdaptiveMaxPool2d</span>((<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)),<br>    nn<span class="hljs-selector-class">.Flatten</span>(),<br>    nn<span class="hljs-selector-class">.Linear</span>(<span class="hljs-number">64</span>,<span class="hljs-number">32</span>),<br>    nn<span class="hljs-selector-class">.ReLU</span>(),<br>    nn<span class="hljs-selector-class">.Linear</span>(<span class="hljs-number">32</span>,<span class="hljs-number">1</span>),<br>    nn<span class="hljs-selector-class">.Sigmoid</span>()<br>)<br><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(net)</span></span><br></code></pre></td></tr></table></figure><h5 id="3，利用OrderedDict"><a href="#3，利用OrderedDict" class="headerlink" title="3，利用OrderedDict"></a>3，利用OrderedDict</h5><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs vim">from collections import OrderedDict<br><br>net = <span class="hljs-keyword">nn</span>.Sequential(OrderedDict(<br>          [(<span class="hljs-string">&quot;conv1&quot;</span>,<span class="hljs-keyword">nn</span>.Conv2d(in_channels=<span class="hljs-number">3</span>,out_channels=<span class="hljs-number">32</span>,kernel_size = <span class="hljs-number">3</span>)),<br>            (<span class="hljs-string">&quot;pool1&quot;</span>,<span class="hljs-keyword">nn</span>.MaxPool2d(kernel_size = <span class="hljs-number">2</span>,stride = <span class="hljs-number">2</span>)),<br>            (<span class="hljs-string">&quot;conv2&quot;</span>,<span class="hljs-keyword">nn</span>.Conv2d(in_channels=<span class="hljs-number">32</span>,out_channels=<span class="hljs-number">64</span>,kernel_size = <span class="hljs-number">5</span>)),<br>            (<span class="hljs-string">&quot;pool2&quot;</span>,<span class="hljs-keyword">nn</span>.MaxPool2d(kernel_size = <span class="hljs-number">2</span>,stride = <span class="hljs-number">2</span>)),<br>            (<span class="hljs-string">&quot;dropout&quot;</span>,<span class="hljs-keyword">nn</span>.Dropout2d(<span class="hljs-keyword">p</span> = <span class="hljs-number">0.1</span>)),<br>            (<span class="hljs-string">&quot;adaptive_pool&quot;</span>,<span class="hljs-keyword">nn</span>.AdaptiveMaxPool2d((<span class="hljs-number">1</span>,<span class="hljs-number">1</span>))),<br>            (<span class="hljs-string">&quot;flatten&quot;</span>,<span class="hljs-keyword">nn</span>.Flatten()),<br>            (<span class="hljs-string">&quot;linear1&quot;</span>,<span class="hljs-keyword">nn</span>.Linear(<span class="hljs-number">64</span>,<span class="hljs-number">32</span>)),<br>            (<span class="hljs-string">&quot;relu&quot;</span>,<span class="hljs-keyword">nn</span>.ReLU()),<br>            (<span class="hljs-string">&quot;linear2&quot;</span>,<span class="hljs-keyword">nn</span>.Linear(<span class="hljs-number">32</span>,<span class="hljs-number">1</span>)),<br>            (<span class="hljs-string">&quot;sigmoid&quot;</span>,<span class="hljs-keyword">nn</span>.Sigmoid())<br>          ])<br>        )<br><span class="hljs-keyword">print</span>(net)<br></code></pre></td></tr></table></figure><h4 id="三，继承nn-Module基类构建模型并辅助应用模型容器进行封装"><a href="#三，继承nn-Module基类构建模型并辅助应用模型容器进行封装" class="headerlink" title="三，继承nn.Module基类构建模型并辅助应用模型容器进行封装"></a>三，继承nn.Module基类构建模型并辅助应用模型容器进行封装</h4><p>当模型的结构比较复杂时，我们可以应用模型容器(nn.Sequential,nn.ModuleList,nn.ModuleDict)对模型的部分结构进行封装。</p><p>这样做会让模型整体更加有层次感，有时候也能减少代码量。</p><p>注意，在下面的范例中我们每次仅仅使用一种模型容器，但实际上这些模型容器的使用是非常灵活的，可以在一个模型中任意组合任意嵌套使用。</p><h5 id="1，nn-Sequential作为模型容器"><a href="#1，nn-Sequential作为模型容器" class="headerlink" title="1，nn.Sequential作为模型容器"></a>1，nn.Sequential作为模型容器</h5><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-type">Net</span>(<span class="hljs-title">nn</span>.<span class="hljs-type">Module</span>):</span><br><span class="hljs-class">    </span><br><span class="hljs-class">    def __init__(<span class="hljs-title">self</span>):</span><br><span class="hljs-class">        super(<span class="hljs-type">Net</span>, <span class="hljs-title">self</span>).__init__()</span><br><span class="hljs-class">        self.conv = nn.<span class="hljs-type">Sequential</span>(</span><br><span class="hljs-class">            <span class="hljs-title">nn</span>.<span class="hljs-type">Conv2d</span>(<span class="hljs-title">in_channels</span>=3,<span class="hljs-title">out_channels</span>=32,<span class="hljs-title">kernel_size</span> = 3),</span><br><span class="hljs-class">            nn.<span class="hljs-type">MaxPool2d</span>(<span class="hljs-title">kernel_size</span> = 2,<span class="hljs-title">stride</span> = 2),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Conv2d</span>(<span class="hljs-title">in_channels</span>=32,<span class="hljs-title">out_channels</span>=64,<span class="hljs-title">kernel_size</span> = 5),</span><br><span class="hljs-class">            nn.<span class="hljs-type">MaxPool2d</span>(<span class="hljs-title">kernel_size</span> = 2,<span class="hljs-title">stride</span> = 2),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Dropout2d</span>(<span class="hljs-title">p</span> = 0.1),</span><br><span class="hljs-class">            nn.<span class="hljs-type">AdaptiveMaxPool2d</span>((1,1))</span><br><span class="hljs-class">        )</span><br><span class="hljs-class">        self.dense = nn.<span class="hljs-type">Sequential</span>(</span><br><span class="hljs-class">            <span class="hljs-title">nn</span>.<span class="hljs-type">Flatten</span>(),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Linear</span>(64,32),</span><br><span class="hljs-class">            nn.<span class="hljs-type">ReLU</span>(),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Linear</span>(32,1),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Sigmoid</span>()</span><br><span class="hljs-class">        )</span><br><span class="hljs-class">    def forward(<span class="hljs-title">self</span>,<span class="hljs-title">x</span>):</span><br><span class="hljs-class">        x = self.conv(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        y = self.dense(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        return y </span><br><span class="hljs-class">    </span><br><span class="hljs-class">net = <span class="hljs-type">Net</span>()</span><br><span class="hljs-class">print(<span class="hljs-title">net</span>)</span><br></code></pre></td></tr></table></figure><h5 id="2，nn-ModuleList作为模型容器"><a href="#2，nn-ModuleList作为模型容器" class="headerlink" title="2，nn.ModuleList作为模型容器"></a>2，nn.ModuleList作为模型容器</h5><p>注意下面中的ModuleList不能用Python中的列表代替。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-type">Net</span>(<span class="hljs-title">nn</span>.<span class="hljs-type">Module</span>):</span><br><span class="hljs-class">    </span><br><span class="hljs-class">    def __init__(<span class="hljs-title">self</span>):</span><br><span class="hljs-class">        super(<span class="hljs-type">Net</span>, <span class="hljs-title">self</span>).__init__()</span><br><span class="hljs-class">        self.layers = nn.<span class="hljs-type">ModuleList</span>([</span><br><span class="hljs-class">            <span class="hljs-title">nn</span>.<span class="hljs-type">Conv2d</span>(<span class="hljs-title">in_channels</span>=3,<span class="hljs-title">out_channels</span>=32,<span class="hljs-title">kernel_size</span> = 3),</span><br><span class="hljs-class">            nn.<span class="hljs-type">MaxPool2d</span>(<span class="hljs-title">kernel_size</span> = 2,<span class="hljs-title">stride</span> = 2),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Conv2d</span>(<span class="hljs-title">in_channels</span>=32,<span class="hljs-title">out_channels</span>=64,<span class="hljs-title">kernel_size</span> = 5),</span><br><span class="hljs-class">            nn.<span class="hljs-type">MaxPool2d</span>(<span class="hljs-title">kernel_size</span> = 2,<span class="hljs-title">stride</span> = 2),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Dropout2d</span>(<span class="hljs-title">p</span> = 0.1),</span><br><span class="hljs-class">            nn.<span class="hljs-type">AdaptiveMaxPool2d</span>((1,1)),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Flatten</span>(),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Linear</span>(64,32),</span><br><span class="hljs-class">            nn.<span class="hljs-type">ReLU</span>(),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Linear</span>(32,1),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Sigmoid</span>()]</span><br><span class="hljs-class">        )</span><br><span class="hljs-class">    def forward(<span class="hljs-title">self</span>,<span class="hljs-title">x</span>):</span><br><span class="hljs-class">        for layer in self.layers:</span><br><span class="hljs-class">            x = layer(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        return x</span><br><span class="hljs-class">net = <span class="hljs-type">Net</span>()</span><br><span class="hljs-class">print(<span class="hljs-title">net</span>)</span><br></code></pre></td></tr></table></figure><h5 id="3，nn-ModuleDict作为模型容器"><a href="#3，nn-ModuleDict作为模型容器" class="headerlink" title="3，nn.ModuleDict作为模型容器"></a>3，nn.ModuleDict作为模型容器</h5><p>注意下面中的ModuleDict不能用Python中的字典代替。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs css">class Net(nn<span class="hljs-selector-class">.Module</span>):<br>    <br>    def <span class="hljs-built_in">__init__</span>(self):<br>        <span class="hljs-built_in">super</span>(Net, self).<span class="hljs-built_in">__init__</span>()<br>        self.layers_dict = nn.<span class="hljs-built_in">ModuleDict</span>(&#123;<span class="hljs-string">&quot;conv1&quot;</span>:nn.<span class="hljs-built_in">Conv2d</span>(in_channels=<span class="hljs-number">3</span>,out_channels=<span class="hljs-number">32</span>,kernel_size = <span class="hljs-number">3</span>),<br>               <span class="hljs-string">&quot;pool&quot;</span>: nn.<span class="hljs-built_in">MaxPool2d</span>(kernel_size = <span class="hljs-number">2</span>,stride = <span class="hljs-number">2</span>),<br>               <span class="hljs-string">&quot;conv2&quot;</span>:nn.<span class="hljs-built_in">Conv2d</span>(in_channels=<span class="hljs-number">32</span>,out_channels=<span class="hljs-number">64</span>,kernel_size = <span class="hljs-number">5</span>),<br>               <span class="hljs-string">&quot;dropout&quot;</span>: nn.<span class="hljs-built_in">Dropout2d</span>(p = <span class="hljs-number">0.1</span>),<br>               <span class="hljs-string">&quot;adaptive&quot;</span>:nn.<span class="hljs-built_in">AdaptiveMaxPool2d</span>((<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)),<br>               <span class="hljs-string">&quot;flatten&quot;</span>: nn.<span class="hljs-built_in">Flatten</span>(),<br>               <span class="hljs-string">&quot;linear1&quot;</span>: nn.<span class="hljs-built_in">Linear</span>(<span class="hljs-number">64</span>,<span class="hljs-number">32</span>),<br>               <span class="hljs-string">&quot;relu&quot;</span>:nn.<span class="hljs-built_in">ReLU</span>(),<br>               <span class="hljs-string">&quot;linear2&quot;</span>: nn.<span class="hljs-built_in">Linear</span>(<span class="hljs-number">32</span>,<span class="hljs-number">1</span>),<br>               <span class="hljs-string">&quot;sigmoid&quot;</span>: nn.<span class="hljs-built_in">Sigmoid</span>()<br>              &#125;)<br>    def forward(self,x):<br>        layers = [<span class="hljs-string">&quot;conv1&quot;</span>,<span class="hljs-string">&quot;pool&quot;</span>,<span class="hljs-string">&quot;conv2&quot;</span>,<span class="hljs-string">&quot;pool&quot;</span>,<span class="hljs-string">&quot;dropout&quot;</span>,<span class="hljs-string">&quot;adaptive&quot;</span>,<br>                  <span class="hljs-string">&quot;flatten&quot;</span>,<span class="hljs-string">&quot;linear1&quot;</span>,<span class="hljs-string">&quot;relu&quot;</span>,<span class="hljs-string">&quot;linear2&quot;</span>,<span class="hljs-string">&quot;sigmoid&quot;</span>]<br>        for layer in layers:<br>            x = self.layers_dict[layer](x)<br>        return x<br>net = <span class="hljs-built_in">Net</span>()<br><span class="hljs-built_in">print</span>(net)<br></code></pre></td></tr></table></figure><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记10-TensorBoard可视化</title>
    <link href="/2022/01/29/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010-TensorBoard%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    <url>/2022/01/29/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010-TensorBoard%E5%8F%AF%E8%A7%86%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><p>Pytorch中利用TensorBoard可视化的大概过程如下：</p><p>首先在Pytorch中指定一个目录创建一个torch.utils.tensorboard.SummaryWriter日志写入器。</p><p>然后根据需要可视化的信息，利用日志写入器将相应信息日志写入我们指定的目录。</p><p>最后就可以传入日志目录作为参数启动TensorBoard，然后就可以在TensorBoard中愉快地看片了。</p><p>我们主要介绍Pytorch中利用TensorBoard进行如下方面信息的可视化的方法。</p><ul><li><p>可视化模型结构： writer.add_graph</p></li><li><p>可视化指标变化： writer.add_scalar</p></li><li><p>可视化参数分布： writer.add_histogram</p></li><li><p>可视化原始图像： writer.add_image 或 writer.add_images</p></li><li><p>可视化人工绘图： writer.add_figure</p></li></ul><h4 id="可视化模型结构"><a href="#可视化模型结构" class="headerlink" title="可视化模型结构"></a>可视化模型结构</h4><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> torch <br><span class="hljs-title">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-title">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><span class="hljs-title">from</span> torchkeras <span class="hljs-keyword">import</span> Model,summary<br><span class="hljs-class"></span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-type">Net</span>(<span class="hljs-title">nn</span>.<span class="hljs-type">Module</span>):</span><br><span class="hljs-class">    </span><br><span class="hljs-class">    def __init__(<span class="hljs-title">self</span>):</span><br><span class="hljs-class">        super(<span class="hljs-type">Net</span>, <span class="hljs-title">self</span>).__init__()</span><br><span class="hljs-class">        self.conv1 = nn.<span class="hljs-type">Conv2d</span>(<span class="hljs-title">in_channels</span>=3,<span class="hljs-title">out_channels</span>=32,<span class="hljs-title">kernel_size</span> = 3)</span><br><span class="hljs-class">        self.pool = nn.<span class="hljs-type">MaxPool2d</span>(<span class="hljs-title">kernel_size</span> = 2,<span class="hljs-title">stride</span> = 2)</span><br><span class="hljs-class">        self.conv2 = nn.<span class="hljs-type">Conv2d</span>(<span class="hljs-title">in_channels</span>=32,<span class="hljs-title">out_channels</span>=64,<span class="hljs-title">kernel_size</span> = 5)</span><br><span class="hljs-class">        self.dropout = nn.<span class="hljs-type">Dropout2d</span>(<span class="hljs-title">p</span> = 0.1)</span><br><span class="hljs-class">        self.adaptive_pool = nn.<span class="hljs-type">AdaptiveMaxPool2d</span>((1,1))</span><br><span class="hljs-class">        self.flatten = nn.<span class="hljs-type">Flatten</span>()</span><br><span class="hljs-class">        self.linear1 = nn.<span class="hljs-type">Linear</span>(64,32)</span><br><span class="hljs-class">        self.relu = nn.<span class="hljs-type">ReLU</span>()</span><br><span class="hljs-class">        self.linear2 = nn.<span class="hljs-type">Linear</span>(32,1)</span><br><span class="hljs-class">        self.sigmoid = nn.<span class="hljs-type">Sigmoid</span>()</span><br><span class="hljs-class">        </span><br><span class="hljs-class">    def forward(<span class="hljs-title">self</span>,<span class="hljs-title">x</span>):</span><br><span class="hljs-class">        x = self.conv1(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        x = self.pool(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        x = self.conv2(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        x = self.pool(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        x = self.dropout(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        x = self.adaptive_pool(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        x = self.flatten(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        x = self.linear1(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        x = self.relu(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        x = self.linear2(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        y = self.sigmoid(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        return y</span><br><span class="hljs-class">        </span><br><span class="hljs-class">net = <span class="hljs-type">Net</span>()</span><br><span class="hljs-class">print(<span class="hljs-title">net</span>)</span><br><span class="hljs-class"></span><br><span class="hljs-class">writer = <span class="hljs-type">SummaryWriter</span>(&#x27;./<span class="hljs-title">data</span>/<span class="hljs-title">tensorboard&#x27;</span>)</span><br><span class="hljs-class">writer.add_graph(<span class="hljs-title">net</span>,<span class="hljs-title">input_to_model</span> = <span class="hljs-title">torch</span>.<span class="hljs-title">rand</span>(1,3,32,32))</span><br><span class="hljs-class">writer.close()</span><br></code></pre></td></tr></table></figure><figure class="highlight cos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cos"><span class="hljs-built_in">%load</span>_ext tensorboard<br>#<span class="hljs-built_in">%tensorboard</span> --logdir ./data/tensorboard<br></code></pre></td></tr></table></figure><figure class="highlight capnproto"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs capnproto"><span class="hljs-keyword">from</span> tensorboard <span class="hljs-keyword">import</span> notebook<br><span class="hljs-comment">#查看启动的tensorboard程序</span><br>notebook.list() <br></code></pre></td></tr></table></figure><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs vala"><span class="hljs-meta">#启动tensorboard程序</span><br>notebook.start(<span class="hljs-string">&quot;--logdir ./data/tensorboard&quot;</span>)<br><span class="hljs-meta">#等价于在命令行中执行 tensorboard --logdir ./data/tensorboard</span><br><span class="hljs-meta">#可以在浏览器中打开 http://localhost:6006/ 查看</span><br></code></pre></td></tr></table></figure><h4 id="可视化指标变化"><a href="#可视化指标变化" class="headerlink" title="可视化指标变化"></a>可视化指标变化</h4><p>有时候在训练过程中，如果能够实时动态地查看loss和各种metric的变化曲线，那么无疑可以帮助我们更加直观地了解模型的训练情况。</p><p>注意，writer.add_scalar仅能对标量的值的变化进行可视化。因此它一般用于对loss和metric的变化进行可视化分析。</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-built_in">import</span> numpy as np <br><span class="hljs-built_in">import</span> torch <br>from torch.utils.tensorboard <span class="hljs-built_in">import</span> SummaryWriter<br><br><span class="hljs-comment"># f(x) = a*x**2 + b*x + c的最小值</span><br><span class="hljs-attr">x</span> = torch.tensor(<span class="hljs-number">0.0</span>,<span class="hljs-attr">requires_grad</span> = True) <span class="hljs-comment"># x需要被求导</span><br><span class="hljs-attr">a</span> = torch.tensor(<span class="hljs-number">1.0</span>)<br><span class="hljs-attr">b</span> = torch.tensor(-<span class="hljs-number">2.0</span>)<br><span class="hljs-attr">c</span> = torch.tensor(<span class="hljs-number">1.0</span>)<br><br><span class="hljs-attr">optimizer</span> = torch.optim.SGD(<span class="hljs-attr">params=[x],lr</span> = <span class="hljs-number">0.01</span>)<br><br><br>def f(x):<br>    <span class="hljs-attr">result</span> = a*torch.pow(x,<span class="hljs-number">2</span>) + b*x + c <br>    return(result)<br><br><span class="hljs-attr">writer</span> = SummaryWriter(&#x27;./data/tensorboard&#x27;)<br>for i <span class="hljs-keyword">in</span> range(<span class="hljs-number">500</span>):<br>    optimizer.zero_grad()<br>    <span class="hljs-attr">y</span> = f(x)<br>    y.backward()<br>    optimizer.step()<br>    writer.add_scalar(<span class="hljs-string">&quot;x&quot;</span>,x.item(),i) <span class="hljs-comment">#日志中记录x在第step i 的值</span><br>    writer.add_scalar(<span class="hljs-string">&quot;y&quot;</span>,y.item(),i) <span class="hljs-comment">#日志中记录y在第step i 的值</span><br><br>writer.close()<br>    <br>print(<span class="hljs-string">&quot;y=&quot;</span>,f(x).data,<span class="hljs-string">&quot;;&quot;</span>,<span class="hljs-string">&quot;x=&quot;</span>,x.data)<br></code></pre></td></tr></table></figure><h4 id="可视化参数分布"><a href="#可视化参数分布" class="headerlink" title="可视化参数分布"></a>可视化参数分布</h4><p>如果需要对模型的参数(一般非标量)在训练过程中的变化进行可视化，可以使用 writer.add_histogram。</p><p>它能够观测张量值分布的直方图随训练步骤的变化趋势。</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs maxima">import numpy as <span class="hljs-built_in">np</span> <br>import torch <br>from torch.utils.tensorboard import SummaryWriter<br><br># 创建正态分布的张量模拟参数矩阵<br>def norm(<span class="hljs-built_in">mean</span>,<span class="hljs-built_in">std</span>):<br>    t = <span class="hljs-built_in">std</span>*torch.randn((<span class="hljs-number">100</span>,<span class="hljs-number">20</span>))+<span class="hljs-built_in">mean</span><br>    <span class="hljs-built_in">return</span> t<br><br>writer = SummaryWriter(&#x27;./data/tensorboard&#x27;)<br><span class="hljs-keyword">for</span> <span class="hljs-keyword">step</span>,<span class="hljs-built_in">mean</span> <span class="hljs-keyword">in</span> enumerate(<span class="hljs-built_in">range</span>(-<span class="hljs-number">10</span>,<span class="hljs-number">10</span>,<span class="hljs-number">1</span>)):<br>    w = norm(<span class="hljs-built_in">mean</span>,<span class="hljs-number">1</span>)<br>    writer.add_histogram(<span class="hljs-string">&quot;w&quot;</span>,w, <span class="hljs-keyword">step</span>)<br>    writer.<span class="hljs-built_in">flush</span>()<br>writer.<span class="hljs-built_in">close</span>()<br></code></pre></td></tr></table></figure><h4 id="可视化原始图像"><a href="#可视化原始图像" class="headerlink" title="可视化原始图像"></a>可视化原始图像</h4><p>如果我们做图像相关的任务，也可以将原始的图片在tensorboard中进行可视化展示。</p><p>如果只写入一张图片信息，可以使用writer.add_image。</p><p>如果要写入多张图片信息，可以使用writer.add_images。</p><p>也可以用 torchvision.utils.make_grid将多张图片拼成一张图片，然后用writer.add_image写入。</p><p>注意，传入的是代表图片信息的Pytorch中的张量数据。</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset,DataLoader<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms,datasets <br><br><br>transform_train = transforms.Compose(<br><span class="hljs-string">    [transforms.ToTensor()]</span>)<br>transform_valid = transforms.Compose(<br><span class="hljs-string">    [transforms.ToTensor()]</span>)<br></code></pre></td></tr></table></figure><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-attr">ds_train</span> = datasets.ImageFolder(<span class="hljs-string">&quot;/home/kesci/input/data6936/data/cifar2/train/&quot;</span>,<br>            <span class="hljs-attr">transform</span> = transform_train,<span class="hljs-attr">target_transform=</span> lambda t:torch.tensor([t]).float())<br><span class="hljs-attr">ds_valid</span> = datasets.ImageFolder(<span class="hljs-string">&quot;/home/kesci/input/data6936/data/cifar2/test/&quot;</span>,<br>            <span class="hljs-attr">transform</span> = transform_train,<span class="hljs-attr">target_transform=</span> lambda t:torch.tensor([t]).float())<br><br>print(ds_train.class_to_idx)<br><br><span class="hljs-attr">dl_train</span> = DataLoader(ds_train,<span class="hljs-attr">batch_size</span> = <span class="hljs-number">50</span>,<span class="hljs-attr">shuffle</span> = True,<span class="hljs-attr">num_workers=3)</span><br><span class="hljs-attr">dl_valid</span> = DataLoader(ds_valid,<span class="hljs-attr">batch_size</span> = <span class="hljs-number">50</span>,<span class="hljs-attr">shuffle</span> = True,<span class="hljs-attr">num_workers=3)</span><br><br><span class="hljs-attr">dl_train_iter</span> = iter(dl_train)<br>images, <span class="hljs-attr">labels</span> = dl_train_iter.next()<br><br><span class="hljs-comment"># 仅查看一张图片</span><br><span class="hljs-attr">writer</span> = SummaryWriter(&#x27;/home/kesci/input/data6936/data/tensorboard&#x27;)<br>writer.add_image(&#x27;images[<span class="hljs-number">0</span>]&#x27;, images[<span class="hljs-number">0</span>])<br>writer.close()<br><br><span class="hljs-comment"># 将多张图片拼接成一张图片，中间用黑色网格分割</span><br><span class="hljs-attr">writer</span> = SummaryWriter(&#x27;/home/kesci/input/data6936/data/tensorboard&#x27;)<br><span class="hljs-comment"># create grid of images</span><br><span class="hljs-attr">img_grid</span> = torchvision.utils.make_grid(images)<br>writer.add_image(&#x27;image_grid&#x27;, img_grid)<br>writer.close()<br><br><span class="hljs-comment"># 将多张图片直接写入</span><br><span class="hljs-attr">writer</span> = SummaryWriter(&#x27;/home/kesci/input/data6936/data/tensorboard&#x27;)<br>writer.add_images(<span class="hljs-string">&quot;images&quot;</span>,images,<span class="hljs-attr">global_step</span> = <span class="hljs-number">0</span>)<br>writer.close()<br></code></pre></td></tr></table></figure><h4 id="可视化人工绘图"><a href="#可视化人工绘图" class="headerlink" title="可视化人工绘图"></a>可视化人工绘图</h4><p>如果我们将matplotlib绘图的结果再 tensorboard中展示，可以使用 add_figure.</p><p>注意，和writer.add_image不同的是，writer.add_figure需要传入matplotlib的figure对象。</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-built_in">import</span> torch<br><span class="hljs-built_in">import</span> torchvision<br>from torch <span class="hljs-built_in">import</span> nn<br>from torch.utils.data <span class="hljs-built_in">import</span> Dataset,DataLoader<br>from torchvision <span class="hljs-built_in">import</span> transforms,datasets <br><br><br><span class="hljs-attr">transform_train</span> = transforms.Compose(<br>    [transforms.ToTensor()])<br><span class="hljs-attr">transform_valid</span> = transforms.Compose(<br>    [transforms.ToTensor()])<br><br><span class="hljs-attr">ds_train</span> = datasets.ImageFolder(<span class="hljs-string">&quot;/home/kesci/input/data6936/data/cifar2/train/&quot;</span>,<br>            <span class="hljs-attr">transform</span> = transform_train,<span class="hljs-attr">target_transform=</span> lambda t:torch.tensor([t]).float())<br><span class="hljs-attr">ds_valid</span> = datasets.ImageFolder(<span class="hljs-string">&quot;/home/kesci/input/data6936/data/cifar2/test/&quot;</span>,<br>            <span class="hljs-attr">transform</span> = transform_train,<span class="hljs-attr">target_transform=</span> lambda t:torch.tensor([t]).float())<br><br>print(ds_train.class_to_idx)<br></code></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">%matplotlib inline<br>%config <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">InlineBackend</span>.</span></span>figure_format = &#x27;svg&#x27;<br>from matplotlib import pyplot <span class="hljs-keyword">as</span> plt <br><br>figure = plt.figure(figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">8</span>)) <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">9</span>):<br>    img,label = ds_train<span class="hljs-literal">[<span class="hljs-identifier">i</span>]</span><br>    img = img.permute(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>)<br>    ax=plt.subplot(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>,i+<span class="hljs-number">1</span>)<br>    ax.imshow(img.numpy<span class="hljs-literal">()</span>)<br>    ax.set<span class="hljs-constructor">_title(<span class="hljs-string">&quot;label = %d&quot;</span>%<span class="hljs-params">label</span>.<span class="hljs-params">item</span>()</span>)<br>    ax.set<span class="hljs-constructor">_xticks([])</span><br>    ax.set<span class="hljs-constructor">_yticks([])</span> <br>plt.show<span class="hljs-literal">()</span><br><br>writer = <span class="hljs-constructor">SummaryWriter(&#x27;.<span class="hljs-operator">/</span><span class="hljs-params">data</span><span class="hljs-operator">/</span><span class="hljs-params">tensorboard</span>&#x27;)</span><br>writer.add<span class="hljs-constructor">_figure(&#x27;<span class="hljs-params">figure</span>&#x27;,<span class="hljs-params">figure</span>,<span class="hljs-params">global_step</span>=0)</span><br>writer.close<span class="hljs-literal">()</span><br></code></pre></td></tr></table></figure><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记9-损失函数</title>
    <link href="/2022/01/27/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B09-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    <url>/2022/01/27/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B09-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="各种损失函数"><a href="#各种损失函数" class="headerlink" title="各种损失函数"></a>各种损失函数</h2><span id="more"></span><p>一般来说，监督学习的目标函数由损失函数和正则化项组成。(Objective = Loss + Regularization)</p><p>Pytorch中的损失函数一般在训练模型时候指定。</p><p>注意Pytorch中内置的损失函数的参数和tensorflow不同，是y_pred在前，y_true在后，而Tensorflow是y_true在前，y_pred在后。</p><ul><li><p>对于回归模型，通常使用的内置损失函数是均方损失函数nn.MSELoss 。</p></li><li><p>对于二分类模型，通常使用的是二元交叉熵损失函数nn.BCELoss (输入已经是sigmoid激活函数之后的结果)或者 nn.BCEWithLogitsLoss (输入尚未经过nn.Sigmoid激活函数) 。</p></li><li><p>对于多分类模型，一般推荐使用交叉熵损失函数 nn.CrossEntropyLoss。(y_true需要是一维的，是类别编码。y_pred未经过nn.Softmax激活。)</p></li></ul><p>此外，如果多分类的y_pred经过了nn.LogSoftmax激活，可以使用nn.NLLLoss损失函数(The negative log likelihood loss)。<br>这种方法和直接使用nn.CrossEntropyLoss等价。</p><p>如果有需要，也可以自定义损失函数，自定义损失函数需要接收两个张量y_pred，y_true作为输入参数，并输出一个标量作为损失函数值。</p><p>Pytorch中的正则化项一般通过自定义的方式和损失函数一起添加作为目标函数。</p><p>如果仅仅使用L2正则化，也可以利用优化器的weight_decay参数来实现相同的效果。</p><h4 id="内置损失函数"><a href="#内置损失函数" class="headerlink" title="内置损失函数"></a>内置损失函数</h4><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> numpy as np<br><span class="hljs-attribute">import</span> pandas as pd<br><span class="hljs-attribute">import</span> torch <br><span class="hljs-attribute">from</span> torch import nn <br><span class="hljs-attribute">import</span> torch.nn.functional as F <br><br><br><span class="hljs-attribute">y_pred</span> = torch.tensor([[<span class="hljs-number">10</span>.<span class="hljs-number">0</span>,<span class="hljs-number">0</span>.<span class="hljs-number">0</span>,-<span class="hljs-number">10</span>.<span class="hljs-number">0</span>],[<span class="hljs-number">8</span>.<span class="hljs-number">0</span>,<span class="hljs-number">8</span>.<span class="hljs-number">0</span>,<span class="hljs-number">8</span>.<span class="hljs-number">0</span>]])<br><span class="hljs-attribute">y_true</span> = torch.tensor([<span class="hljs-number">0</span>,<span class="hljs-number">2</span>])<br><br><span class="hljs-comment"># 直接调用交叉熵损失</span><br><span class="hljs-attribute">ce</span> = nn.CrossEntropyLoss()(y_pred,y_true)<br><span class="hljs-attribute">print</span>(ce)<br><br><span class="hljs-comment"># 等价于先计算nn.LogSoftmax激活，再调用NLLLoss</span><br><span class="hljs-attribute">y_pred_logsoftmax</span> = nn.LogSoftmax(dim = <span class="hljs-number">1</span>)(y_pred)<br><span class="hljs-attribute">nll</span> = nn.NLLLoss()(y_pred_logsoftmax,y_true)<br><span class="hljs-attribute">print</span>(nll)<br></code></pre></td></tr></table></figure><p>内置的损失函数一般有类的实现和函数的实现两种形式。</p><p>如：nn.BCE 和 F.binary_cross_entropy 都是二元交叉熵损失函数，前者是类的实现形式，后者是函数的实现形式。</p><p>实际上类的实现形式通常是调用函数的实现形式并用nn.Module封装后得到的。</p><p>一般我们常用的是类的实现形式。它们封装在torch.nn模块下，并且类名以Loss结尾。</p><p>常用的一些内置损失函数说明如下。</p><ul><li><p>nn.MSELoss（均方误差损失，也叫做L2损失，用于回归）</p></li><li><p>nn.L1Loss （L1损失，也叫做绝对值误差损失，用于回归）</p></li><li><p>nn.SmoothL1Loss (平滑L1损失，当输入在-1到1之间时，平滑为L2损失，用于回归)</p></li><li><p>nn.BCELoss (二元交叉熵，用于二分类，输入已经过nn.Sigmoid激活，对不平衡数据集可以用weigths参数调整类别权重)</p></li><li><p>nn.BCEWithLogitsLoss (二元交叉熵，用于二分类，输入未经过nn.Sigmoid激活)</p></li><li><p>nn.CrossEntropyLoss (交叉熵，用于多分类，要求label为稀疏编码，输入未经过nn.Softmax激活，对不平衡数据集可以用weigths参数调整类别权重)</p></li><li><p>nn.NLLLoss (负对数似然损失，用于多分类，要求label为稀疏编码，输入经过nn.LogSoftmax激活)</p></li><li><p>nn.CosineSimilarity(余弦相似度，可用于多分类)</p></li><li><p>nn.AdaptiveLogSoftmaxWithLoss (一种适合非常多类别且类别分布很不均衡的损失函数，会自适应地将多个小类别合成一个cluster)</p></li></ul><p>更多损失函数的介绍参考如下知乎文章：</p><p>《PyTorch的十八个损失函数》</p><ul><li><a href="https://zhuanlan.zhihu.com/p/61379965">https://zhuanlan.zhihu.com/p/61379965</a></li></ul><h4 id="自定义损失函数"><a href="#自定义损失函数" class="headerlink" title="自定义损失函数"></a>自定义损失函数</h4><p>自定义损失函数接收两个张量y_pred,y_true作为输入参数，并输出一个标量作为损失函数值。</p><p>也可以对nn.Module进行子类化，重写forward方法实现损失的计算逻辑，从而得到损失函数的类的实现。</p><p>下面是一个Focal Loss的自定义实现示范。Focal Loss是一种对binary_crossentropy的改进损失函数形式。</p><p>它在样本不均衡和存在较多易分类的样本时相比binary_crossentropy具有明显的优势。</p><p>它有两个可调参数，alpha参数和gamma参数。其中alpha参数主要用于衰减负样本的权重，gamma参数主要用于衰减容易训练样本的权重。</p><p>从而让模型更加聚焦在正样本和困难样本上。这就是为什么这个损失函数叫做Focal Loss。</p><p>详见《5分钟理解Focal Loss与GHM——解决样本不平衡利器》</p><ul><li><a href="https://zhuanlan.zhihu.com/p/80594704">https://zhuanlan.zhihu.com/p/80594704</a></li></ul><h4 id="自定义L1和L2正则化项"><a href="#自定义L1和L2正则化项" class="headerlink" title="自定义L1和L2正则化项"></a>自定义L1和L2正则化项</h4><p>通常认为L1 正则化可以产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择。</p><p>而L2 正则化可以防止模型过拟合（overfitting）。一定程度上，L1也可以防止过拟合。</p><p>下面以一个二分类问题为例，演示给模型的目标函数添加自定义L1和L2正则化项的方法。</p><p>这个范例同时演示了上一个部分的FocalLoss的使用</p><p>示例参考 <a href="https://www.heywhale.com/mw/project/5f33d61caf3980002cb83d18">https://www.heywhale.com/mw/project/5f33d61caf3980002cb83d18</a></p><h4 id="通过优化器实现L2正则化"><a href="#通过优化器实现L2正则化" class="headerlink" title="通过优化器实现L2正则化"></a>通过优化器实现L2正则化</h4><p>如果仅仅需要使用L2正则化，那么也可以利用优化器的weight_decay参数来实现。</p><p>weight_decay参数可以设置参数在训练过程中的衰减，这和L2正则化的作用效果等价。</p><p>Pytorch的优化器支持一种称之为Per-parameter options的操作，就是对每一个参数进行特定的学习率，权重衰减率指定，以满足更为细致的要求。</p><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记8-模型层layers</title>
    <link href="/2022/01/24/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08-%E6%A8%A1%E5%9E%8B%E5%B1%82layers/"/>
    <url>/2022/01/24/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08-%E6%A8%A1%E5%9E%8B%E5%B1%82layers/</url>
    
    <content type="html"><![CDATA[<h2 id="深度学习模型一般由各种模型层组合而成"><a href="#深度学习模型一般由各种模型层组合而成" class="headerlink" title="深度学习模型一般由各种模型层组合而成"></a>深度学习模型一般由各种模型层组合而成</h2><span id="more"></span><p>torch.nn中内置了非常丰富的各种模型层。它们都属于nn.Module的子类，具备参数管理功能。<br>例如：</p><ul><li>nn.Linear, nn.Flatten, nn.Dropout, nn.BatchNorm2d</li><li>nn.Conv2d,nn.AvgPool2d,nn.Conv1d,nn.ConvTranspose2d</li><li>nn.Embedding,nn.GRU,nn.LSTM</li><li>nn.Transformer</li></ul><p>如果这些内置模型层不能够满足需求，我们也可以通过继承nn.Module基类构建自定义的模型层。<br>实际上，pytorch不区分模型和模型层，都是通过继承nn.Module进行构建。<br>因此，我们只要继承nn.Module基类并实现forward方法即可自定义模型层。</p><h4 id="内置模型层"><a href="#内置模型层" class="headerlink" title="内置模型层"></a>内置模型层</h4><p>一些常用的内置模型层简单介绍如下。</p><p>基础层</p><ul><li>nn.Linear：全连接层。参数个数 = 输入层特征数× 输出层特征数(weight)＋ 输出层特征数(bias)</li><li>nn.Flatten：压平层，用于将多维张量样本压成一维张量样本。</li><li>nn.BatchNorm1d：一维批标准化层。通过线性变换将输入批次缩放平移到稳定的均值和标准差。可以增强模型对输入不同分布的适应性，加快模型训练速度，有轻微正则化效果。一般在激活函数之前使用。可以用afine参数设置该层是否含有可以训练的参数。</li><li>nn.BatchNorm2d：二维批标准化层。</li><li>nn.BatchNorm3d：三维批标准化层。</li><li>nn.Dropout：一维随机丢弃层。一种正则化手段。</li><li>nn.Dropout2d：二维随机丢弃层。</li><li>nn.Dropout3d：三维随机丢弃层。</li><li>nn.Threshold：限幅层。当输入大于或小于阈值范围时，截断之。</li><li>nn.ConstantPad2d： 二维常数填充层。对二维张量样本填充常数扩展长度。</li><li>nn.ReplicationPad1d： 一维复制填充层。对一维张量样本通过复制边缘值填充扩展长度。</li><li>nn.ZeroPad2d：二维零值填充层。对二维张量样本在边缘填充0值.</li><li>nn.GroupNorm：组归一化。一种替代批归一化的方法，将通道分成若干组进行归一。不受batch大小限制，据称性能和效果都优于BatchNorm。</li><li>nn.LayerNorm：层归一化。较少使用。</li><li>nn.InstanceNorm2d: 样本归一化。较少使用。</li></ul><p>各种归一化技术参考如下知乎文章《FAIR何恺明等人提出组归一化：替代批归一化，不受批量大小限制》</p><ul><li><a href="https://zhuanlan.zhihu.com/p/34858971">https://zhuanlan.zhihu.com/p/34858971</a></li></ul><p>卷积网络相关层</p><ul><li><p>nn.Conv1d：普通一维卷积，常用于文本。参数个数 = 输入通道数×卷积核尺寸(如3)×卷积核个数 + 卷积核尺寸(如3）</p></li><li><p>nn.Conv2d：普通二维卷积，常用于图像。参数个数 = 输入通道数×卷积核尺寸(如3乘3)×卷积核个数 + 卷积核尺寸(如3乘3)<br>通过调整dilation参数大于1，可以变成空洞卷积，增大卷积核感受野。<br>通过调整groups参数不为1，可以变成分组卷积。分组卷积中不同分组使用相同的卷积核，显著减少参数数量。<br>当groups参数等于通道数时，相当于tensorflow中的二维深度卷积层tf.keras.layers.DepthwiseConv2D。<br>利用分组卷积和1乘1卷积的组合操作，可以构造相当于Keras中的二维深度可分离卷积层tf.keras.layers.SeparableConv2D。</p></li><li><p>nn.Conv3d：普通三维卷积，常用于视频。参数个数 = 输入通道数×卷积核尺寸(如3乘3乘3)×卷积核个数 + 卷积核尺寸(如3乘3乘3) 。</p></li><li><p>nn.MaxPool1d: 一维最大池化。</p></li><li><p>nn.MaxPool2d：二维最大池化。一种下采样方式。没有需要训练的参数。</p></li><li><p>nn.MaxPool3d：三维最大池化。</p></li><li><p>nn.AdaptiveMaxPool2d：二维自适应最大池化。无论输入图像的尺寸如何变化，输出的图像尺寸是固定的。</p></li><li><p>该函数的实现原理，大概是通过输入图像的尺寸和要得到的输出图像的尺寸来反向推算池化算子的padding,stride等参数。</p></li><li><p>nn.FractionalMaxPool2d：二维分数最大池化。普通最大池化通常输入尺寸是输出的整数倍。而分数最大池化则可以不必是整数。分数最大池化使用了一些随机采样策略，有一定的正则效果，可以用它来代替普通最大池化和Dropout层。</p></li><li><p>nn.AvgPool2d：二维平均池化。</p></li><li><p>nn.AdaptiveAvgPool2d：二维自适应平均池化。无论输入的维度如何变化，输出的维度是固定的。</p></li><li><p>nn.ConvTranspose2d：二维卷积转置层，俗称反卷积层。并非卷积的逆操作，但在卷积核相同的情况下，当其输入尺寸是卷积操作输出尺寸的情况下，卷积转置的输出尺寸恰好是卷积操作的输入尺寸。在语义分割中可用于上采样。</p></li><li><p>nn.Upsample：上采样层，操作效果和池化相反。可以通过mode参数控制上采样策略为”nearest”最邻近策略或”linear”线性插值策略。</p></li><li><p>nn.Unfold：滑动窗口提取层。其参数和卷积操作nn.Conv2d相同。实际上，卷积操作可以等价于nn.Unfold和nn.Linear以及nn.Fold的一个组合。<br>其中nn.Unfold操作可以从输入中提取各个滑动窗口的数值矩阵，并将其压平成一维。利用nn.Linear将nn.Unfold的输出和卷积核做乘法后，再使用</p></li><li><p>nn.Fold操作将结果转换成输出图片形状。</p></li><li><p>nn.Fold：逆滑动窗口提取层。</p></li></ul><p>循环网络相关层</p><ul><li>nn.Embedding：嵌入层。一种比Onehot更加有效的对离散特征进行编码的方法。一般用于将输入中的单词映射为稠密向量。嵌入层的参数需要学习。</li><li>nn.LSTM：长短记忆循环网络层【支持多层】。最普遍使用的循环网络层。具有携带轨道，遗忘门，更新门，输出门。可以较为有效地缓解梯度消失问题，从而能够适用长期依赖问题。设置bidirectional = True时可以得到双向LSTM。需要注意的时，默认的输入和输出形状是(seq,batch,feature), 如果需要将batch维度放在第0维，则要设置batch_first参数设置为True。</li><li>nn.GRU：门控循环网络层【支持多层】。LSTM的低配版，不具有携带轨道，参数数量少于LSTM，训练速度更快。</li><li>nn.RNN：简单循环网络层【支持多层】。容易存在梯度消失，不能够适用长期依赖问题。一般较少使用。</li><li>nn.LSTMCell：长短记忆循环网络单元。和nn.LSTM在整个序列上迭代相比，它仅在序列上迭代一步。一般较少使用。</li><li>nn.GRUCell：门控循环网络单元。和nn.GRU在整个序列上迭代相比，它仅在序列上迭代一步。一般较少使用。</li><li>nn.RNNCell：简单循环网络单元。和nn.RNN在整个序列上迭代相比，它仅在序列上迭代一步。一般较少使用。</li></ul><p>Transformer相关层</p><ul><li>nn.Transformer：Transformer网络结构。Transformer网络结构是替代循环网络的一种结构，解决了循环网络难以并行，难以捕捉长期依赖的缺陷。它是目前NLP任务的主流模型的主要构成部分。Transformer网络结构由TransformerEncoder编码器和TransformerDecoder解码器组成。编码器和解码器的核心是MultiheadAttention多头注意力层。</li><li>nn.TransformerEncoder：Transformer编码器结构。由多个 nn.TransformerEncoderLayer编码器层组成。</li><li>nn.TransformerDecoder：Transformer解码器结构。由多个 nn.TransformerDecoderLayer解码器层组成。</li><li>nn.TransformerEncoderLayer：Transformer的编码器层。</li><li>nn.TransformerDecoderLayer：Transformer的解码器层。</li><li>nn.MultiheadAttention：多头注意力层。</li></ul><p>Transformer原理介绍可以参考如下知乎文章《详解Transformer(Attention Is All You Need)》</p><ul><li><a href="https://zhuanlan.zhihu.com/p/48508221">https://zhuanlan.zhihu.com/p/48508221</a></li></ul><h4 id="自定义模型层"><a href="#自定义模型层" class="headerlink" title="自定义模型层"></a>自定义模型层</h4><p>下面是Pytorch的nn.Linear层的源码，可以仿照它来自定义模型层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Linear</span>(<span class="hljs-params">nn.Module</span>):</span><br>    __constants__ = [<span class="hljs-string">&#x27;in_features&#x27;</span>, <span class="hljs-string">&#x27;out_features&#x27;</span>]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, in_features, out_features, bias=<span class="hljs-literal">True</span></span>):</span><br>        <span class="hljs-built_in">super</span>(Linear, self).__init__()<br>        self.in_features = in_features<br>        self.out_features = out_features<br>        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))<br>        <span class="hljs-keyword">if</span> bias:<br>            self.bias = nn.Parameter(torch.Tensor(out_features))<br>        <span class="hljs-keyword">else</span>:<br>            self.register_parameter(<span class="hljs-string">&#x27;bias&#x27;</span>, <span class="hljs-literal">None</span>)<br>        self.reset_parameters()<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reset_parameters</span>(<span class="hljs-params">self</span>):</span><br>        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(<span class="hljs-number">5</span>))<br>        <span class="hljs-keyword">if</span> self.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)<br>            bound = <span class="hljs-number">1</span> / math.sqrt(fan_in)<br>            nn.init.uniform_(self.bias, -bound, bound)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):</span><br>        <span class="hljs-keyword">return</span> F.linear(<span class="hljs-built_in">input</span>, self.weight, self.bias)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">extra_repr</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;in_features=&#123;&#125;, out_features=&#123;&#125;, bias=&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<br>            self.in_features, self.out_features, self.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span><br>        )<br><br><br>linear = nn.Linear(<span class="hljs-number">20</span>, <span class="hljs-number">30</span>)<br>inputs = torch.randn(<span class="hljs-number">128</span>, <span class="hljs-number">20</span>)<br>output = linear(inputs)<br><span class="hljs-built_in">print</span>(output.size())<br></code></pre></td></tr></table></figure><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记7-Dataset和DataLoader</title>
    <link href="/2022/01/21/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07-Dataset%E5%92%8CDataLoader/"/>
    <url>/2022/01/21/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07-Dataset%E5%92%8CDataLoader/</url>
    
    <content type="html"><![CDATA[<h2 id="Pytorch通常使用Dataset和DataLoader这两个工具类来构建数据管道"><a href="#Pytorch通常使用Dataset和DataLoader这两个工具类来构建数据管道" class="headerlink" title="Pytorch通常使用Dataset和DataLoader这两个工具类来构建数据管道"></a>Pytorch通常使用Dataset和DataLoader这两个工具类来构建数据管道</h2><span id="more"></span><p>Dataset定义了数据集的内容，它相当于一个类似列表的数据结构，具有确定的长度，能够用索引获取数据集中的元素。<br>而DataLoader定义了按batch加载数据集的方法，它是一个实现了__iter_方法的可迭代对象，每次迭代输出一个batch的数据。<br>DataLoader能够控制batch的大小，batch中元素的采样方法，以及将batch结果整理成模型所需输入形式的方法，并且能够使用多进程读取数据。<br>在绝大部分情况下，用户只需实现Dataset的__len__方法和__getitem__方法，就可以轻松构建自己的数据集，并用默认数据管道进行加载。</p><h5 id="Dataset和DataLoader概述"><a href="#Dataset和DataLoader概述" class="headerlink" title="Dataset和DataLoader概述"></a>Dataset和DataLoader概述</h5><h6 id="1，获取一个batch数据的步骤"><a href="#1，获取一个batch数据的步骤" class="headerlink" title="1，获取一个batch数据的步骤"></a>1，获取一个batch数据的步骤</h6><p>(假定数据集的特征和标签分别表示为张量X和Y，数据集可以表示为(X,Y), 假定batch大小为m)</p><p>1，首先我们要确定数据集的长度n。</p><p>结果类似：n = 1000。</p><p>2，然后我们从0到n-1的范围中抽样出m个数(batch大小)。</p><p>假定m=4, 拿到的结果是一个列表，类似：indices = [1,4,8,9]</p><p>3，接着我们从数据集中去取这m个数对应下标的元素。</p><p>拿到的结果是一个元组列表，类似：samples = [(X[1],Y[1]),(X[4],Y[4]),(X[8],Y[8]),(X[9],Y[9])]</p><p>4，最后我们将结果整理成两个张量作为输出。</p><p>拿到的结果是两个张量，类似batch = (features,labels)，</p><p>其中 features = torch.stack([X[1],X[4],X[8],X[9]])</p><p>labels = torch.stack([Y[1],Y[4],Y[8],Y[9]])</p><h6 id="2，Dataset和DataLoader的功能分工"><a href="#2，Dataset和DataLoader的功能分工" class="headerlink" title="2，Dataset和DataLoader的功能分工"></a>2，Dataset和DataLoader的功能分工</h6><p>上述第1个步骤确定数据集的长度是由 Dataset的__len__ 方法实现的。</p><p>第2个步骤从0到n-1的范围中抽样出m个数的方法是由 DataLoader的 sampler和 batch_sampler参数指定的。</p><p>sampler参数指定单个元素抽样方法，一般无需用户设置，程序默认在DataLoader的参数shuffle=True时采用随机抽样，shuffle=False时采用顺序抽样。</p><p>batch_sampler参数将多个抽样的元素整理成一个列表，一般无需用户设置，默认方法在DataLoader的参数drop_last=True时会丢弃数据集最后一个长度不能被batch大小整除的批次，在drop_last=False时保留最后一个批次。</p><p>第3个步骤的核心逻辑根据下标取数据集中的元素 是由 Dataset的 __getitem__方法实现的。</p><p>第4个步骤的逻辑由DataLoader的参数collate_fn指定。一般情况下也无需用户设置。</p><h6 id="3，Dataset和DataLoader的主要接口"><a href="#3，Dataset和DataLoader的主要接口" class="headerlink" title="3，Dataset和DataLoader的主要接口"></a>3，Dataset和DataLoader的主要接口</h6><p>以下是 Dataset和 DataLoader的核心接口逻辑伪代码，不完全和源码一致。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch <br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Dataset</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">pass</span><br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">raise</span> NotImplementedError<br>        <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span>(<span class="hljs-params">self,index</span>):</span><br>        <span class="hljs-keyword">raise</span> NotImplementedError<br>        <br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DataLoader</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,dataset,batch_size,collate_fn,shuffle = <span class="hljs-literal">True</span>,drop_last = <span class="hljs-literal">False</span></span>):</span><br>        self.dataset = dataset<br>        self.sampler =torch.utils.data.RandomSampler <span class="hljs-keyword">if</span> shuffle <span class="hljs-keyword">else</span> \<br>           torch.utils.data.SequentialSampler<br>        self.batch_sampler = torch.utils.data.BatchSampler<br>        self.sample_iter = self.batch_sampler(<br>            self.sampler(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(dataset))),<br>            batch_size = batch_size,drop_last = drop_last)<br>        <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__next__</span>(<span class="hljs-params">self</span>):</span><br>        indices = <span class="hljs-built_in">next</span>(self.sample_iter)<br>        batch = self.collate_fn([self.dataset[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> indices])<br>        <span class="hljs-keyword">return</span> batch<br></code></pre></td></tr></table></figure><h5 id="使用Dataset创建数据集"><a href="#使用Dataset创建数据集" class="headerlink" title="使用Dataset创建数据集"></a>使用Dataset创建数据集</h5><p>Dataset创建数据集常用的方法有：</p><ul><li><p>使用 torch.utils.data.TensorDataset 根据Tensor创建数据集(numpy的array，Pandas的DataFrame需要先转换成Tensor)。</p></li><li><p>使用 torchvision.datasets.ImageFolder 根据图片目录创建图片数据集。</p></li><li><p>继承 torch.utils.data.Dataset 创建自定义数据集。</p></li></ul><p>此外，还可以通过</p><ul><li><p>torch.utils.data.random_split 将一个数据集分割成多份，常用于分割训练集，验证集和测试集。</p></li><li><p>调用Dataset的加法运算符(+)将多个数据集合并成一个数据集。</p></li></ul><h6 id="1，根据Tensor创建数据集"><a href="#1，根据Tensor创建数据集" class="headerlink" title="1，根据Tensor创建数据集"></a>1，根据Tensor创建数据集</h6><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><span class="hljs-keyword">import</span> torch <br><span class="hljs-title">from</span> torch.utils.data <span class="hljs-keyword">import</span> TensorDataset,Dataset,DataLoader,random_split <br></code></pre></td></tr></table></figure><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-meta"># 根据Tensor创建数据集</span><br><br><span class="hljs-title">from</span> sklearn <span class="hljs-keyword">import</span> datasets <br><span class="hljs-title">iris</span> = datasets.load_iris()<br><span class="hljs-title">ds_iris</span> = <span class="hljs-type">TensorDataset</span>(torch.tensor(iris.<span class="hljs-class"><span class="hljs-keyword">data</span>),torch.tensor(<span class="hljs-title">iris</span>.<span class="hljs-title">target</span>))</span><br><br><span class="hljs-meta"># 分割成训练集和预测集</span><br><span class="hljs-title">n_train</span> = int(len(ds_iris)*<span class="hljs-number">0.8</span>)<br><span class="hljs-title">n_valid</span> = len(ds_iris) - n_train<br><span class="hljs-title">ds_train</span>,ds_valid = random_split(ds_iris,[n_train,n_valid])<br><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">type</span>(<span class="hljs-title">ds_iris</span>))</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">type</span>(<span class="hljs-title">ds_train</span>))</span><br></code></pre></td></tr></table></figure><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs maxima"># 使用DataLoader加载数据集<br>dl_train,dl_valid = DataLoader(ds_train,batch_size = <span class="hljs-number">8</span>),DataLoader(ds_valid,batch_size = <span class="hljs-number">8</span>)<br><br><span class="hljs-keyword">for</span> <span class="hljs-built_in">features</span>,<span class="hljs-built_in">labels</span> <span class="hljs-keyword">in</span> dl_train:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">features</span>,<span class="hljs-built_in">labels</span>)<br>    <span class="hljs-built_in">break</span><br></code></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"># 演示加法运算符（<span class="hljs-string">`+`</span>）的合并作用<br>ds_data = ds_train + ds_valid<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;len(ds_train) = &#x27;</span>,<span class="hljs-built_in">len</span>(ds_train))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;len(ds_valid) = &#x27;</span>,<span class="hljs-built_in">len</span>(ds_valid))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;len(ds_train+ds_valid) = &#x27;</span>,<span class="hljs-built_in">len</span>(ds_data))<br></code></pre></td></tr></table></figure><h6 id="2，根据图片目录创建图片数据集"><a href="#2，根据图片目录创建图片数据集" class="headerlink" title="2，根据图片目录创建图片数据集"></a>2，根据图片目录创建图片数据集</h6><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><span class="hljs-keyword">import</span> torch <br><span class="hljs-title">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-title">from</span> torchvision <span class="hljs-keyword">import</span> transforms,datasets<br></code></pre></td></tr></table></figure><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-comment">#一些常用的图片增强操作</span><br>from PIL <span class="hljs-built_in">import</span> Image<br><span class="hljs-attr">img</span> = Image.open(&#x27;/home/kesci/input/data6936/data/cat.jpeg&#x27;)<br><br><span class="hljs-comment"># 随机数值翻转</span><br>transforms.RandomVerticalFlip()(img)<br><br><span class="hljs-comment">#随机旋转</span><br>transforms.RandomRotation(<span class="hljs-number">45</span>)(img)<br><br><span class="hljs-comment"># 定义图片增强操作</span><br><span class="hljs-attr">transform_train</span> = transforms.Compose([<br>   transforms.RandomHorizontalFlip(), <span class="hljs-comment">#随机水平翻转</span><br>   transforms.RandomVerticalFlip(), <span class="hljs-comment">#随机垂直翻转</span><br>   transforms.RandomRotation(<span class="hljs-number">45</span>),  <span class="hljs-comment">#随机在45度角度内旋转</span><br>   transforms.ToTensor() <span class="hljs-comment">#转换成张量</span><br>  ]<br>) <br><br><span class="hljs-attr">transform_valid</span> = transforms.Compose([<br>    transforms.ToTensor()<br>  ]<br>)<br><br></code></pre></td></tr></table></figure><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs maxima"># 根据图片目录创建数据集<br>ds_train = datasets.ImageFolder(<span class="hljs-string">&quot;/home/kesci/input/data6936/data/cifar2/train/&quot;</span>,<br>            <span class="hljs-built_in">transform</span> = transform_train,target_transform= <span class="hljs-built_in">lambda</span> t:torch.tensor([t]).<span class="hljs-built_in">float</span>())<br>ds_valid = datasets.ImageFolder(<span class="hljs-string">&quot;/home/kesci/input/data6936/data/cifar2/test/&quot;</span>,<br>            <span class="hljs-built_in">transform</span> = transform_train,target_transform= <span class="hljs-built_in">lambda</span> t:torch.tensor([t]).<span class="hljs-built_in">float</span>())<br><br><span class="hljs-built_in">print</span>(ds_train.class_to_idx)<br></code></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 使用DataLoader加载数据集</span><br>dl_train = DataLoader(ds_train,batch_size = 50,shuffle = <span class="hljs-literal">True</span>,<span class="hljs-attribute">num_workers</span>=3)<br>dl_valid = DataLoader(ds_valid,batch_size = 50,shuffle = <span class="hljs-literal">True</span>,<span class="hljs-attribute">num_workers</span>=3)<br><br><span class="hljs-keyword">for</span> features,labels <span class="hljs-keyword">in</span> dl_train:<br>    <span class="hljs-builtin-name">print</span>(features.shape)<br>    <span class="hljs-builtin-name">print</span>(labels.shape)<br>    break<br><br></code></pre></td></tr></table></figure><h6 id="创建自定义数据集"><a href="#创建自定义数据集" class="headerlink" title="创建自定义数据集"></a>创建自定义数据集</h6><p>下面通过继承Dataset类创建imdb文本分类任务的自定义数据集。</p><p>大概思路如下：首先，对训练集文本分词构建词典。然后将训练集文本和测试集文本数据转换成token单词编码。</p><p>接着将转换成单词编码的训练集数据和测试集数据按样本分割成多个文件，一个文件代表一个样本。</p><p>最后，我们可以根据文件名列表获取对应序号的样本内容，从而构建Dataset数据集。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd <br><span class="hljs-title">from</span> collections <span class="hljs-keyword">import</span> OrderedDict<br><span class="hljs-keyword">import</span> re,string<br><br><span class="hljs-type">MAX_WORDS</span> = <span class="hljs-number">10000</span>  # 仅考虑最高频的<span class="hljs-number">10000</span>个词<br><span class="hljs-type">MAX_LEN</span> = <span class="hljs-number">200</span>  # 每个样本保留<span class="hljs-number">200</span>个词的长度<br><span class="hljs-type">BATCH_SIZE</span> = <span class="hljs-number">20</span> <br><br><span class="hljs-title">train_data_path</span> = &#x27;/home/kesci/input/data6936/<span class="hljs-class"><span class="hljs-keyword">data</span>/imdb/train.tsv&#x27;</span><br><span class="hljs-title">test_data_path</span> = &#x27;/home/kesci/input/data6936/<span class="hljs-class"><span class="hljs-keyword">data</span>/imdb/test.tsv&#x27;</span><br><span class="hljs-title">train_token_path</span> = &#x27;/home/kesci/input/data6936/<span class="hljs-class"><span class="hljs-keyword">data</span>/imdb/train_token.tsv&#x27;</span><br><span class="hljs-title">test_token_path</span> =  &#x27;/home/kesci/input/data6936/<span class="hljs-class"><span class="hljs-keyword">data</span>/imdb/test_token.tsv&#x27;</span><br><span class="hljs-title">train_samples_path</span> = &#x27;/home/kesci/input/data6936/<span class="hljs-class"><span class="hljs-keyword">data</span>/imdb/train_samples/&#x27;</span><br><span class="hljs-title">test_samples_path</span> =  &#x27;/home/kesci/input/data6936/<span class="hljs-class"><span class="hljs-keyword">data</span>/imdb/test_samples/&#x27;</span><br></code></pre></td></tr></table></figure><p>首先我们构建词典，并保留最高频的MAX_WORDS个词。</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs applescript"><span class="hljs-comment">##构建词典</span><br><br>word_count_dict = &#123;&#125;<br><br><span class="hljs-comment">#清洗文本</span><br>def clean_text(<span class="hljs-built_in">text</span>):<br>    lowercase = <span class="hljs-built_in">text</span>.lower().replace(<span class="hljs-string">&quot;\n&quot;</span>,<span class="hljs-string">&quot; &quot;</span>)<br>    stripped_html = re.sub(&#x27;&lt;br /&gt;&#x27;, &#x27; &#x27;,lowercase)<br>    cleaned_punctuation = re.sub(&#x27;[%s]&#x27;%re.escape(<span class="hljs-built_in">string</span>.punctuation),&#x27;&#x27;,stripped_html)<br><span class="hljs-built_in">    return</span> cleaned_punctuation<br><br><span class="hljs-keyword">with</span> open(train_data_path,<span class="hljs-string">&quot;r&quot;</span>,encoding = &#x27;utf<span class="hljs-number">-8</span>&#x27;) <span class="hljs-keyword">as</span> f:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<br>        label,<span class="hljs-built_in">text</span> = line.split(<span class="hljs-string">&quot;\t&quot;</span>)<br>        cleaned_text = clean_text(<span class="hljs-built_in">text</span>)<br>        <span class="hljs-keyword">for</span> <span class="hljs-built_in">word</span> <span class="hljs-keyword">in</span> cleaned_text.split(<span class="hljs-string">&quot; &quot;</span>):<br>            word_count_dict[<span class="hljs-built_in">word</span>] = word_count_dict.<span class="hljs-keyword">get</span>(<span class="hljs-built_in">word</span>,<span class="hljs-number">0</span>)+<span class="hljs-number">1</span> <br><br>df_word_dict = pd.DataFrame(pd.Series(word_count_dict,<span class="hljs-built_in">name</span> = <span class="hljs-string">&quot;count&quot;</span>))<br>df_word_dict = df_word_dict.sort_values(<span class="hljs-keyword">by</span> = <span class="hljs-string">&quot;count&quot;</span>,ascending =False)<br><br>df_word_dict = df_word_dict[<span class="hljs-number">0</span>:MAX_WORDS<span class="hljs-number">-2</span>] <span class="hljs-comment">#  </span><br>df_word_dict[<span class="hljs-string">&quot;word_id&quot;</span>] = range(<span class="hljs-number">2</span>,MAX_WORDS) <span class="hljs-comment">#编号0和1分别留给未知词&lt;unkown&gt;和填充&lt;padding&gt;</span><br><br>word_id_dict = df_word_dict[<span class="hljs-string">&quot;word_id&quot;</span>].to_dict()<br><br>df_word_dict.head(<span class="hljs-number">10</span>)<br></code></pre></td></tr></table></figure><p>然后我们利用构建好的词典，将文本转换成token序号。</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver"><span class="hljs-comment">#转换token</span><br><br><span class="hljs-comment"># 填充文本</span><br>def pad(data_list,pad_length):<br>    padded_list = data_list.copy()<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(data_list)&gt; pad_length:<br>         padded_list = data_list[-pad_length:]<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(data_list)&lt; pad_length:<br>         padded_list = [<span class="hljs-number">1</span>]*(pad_length-<span class="hljs-built_in">len</span>(data_list))+data_list<br>    <span class="hljs-literal">return</span> padded_list<br><br>def text_to_token(text_file,token_file):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(text_file,<span class="hljs-string">&quot;r&quot;</span>,encoding = <span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> fin,\<br>      <span class="hljs-built_in">open</span>(token_file,<span class="hljs-string">&quot;w&quot;</span>,encoding = <span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> fout:<br>        <span class="hljs-keyword">for</span> <span class="hljs-built_in">line</span> <span class="hljs-keyword">in</span> fin:<br>            label,<span class="hljs-keyword">text</span> = <span class="hljs-built_in">line</span>.<span class="hljs-built_in">split</span>(<span class="hljs-string">&quot;\t&quot;</span>)<br>            cleaned_text = clean_text(<span class="hljs-keyword">text</span>)<br>            word_token_list = [word_id_dict.<span class="hljs-built_in">get</span>(<span class="hljs-built_in">word</span>, <span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> <span class="hljs-built_in">word</span> <span class="hljs-keyword">in</span> cleaned_text.<span class="hljs-built_in">split</span>(<span class="hljs-string">&quot; &quot;</span>)]<br>            pad_list = pad(word_token_list,MAX_LEN)<br>            out_line = label+<span class="hljs-string">&quot;\t&quot;</span>+<span class="hljs-string">&quot; &quot;</span>.join([str(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> pad_list])<br>            fout.<span class="hljs-built_in">write</span>(out_line+<span class="hljs-string">&quot;\n&quot;</span>)<br>        <br>text_to_token(train_data_path,train_token_path)<br>text_to_token(test_data_path,test_token_path)<br></code></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"># 分割样本<br>import os<br><br><span class="hljs-keyword">if</span> not os.path.exists(train_samples_path):<br>    os.mkdir(train_samples_path)<br>    <br><span class="hljs-keyword">if</span> not os.path.exists(test_samples_path):<br>    os.mkdir(test_samples_path)<br>    <br>    <br>def split<span class="hljs-constructor">_samples(<span class="hljs-params">token_path</span>,<span class="hljs-params">samples_dir</span>)</span>:<br>    <span class="hljs-keyword">with</span> <span class="hljs-keyword">open</span>(token_path,<span class="hljs-string">&quot;r&quot;</span>,encoding = &#x27;utf-<span class="hljs-number">8</span>&#x27;) <span class="hljs-keyword">as</span> fin:<br>        i = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> fin:<br>            <span class="hljs-keyword">with</span> <span class="hljs-keyword">open</span>(samples_dir+<span class="hljs-string">&quot;%d.txt&quot;</span>%i,<span class="hljs-string">&quot;w&quot;</span>,encoding = <span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> fout:<br>                fout.write(line)<br>            i = i+<span class="hljs-number">1</span><br><br>split<span class="hljs-constructor">_samples(<span class="hljs-params">train_token_path</span>,<span class="hljs-params">train_samples_path</span>)</span><br>split<span class="hljs-constructor">_samples(<span class="hljs-params">test_token_path</span>,<span class="hljs-params">test_samples_path</span>)</span><br></code></pre></td></tr></table></figure><p>一切准备就绪，我们可以创建数据集Dataset, 从文件名称列表中读取文件内容了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">imdbDataset</span>(<span class="hljs-params">Dataset</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,samples_dir</span>):</span><br>        self.samples_dir = samples_dir<br>        self.samples_paths = os.listdir(samples_dir)<br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.samples_paths)<br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span>(<span class="hljs-params">self,index</span>):</span><br>        path = self.samples_dir + self.samples_paths[index]<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(path,<span class="hljs-string">&quot;r&quot;</span>,encoding = <span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>            line = f.readline()<br>            label,tokens = line.split(<span class="hljs-string">&quot;\t&quot;</span>)<br>            label = torch.tensor([<span class="hljs-built_in">float</span>(label)],dtype = torch.<span class="hljs-built_in">float</span>)<br>            feature = torch.tensor([<span class="hljs-built_in">int</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> tokens.split(<span class="hljs-string">&quot; &quot;</span>)],dtype = torch.long)<br>            <span class="hljs-keyword">return</span>  (feature,label)<br></code></pre></td></tr></table></figure><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">ds_train</span> = imdbDataset(train_samples_path)<br><span class="hljs-attr">ds_test</span> = imdbDataset(test_samples_path)<br></code></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">dl_train = <span class="hljs-constructor">DataLoader(<span class="hljs-params">ds_train</span>,<span class="hljs-params">batch_size</span> = BATCH_SIZE,<span class="hljs-params">shuffle</span> = True,<span class="hljs-params">num_workers</span>=4)</span><br>dl_test = <span class="hljs-constructor">DataLoader(<span class="hljs-params">ds_test</span>,<span class="hljs-params">batch_size</span> = BATCH_SIZE,<span class="hljs-params">num_workers</span>=4)</span><br><br><span class="hljs-keyword">for</span> features,labels <span class="hljs-keyword">in</span> dl_train:<br>    print(features)<br>    print(labels)<br>    break<br></code></pre></td></tr></table></figure><p>最后构建模型测试一下数据集管道是否可用。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">import torch<br>from torch import nn <br>import importlib <br>from torchkeras import Model,summary<br><br><span class="hljs-keyword">class</span> <span class="hljs-constructor">Net(Model)</span>:<br>    <br>    def <span class="hljs-constructor">__init__(<span class="hljs-params">self</span>)</span>:<br>        super(Net, self).<span class="hljs-constructor">__init__()</span><br>        <br>        #设置padding_idx参数后将在训练过程中将填充的token始终赋值为<span class="hljs-number">0</span>向量<br>        self.embedding = nn.<span class="hljs-constructor">Embedding(<span class="hljs-params">num_embeddings</span> = MAX_WORDS,<span class="hljs-params">embedding_dim</span> = 3,<span class="hljs-params">padding_idx</span> = 1)</span><br>        self.conv = nn.<span class="hljs-constructor">Sequential()</span><br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;conv_1&quot;</span>,<span class="hljs-params">nn</span>.Conv1d(<span class="hljs-params">in_channels</span> = 3,<span class="hljs-params">out_channels</span> = 16,<span class="hljs-params">kernel_size</span> = 5)</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;pool_1&quot;</span>,<span class="hljs-params">nn</span>.MaxPool1d(<span class="hljs-params">kernel_size</span> = 2)</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;relu_1&quot;</span>,<span class="hljs-params">nn</span>.ReLU()</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;conv_2&quot;</span>,<span class="hljs-params">nn</span>.Conv1d(<span class="hljs-params">in_channels</span> = 16,<span class="hljs-params">out_channels</span> = 128,<span class="hljs-params">kernel_size</span> = 2)</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;pool_2&quot;</span>,<span class="hljs-params">nn</span>.MaxPool1d(<span class="hljs-params">kernel_size</span> = 2)</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;relu_2&quot;</span>,<span class="hljs-params">nn</span>.ReLU()</span>)<br>        <br>        self.dense = nn.<span class="hljs-constructor">Sequential()</span><br>        self.dense.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;flatten&quot;</span>,<span class="hljs-params">nn</span>.Flatten()</span>)<br>        self.dense.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;linear&quot;</span>,<span class="hljs-params">nn</span>.Linear(6144,1)</span>)<br>        self.dense.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;sigmoid&quot;</span>,<span class="hljs-params">nn</span>.Sigmoid()</span>)<br>        <br>    def forward(self,x):<br>        x = self.embedding(x).transpose(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)<br>        x = self.conv(x)<br>        y = self.dense(x)<br>        return y<br>        <br>model = <span class="hljs-constructor">Net()</span><br>print(model)<br><br>model.summary(input_shape = (<span class="hljs-number">200</span>,),input_dtype = torch.LongTensor)<br></code></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"># 编译模型<br>def accuracy(y_pred,y_true):<br>    y_pred = torch.where(y_pred&gt;<span class="hljs-number">0.5</span>,torch.ones<span class="hljs-constructor">_like(<span class="hljs-params">y_pred</span>,<span class="hljs-params">dtype</span> = <span class="hljs-params">torch</span>.<span class="hljs-params">float32</span>)</span>,<br>                      torch.zeros<span class="hljs-constructor">_like(<span class="hljs-params">y_pred</span>,<span class="hljs-params">dtype</span> = <span class="hljs-params">torch</span>.<span class="hljs-params">float32</span>)</span>)<br>    acc = torch.mean(<span class="hljs-number">1</span>-torch.abs(y_true-y_pred))<br>    return acc<br><br>model.compile(loss_func = nn.<span class="hljs-constructor">BCELoss()</span>,optimizer= torch.optim.<span class="hljs-constructor">Adagrad(<span class="hljs-params">model</span>.<span class="hljs-params">parameters</span>()</span>,lr = <span class="hljs-number">0.02</span>),<br>             metrics_dict=&#123;<span class="hljs-string">&quot;accuracy&quot;</span>:accuracy&#125;)<br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># 训练模型</span><br><span class="hljs-attribute">dfhistory</span> = model.fit(<span class="hljs-number">10</span>,dl_train,dl_val=dl_test,log_step_freq= <span class="hljs-number">200</span>)<br></code></pre></td></tr></table></figure><h5 id="使用DataLoader加载数据集"><a href="#使用DataLoader加载数据集" class="headerlink" title="使用DataLoader加载数据集"></a>使用DataLoader加载数据集</h5><p>DataLoader能够控制batch的大小，batch中元素的采样方法，以及将batch结果整理成模型所需输入形式的方法，并且能够使用多进程读取数据。</p><p>DataLoader的函数签名如下。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs routeros">DataLoader(  <br>    dataset,  <br>    <span class="hljs-attribute">batch_size</span>=1,  <br>    <span class="hljs-attribute">shuffle</span>=<span class="hljs-literal">False</span>,  <br>    <span class="hljs-attribute">sampler</span>=None,  <br>    <span class="hljs-attribute">batch_sampler</span>=None,  <br>    <span class="hljs-attribute">num_workers</span>=0,  <br>    <span class="hljs-attribute">collate_fn</span>=None,  <br>    <span class="hljs-attribute">pin_memory</span>=<span class="hljs-literal">False</span>,  <br>    <span class="hljs-attribute">drop_last</span>=<span class="hljs-literal">False</span>,  <br>    <span class="hljs-attribute">timeout</span>=0,  <br>    <span class="hljs-attribute">worker_init_fn</span>=None,  <br>    <span class="hljs-attribute">multiprocessing_context</span>=None,  <br>)<br></code></pre></td></tr></table></figure><p>一般情况下，我们仅仅会配置 dataset, batch_size, shuffle, num_workers, drop_last这五个参数，其他参数使用默认值即可。</p><p>DataLoader除了可以加载我们前面讲的 torch.utils.data.Dataset 外，还能够加载另外一种数据集 torch.utils.data.IterableDataset。</p><p>和Dataset数据集相当于一种列表结构不同，IterableDataset相当于一种迭代器结构。 它更加复杂，一般较少使用。</p><ul><li>dataset : 数据集</li><li>batch_size: 批次大小</li><li>shuffle: 是否乱序</li><li>sampler: 样本采样函数，一般无需设置。</li><li>batch_sampler: 批次采样函数，一般无需设置。</li><li>num_workers: 使用多进程读取数据，设置的进程数。</li><li>collate_fn: 整理一个批次数据的函数。</li><li>pin_memory: 是否设置为锁业内存。默认为False，锁业内存不会使用虚拟内存(硬盘)，从锁业内存拷贝到GPU上速度会更快。</li><li>drop_last: 是否丢弃最后一个样本数量不足batch_size批次数据。</li><li>timeout: 加载一个数据批次的最长等待时间，一般无需设置。</li><li>worker_init_fn: 每个worker中dataset的初始化函数，常用于 IterableDataset。一般不使用。</li></ul><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-comment">#构建输入数据管道</span><br><span class="hljs-attr">ds</span> = TensorDataset(torch.arange(<span class="hljs-number">1</span>,<span class="hljs-number">50</span>))<br><span class="hljs-attr">dl</span> = DataLoader(ds,<br>                <span class="hljs-attr">batch_size</span> = <span class="hljs-number">10</span>,<br>                <span class="hljs-attr">shuffle=</span> True,<br>                <span class="hljs-attr">num_workers=2,</span><br>                <span class="hljs-attr">drop_last</span> = True)<br><span class="hljs-comment">#迭代数据</span><br>for batch, <span class="hljs-keyword">in</span> dl:<br>    print(batch)<br></code></pre></td></tr></table></figure><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记6-nn.functional和nn.Module</title>
    <link href="/2022/01/20/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06-nn-functional%E5%92%8Cnn-Module/"/>
    <url>/2022/01/20/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06-nn-functional%E5%92%8Cnn-Module/</url>
    
    <content type="html"><![CDATA[<h2 id="神经网络相关的组件-如激活函数，模型层，损失函数"><a href="#神经网络相关的组件-如激活函数，模型层，损失函数" class="headerlink" title="神经网络相关的组件(如激活函数，模型层，损失函数)"></a>神经网络相关的组件(如激活函数，模型层，损失函数)</h2><span id="more"></span><h5 id="nn-functional-和-nn-Module"><a href="#nn-functional-和-nn-Module" class="headerlink" title="nn.functional 和 nn.Module"></a>nn.functional 和 nn.Module</h5><p>Pytorch和神经网络相关的功能组件大多都封装在 torch.nn模块下。<br>这些功能组件的绝大部分既有函数形式实现，也有类形式实现。<br>其中nn.functional(一般引入后改名为F)有各种功能组件的函数实现。例如：</p><h6 id="激活函数"><a href="#激活函数" class="headerlink" title="(激活函数)"></a>(激活函数)</h6><ul><li>F.relu</li><li>F.sigmoid</li><li>F.tanh</li><li>F.softmax</li></ul><h6 id="模型层"><a href="#模型层" class="headerlink" title="(模型层)"></a>(模型层)</h6><ul><li>F.linear</li><li>F.conv2d</li><li>F.max_pool2d</li><li>F.dropout2d</li><li>F.embedding</li></ul><h6 id="损失函数"><a href="#损失函数" class="headerlink" title="(损失函数)"></a>(损失函数)</h6><ul><li>F.binary_cross_entropy</li><li>F.mse_loss</li><li>F.cross_entropy</li></ul><p>为了便于对参数进行管理，一般通过继承 nn.Module 转换成为类的实现形式，并直接封装在 nn 模块下。例如：</p><h6 id="激活函数-1"><a href="#激活函数-1" class="headerlink" title="(激活函数)"></a>(激活函数)</h6><ul><li>nn.ReLU</li><li>nn.Sigmoid</li><li>nn.Tanh</li><li>nn.Softmax</li></ul><h6 id="模型层-1"><a href="#模型层-1" class="headerlink" title="(模型层)"></a>(模型层)</h6><ul><li>nn.Linear</li><li>nn.Conv2d</li><li>nn.MaxPool2d</li><li>nn.Dropout2d</li><li>nn.Embedding</li></ul><h6 id="损失函数-1"><a href="#损失函数-1" class="headerlink" title="(损失函数)"></a>(损失函数)</h6><ul><li>nn.BCELoss</li><li>nn.MSELoss</li><li>nn.CrossEntropyLoss</li></ul><p>实际上nn.Module除了可以管理其引用的各种参数，还可以管理其引用的子模块，功能十分强大。</p><h5 id="使用nn-Module来管理参数"><a href="#使用nn-Module来管理参数" class="headerlink" title="使用nn.Module来管理参数"></a>使用nn.Module来管理参数</h5><p>在Pytorch中，模型的参数是需要被优化器训练的，因此，通常要设置参数为 requires_grad = True 的张量。<br>同时，在一个模型中，往往有许多的参数，要手动管理这些参数并不是一件容易的事情。<br>Pytorch一般将参数用nn.Parameter来表示，并且用nn.Module来管理其结构下的所有参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch <br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn <br><span class="hljs-keyword">import</span> torch.nn.functional  <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># nn.Parameter 具有 requires_grad = True 属性</span><br>w = nn.Parameter(torch.randn(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>))<br><span class="hljs-built_in">print</span>(w)<br><span class="hljs-built_in">print</span>(w.requires_grad)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">arameter containing:</span><br><span class="hljs-string">tensor([[ 1.2790,  0.6851],</span><br><span class="hljs-string">        [-1.9961,  0.4121]], requires_grad=True)</span><br><span class="hljs-string">True</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment"># nn.ParameterList 可以将多个nn.Parameter组成一个列表</span><br>params_list = nn.ParameterList([nn.Parameter(torch.rand(<span class="hljs-number">8</span>,i)) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>)])<br><span class="hljs-built_in">print</span>(params_list)<br><span class="hljs-built_in">print</span>(params_list[<span class="hljs-number">0</span>].requires_grad)<br><br><span class="hljs-comment"># nn.ParameterDict 可以将多个nn.Parameter组成一个字典</span><br>params_dict = nn.ParameterDict(&#123;<span class="hljs-string">&quot;a&quot;</span>:nn.Parameter(torch.rand(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)),<br>                               <span class="hljs-string">&quot;b&quot;</span>:nn.Parameter(torch.zeros(<span class="hljs-number">2</span>))&#125;)<br><span class="hljs-built_in">print</span>(params_dict)<br><span class="hljs-built_in">print</span>(params_dict[<span class="hljs-string">&quot;a&quot;</span>].requires_grad)<br></code></pre></td></tr></table></figure><figure class="highlight monkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs monkey"><span class="hljs-meta"># 可以用Module将它们管理起来</span><span class="hljs-meta"></span><br><span class="hljs-meta"># module.parameters()返回一个生成器，包括其结构下的所有parameters</span><br><br><span class="hljs-keyword">module</span> = nn.<span class="hljs-keyword">Module</span>()<br><span class="hljs-keyword">module</span>.w = w<br><span class="hljs-keyword">module</span>.params_list = params_list<br><span class="hljs-keyword">module</span>.params_dict = params_dict<br><br>num_param = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> param in <span class="hljs-keyword">module</span>.parameters():<br>    <span class="hljs-built_in">print</span>(param,<span class="hljs-string">&quot;\n&quot;</span>)<br>    num_param = num_param + <span class="hljs-number">1</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;number of Parameters =&quot;</span>,num_param)<br></code></pre></td></tr></table></figure><p>实践当中，一般通过继承nn.Module来构建模块类，并将所有含有需要学习的参数的部分放在构造函数中。<br>以下范例为Pytorch中nn.Linear的源码的简化版本<br>可以看到它将需要学习的参数放在了__init__构造函数中，并在forward中调用F.linear函数来实现计算逻辑。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Linear</span>(<span class="hljs-params">nn.Module</span>):</span><br>    __constants__ = [<span class="hljs-string">&#x27;in_features&#x27;</span>, <span class="hljs-string">&#x27;out_features&#x27;</span>]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, in_features, out_features, bias=<span class="hljs-literal">True</span></span>):</span><br>        <span class="hljs-built_in">super</span>(Linear, self).__init__()<br>        self.in_features = in_features<br>        self.out_features = out_features<br>        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))<br>        <span class="hljs-keyword">if</span> bias:<br>            self.bias = nn.Parameter(torch.Tensor(out_features))<br>        <span class="hljs-keyword">else</span>:<br>            self.register_parameter(<span class="hljs-string">&#x27;bias&#x27;</span>, <span class="hljs-literal">None</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):</span><br>        <span class="hljs-keyword">return</span> F.linear(<span class="hljs-built_in">input</span>, self.weight, self.bias)<br></code></pre></td></tr></table></figure><h5 id="使用nn-Module来管理子模块"><a href="#使用nn-Module来管理子模块" class="headerlink" title="使用nn.Module来管理子模块"></a>使用nn.Module来管理子模块</h5><p>一般情况下，我们都很少直接使用 nn.Parameter来定义参数构建模型，而是通过一些拼装一些常用的模型层来构造模型。<br>这些模型层也是继承自nn.Module的对象,本身也包括参数，属于我们要定义的模块的子模块。</p><p>nn.Module提供了一些方法可以管理这些子模块。</p><ul><li>children() 方法: 返回生成器，包括模块下的所有子模块。</li><li>named_children()方法：返回一个生成器，包括模块下的所有子模块，以及它们的名字。</li><li>modules()方法：返回一个生成器，包括模块下的所有各个层级的模块，包括模块本身。</li><li>named_modules()方法：返回一个生成器，包括模块下的所有各个层级的模块以及它们的名字，包括模块本身。</li></ul><p>其中chidren()方法和named_children()方法较多使用。<br>modules()方法和named_modules()方法较少使用，其功能可以通过多个named_children()的嵌套使用实现。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><span class="hljs-keyword">class</span> <span class="hljs-constructor">Net(<span class="hljs-params">nn</span>.Module)</span>:<br>    <br>    def <span class="hljs-constructor">__init__(<span class="hljs-params">self</span>)</span>:<br>        super(Net, self).<span class="hljs-constructor">__init__()</span><br>        <br>        self.embedding = nn.<span class="hljs-constructor">Embedding(<span class="hljs-params">num_embeddings</span> = 10000,<span class="hljs-params">embedding_dim</span> = 3,<span class="hljs-params">padding_idx</span> = 1)</span><br>        self.conv = nn.<span class="hljs-constructor">Sequential()</span><br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;conv_1&quot;</span>,<span class="hljs-params">nn</span>.Conv1d(<span class="hljs-params">in_channels</span> = 3,<span class="hljs-params">out_channels</span> = 16,<span class="hljs-params">kernel_size</span> = 5)</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;pool_1&quot;</span>,<span class="hljs-params">nn</span>.MaxPool1d(<span class="hljs-params">kernel_size</span> = 2)</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;relu_1&quot;</span>,<span class="hljs-params">nn</span>.ReLU()</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;conv_2&quot;</span>,<span class="hljs-params">nn</span>.Conv1d(<span class="hljs-params">in_channels</span> = 16,<span class="hljs-params">out_channels</span> = 128,<span class="hljs-params">kernel_size</span> = 2)</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;pool_2&quot;</span>,<span class="hljs-params">nn</span>.MaxPool1d(<span class="hljs-params">kernel_size</span> = 2)</span>)<br>        self.conv.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;relu_2&quot;</span>,<span class="hljs-params">nn</span>.ReLU()</span>)<br>        <br>        self.dense = nn.<span class="hljs-constructor">Sequential()</span><br>        self.dense.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;flatten&quot;</span>,<span class="hljs-params">nn</span>.Flatten()</span>)<br>        self.dense.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;linear&quot;</span>,<span class="hljs-params">nn</span>.Linear(6144,1)</span>)<br>        self.dense.add<span class="hljs-constructor">_module(<span class="hljs-string">&quot;sigmoid&quot;</span>,<span class="hljs-params">nn</span>.Sigmoid()</span>)<br>        <br>    def forward(self,x):<br>        x = self.embedding(x).transpose(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)<br>        x = self.conv(x)<br>        y = self.dense(x)<br>        return y<br>    <br>net = <span class="hljs-constructor">Net()</span><br></code></pre></td></tr></table></figure><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-selector-tag">i</span> = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> child <span class="hljs-keyword">in</span> net<span class="hljs-selector-class">.children</span>():<br>    i+=<span class="hljs-number">1</span><br>    print(child,<span class="hljs-string">&quot;\n&quot;</span>)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">&quot;child number&quot;</span>,i)</span></span><br><br><br><span class="hljs-selector-tag">i</span> = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> name,child <span class="hljs-keyword">in</span> net<span class="hljs-selector-class">.named_children</span>():<br>    i+=<span class="hljs-number">1</span><br>    print(name,<span class="hljs-string">&quot;:&quot;</span>,child,<span class="hljs-string">&quot;\n&quot;</span>)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">&quot;child number&quot;</span>,i)</span></span><br><br><br><span class="hljs-selector-tag">i</span> = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> module <span class="hljs-keyword">in</span> net<span class="hljs-selector-class">.modules</span>():<br>    i+=<span class="hljs-number">1</span><br>    print(module)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">&quot;module number:&quot;</span>,i)</span></span><br><br></code></pre></td></tr></table></figure><p>下面我们通过named_children方法找到embedding层，并将其参数设置为不可训练(相当于冻结embedding层)。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs stylus">children_dict = &#123;name:module <span class="hljs-keyword">for</span> name,module <span class="hljs-keyword">in</span> net<span class="hljs-selector-class">.named_children</span>()&#125;<br><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(children_dict)</span></span><br>embedding = children_dict<span class="hljs-selector-attr">[<span class="hljs-string">&quot;embedding&quot;</span>]</span><br>embedding<span class="hljs-selector-class">.requires_grad_</span>(False) #冻结其参数<br></code></pre></td></tr></table></figure><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">#可以看到其第一层的参数已经不可以被训练了。<br>for param in embedding.parameters():<br><span class="hljs-code">    print(param.requires_grad)</span><br><span class="hljs-code">    print(param.numel())</span><br><br>&#x27;&#x27;&#x27;<br><span class="hljs-code">False</span><br><span class="hljs-code">30000</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-title">from</span> torchkeras <span class="hljs-keyword">import</span> summary<br><span class="hljs-title">summary</span>(net,input_shape = (<span class="hljs-number">200</span>,),input_d<span class="hljs-keyword">type</span> = torch.<span class="hljs-type">LongTensor</span>)<br># 不可训练参数数量增加<br></code></pre></td></tr></table></figure><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记5-张量的数学运算</title>
    <link href="/2022/01/20/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05-%E5%BC%A0%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97/"/>
    <url>/2022/01/20/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05-%E5%BC%A0%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97/</url>
    
    <content type="html"><![CDATA[<h2 id="张量数学运算主要有：标量运算，向量运算，矩阵运算，以及张量运算的广播机制"><a href="#张量数学运算主要有：标量运算，向量运算，矩阵运算，以及张量运算的广播机制" class="headerlink" title="张量数学运算主要有：标量运算，向量运算，矩阵运算，以及张量运算的广播机制"></a>张量数学运算主要有：标量运算，向量运算，矩阵运算，以及张量运算的广播机制</h2><span id="more"></span><h5 id="标量运算"><a href="#标量运算" class="headerlink" title="标量运算"></a>标量运算</h5><p>张量的数学运算符可以分为标量运算符、向量运算符、以及矩阵运算符。<br>加减乘除乘方，以及三角函数，指数，对数等常见函数，逻辑比较运算符等都是标量运算符。<br>标量运算符的特点是对张量实施逐元素运算。<br>有些标量运算符对常用的数学运算符进行了重载。并且支持类似numpy的广播特性。</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"># 幅值裁剪<br>x = torch.tensor([0.9,-0.8,100.0,-20.0,0.7])<br>y = torch.clamp(x,min=-1,max = 1)<br>z = torch.clamp(x,max = 1)<br>print(y)<br>print(z)<br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor([ 0.9000, -0.8000,  1.0000, -1.0000,  0.7000])</span><br><span class="hljs-code">tensor([  0.9000,  -0.8000,   1.0000, -20.0000,   0.7000])</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><h5 id="向量运算"><a href="#向量运算" class="headerlink" title="向量运算"></a>向量运算</h5><p>向量运算符只在一个特定轴上运算，将一个向量映射到一个标量或者另外一个向量</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-selector-tag">a</span> = torch<span class="hljs-selector-class">.arange</span>(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>)<span class="hljs-selector-class">.float</span>()<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(torch.sum(a)</span></span>)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(torch.mean(a)</span></span>)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(torch.max(a)</span></span>)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(torch.min(a)</span></span>)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(torch.prod(a)</span></span>) #累乘<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(torch.std(a)</span></span>)  #标准差<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(torch.var(a)</span></span>)  #方差<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(torch.median(a)</span></span>) #中位数<br></code></pre></td></tr></table></figure><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs stylus">#指定维度计算统计值<br><span class="hljs-selector-tag">b</span> = <span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.view</span>(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(b)</span></span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(torch.max(b,dim = <span class="hljs-number">0</span>)</span></span>)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(torch.max(b,dim = <span class="hljs-number">1</span>)</span></span>)<br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment">#torch.sort和torch.topk可以对张量排序</span><br><span class="hljs-attribute">a</span> = torch.tensor([[<span class="hljs-number">9</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>],[<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">2</span>],[<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">4</span>]]).float()<br><span class="hljs-attribute">print</span>(torch.topk(a,<span class="hljs-number">2</span>,dim = <span class="hljs-number">0</span>),<span class="hljs-string">&quot;\n&quot;</span>)<br><span class="hljs-attribute">print</span>(torch.topk(a,<span class="hljs-number">2</span>,dim = <span class="hljs-number">1</span>),<span class="hljs-string">&quot;\n&quot;</span>)<br><span class="hljs-attribute">print</span>(torch.sort(a,dim = <span class="hljs-number">1</span>),<span class="hljs-string">&quot;\n&quot;</span>)<br><br><span class="hljs-comment">#利用torch.topk可以在Pytorch中实现KNN算法</span><br></code></pre></td></tr></table></figure><h5 id="矩阵运算"><a href="#矩阵运算" class="headerlink" title="矩阵运算"></a>矩阵运算</h5><p>矩阵必须是二维的。类似torch.tensor([1,2,3])这样的不是矩阵。<br>矩阵运算包括：矩阵乘法，矩阵转置，矩阵逆，矩阵求迹，矩阵范数，矩阵行列式，矩阵求特征值，矩阵分解等运算。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs stylus">#矩阵乘法<br><span class="hljs-selector-tag">a</span> = torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[[1,2]</span>,<span class="hljs-selector-attr">[3,4]</span>])<br><span class="hljs-selector-tag">b</span> = torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[[2,0]</span>,<span class="hljs-selector-attr">[0,2]</span>])<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(a@b)</span></span>  #等价于torch<span class="hljs-selector-class">.matmul</span>(<span class="hljs-selector-tag">a</span>,b) 或 torch<span class="hljs-selector-class">.mm</span>(<span class="hljs-selector-tag">a</span>,b)<br><br>#矩阵转置<br><span class="hljs-selector-tag">a</span> = torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[[1.0,2]</span>,<span class="hljs-selector-attr">[3,4]</span>])<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(a.t()</span></span>)<br><br>#矩阵逆，必须为浮点类型<br><span class="hljs-selector-tag">a</span> = torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[[1.0,2]</span>,<span class="hljs-selector-attr">[3,4]</span>])<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(torch.inverse(a)</span></span>)<br><br>#矩阵求trace<br><span class="hljs-selector-tag">a</span> = torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[[1.0,2]</span>,<span class="hljs-selector-attr">[3,4]</span>])<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(torch.trace(a)</span></span>)<br><br>#矩阵求范数<br><span class="hljs-selector-tag">a</span> = torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[[1.0,2]</span>,<span class="hljs-selector-attr">[3,4]</span>])<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(torch.norm(a)</span></span>)<br><br>#矩阵行列式<br><span class="hljs-selector-tag">a</span> = torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[[1.0,2]</span>,<span class="hljs-selector-attr">[3,4]</span>])<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(torch.det(a)</span></span>)<br><br>#矩阵特征值和特征向量<br><span class="hljs-selector-tag">a</span> = torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[[1.0,2]</span>,<span class="hljs-selector-attr">[-5,4]</span>],dtype = torch.<span class="hljs-attribute">float</span>)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(torch.eig(a,eigenvectors=True)</span></span>)<br><br>#两个特征值分别是 -<span class="hljs-number">2.5</span>+<span class="hljs-number">2.7839</span>j, <span class="hljs-number">2.5</span>-<span class="hljs-number">2.7839</span>j <br><br><br>#矩阵QR分解, 将一个方阵分解为一个正交矩阵q和上三角矩阵r<br>#QR分解实际上是对矩阵a实施Schmidt正交化得到<span class="hljs-selector-tag">q</span><br><span class="hljs-selector-tag">a</span>  = torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[[1.0,2.0]</span>,<span class="hljs-selector-attr">[3.0,4.0]</span>])<br><span class="hljs-selector-tag">q</span>,r = torch<span class="hljs-selector-class">.qr</span>(a)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(q,<span class="hljs-string">&quot;\n&quot;</span>)</span></span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(r,<span class="hljs-string">&quot;\n&quot;</span>)</span></span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(q@r)</span></span><br><br><br>#矩阵svd分解<br>#svd分解可以将任意一个矩阵分解为一个正交矩阵u,一个对角阵s和一个正交矩阵v<span class="hljs-selector-class">.t</span>()的乘积<br>#svd常用于矩阵压缩和降维<br>a=torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[[1.0,2.0]</span>,<span class="hljs-selector-attr">[3.0,4.0]</span>,<span class="hljs-selector-attr">[5.0,6.0]</span>])<br><br>u,s,v = torch<span class="hljs-selector-class">.svd</span>(a)<br><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(u,<span class="hljs-string">&quot;\n&quot;</span>)</span></span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(s,<span class="hljs-string">&quot;\n&quot;</span>)</span></span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(v,<span class="hljs-string">&quot;\n&quot;</span>)</span></span><br><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(u@torch.diag(s)</span></span>@v<span class="hljs-selector-class">.t</span>())<br><br>#利用svd分解可以在Pytorch中实现主成分分析降维<br></code></pre></td></tr></table></figure><h5 id="广播机制"><a href="#广播机制" class="headerlink" title="广播机制"></a>广播机制</h5><p>Pytorch的广播规则和numpy是一样的:</p><ul><li>1、如果张量的维度不同，将维度较小的张量进行扩展，直到两个张量的维度都一样。</li><li>2、如果两个张量在某个维度上的长度是相同的，或者其中一个张量在该维度上的长度为1，那么我们就说这两个张量在该维度上是相容的。</li><li>3、如果两个张量在所有维度上都是相容的，它们就能使用广播。</li><li>4、广播之后，每个维度的长度将取两个张量在该维度长度的较大值。</li><li>5、在任何一个维度上，如果一个张量的长度为1，另一个张量长度大于1，那么在该维度上，就好像是对第一个张量进行了复制。</li></ul><p>torch.broadcast_tensors可以将多个张量根据广播规则转换成相同的维度。</p><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记4-张量的结构操作</title>
    <link href="/2022/01/19/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04-%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BB%93%E6%9E%84%E6%93%8D%E4%BD%9C/"/>
    <url>/2022/01/19/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04-%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BB%93%E6%9E%84%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h2 id="张量的操作主要包括张量的结构操作和张量的数学运算"><a href="#张量的操作主要包括张量的结构操作和张量的数学运算" class="headerlink" title="张量的操作主要包括张量的结构操作和张量的数学运算"></a>张量的操作主要包括张量的结构操作和张量的数学运算</h2><span id="more"></span><p>张量结构操作诸如：张量创建，索引切片，维度变换，合并分割。<br>张量数学运算主要有：标量运算，向量运算，矩阵运算。另外我们会介绍张量运算的广播机制。</p><h5 id="创建张量"><a href="#创建张量" class="headerlink" title="创建张量"></a>创建张量</h5><p>张量创建的许多方法和numpy中创建array的方法很像</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">import numpy as np<br>import torch <br><br>a = torch.tensor([1,2,3],dtype = torch.float)<br>print(a)<br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor([1., 2., 3.])</span><br>&#x27;&#x27;&#x27;<br><br>b = torch.arange(1,10,step = 2)<br>print(b)<br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor([1, 3, 5, 7, 9])</span><br>&#x27;&#x27;&#x27;<br><br>c = torch.linspace(0.0, 2*3.14, 10)<br>print(c)<br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor([0.0000, 0.6978, 1.3956, 2.0933, 2.7911, 3.4889, 4.1867, 4.8844, 5.5822,</span><br><span class="hljs-code">        6.2800])</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><p>另外还有 torch.ones()、torch.zero_like()、torch.zeros() 等方法创建</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"># 均匀随机分布<br>torch.manual_seed(0)<br>minval, maxval = 0, 10<br>a = minval + (maxval - minval) * torch.rand([5])<br>print(a)<br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor([4.9626, 7.6822, 0.8848, 1.3203, 3.0742])</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"># 正太分布随机<br>b = torch.normal(mean = torch.zeros(3,3), std = torch.ones(3,3))<br>print(b)<br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor([[ 0.5507,  0.2704,  0.6472],</span><br><span class="hljs-code">        [ 0.2490, -0.3354,  0.4564],</span><br><span class="hljs-code">        [-0.6255,  0.4539, -1.3740]])</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"># 整数随机排列<br>d = torch.randperm(20)<br>print(d)<br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor([ 3, 17,  9, 19,  1, 18,  4, 13, 15, 12,  0, 16,  7, 11,  2,  5,  8, 10,</span><br><span class="hljs-code">         6, 14])</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><p>此外还有 torch.eye() (单位矩阵) 、 torch.diag() (对角矩阵) 等</p><h5 id="索引切片"><a href="#索引切片" class="headerlink" title="索引切片"></a>索引切片</h5><p>张量的索引切片方式和numpy几乎是一样的。切片时支持缺省参数和省略号。可以通过索引和切片对部分元素进行修改。<br>此外，对于不规则的切片提取,可以使用 torch.index_select, torch.masked_select, torch.take<br>如果要通过修改张量的某些元素得到新的张量，可以使用 torch.where,torch.masked_fill,torch.index_fill</p><ul><li>torch.where可以理解为if的张量版本。</li><li>torch.index_fill的选取元素逻辑和torch.index_select相同。</li><li>torch.masked_fill的选取元素逻辑和torch.masked_select相同。</li></ul><h5 id="维度变换"><a href="#维度变换" class="headerlink" title="维度变换"></a>维度变换</h5><p>维度变换相关函数主要有 torch.reshape(或者调用张量的view方法), torch.squeeze, torch.unsqueeze, torch.transpose</p><ul><li>torch.reshape 可以改变张量的形状。</li><li>torch.squeeze 可以减少维度。</li><li>torch.unsqueeze 可以增加维度。</li><li>torch.transpose 可以交换维度。</li></ul><p>如果张量在某个维度上只有一个元素，利用torch.squeeze可以消除这个维度。<br>torch.unsqueeze的作用和torch.squeeze的作用相反。</p><p>torch.transpose可以交换张量的维度，torch.transpose常用于图片存储格式的变换上。<br>如果是二维的矩阵，通常会调用矩阵的转置方法 matrix.t()，等价于 torch.transpose(matrix,0,1)。</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">minval=0<br>maxval=255<br># Batch,Height,Width,Channel<br>data = torch.floor(minval + (maxval-minval)*torch.rand([100,256,256,4])).int()<br>print(data.shape)<br><br># 转换成 Pytorch默认的图片格式 Batch,Channel,Height,Width <br># 需要交换两次<br>data<span class="hljs-emphasis">_t = torch.transpose(torch.transpose(data,1,2),1,3)</span><br><span class="hljs-emphasis">print(data_</span>t.shape)<br>&#x27;&#x27;&#x27;<br><span class="hljs-code">torch.Size([100, 256, 256, 4])</span><br><span class="hljs-code">torch.Size([100, 4, 256, 256])</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><h5 id="合并分割"><a href="#合并分割" class="headerlink" title="合并分割"></a>合并分割</h5><p>可以用torch.cat方法和torch.stack方法将多个张量合并，可以用torch.split方法把一个张量分割成多个张量。<br>torch.cat和torch.stack有略微的区别，torch.cat是连接，不会增加维度，而torch.stack是堆叠，会增加维度。<br>torch.split是torch.cat的逆运算，可以指定分割份数平均分割，也可以通过指定每份的记录数量进行分割</p><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记3-动态计算图</title>
    <link href="/2022/01/18/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03-%E5%8A%A8%E6%80%81%E8%AE%A1%E7%AE%97%E5%9B%BE/"/>
    <url>/2022/01/18/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03-%E5%8A%A8%E6%80%81%E8%AE%A1%E7%AE%97%E5%9B%BE/</url>
    
    <content type="html"><![CDATA[<h2 id="动态计算图"><a href="#动态计算图" class="headerlink" title="动态计算图"></a>动态计算图</h2><span id="more"></span><h5 id="Pytorch的动态计算图"><a href="#Pytorch的动态计算图" class="headerlink" title="Pytorch的动态计算图"></a>Pytorch的动态计算图</h5><p>包括：</p><ul><li>动态计算图简介</li><li>计算图中的Function</li><li>计算图和反向传播</li><li>叶子节点和非叶子节点</li><li>计算图在TensorBoard中的可视化</li></ul><h5 id="动态计算图简介"><a href="#动态计算图简介" class="headerlink" title="动态计算图简介"></a>动态计算图简介</h5><p>Pytorch的计算图由节点和边组成，节点表示张量或者Function，边表示张量和Function之间的依赖关系。<br>Pytorch中的计算图是动态图。这里的动态主要有两重含义。<br>第一层含义是：计算图的正向传播是立即执行的。无需等待完整的计算图创建完毕，每条语句都会在计算图中动态添加节点和边，并立即执行正向传播得到计算结果。<br>第二层含义是：计算图在反向传播后立即销毁。下次调用需要重新构建计算图。如果在程序中使用了backward方法执行了反向传播，或者利用torch.autograd.grad方法计算了梯度，那么创建的计算图会被立即销毁，释放存储空间，下次调用需要重新创建。</p><h6 id="计算图的正向传播是立即执行的。"><a href="#计算图的正向传播是立即执行的。" class="headerlink" title="计算图的正向传播是立即执行的。"></a>计算图的正向传播是立即执行的。</h6><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">import torch <br>w = torch.tensor([[3.0,1.0]],requires<span class="hljs-emphasis">_grad=True)</span><br><span class="hljs-emphasis">b = torch.tensor([[3.0]],requires_grad=True)</span><br><span class="hljs-emphasis">X = torch.randn(10,2)</span><br><span class="hljs-emphasis">Y = torch.randn(10,1)</span><br><span class="hljs-emphasis">Y_hat = X@w.t() + b  # Y_hat定义后其正向传播被立即执行，与其后面的loss创建语句无关</span><br><span class="hljs-emphasis">loss = torch.mean(torch.pow(Y_</span>hat-Y,2))<br><br>print(loss.data)<br>print(Y_hat.data)<br><br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor(16.8885)</span><br><span class="hljs-code">tensor([[ 3.3509],</span><br><span class="hljs-code">        [-2.5233],</span><br><span class="hljs-code">        [ 5.1586],</span><br><span class="hljs-code">        [ 4.9135],</span><br><span class="hljs-code">        [ 1.0449],</span><br><span class="hljs-code">        [ 8.0712],</span><br><span class="hljs-code">        [ 5.0686],</span><br><span class="hljs-code">        [ 0.5840],</span><br><span class="hljs-code">        [-0.0614],</span><br><span class="hljs-code">        [ 2.7492]])</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><h6 id="计算图在反向传播后立即销毁。"><a href="#计算图在反向传播后立即销毁。" class="headerlink" title="计算图在反向传播后立即销毁。"></a>计算图在反向传播后立即销毁。</h6><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> torch <br><span class="hljs-attribute">w</span> = torch.tensor([[<span class="hljs-number">3</span>.<span class="hljs-number">0</span>,<span class="hljs-number">1</span>.<span class="hljs-number">0</span>]],requires_grad=True)<br><span class="hljs-attribute">b</span> = torch.tensor([[<span class="hljs-number">3</span>.<span class="hljs-number">0</span>]],requires_grad=True)<br><span class="hljs-attribute">X</span> = torch.randn(<span class="hljs-number">10</span>,<span class="hljs-number">2</span>)<br><span class="hljs-attribute">Y</span> = torch.randn(<span class="hljs-number">10</span>,<span class="hljs-number">1</span>)<br><span class="hljs-attribute">Y_hat</span> = X@w.t() + b  # Y_hat定义后其正向传播被立即执行，与其后面的loss创建语句无关<br><span class="hljs-attribute">loss</span> = torch.mean(torch.pow(Y_hat-Y,<span class="hljs-number">2</span>))<br><br><span class="hljs-comment">#计算图在反向传播后立即销毁，如果需要保留计算图, 需要设置retain_graph = True</span><br><span class="hljs-attribute">loss</span>.backward()  #loss.backward(retain_graph = True) <br><br><span class="hljs-comment">#loss.backward() #如果再次执行反向传播将报错</span><br></code></pre></td></tr></table></figure><h5 id="计算图中的Function"><a href="#计算图中的Function" class="headerlink" title="计算图中的Function"></a>计算图中的Function</h5><p>计算图中的 张量我们已经比较熟悉了, 计算图中的另外一种节点是Function, 实际上就是 Pytorch中各种对张量操作的函数。<br>这些Function和我们Python中的函数有一个较大的区别，那就是它同时包括正向计算逻辑和反向传播的逻辑。<br>我们可以通过继承torch.autograd.Function来创建这种支持反向传播的Function</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch <br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyReLU</span>(<span class="hljs-params">torch.autograd.Function</span>):</span><br>   <br>    <span class="hljs-comment">#正向传播逻辑，可以用ctx存储一些值，供反向传播使用。</span><br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">ctx, <span class="hljs-built_in">input</span></span>):</span><br>        ctx.save_for_backward(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">input</span>.clamp(<span class="hljs-built_in">min</span>=<span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment">#反向传播逻辑</span><br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">backward</span>(<span class="hljs-params">ctx, grad_output</span>):</span><br>        <span class="hljs-built_in">input</span>, = ctx.saved_tensors<br>        grad_input = grad_output.clone()<br>        grad_input[<span class="hljs-built_in">input</span> &lt; <span class="hljs-number">0</span>] = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">return</span> grad_input<br><br><br>w = torch.tensor([[<span class="hljs-number">3.0</span>,<span class="hljs-number">1.0</span>]],requires_grad=<span class="hljs-literal">True</span>)<br>b = torch.tensor([[<span class="hljs-number">3.0</span>]],requires_grad=<span class="hljs-literal">True</span>)<br>X = torch.tensor([[-<span class="hljs-number">1.0</span>,-<span class="hljs-number">1.0</span>],[<span class="hljs-number">1.0</span>,<span class="hljs-number">1.0</span>]])<br>Y = torch.tensor([[<span class="hljs-number">2.0</span>,<span class="hljs-number">3.0</span>]])<br><br>relu = MyReLU.apply <span class="hljs-comment"># relu现在也可以具有正向传播和反向传播功能</span><br>Y_hat = relu(X@w.t() + b)<br>loss = torch.mean(torch.<span class="hljs-built_in">pow</span>(Y_hat-Y,<span class="hljs-number">2</span>))<br><br>loss.backward()<br><br><span class="hljs-built_in">print</span>(w.grad)<br><span class="hljs-built_in">print</span>(b.grad)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">tensor([[4.5000, 4.5000]])</span><br><span class="hljs-string">tensor([[4.5000]])</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"># Y<span class="hljs-emphasis">_hat的梯度函数即是我们自己所定义的 MyReLU.backward</span><br><span class="hljs-emphasis">print(Y_hat.grad_</span>fn)<br>&#x27;&#x27;&#x27;<br><span class="hljs-code">&lt;torch.autograd.function.MyReLUBackward object at 0x7efe582c7ba8&gt;</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><h5 id="计算图与反向传播"><a href="#计算图与反向传播" class="headerlink" title="计算图与反向传播"></a>计算图与反向传播</h5><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> torch <br><br><span class="hljs-attribute">x</span> = torch.tensor(<span class="hljs-number">3</span>.<span class="hljs-number">0</span>,requires_grad=True)<br><span class="hljs-attribute">y1</span> = x + <span class="hljs-number">1</span><br><span class="hljs-attribute">y2</span> = <span class="hljs-number">2</span>*x<br><span class="hljs-attribute">loss</span> = (y<span class="hljs-number">1</span>-y<span class="hljs-number">2</span>)**<span class="hljs-number">2</span><br><br><span class="hljs-attribute">loss</span>.backward()<br></code></pre></td></tr></table></figure><p>loss.backward()语句调用后，依次发生以下计算过程。</p><ul><li>1，loss自己的grad梯度赋值为1，即对自身的梯度为1。</li><li>2，loss根据其自身梯度以及关联的backward方法，计算出其对应的自变量即y1和y2的梯度，将该值赋值到y1.grad和y2.grad。</li><li>3，y2和y1根据其自身梯度以及关联的backward方法, 分别计算出其对应的自变量x的梯度，x.grad将其收到的多个梯度值累加。</li></ul><p>（注意，1,2,3步骤的求梯度顺序和对多个梯度值的累加规则恰好是求导链式法则的程序表述）<br>正因为求导链式法则衍生的梯度累加规则，张量的grad梯度不会自动清零，在需要的时候需要手动置零。</p><h5 id="叶子节点和非叶子节点"><a href="#叶子节点和非叶子节点" class="headerlink" title="叶子节点和非叶子节点"></a>叶子节点和非叶子节点</h5><p>执行下面代码，我们会发现 loss.grad并不是我们期望的1,而是 None。类似地 y1.grad 以及 y2.grad也是 None.<br>这是为什么呢？这是由于它们不是叶子节点张量。<br>在反向传播过程中，只有 is_leaf=True 的叶子节点，需要求导的张量的导数结果才会被最后保留下来。<br>那么什么是叶子节点张量呢？叶子节点张量需要满足两个条件。</p><ul><li>1，叶子节点张量是由用户直接创建的张量，而非由某个Function通过计算得到的张量。</li><li>2，叶子节点张量的 requires_grad属性必须为True.</li></ul><p>Pytorch设计这样的规则主要是为了节约内存或者显存空间，因为几乎所有的时候，用户只会关心他自己直接创建的张量的梯度。<br>所有依赖于叶子节点张量的张量, 其requires_grad 属性必定是True的，但其梯度值只在计算过程中被用到，不会最终存储到grad属性中。<br>如果需要保留中间计算结果的梯度到grad属性中，可以使用 retain_grad方法。<br>如果仅仅是为了调试代码查看梯度值，可以利用register_hook打印日志。</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">import torch <br><br>x = torch.tensor(3.0,requires_grad=True)<br>y1 = x + 1<br>y2 = 2*x<br>loss = (y1-y2)**2<br><br>loss.backward()<br>print(&quot;loss.grad:&quot;, loss.grad)<br>print(&quot;y1.grad:&quot;, y1.grad)<br>print(&quot;y2.grad:&quot;, y2.grad)<br>print(x.grad)<br><br>&#x27;&#x27;&#x27;<br><span class="hljs-code">loss.grad: None</span><br><span class="hljs-code">y1.grad: None</span><br><span class="hljs-code">y2.grad: None</span><br><span class="hljs-code">tensor(4.)</span><br>&#x27;&#x27;&#x27;<br><br>print(x.is<span class="hljs-emphasis">_leaf)</span><br><span class="hljs-emphasis">print(y1.is_leaf)</span><br><span class="hljs-emphasis">print(y2.is_leaf)</span><br><span class="hljs-emphasis">print(loss.is_</span>leaf)<br><br>&#x27;&#x27;&#x27;<br><span class="hljs-code">True</span><br><span class="hljs-code">False</span><br><span class="hljs-code">False</span><br><span class="hljs-code">False</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><p>利用retain_grad可以保留非叶子节点的梯度值，利用register_hook可以查看非叶子节点的梯度值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch <br><br><span class="hljs-comment">#正向传播</span><br>x = torch.tensor(<span class="hljs-number">3.0</span>,requires_grad=<span class="hljs-literal">True</span>)<br>y1 = x + <span class="hljs-number">1</span><br>y2 = <span class="hljs-number">2</span>*x<br>loss = (y1-y2)**<span class="hljs-number">2</span><br><br><span class="hljs-comment">#非叶子节点梯度显示控制</span><br>y1.register_hook(<span class="hljs-keyword">lambda</span> grad: <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;y1 grad: &#x27;</span>, grad))<br>y2.register_hook(<span class="hljs-keyword">lambda</span> grad: <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;y2 grad: &#x27;</span>, grad))<br>loss.retain_grad()<br><br><span class="hljs-comment">#反向传播</span><br>loss.backward()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;loss.grad:&quot;</span>, loss.grad)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x.grad:&quot;</span>, x.grad)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">y2 grad:  tensor(4.)</span><br><span class="hljs-string">y1 grad:  tensor(-4.)</span><br><span class="hljs-string">loss.grad: tensor(1.)</span><br><span class="hljs-string">x.grad: tensor(4.)</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><h5 id="计算图在TensorBoard中的可视化"><a href="#计算图在TensorBoard中的可视化" class="headerlink" title="计算图在TensorBoard中的可视化"></a>计算图在TensorBoard中的可视化</h5><p>可以利用 torch.utils.tensorboard 将计算图导出到 TensorBoard进行可视化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn <br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Net</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(Net, self).__init__()<br>        self.w = nn.Parameter(torch.randn(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>))<br>        self.b = nn.Parameter(torch.zeros(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>))<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        y = x@self.w + self.b<br>        <span class="hljs-keyword">return</span> y<br><br>net = Net()<br><br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br>writer = SummaryWriter(<span class="hljs-string">&#x27;./data/tensorboard&#x27;</span>)<br>writer.add_graph(net,input_to_model = torch.rand(<span class="hljs-number">10</span>,<span class="hljs-number">2</span>))<br>writer.close()<br><br>%load_ext tensorboard<br><span class="hljs-comment">#%tensorboard --logdir ./data/tensorboard</span><br><br><span class="hljs-keyword">from</span> tensorboard <span class="hljs-keyword">import</span> notebook<br>notebook.<span class="hljs-built_in">list</span>()<br><br><span class="hljs-comment">#在tensorboard中查看模型</span><br>notebook.start(<span class="hljs-string">&quot;--logdir ./data/tensorboard&quot;</span>)<br></code></pre></td></tr></table></figure><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记2-自动微分机制</title>
    <link href="/2022/01/18/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02-%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86%E6%9C%BA%E5%88%B6/"/>
    <url>/2022/01/18/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02-%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h2 id="自动微分机制"><a href="#自动微分机制" class="headerlink" title="自动微分机制"></a>自动微分机制</h2><span id="more"></span><p>神经网络通常依赖反向传播求梯度来更新网络参数，求梯度过程通常是一件非常复杂而容易出错的事情。而深度学习框架可以帮助我们自动地完成这种求梯度运算。<br>Pytorch一般通过反向传播 backward 方法 实现这种求梯度计算。该方法求得的梯度将存在对应自变量张量的grad属性下。除此之外，也能够调用torch.autograd.grad 函数来实现求梯度计算。这就是Pytorch的自动微分机制。</p><h5 id="利用backward方法求导数"><a href="#利用backward方法求导数" class="headerlink" title="利用backward方法求导数"></a>利用backward方法求导数</h5><p>backward 方法通常在一个标量张量上调用，该方法求得的梯度将存在对应自变量张量的grad属性下。如果调用的张量非标量，则要传入一个和它同形状 的gradient参数张量。相当于用该gradient参数张量与调用张量作向量点乘，得到的标量结果再反向传播。</p><h6 id="标量的反向传播"><a href="#标量的反向传播" class="headerlink" title="标量的反向传播"></a>标量的反向传播</h6><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">import numpy as np <br>import torch <br><br># f(x) = a*x**2 <span class="hljs-code">+ b*x +</span> c的导数<br><br>x = torch.tensor(0.0,requires_grad = True) # x需要被求导<br>a = torch.tensor(1.0)<br>b = torch.tensor(-2.0)<br>c = torch.tensor(1.0)<br>y = a*torch.pow(x,2) <span class="hljs-code">+ b*x +</span> c <br><br>y.backward()<br>dy<span class="hljs-emphasis">_dx = x.grad</span><br><span class="hljs-emphasis">print(dy_</span>dx)<br><br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor(-2.)</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><h6 id="非标量的反向传播"><a href="#非标量的反向传播" class="headerlink" title="非标量的反向传播"></a>非标量的反向传播</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><span class="hljs-keyword">import</span> torch <br><br><span class="hljs-comment"># f(x) = a*x**2 + b*x + c</span><br><br>x = torch.tensor([[<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>],[<span class="hljs-number">1.0</span>,<span class="hljs-number">2.0</span>]],requires_grad = <span class="hljs-literal">True</span>) <span class="hljs-comment"># x需要被求导</span><br>a = torch.tensor(<span class="hljs-number">1.0</span>)<br>b = torch.tensor(-<span class="hljs-number">2.0</span>)<br>c = torch.tensor(<span class="hljs-number">1.0</span>)<br>y = a*torch.<span class="hljs-built_in">pow</span>(x,<span class="hljs-number">2</span>) + b*x + c <br><br>gradient = torch.tensor([[<span class="hljs-number">1.0</span>,<span class="hljs-number">1.0</span>],[<span class="hljs-number">1.0</span>,<span class="hljs-number">1.0</span>]])<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x:\n&quot;</span>,x)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y:\n&quot;</span>,y)<br>y.backward(gradient = gradient)<br>x_grad = x.grad<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x_grad:\n&quot;</span>,x_grad)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">x:</span><br><span class="hljs-string"> tensor([[0., 0.],</span><br><span class="hljs-string">        [1., 2.]], requires_grad=True)</span><br><span class="hljs-string">y:</span><br><span class="hljs-string"> tensor([[1., 1.],</span><br><span class="hljs-string">        [0., 1.]], grad_fn=&lt;AddBackward0&gt;)</span><br><span class="hljs-string">x_grad:</span><br><span class="hljs-string"> tensor([[-2., -2.],</span><br><span class="hljs-string">        [ 0.,  2.]])</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><h6 id="非标量的反向传播可以用标量的反向传播实现"><a href="#非标量的反向传播可以用标量的反向传播实现" class="headerlink" title="非标量的反向传播可以用标量的反向传播实现"></a>非标量的反向传播可以用标量的反向传播实现</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><span class="hljs-keyword">import</span> torch <br><br><span class="hljs-comment"># f(x) = a*x**2 + b*x + c</span><br><br>x = torch.tensor([[<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>],[<span class="hljs-number">1.0</span>,<span class="hljs-number">2.0</span>]],requires_grad = <span class="hljs-literal">True</span>) <span class="hljs-comment"># x需要被求导</span><br>a = torch.tensor(<span class="hljs-number">1.0</span>)<br>b = torch.tensor(-<span class="hljs-number">2.0</span>)<br>c = torch.tensor(<span class="hljs-number">1.0</span>)<br>y = a*torch.<span class="hljs-built_in">pow</span>(x,<span class="hljs-number">2</span>) + b*x + c <br><br>gradient = torch.tensor([[<span class="hljs-number">1.0</span>,<span class="hljs-number">1.0</span>],[<span class="hljs-number">1.0</span>,<span class="hljs-number">1.0</span>]])<br>z = torch.<span class="hljs-built_in">sum</span>(y*gradient)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x:&quot;</span>,x)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y:&quot;</span>,y)<br>z.backward()<br>x_grad = x.grad<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x_grad:\n&quot;</span>,x_grad)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">x: tensor([[0., 0.],</span><br><span class="hljs-string">        [1., 2.]], requires_grad=True)</span><br><span class="hljs-string">y: tensor([[1., 1.],</span><br><span class="hljs-string">        [0., 1.]], grad_fn=&lt;AddBackward0&gt;)</span><br><span class="hljs-string">x_grad:</span><br><span class="hljs-string"> tensor([[-2., -2.],</span><br><span class="hljs-string">        [ 0.,  2.]])</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><h5 id="利用autograd-grad方法求导数"><a href="#利用autograd-grad方法求导数" class="headerlink" title="利用autograd.grad方法求导数"></a>利用autograd.grad方法求导数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><span class="hljs-keyword">import</span> torch <br><br><span class="hljs-comment"># f(x) = a*x**2 + b*x + c的导数</span><br><br>x = torch.tensor(<span class="hljs-number">0.0</span>,requires_grad = <span class="hljs-literal">True</span>) <span class="hljs-comment"># x需要被求导</span><br>a = torch.tensor(<span class="hljs-number">1.0</span>)<br>b = torch.tensor(-<span class="hljs-number">2.0</span>)<br>c = torch.tensor(<span class="hljs-number">1.0</span>)<br>y = a*torch.<span class="hljs-built_in">pow</span>(x,<span class="hljs-number">2</span>) + b*x + c<br><br><br><span class="hljs-comment"># create_graph 设置为 True 将允许创建更高阶的导数 </span><br>dy_dx = torch.autograd.grad(y,x,create_graph=<span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>]<br><span class="hljs-built_in">print</span>(dy_dx.data)<br><br><span class="hljs-comment"># 求二阶导数</span><br>dy2_dx2 = torch.autograd.grad(dy_dx,x)[<span class="hljs-number">0</span>] <br><br><span class="hljs-built_in">print</span>(dy2_dx2.data)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">tensor(-2.)</span><br><span class="hljs-string">tensor(2.)</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">import numpy as np <br>import torch <br><br>x1 = torch.tensor(1.0,requires<span class="hljs-emphasis">_grad = True) # x需要被求导</span><br><span class="hljs-emphasis">x2 = torch.tensor(2.0,requires_</span>grad = True)<br><br>y1 = x1*x2<br>y2 = x1+x2<br><br><br># 允许同时对多个自变量求导数<br>(dy1<span class="hljs-emphasis">_dx1,dy1_dx2) = torch.autograd.grad(outputs=y1,inputs = [x1,x2],retain_graph = True)</span><br><span class="hljs-emphasis">print(dy1_dx1,dy1_</span>dx2)<br><br># 如果有多个因变量，相当于把多个因变量的梯度结果求和<br>(dy12<span class="hljs-emphasis">_dx1,dy12_dx2) = torch.autograd.grad(outputs=[y1,y2],inputs = [x1,x2])</span><br><span class="hljs-emphasis">print(dy12_dx1,dy12_</span>dx2)<br><br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor(2.) tensor(1.)</span><br><span class="hljs-code">tensor(3.) tensor(2.)</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><h5 id="利用自动微分和优化器求最小值"><a href="#利用自动微分和优化器求最小值" class="headerlink" title="利用自动微分和优化器求最小值"></a>利用自动微分和优化器求最小值</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><span class="hljs-keyword">import</span> torch <br><br><span class="hljs-comment"># f(x) = a*x**2 + b*x + c的最小值</span><br><br>x = torch.tensor(<span class="hljs-number">0.0</span>,requires_grad = <span class="hljs-literal">True</span>) <span class="hljs-comment"># x需要被求导</span><br>a = torch.tensor(<span class="hljs-number">1.0</span>)<br>b = torch.tensor(-<span class="hljs-number">2.0</span>)<br>c = torch.tensor(<span class="hljs-number">1.0</span>)<br><br>optimizer = torch.optim.SGD(params=[x],lr = <span class="hljs-number">0.01</span>)<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">f</span>(<span class="hljs-params">x</span>):</span><br>    result = a*torch.<span class="hljs-built_in">pow</span>(x,<span class="hljs-number">2</span>) + b*x + c <br>    <span class="hljs-keyword">return</span>(result)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">500</span>):<br>    optimizer.zero_grad()<br>    y = f(x)<br>    y.backward()<br>    optimizer.step()<br>   <br>    <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y=&quot;</span>,f(x).data,<span class="hljs-string">&quot;;&quot;</span>,<span class="hljs-string">&quot;x=&quot;</span>,x.data)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">y= tensor(0.) ; x= tensor(1.0000)</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记1-张量数据结构</title>
    <link href="/2022/01/18/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01-%E5%BC%A0%E9%87%8F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <url>/2022/01/18/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01-%E5%BC%A0%E9%87%8F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
    
    <content type="html"><![CDATA[<h2 id="张量的数据类型、张量的维度、张量的尺寸、张量和numpy数组等"><a href="#张量的数据类型、张量的维度、张量的尺寸、张量和numpy数组等" class="headerlink" title="张量的数据类型、张量的维度、张量的尺寸、张量和numpy数组等"></a>张量的数据类型、张量的维度、张量的尺寸、张量和numpy数组等</h2><span id="more"></span><p>Pytorch的基本数据结构是张量Tensor。张量即多维数组。Pytorch的张量和numpy中的array很类似。</p><h5 id="张量的数据类型"><a href="#张量的数据类型" class="headerlink" title="张量的数据类型"></a>张量的数据类型</h5><p>张量的数据类型和numpy.array基本一一对应，但是不支持str类型。包括:</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs angelscript">torch.<span class="hljs-built_in">float</span>64(torch.<span class="hljs-built_in">double</span>),<br><br>torch.<span class="hljs-built_in">float</span>32(torch.<span class="hljs-built_in">float</span>),<br><br>torch.<span class="hljs-built_in">float</span>16,<br><br>torch.<span class="hljs-built_in">int</span>64(torch.long),<br><br>torch.<span class="hljs-built_in">int</span>32(torch.<span class="hljs-built_in">int</span>),<br><br>torch.<span class="hljs-built_in">int</span>16,<br><br>torch.<span class="hljs-built_in">int</span>8,<br><br>torch.<span class="hljs-built_in">uint</span>8,<br><br>torch.<span class="hljs-built_in">bool</span><br></code></pre></td></tr></table></figure><p>一般神经网络建模使用的都是torch.float32类型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch <br><br><span class="hljs-comment"># 自动推断数据类型</span><br>i = torch.tensor(<span class="hljs-number">1</span>);<span class="hljs-built_in">print</span>(i,i.dtype)<br>x = torch.tensor(<span class="hljs-number">2.0</span>);<span class="hljs-built_in">print</span>(x,x.dtype)<br>b = torch.tensor(<span class="hljs-literal">True</span>);<span class="hljs-built_in">print</span>(b,b.dtype)<br><span class="hljs-string">&#x27;&#x27;&#x27; # 输出</span><br><span class="hljs-string">tensor(1) torch.int64</span><br><span class="hljs-string">tensor(2.) torch.float32</span><br><span class="hljs-string">tensor(True) torch.bool</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment"># 指定数据类型</span><br>i = torch.tensor(<span class="hljs-number">1</span>,dtype = torch.int32);<span class="hljs-built_in">print</span>(i,i.dtype)<br>x = torch.tensor(<span class="hljs-number">2.0</span>,dtype = torch.double);<span class="hljs-built_in">print</span>(x,x.dtype)<br>‘’‘<br>tensor(<span class="hljs-number">1</span>, dtype=torch.int32) torch.int32<br>tensor(<span class="hljs-number">2.</span>, dtype=torch.float64) torch.float64<br>’‘’<br><br><span class="hljs-comment"># 使用特定类型构造函数</span><br>i = torch.IntTensor(<span class="hljs-number">1</span>);<span class="hljs-built_in">print</span>(i,i.dtype)<br>x = torch.Tensor(np.array(<span class="hljs-number">2.0</span>));<span class="hljs-built_in">print</span>(x,x.dtype) <span class="hljs-comment">#等价于torch.FloatTensor</span><br>b = torch.BoolTensor(np.array([<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>])); <span class="hljs-built_in">print</span>(b,b.dtype)<br>‘’‘<br>tensor([<span class="hljs-number">1266789664</span>], dtype=torch.int32) torch.int32<br>tensor(<span class="hljs-number">2.</span>) torch.float32<br>tensor([ <span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>,  <span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>]) torch.<span class="hljs-built_in">bool</span><br>’‘’<br><br><span class="hljs-comment"># 不同类型进行转换</span><br>i = torch.tensor(<span class="hljs-number">1</span>); <span class="hljs-built_in">print</span>(i,i.dtype)<br>x = i.<span class="hljs-built_in">float</span>(); <span class="hljs-built_in">print</span>(x,x.dtype) <span class="hljs-comment">#调用 float方法转换成浮点类型</span><br>y = i.<span class="hljs-built_in">type</span>(torch.<span class="hljs-built_in">float</span>); <span class="hljs-built_in">print</span>(y,y.dtype) <span class="hljs-comment">#使用type函数转换成浮点类型</span><br>z = i.type_as(x);<span class="hljs-built_in">print</span>(z,z.dtype) <span class="hljs-comment">#使用type_as方法转换成某个Tensor相同类型</span><br>‘’‘<br>tensor(<span class="hljs-number">1</span>) torch.int64<br>tensor(<span class="hljs-number">1.</span>) torch.float32<br>tensor(<span class="hljs-number">1.</span>) torch.float32<br>tensor(<span class="hljs-number">1.</span>) torch.float32<br>’‘’<br></code></pre></td></tr></table></figure><h5 id="张量的维度"><a href="#张量的维度" class="headerlink" title="张量的维度"></a>张量的维度</h5><p>不同类型的数据可以用不同维度(dimension)的张量来表示。标量为0维张量，向量为1维张量，矩阵为2维张量。彩色图像有rgb三个通道，可以表示为3维张量。视频还有时间维，可以表示为4维张量。<br>可以简单地总结为：有几层中括号，就是多少维的张量。</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">scalar = torch.tensor(True)<br>print(scalar)<br>print(scalar.dim())  # 标量，0维张量<br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor(True)</span><br><span class="hljs-code">0</span><br>&#x27;&#x27;&#x27;<br><br>vector = torch.tensor([1.0,2.0,3.0,4.0]) #向量，1维张量<br>print(vector)<br>print(vector.dim())<br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor([1., 2., 3., 4.])</span><br><span class="hljs-code">1</span><br>&#x27;&#x27;&#x27;<br><br>matrix = torch.tensor([[1.0,2.0],[3.0,4.0]]) #矩阵, 2维张量<br>print(matrix)<br>print(matrix.dim())<br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor([[1., 2.],</span><br><span class="hljs-code">        [3., 4.]])</span><br><span class="hljs-code">2</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><h5 id="张量的尺寸"><a href="#张量的尺寸" class="headerlink" title="张量的尺寸"></a>张量的尺寸</h5><p>可以使用 shape属性或者 size()方法查看张量在每一维的长度.可以使用 view 方法改变张量的尺寸。<br>如果view方法改变尺寸失败，可以使用reshape方法.</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"># 使用view可以改变张量尺寸<br>vector = torch.arange(0,12)<br>print(vector)<br>print(vector.shape)<br><br>matrix34 = vector.view(3,4)<br>print(matrix34)<br>print(matrix34.shape)<br><br>matrix43 = vector.view(4,-1) #-1表示该位置长度由程序自动推断<br>print(matrix43)<br>print(matrix43.shape)<br><br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])</span><br><span class="hljs-code">torch.Size([12])</span><br><span class="hljs-code">tensor([[ 0,  1,  2,  3],</span><br><span class="hljs-code">        [ 4,  5,  6,  7],</span><br><span class="hljs-code">        [ 8,  9, 10, 11]])</span><br><span class="hljs-code">torch.Size([3, 4])</span><br><span class="hljs-code">tensor([[ 0,  1,  2],</span><br><span class="hljs-code">        [ 3,  4,  5],</span><br><span class="hljs-code">        [ 6,  7,  8],</span><br><span class="hljs-code">        [ 9, 10, 11]])</span><br><span class="hljs-code">torch.Size([4, 3])</span><br>&#x27;&#x27;&#x27;<br><br># 有些操作会让张量存储结构扭曲，直接使用view会失败，可以用reshape方法<br>matrix26 = torch.arange(0,12).view(2,6)<br>print(matrix26)<br>print(matrix26.shape)<br><br># 转置操作让张量存储结构扭曲<br>matrix62 = matrix26.t()<br>print(matrix62.is_contiguous())<br><br># 直接使用view方法会失败，可以使用reshape方法<br>#matrix34 = matrix62.view(3,4) #error!<br>matrix34 = matrix62.reshape(3,4) #等价于matrix34 = matrix62.contiguous().view(3,4)<br>print(matrix34)<br><br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor([[ 0,  1,  2,  3,  4,  5],</span><br><span class="hljs-code">        [ 6,  7,  8,  9, 10, 11]])</span><br><span class="hljs-code">torch.Size([2, 6])</span><br><span class="hljs-code">False</span><br><span class="hljs-code">tensor([[ 0,  6,  1,  7],</span><br><span class="hljs-code">        [ 2,  8,  3,  9],</span><br><span class="hljs-code">        [ 4, 10,  5, 11]])</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><h5 id="张量和numpy数组"><a href="#张量和numpy数组" class="headerlink" title="张量和numpy数组"></a>张量和numpy数组</h5><p>可以用numpy方法从Tensor得到numpy数组，也可以用torch.from_numpy从numpy数组得到Tensor。这两种方法关联的Tensor和numpy数组是共享数据内存的。如果改变其中一个，另外一个的值也会发生改变。如果有需要，可以用张量的clone方法拷贝张量，中断这种关联。<br>此外，还可以使用item方法从标量张量得到对应的Python数值。使用tolist方法从张量得到对应的Python数值列表。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#torch.from_numpy函数从numpy数组得到Tensor</span><br>arr = np.zeros(<span class="hljs-number">3</span>)<br>tensor = torch.from_numpy(arr)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;before add 1:&quot;</span>)<br><span class="hljs-built_in">print</span>(arr)<br><span class="hljs-built_in">print</span>(tensor)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nafter add 1:&quot;</span>)<br>np.add(arr,<span class="hljs-number">1</span>, out = arr) <span class="hljs-comment">#给 arr增加1，tensor也随之改变</span><br><span class="hljs-built_in">print</span>(arr)<br><span class="hljs-built_in">print</span>(tensor)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">before add 1:</span><br><span class="hljs-string">[0. 0. 0.]</span><br><span class="hljs-string">tensor([0., 0., 0.], dtype=torch.float64)</span><br><span class="hljs-string"></span><br><span class="hljs-string">after add 1:</span><br><span class="hljs-string">[1. 1. 1.]</span><br><span class="hljs-string">tensor([1., 1., 1.], dtype=torch.float64)</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment"># numpy方法从Tensor得到numpy数组</span><br>tensor = torch.zeros(<span class="hljs-number">3</span>)<br>arr = tensor.numpy()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;before add 1:&quot;</span>)<br><span class="hljs-built_in">print</span>(tensor)<br><span class="hljs-built_in">print</span>(arr)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nafter add 1:&quot;</span>)<br><span class="hljs-comment">#使用带下划线的方法表示计算结果会返回给调用 张量</span><br>tensor.add_(<span class="hljs-number">1</span>) <span class="hljs-comment">#给 tensor增加1，arr也随之改变 </span><br><span class="hljs-comment">#或： torch.add(tensor,1,out = tensor)</span><br><span class="hljs-built_in">print</span>(tensor)<br><span class="hljs-built_in">print</span>(arr)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">before add 1:</span><br><span class="hljs-string">tensor([0., 0., 0.])</span><br><span class="hljs-string">[0. 0. 0.]</span><br><span class="hljs-string"></span><br><span class="hljs-string">after add 1:</span><br><span class="hljs-string">tensor([1., 1., 1.])</span><br><span class="hljs-string">[1. 1. 1.]</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment"># 可以用clone() 方法拷贝张量，中断这种关联</span><br>tensor = torch.zeros(<span class="hljs-number">3</span>)<br><br><span class="hljs-comment">#使用clone方法拷贝张量, 拷贝后的张量和原始张量内存独立</span><br>arr = tensor.clone().numpy() <span class="hljs-comment"># 也可以使用tensor.data.numpy()</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;before add 1:&quot;</span>)<br><span class="hljs-built_in">print</span>(tensor)<br><span class="hljs-built_in">print</span>(arr)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nafter add 1:&quot;</span>)<br><span class="hljs-comment">#使用 带下划线的方法表示计算结果会返回给调用 张量</span><br>tensor.add_(<span class="hljs-number">1</span>) <span class="hljs-comment">#给 tensor增加1，arr不再随之改变</span><br><span class="hljs-built_in">print</span>(tensor)<br><span class="hljs-built_in">print</span>(arr)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">before add 1:</span><br><span class="hljs-string">tensor([0., 0., 0.])</span><br><span class="hljs-string">[0. 0. 0.]</span><br><span class="hljs-string"></span><br><span class="hljs-string">after add 1:</span><br><span class="hljs-string">tensor([1., 1., 1.])</span><br><span class="hljs-string">[0. 0. 0.]</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment"># item方法和tolist方法可以将张量转换成Python数值和数值列表</span><br>scalar = torch.tensor(<span class="hljs-number">1.0</span>)<br>s = scalar.item()<br><span class="hljs-built_in">print</span>(s)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(s))<br><br>tensor = torch.rand(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)<br>t = tensor.tolist()<br><span class="hljs-built_in">print</span>(t)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(t))<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">1.0</span><br><span class="hljs-string">&lt;class &#x27;float&#x27;&gt;</span><br><span class="hljs-string">[[0.5526873469352722, 0.46957558393478394], [0.6724914312362671, 0.26923561096191406]]</span><br><span class="hljs-string">&lt;class &#x27;list&#x27;&gt;</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第一个python包</title>
    <link href="/2021/12/29/%E7%AC%AC%E4%B8%80%E4%B8%AApython%E5%8C%85/"/>
    <url>/2021/12/29/%E7%AC%AC%E4%B8%80%E4%B8%AApython%E5%8C%85/</url>
    
    <content type="html"><![CDATA[<h2 id="Senior-Data-Structure-Tools–SDStools"><a href="#Senior-Data-Structure-Tools–SDStools" class="headerlink" title="Senior Data Structure Tools–SDStools"></a>Senior Data Structure Tools–SDStools</h2><span id="more"></span><p>python标准库中没有链表、树、图等高级数据结构，所以整理了一些网上的代码到这个库中。</p><h5 id="链表："><a href="#链表：" class="headerlink" title="链表："></a>链表：</h5><ul><li><a href="https://zhuanlan.zhihu.com/p/60057180">https://zhuanlan.zhihu.com/p/60057180</a></li><li><a href="https://jackkuo666.github.io/Data_Structure_with_Python_book/chapter3/section1.html">https://jackkuo666.github.io/Data_Structure_with_Python_book/chapter3/section1.html</a></li></ul><h5 id="如何发布包到pypi"><a href="#如何发布包到pypi" class="headerlink" title="如何发布包到pypi"></a>如何发布包到pypi</h5><p>我的项目目录结构如下：<br><img src="/img/article/py.jpg"></p><p>打包主要就是setup的编写</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs clean">setup(<br>    name=NAME,<br>    version=about[<span class="hljs-string">&#x27;__version__&#x27;</span>],<br>    description=DESCRIPTION,<br>    long_description=long_description,<br>    long_description_content_type=<span class="hljs-string">&#x27;text/markdown&#x27;</span>,<br>    author=AUTHOR,<br>    author_email=EMAIL,<br>    python_requires=REQUIRES_PYTHON,<br>    url=URL,<br>    packages=find_packages(),                ## 必须，如果需要打包test文件夹或其他可参考下面格式进行添加<br>    # packages=find_packages(exclude=[<span class="hljs-string">&quot;tests&quot;</span>, <span class="hljs-string">&quot;*.tests&quot;</span>, <span class="hljs-string">&quot;*.tests.*&quot;</span>, <span class="hljs-string">&quot;tests.*&quot;</span>]),<br>    # If your package is a single <span class="hljs-keyword">module</span>, use this instead <span class="hljs-keyword">of</span> <span class="hljs-string">&#x27;packages&#x27;</span>:<br>    # py_modules=[<span class="hljs-string">&#x27;SDStools&#x27;</span>],<br><br>    # entry_points=&#123;<br>    #     <span class="hljs-string">&#x27;console_scripts&#x27;</span>: [<span class="hljs-string">&#x27;mycli=mymodule:cli&#x27;</span>],<br>    # &#125;,<br>    install_requires=REQUIRED,<br>    extras_require=EXTRAS,<br>    # package_data=&#123;<br>    #     # include json and pkl files<br>    #     <span class="hljs-string">&#x27;&#x27;</span>: [<span class="hljs-string">&#x27;*.json&#x27;</span>, <span class="hljs-string">&#x27;models/*.pkl&#x27;</span>, <span class="hljs-string">&#x27;models/*.json&#x27;</span>],<br>    # &#125;,<br>    include_package_data=<span class="hljs-literal">True</span>,<br>    license=<span class="hljs-string">&#x27;MIT&#x27;</span>,<br>    classifiers=[<br>        # Trove classifiers<br>        # Full list: https:<span class="hljs-comment">//pypi.python.org/pypi?%3Aaction=list_classifiers</span><br>        <span class="hljs-string">&#x27;License :: OSI Approved :: MIT License&#x27;</span>,<br>        <span class="hljs-string">&#x27;Programming Language :: Python&#x27;</span>,<br>        <span class="hljs-string">&#x27;Programming Language :: Python :: 3&#x27;</span>,<br>        <span class="hljs-string">&#x27;Programming Language :: Python :: 3.6&#x27;</span>,<br>        <span class="hljs-string">&#x27;Programming Language :: Python :: Implementation :: CPython&#x27;</span>,<br>        <span class="hljs-string">&#x27;Programming Language :: Python :: Implementation :: PyPy&#x27;</span><br>    ],<br>    # $ setup.py publish support.<br>    cmdclass=&#123;<br>        <span class="hljs-string">&#x27;upload&#x27;</span>: UploadCommand,<br>    &#125;,<br>)<br></code></pre></td></tr></table></figure><p>编写完可以进行本地打包安装测试：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">python setup.py <span class="hljs-keyword">build </span>    <span class="hljs-comment"># 执行构建, 会将包的内容构建到 build 文件夹下。</span><br></code></pre></td></tr></table></figure><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">python setup.py <span class="hljs-keyword">install</span>  <span class="hljs-comment"># 会将包直接安装到当前解释器的 site-packages 下，安装完成后即可以使用 pip list 命令查看到。</span><br></code></pre></td></tr></table></figure><p>如果没什么问题的话就可以提交到pypi了。</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">python</span> setup.<span class="hljs-keyword">py</span> sdist  ## 打包<br>twine upload dist/*    ## 发布<br># <span class="hljs-keyword">python</span> setup.<span class="hljs-keyword">py</span> upload   ## 如果setup.<span class="hljs-keyword">py</span>里有upload命令也可一键执行打包发布<br></code></pre></td></tr></table></figure><p>参考：</p><ul><li><a href="https://www.jiqizhixin.com/articles/19060901">https://www.jiqizhixin.com/articles/19060901</a></li><li><a href="https://zhuanlan.zhihu.com/p/66603015">https://zhuanlan.zhihu.com/p/66603015</a></li><li><a href="https://zhuanlan.zhihu.com/p/66603015">https://zhuanlan.zhihu.com/p/66603015</a></li></ul><h5 id="源码地址"><a href="#源码地址" class="headerlink" title="源码地址"></a>源码地址</h5><ul><li><a href="https://github.com/shubihu/SDSTools">https://github.com/shubihu/SDSTools</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LeetCode</title>
    <link href="/2021/12/28/leetcode/"/>
    <url>/2021/12/28/leetcode/</url>
    
    <content type="html"><![CDATA[<h2 id="力扣笔记"><a href="#力扣笔记" class="headerlink" title="力扣笔记"></a>力扣笔记</h2><span id="more"></span><h5 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h5><p>给定一个字符串 s ，其中包含字母顺序打乱的用英文单词表示的若干数字（0-9）。按 升序 返回原始的数字。例如：输入：s = “owoztneoer”，输出：”012”。<br>原题地址：<a href="https://leetcode-cn.com/problems/reconstruct-original-digits-from-english/">https://leetcode-cn.com/problems/reconstruct-original-digits-from-english/</a></p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs vim">### 我的方案，使用了递归，，但依然很惨，没通过力扣的检验（超出时间限制）<br><br>def originalDigits(s):<br>    en_num = &#123;<span class="hljs-string">&#x27;zero&#x27;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&#x27;one&#x27;</span>:<span class="hljs-number">1</span>,<span class="hljs-string">&#x27;two&#x27;</span>:<span class="hljs-number">2</span>, <span class="hljs-string">&#x27;three&#x27;</span>:<span class="hljs-number">3</span>,<span class="hljs-string">&#x27;four&#x27;</span>:<span class="hljs-number">4</span>,<span class="hljs-string">&#x27;five&#x27;</span>:<span class="hljs-number">5</span>,<span class="hljs-string">&#x27;six&#x27;</span>:<span class="hljs-number">6</span>,<span class="hljs-string">&#x27;seven&#x27;</span>:<span class="hljs-number">7</span>,<br>    <span class="hljs-string">&#x27;eight&#x27;</span>:<span class="hljs-number">8</span>,<span class="hljs-string">&#x27;nine&#x27;</span>:<span class="hljs-number">9</span>&#125;<br><br>    ss = []<br>    <span class="hljs-keyword">for</span> <span class="hljs-keyword">k</span>, v in en_num.<span class="hljs-built_in">items</span>():<br>        <span class="hljs-keyword">l</span> = <span class="hljs-built_in">len</span>(<span class="hljs-keyword">k</span>)<br>        <span class="hljs-keyword">c</span> = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i in <span class="hljs-keyword">k</span>:<br>            <span class="hljs-keyword">if</span> i in <span class="hljs-variable">s:</span><br>                <span class="hljs-keyword">c</span> += <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">c</span> == <span class="hljs-variable">l:</span><br>            ss.<span class="hljs-keyword">append</span>(str(v))<br>            <span class="hljs-keyword">for</span> <span class="hljs-keyword">j</span> in <span class="hljs-keyword">k</span>:<br>                s = s.replace(<span class="hljs-keyword">j</span>, <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">if</span> <span class="hljs-variable">s:</span><br>        ss.<span class="hljs-keyword">append</span>(originalDigits(s))<br>        ss.<span class="hljs-keyword">sort</span>()<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;&#x27;</span>.<span class="hljs-keyword">join</span>(ss)<br>    <span class="hljs-keyword">else</span>:<br>        ss.<span class="hljs-keyword">sort</span>()<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;&#x27;</span>.<span class="hljs-keyword">join</span>(ss)<br></code></pre></td></tr></table></figure><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs prolog">## 力扣方案<br><br>class <span class="hljs-symbol">Solution</span>:<br>    def originalDigits(self, s: str) -&gt; str:<br>        c = <span class="hljs-symbol">Counter</span>(s)<br><br>        cnt = [<span class="hljs-number">0</span>] * <span class="hljs-number">10</span><br>        cnt[<span class="hljs-number">0</span>] = c[<span class="hljs-string">&quot;z&quot;</span>]<br>        cnt[<span class="hljs-number">2</span>] = c[<span class="hljs-string">&quot;w&quot;</span>]<br>        cnt[<span class="hljs-number">4</span>] = c[<span class="hljs-string">&quot;u&quot;</span>]<br>        cnt[<span class="hljs-number">6</span>] = c[<span class="hljs-string">&quot;x&quot;</span>]<br>        cnt[<span class="hljs-number">8</span>] = c[<span class="hljs-string">&quot;g&quot;</span>]<br><br>        cnt[<span class="hljs-number">3</span>] = c[<span class="hljs-string">&quot;h&quot;</span>] - cnt[<span class="hljs-number">8</span>]<br>        cnt[<span class="hljs-number">5</span>] = c[<span class="hljs-string">&quot;f&quot;</span>] - cnt[<span class="hljs-number">4</span>]<br>        cnt[<span class="hljs-number">7</span>] = c[<span class="hljs-string">&quot;s&quot;</span>] - cnt[<span class="hljs-number">6</span>]<br>        <br>        cnt[<span class="hljs-number">1</span>] = c[<span class="hljs-string">&quot;o&quot;</span>] - cnt[<span class="hljs-number">0</span>] - cnt[<span class="hljs-number">2</span>] - cnt[<span class="hljs-number">4</span>]<br><br>        cnt[<span class="hljs-number">9</span>] = c[<span class="hljs-string">&quot;i&quot;</span>] - cnt[<span class="hljs-number">5</span>] - cnt[<span class="hljs-number">6</span>] - cnt[<span class="hljs-number">8</span>]<br><br>        return <span class="hljs-string">&quot;&quot;</span>.join(str(x) * cnt[x] for x in range(<span class="hljs-number">10</span>))<br></code></pre></td></tr></table></figure><p>如果单看这个代码的话我依然看不懂，还是要看解释，解释在上面的网址里都有。反正这个题确实挺考验智商的吧，我这智商还是洗洗睡了。</p><h5 id="题目描述：-1"><a href="#题目描述：-1" class="headerlink" title="题目描述："></a>题目描述：</h5><p>无重复字符串的排列组合。编写一种方法，计算某字符串的所有排列组合，字符串每个字符均不相同。<br>例如输入字符串abc,则打印出由字符a,b,c所能排列出来的所有字符串abc,acb,bac,bca,cab和cba。<br>原题地址：<a href="https://leetcode-cn.com/problems/permutation-i-lcci/">https://leetcode-cn.com/problems/permutation-i-lcci/</a><br>python的itertools包中的permutations函数可以实现。</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs maxima">### itertools.<span class="hljs-built_in">permutations</span>函数源码如下<br><br>def <span class="hljs-built_in">permutation</span>(iterable, r=None):<br>    #  r:<span class="hljs-built_in">length</span> <span class="hljs-built_in">permutations</span> of elements <span class="hljs-keyword">in</span> the iterable<br>    # <span class="hljs-built_in">permutations</span>(&#x27;ABCD&#x27;, <span class="hljs-number">2</span>) --&gt; AB AC AD BA BC BD CA CB CD DA DB DC<br>    # <span class="hljs-built_in">permutations</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>)) --&gt; <span class="hljs-number">012</span> <span class="hljs-number">021</span> <span class="hljs-number">102</span> <span class="hljs-number">120</span> <span class="hljs-number">201</span> <span class="hljs-number">210</span><br>    pool = tuple(iterable)<br>    n = len(pool)<br>    r = n <span class="hljs-keyword">if</span> r <span class="hljs-built_in">is</span> None <span class="hljs-keyword">else</span> r<br>    <span class="hljs-keyword">if</span> r &gt; n:<br>        <span class="hljs-built_in">return</span><br>    <span class="hljs-built_in">indices</span> = list(<span class="hljs-built_in">range</span>(n))<br>    cycles = list(<span class="hljs-built_in">range</span>(n, n-r, -<span class="hljs-number">1</span>))<br>    yield tuple(pool[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">indices</span>[:r])<br>    <span class="hljs-keyword">while</span> n:<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> reversed(<span class="hljs-built_in">range</span>(r)):<br>            cycles[i] -= <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> cycles[i] == <span class="hljs-number">0</span>:<br>                <span class="hljs-built_in">indices</span>[i:] = <span class="hljs-built_in">indices</span>[i+<span class="hljs-number">1</span>:] + <span class="hljs-built_in">indices</span>[i:i+<span class="hljs-number">1</span>]<br>                cycles[i] = n - i<br>            <span class="hljs-keyword">else</span>:<br>                j = cycles[i]<br>                <span class="hljs-built_in">indices</span>[i], <span class="hljs-built_in">indices</span>[-j] = <span class="hljs-built_in">indices</span>[-j], <span class="hljs-built_in">indices</span>[i]<br>                yield tuple(pool[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">indices</span>[:r])<br>                <span class="hljs-built_in">break</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-built_in">return</span><br></code></pre></td></tr></table></figure><p>源码还是挺复杂的，，，，，</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs go">### 力扣方法，也是递归<br><br>def permutation(S):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(S)==<span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">return</span> [S]<br>        ans=[]<br>        <span class="hljs-keyword">for</span> i in <span class="hljs-keyword">range</span>(<span class="hljs-built_in">len</span>(S)):<br>            s=S[:i]+S[i+<span class="hljs-number">1</span>:]              <br>            <span class="hljs-keyword">for</span> <span class="hljs-keyword">string</span> in permutation(s):<br>                ans.<span class="hljs-built_in">append</span>(S[i]+<span class="hljs-keyword">string</span>)<br>        <span class="hljs-keyword">return</span> ans<br></code></pre></td></tr></table></figure><h5 id="题目描述：-2"><a href="#题目描述：-2" class="headerlink" title="题目描述："></a>题目描述：</h5><p>给定两个单词 word1 和 word2，请计算出 word1 与 word2 的最长公共字串长度。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">word1</span> = &#x27;abcfdg&#x27;<br><span class="hljs-attribute">word2</span> = &#x27;bcfdkhi&#x27;<br><br><span class="hljs-attribute">def</span> comm_len(word<span class="hljs-number">1</span>, word<span class="hljs-number">2</span>):<br>    <span class="hljs-attribute">c</span> = <span class="hljs-number">0</span><br>    <span class="hljs-attribute">for</span> i in range(len(word<span class="hljs-number">1</span>)):<br>        <span class="hljs-attribute">if</span> word[i-c:i+<span class="hljs-number">1</span>] in word<span class="hljs-number">2</span>:<br>            <span class="hljs-attribute">c</span> += <span class="hljs-number">1</span><br><br>    <span class="hljs-attribute">return</span> c<br><br></code></pre></td></tr></table></figure><h5 id="题目描述：-3"><a href="#题目描述：-3" class="headerlink" title="题目描述："></a>题目描述：</h5><p>快速排序</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">arr = <span class="hljs-literal">[<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">12</span>, <span class="hljs-number">32</span>, <span class="hljs-number">198</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">15</span>, <span class="hljs-number">112</span>, <span class="hljs-number">132</span>]</span><br><br>def quick<span class="hljs-constructor">_sort(<span class="hljs-params">arr</span>)</span>:<br>    <span class="hljs-keyword">if</span> len(arr) &lt;= <span class="hljs-number">1</span>:<br>        return arr<br>    tmp = arr<span class="hljs-literal">[<span class="hljs-number">0</span>]</span><br>    left = <span class="hljs-literal">[<span class="hljs-identifier">i</span> <span class="hljs-identifier">for</span> <span class="hljs-identifier">i</span> <span class="hljs-identifier">in</span> <span class="hljs-identifier">arr</span>[<span class="hljs-number">1</span>:]</span> <span class="hljs-keyword">if</span> i &lt; tmp]<br>    right = <span class="hljs-literal">[<span class="hljs-identifier">i</span> <span class="hljs-identifier">for</span> <span class="hljs-identifier">i</span> <span class="hljs-identifier">in</span> <span class="hljs-identifier">arr</span>[<span class="hljs-number">1</span>:]</span> <span class="hljs-keyword">if</span> i &gt; tmp]<br>    return quick<span class="hljs-constructor">_sort(<span class="hljs-params">left</span>)</span> + <span class="hljs-literal">[<span class="hljs-identifier">tmp</span>]</span> + quick<span class="hljs-constructor">_sort(<span class="hljs-params">right</span>)</span><br><br>print(quick<span class="hljs-constructor">_sort(<span class="hljs-params">arr</span>)</span>)<br></code></pre></td></tr></table></figure><h5 id="题目描述：-4"><a href="#题目描述：-4" class="headerlink" title="题目描述："></a>题目描述：</h5><p>归并排序应用</p><ul><li><p>1、将两个有序数组合并成一个有序数组</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver"><span class="hljs-keyword">a</span> = [<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">5</span>,<span class="hljs-number">7</span>]<br>b = [<span class="hljs-number">2</span>,<span class="hljs-number">6</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>]<br><br>def <span class="hljs-built_in">merge</span>(left, <span class="hljs-literal">right</span>):<br>    <span class="hljs-string">&#x27;&#x27;</span><span class="hljs-string">&#x27;合并操作，将两个有序数组left[]和right[]合并成一个大的有序数组&#x27;</span><span class="hljs-string">&#x27;&#x27;</span><br>    <span class="hljs-comment">#left与right的下标指针</span><br>    l, r = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>    <span class="hljs-built_in">result</span> = []<br>    <span class="hljs-keyword">while</span> l&lt;<span class="hljs-built_in">len</span>(left) <span class="hljs-keyword">and</span> r&lt;<span class="hljs-built_in">len</span>(<span class="hljs-literal">right</span>):<br>        <span class="hljs-keyword">if</span> left[l] &lt; <span class="hljs-literal">right</span>[r]:<br>            <span class="hljs-built_in">result</span>.append(left[l])<br>            l += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-built_in">result</span>.append(<span class="hljs-literal">right</span>[r])<br>            r += <span class="hljs-number">1</span><br>    <span class="hljs-built_in">result</span> += left[l:]<br>    <span class="hljs-built_in">result</span> += <span class="hljs-literal">right</span>[r:]<br>    <span class="hljs-literal">return</span> <span class="hljs-built_in">result</span><br><br>print(<span class="hljs-built_in">merge</span>(<span class="hljs-keyword">a</span>, b))<br></code></pre></td></tr></table></figure></li><li><ol start="2"><li>每个 SNP 位点用一个长度为 2 的 list 表示，第一个元素为染色体编号（chr，范围为<br>1~22），第二个元素为染色体上的位置（pos）。写一个 python 函数，输入两个正序（按<br>chr 和 pos 排序）的 SNP 位点 list，输出一个合并且去重的正序 SNP 位点 list。不能使用<br>sorted 函数、pandas 库，要求时间复杂度尽可能低。<br>例如：<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs lua">Input: list1 = <span class="hljs-string">[[1,230], [1,4000], [2,500]]</span>, list2 = <span class="hljs-string">[[2,320], [6,70]]</span><br>Output: <span class="hljs-string">[[1,230], [1,4000], [2,320], [2,500], [6,70]]</span><br></code></pre></td></tr></table></figure></li></ol></li></ul><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">list1</span> =<span class="hljs-meta"> [[1,230], [1,4000], [2,500]]</span><br><span class="hljs-attribute">list2</span> =<span class="hljs-meta"> [[2,320], [6,70]]</span><br><br><span class="hljs-attribute">def</span> merge(list<span class="hljs-number">1</span>, list<span class="hljs-number">2</span>):<br>    <span class="hljs-attribute">l</span>, r = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>    <span class="hljs-attribute">result</span> =<span class="hljs-meta"> []</span><br>    <span class="hljs-attribute">while</span> l&lt;len(list<span class="hljs-number">1</span>) and r&lt;len(list<span class="hljs-number">2</span>):<br>        <span class="hljs-attribute">if</span> list<span class="hljs-number">1</span>[l][<span class="hljs-number">0</span>] &lt; list<span class="hljs-number">2</span>[r][<span class="hljs-number">0</span>]:<br>            <span class="hljs-attribute">if</span> list<span class="hljs-number">1</span>[l] not in result:<br>                <span class="hljs-attribute">result</span>.append(list<span class="hljs-number">1</span>[l])<br>            <span class="hljs-attribute">l</span> += <span class="hljs-number">1</span><br>        <span class="hljs-attribute">else</span>:<br>            <span class="hljs-attribute">if</span> list<span class="hljs-number">2</span>[r] not in result:<br>                <span class="hljs-attribute">result</span>.append(list<span class="hljs-number">2</span>[r])<br>            <span class="hljs-attribute">r</span> += <span class="hljs-number">1</span><br><br>    <span class="hljs-attribute">result</span> += list<span class="hljs-number">1</span>[l:]<br>    <span class="hljs-attribute">result</span> += list<span class="hljs-number">2</span>[r:]<br>    <span class="hljs-attribute">return</span> result<br><br><span class="hljs-attribute">print</span>(merge(list<span class="hljs-number">1</span>, list<span class="hljs-number">2</span>))<br></code></pre></td></tr></table></figure><h5 id="题目描述：-5"><a href="#题目描述：-5" class="headerlink" title="题目描述："></a>题目描述：</h5><p>输出单向链表中倒数第k个结点</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Node</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, val=<span class="hljs-number">0</span></span>):</span><br>        self.val = val<br>        self.<span class="hljs-built_in">next</span> = <span class="hljs-literal">None</span><br><br><br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    <span class="hljs-keyword">try</span>:<br>        l, s, k, head = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>()), <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, <span class="hljs-built_in">input</span>().split())), <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>()), Node()<br>        <span class="hljs-keyword">while</span> k:<br>            head.<span class="hljs-built_in">next</span> = Node(s.pop())<br>            head = head.<span class="hljs-built_in">next</span><br>            k -= <span class="hljs-number">1</span><br>        <span class="hljs-built_in">print</span>(head.val)<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure><h5 id="题目描述：-6"><a href="#题目描述：-6" class="headerlink" title="题目描述："></a>题目描述：</h5><p>给定两个单词 word1 和 word2，请计算出将 word1 转换成 word2 所使用的最少操作数。<br>参考：<a href="https://www.jianshu.com/p/9a53f32cf62b">https://www.jianshu.com/p/9a53f32cf62b</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">editDistance</span>(<span class="hljs-params">str1, str2</span>):</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    计算字符串str1和str2的编辑距离</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    edit = [[i+j <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(str2)+<span class="hljs-number">1</span>)] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(str1)+<span class="hljs-number">1</span>)]<br>    <span class="hljs-built_in">print</span>(edit)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(str1)+<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(str2)+<span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">if</span> str1[i-<span class="hljs-number">1</span>] == str2[j-<span class="hljs-number">1</span>]:<br>                d = <span class="hljs-number">0</span><br>            <span class="hljs-keyword">else</span>:<br>                d = <span class="hljs-number">1</span><br>            edit[i][j] = <span class="hljs-built_in">min</span>(edit[i-<span class="hljs-number">1</span>][j]+<span class="hljs-number">1</span>,edit[i][j-<span class="hljs-number">1</span>]+<span class="hljs-number">1</span>,edit[i-<span class="hljs-number">1</span>][j-<span class="hljs-number">1</span>]+d)<br>    <span class="hljs-keyword">return</span> edit[<span class="hljs-built_in">len</span>(str1)][<span class="hljs-built_in">len</span>(str2)]<br><br>editDistance(<span class="hljs-string">&#x27;python&#x27;</span>, <span class="hljs-string">&#x27;pyton&#x27;</span>)<br></code></pre></td></tr></table></figure><h5 id="题目描述：-7"><a href="#题目描述：-7" class="headerlink" title="题目描述："></a>题目描述：</h5><ul><li><p>最长回文字串</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs stylus">s = <span class="hljs-selector-tag">input</span>()<br>win_len = <span class="hljs-number">2</span><br>s_list = <span class="hljs-selector-attr">[]</span><br><span class="hljs-keyword">for</span> <span class="hljs-selector-tag">i</span> <span class="hljs-keyword">in</span> range(len(s)):<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(i+<span class="hljs-number">1</span>, len(s) + <span class="hljs-number">1</span>):<br>        ss = s<span class="hljs-selector-attr">[i:j]</span><br>        <span class="hljs-keyword">if</span> ss == ss<span class="hljs-selector-attr">[::-1]</span>:<br>            s_list<span class="hljs-selector-class">.append</span>(len(ss))<br>            <br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(max(s_list)</span></span>)<br></code></pre></td></tr></table></figure></li><li><p>输入两个 DNA 序列，输出它们的最长公共序列。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Input</span>: seq<span class="hljs-number">1</span> = “AGGCT”, seq<span class="hljs-number">2</span> = “GGCA”<br><span class="hljs-attribute">Output</span>: “GGC”<br></code></pre></td></tr></table></figure></li></ul><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">seq1</span> = &#x27;AGGCT&#x27;<br><span class="hljs-attribute">seq2</span> = &#x27;GGCA&#x27;<br><br><span class="hljs-attribute">def</span> comm_len(seq<span class="hljs-number">1</span>, seq<span class="hljs-number">2</span>):<br>    <span class="hljs-attribute">c</span> = <span class="hljs-number">0</span><br>    <span class="hljs-attribute">seq_list</span> =<span class="hljs-meta"> []</span><br>    <span class="hljs-attribute">for</span> i in range(len(seq<span class="hljs-number">1</span>)):<br>        <span class="hljs-attribute">tmp</span> = seq<span class="hljs-number">1</span>[i-c:i+<span class="hljs-number">1</span>]<br>        <span class="hljs-attribute">if</span> tmp in seq<span class="hljs-number">2</span>:<br>            <span class="hljs-attribute">c</span> += <span class="hljs-number">1</span><br>            <span class="hljs-attribute">seq_list</span>.append(tmp)<br><br>          <br>    <span class="hljs-attribute">return</span> seq_list[-<span class="hljs-number">1</span>]<br><br><span class="hljs-attribute">print</span>(comm_len(seq<span class="hljs-number">1</span>, seq<span class="hljs-number">2</span>))<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>leetcode</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VIP视频解析手机端</title>
    <link href="/2021/12/24/VIP%E8%A7%86%E9%A2%91%E8%A7%A3%E6%9E%90%E6%89%8B%E6%9C%BA%E7%AB%AF/"/>
    <url>/2021/12/24/VIP%E8%A7%86%E9%A2%91%E8%A7%A3%E6%9E%90%E6%89%8B%E6%9C%BA%E7%AB%AF/</url>
    
    <content type="html"><![CDATA[<h2 id="薅各大厂视频羊毛——手机端"><a href="#薅各大厂视频羊毛——手机端" class="headerlink" title="薅各大厂视频羊毛——手机端"></a>薅各大厂视频羊毛——手机端</h2><span id="more"></span><p>以前都是用电脑端Chrome浏览器安装油猴插件及其相应的脚本看视频，但是如果想用电视看视频，用电脑投屏终究是有点麻烦。找了许久还是让我找到了手机端可以使用脚本的浏览器。<br>使用方法也可以直接跳转该地址：<br><a href="https://blog.csdn.net/qq_37759464/article/details/121903038?utm_source=app&amp;app_version=4.20.0&amp;code=app_1562916241&amp;uLinkId=usr1mkqgl919blen">https://blog.csdn.net/qq_37759464/article/details/121903038?utm_source=app&amp;app_version=4.20.0&amp;code=app_1562916241&amp;uLinkId=usr1mkqgl919blen</a></p><p>个人推荐的话：安卓可以使用Via浏览器，真的很简约，官网也一样的简约（<a href="https://viayoo.com/zh-cn/%EF%BC%89%EF%BC%8C%E8%80%8C%E4%B8%94%E4%BA%B2%E6%B5%8B%E5%8F%AF%E4%BB%A5%E5%AE%9E%E7%8E%B0VIP%E8%A7%86%E9%A2%91%E8%A7%A3%E6%9E%90%E3%80%82%E8%8B%B9%E6%9E%9CIOS%E7%AB%AF%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8Alook%EF%BC%8C%E4%B8%8D%E8%BF%87%E8%BF%99%E4%B8%AA%E8%BD%AF%E4%BB%B6%E4%B8%8D%E6%98%AF%E5%85%8D%E8%B4%B9%E7%9A%84%EF%BC%88%E7%8E%B0%E5%9C%A8%E7%96%AB%E6%83%85%E6%90%9E%E5%8D%8A%E4%BB%B7%E6%B4%BB%E5%8A%A86%E5%85%83%EF%BC%8C%E4%B8%8D%E8%BF%87%E6%94%AF%E4%BB%98%E5%AE%9D%E6%9C%89%E6%97%B6%E5%80%99%E4%BC%9A%E6%9C%89%E8%8B%B9%E6%9E%9CAppstore%E6%B6%88%E8%B4%B9%E5%88%B8%EF%BC%8C%E6%AF%94%E5%A6%82%E4%BF%BA%E4%BB%8A%E5%A4%A9%E9%A2%86%E4%BA%869%E5%85%83%EF%BC%8C%E6%9E%9C%E6%96%AD%E5%85%A5%E6%89%8B%E7%99%BD%E6%8D%A1%E4%BA%86%E8%BF%99%E4%B8%AA%E6%B5%8F%E8%A7%88%E5%99%A8%EF%BC%89%E3%80%82">https://viayoo.com/zh-cn/），而且亲测可以实现VIP视频解析。苹果IOS端可以使用Alook，不过这个软件不是免费的（现在疫情搞半价活动6元，不过支付宝有时候会有苹果Appstore消费券，比如俺今天领了9元，果断入手白捡了这个浏览器）。</a></p><p>安装好浏览器后就是安装脚本了，上面的地址里有详细的方法，脚本的地址在此：<br><a href="https://greasyfork.org/zh-CN/scripts/435698-%E5%85%A8%E7%BD%91vip%E8%A7%86%E9%A2%91%E8%87%AA%E5%8A%A8%E8%A7%A3%E6%9E%90%E6%92%AD%E6%94%BE%E5%99%A8-%E5%B7%B2%E9%80%82%E9%85%8D%E6%89%8B%E6%9C%BA%E3%80%82">https://greasyfork.org/zh-CN/scripts/435698-%E5%85%A8%E7%BD%91vip%E8%A7%86%E9%A2%91%E8%87%AA%E5%8A%A8%E8%A7%A3%E6%9E%90%E6%92%AD%E6%94%BE%E5%99%A8-%E5%B7%B2%E9%80%82%E9%85%8D%E6%89%8B%E6%9C%BA。</a></p><p>说下我安装过程中遇到的问题吧，就是全选复制那块，不知道为啥就是不能全选，没办法只能慢慢拖拽光标进行全选然后复制（脚本是真长）。</p><p>手机投屏的话，安卓可以用乐播投屏，苹果的话直接用自带的屏幕镜像进行投屏就OK了。</p><p>当然了如果有钱开VIP就可以直接忽略本文啦，不过爱奇艺又要涨价了。</p>]]></content>
    
    
    <categories>
      
      <category>TroubleShoot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>薅羊毛</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JupyterNotebook远程云服务器</title>
    <link href="/2021/11/30/jupyter/"/>
    <url>/2021/11/30/jupyter/</url>
    
    <content type="html"><![CDATA[<h2 id="搭建Jupyter-Notebook远程云服务器"><a href="#搭建Jupyter-Notebook远程云服务器" class="headerlink" title="搭建Jupyter Notebook远程云服务器"></a>搭建Jupyter Notebook远程云服务器</h2><span id="more"></span><h5 id="安装Jupyter"><a href="#安装Jupyter" class="headerlink" title="安装Jupyter"></a>安装Jupyter</h5><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs verilog">pip install Jupyter<br>jupyter notebook --<span class="hljs-keyword">generate</span>-<span class="hljs-keyword">config</span><br></code></pre></td></tr></table></figure><h5 id="设置密码用于设置服务器配置，以及登录Jupyter。打开Python终端，输入以下："><a href="#设置密码用于设置服务器配置，以及登录Jupyter。打开Python终端，输入以下：" class="headerlink" title="设置密码用于设置服务器配置，以及登录Jupyter。打开Python终端，输入以下："></a>设置密码用于设置服务器配置，以及登录Jupyter。打开Python终端，输入以下：</h5><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">jupyter notebook password</span><br></code></pre></td></tr></table></figure><h5 id="设置服务器配置文件"><a href="#设置服务器配置文件" class="headerlink" title="设置服务器配置文件"></a>设置服务器配置文件</h5><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arcade">vim ~<span class="hljs-regexp">/.jupyter/</span>jupyter_notebook_config.py<br></code></pre></td></tr></table></figure><p>在末尾增加以下几行配置信息</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">c.NotebookApp.ip</span> = <span class="hljs-string">&#x27;*&#x27;</span> <span class="hljs-comment">#所有绑定服务器的IP都能访问，若想只在特定ip访问，输入ip地址即可</span><br><span class="hljs-attr">c.NotebookApp.port</span> = <span class="hljs-number">8888</span> <span class="hljs-comment">#将端口设置为自己喜欢的吧，默认是8888</span><br><span class="hljs-attr">c.NotebookApp.open_browser</span> = <span class="hljs-literal">False</span> <span class="hljs-comment">#我们并不想在服务器上直接打开Jupyter Notebook，所以设置成False</span><br><span class="hljs-attr">c.NotebookApp.notebook_dir</span> = <span class="hljs-string">&#x27;/root/jupyter_projects&#x27;</span> <span class="hljs-comment">#这里是设置Jupyter的根目录，若不设置将默认root的根目录，不安全</span><br><span class="hljs-attr">c.NotebookApp.allow_root</span> = <span class="hljs-literal">True</span> <span class="hljs-comment"># 为了安全，Jupyter默认不允许以root权限启动jupyter </span><br></code></pre></td></tr></table></figure><h5 id="启动Jupyter-远程服务器"><a href="#启动Jupyter-远程服务器" class="headerlink" title="启动Jupyter 远程服务器"></a>启动Jupyter 远程服务器</h5><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">jupyter notebook</span><br></code></pre></td></tr></table></figure><p>至此，Jupyter远程服务器以搭建完毕。在本地浏览器上，输入 ip地址:8888，将会打开远程Jupyter。接下来就可以像在本地一样使用服务器上的Jupyter。</p><p>如果出现不能连接的情况，多半是防火墙的问题。<br>简单粗暴一劳永逸的就是关闭防火墙，当然也可进行设置。参考 <a href="https://www.codeleading.com/article/10462087431/">https://www.codeleading.com/article/10462087431/</a></p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arduino">systemctl stop firewalld.service<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>jupyter</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch模型转paddle模型踩坑记录</title>
    <link href="/2021/11/29/pytorch2paddle/"/>
    <url>/2021/11/29/pytorch2paddle/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><h5 id="踩坑1"><a href="#踩坑1" class="headerlink" title="踩坑1"></a>踩坑1</h5><p>网上有很多使用x2paddle把pytorch转paddle的文章，不过大不部分也都是采用的迂回路线，就是先转ONNX，再转paddle，试了下水，果然没有那么简单的事情，一直报错，最后好像报了个 model not support，，，，遂放弃。</p><h5 id="踩坑2"><a href="#踩坑2" class="headerlink" title="踩坑2"></a>踩坑2</h5><p>使用工具不行只有一步一步慢慢转，这也是最开始使用的方法，起初报错没解决才找到x2paddle的，没想到又回归到最原始的方法了。<br>转换的过程一直卡在网络这块，所以就先把网络这块拿出来记录下。</p><h6 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h6><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs clean">######################### torch 版  ############################<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> SeqNet(nn.Module):<br>    def __init__(self):<br>        super(SeqNet, self).__init__()<br>        # input <br>        self.conv1 = nn.Conv1d(<span class="hljs-number">12</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)<br>        self.conv2 = nn.Conv1d(<span class="hljs-number">12</span>, <span class="hljs-number">10</span>, <span class="hljs-number">200</span>)<br>        self.conv3 = nn.Conv1d(<span class="hljs-number">12</span>, <span class="hljs-number">10</span>, <span class="hljs-number">500</span>)<br>        self.conv4 = nn.Conv1d(<span class="hljs-number">12</span>, <span class="hljs-number">10</span>, <span class="hljs-number">1000</span>)<br>        self.pooling = nn.MaxPool2d((<span class="hljs-number">1</span>, <span class="hljs-number">200</span>))<br>        self.fc1 = nn.Linear(<span class="hljs-number">900</span>, <span class="hljs-number">64</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">1</span>)<br><br>    def forward(self, x):<br>        batch_size = x.size(<span class="hljs-number">0</span>)<br>        <br>        out1 = self.pooling(F.relu(self.conv1(x)))<br>        out2 = self.pooling(F.relu(self.conv2(x)))<br>        out3 = self.pooling(F.relu(self.conv3(x)))<br>        out4 = self.pooling(F.relu(self.conv4(x)))<br><br>        out = torch.cat([out1, out2, out3, out4], <span class="hljs-number">2</span>)<br>        out = out.view(batch_size, <span class="hljs-number">-1</span>)<br>        out = self.fc1(out)<br>        out = F.relu(out)<br>        # out = F.dropout(out, p=<span class="hljs-number">0.2</span>)<br>        out = self.fc2(out)<br>        return out<br></code></pre></td></tr></table></figure><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs clean">######################### paddle 版  ############################<br><span class="hljs-keyword">import</span> paddle<br><span class="hljs-keyword">import</span> paddle.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> paddle.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> SeqNet(nn.Layer):<br>    def __init__(self):<br>        super(SeqNet, self).__init__()<br>        # input <br>        self.conv1 = nn.Conv1D(<span class="hljs-number">12</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)<br>        self.conv2 = nn.Conv1D(<span class="hljs-number">12</span>, <span class="hljs-number">10</span>, <span class="hljs-number">200</span>)<br>        self.conv3 = nn.Conv1D(<span class="hljs-number">12</span>, <span class="hljs-number">10</span>, <span class="hljs-number">500</span>)<br>        self.conv4 = nn.Conv1D(<span class="hljs-number">12</span>, <span class="hljs-number">10</span>, <span class="hljs-number">1000</span>)<br>        # self.pooling = nn.MaxPool2D((<span class="hljs-number">1</span>, <span class="hljs-number">200</span>))   <br>        ### torch版的 nn.MaxPool2D 输入数剧格式为（NCHW 或 CHW）,paddle版的 nn.MaxPool2D 输入数据格式只有 NCHW<br>        ### N代表batch_size， C代表channel，H代表高度，W代表宽度<br>        ### 所以这里用 paddle 的 nn.MaxPool1D 替换了 torch 的 nn.MaxPool2D<br>        self.pooling = nn.MaxPool1D(<span class="hljs-number">200</span>)<br>        self.fc1 = nn.Linear(<span class="hljs-number">900</span>, <span class="hljs-number">64</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">1</span>)<br><br>    def forward(self, x):<br>        ### torch.tensor.size 对应 paddle.tensor.shape<br>        batch_size = x.shape[<span class="hljs-number">0</span>]   <br>        <br>        out1 = self.pooling(F.relu(self.conv1(x)))<br>        out2 = self.pooling(F.relu(self.conv2(x)))<br>        out3 = self.pooling(F.relu(self.conv3(x)))<br>        out4 = self.pooling(F.relu(self.conv4(x)))<br>        <br>        ### torch.cat 对应 paddle.concat<br>        # out = torch.cat([out1, out2, out3, out4], <span class="hljs-number">2</span>)  <br>        out = paddle.concat([out1, out2, out3, out4], <span class="hljs-number">2</span>)<br>        ### torch.tensor.view 对应 paddle.tensor.reshape<br>        # out = out.view(batch_size, <span class="hljs-number">-1</span>)<br>        out = paddle.reshape(out, [batch_size, <span class="hljs-number">-1</span>])<br>        out = self.fc1(out)<br>        out = F.relu(out)<br>        # out = F.dropout(out, p=<span class="hljs-number">0.2</span>)<br>        out = self.fc2(out)<br><br>        return out<br></code></pre></td></tr></table></figure><h6 id="对于自定义数据集-paddle和pytorch实现的方法类似"><a href="#对于自定义数据集-paddle和pytorch实现的方法类似" class="headerlink" title="对于自定义数据集 paddle和pytorch实现的方法类似"></a>对于自定义数据集 paddle和pytorch实现的方法类似</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> paddle.io <span class="hljs-keyword">import</span> Dataset<br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyDataset</span>(<span class="hljs-params">Dataset</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    步骤一：继承paddle.io.Dataset类</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, mode=<span class="hljs-string">&#x27;train&#x27;</span></span>):</span><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        步骤二：实现构造函数，定义数据读取方式，划分训练和测试数据集</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(MyDataset, self).__init__()<br><br>        <span class="hljs-keyword">if</span> mode == <span class="hljs-string">&#x27;train&#x27;</span>:<br>            self.data = [<br>                [<span class="hljs-string">&#x27;traindata1&#x27;</span>, <span class="hljs-string">&#x27;label1&#x27;</span>],<br>                [<span class="hljs-string">&#x27;traindata2&#x27;</span>, <span class="hljs-string">&#x27;label2&#x27;</span>],<br>                [<span class="hljs-string">&#x27;traindata3&#x27;</span>, <span class="hljs-string">&#x27;label3&#x27;</span>],<br>                [<span class="hljs-string">&#x27;traindata4&#x27;</span>, <span class="hljs-string">&#x27;label4&#x27;</span>],<br>            ]<br>        <span class="hljs-keyword">else</span>:<br>            self.data = [<br>                [<span class="hljs-string">&#x27;testdata1&#x27;</span>, <span class="hljs-string">&#x27;label1&#x27;</span>],<br>                [<span class="hljs-string">&#x27;testdata2&#x27;</span>, <span class="hljs-string">&#x27;label2&#x27;</span>],<br>                [<span class="hljs-string">&#x27;testdata3&#x27;</span>, <span class="hljs-string">&#x27;label3&#x27;</span>],<br>                [<span class="hljs-string">&#x27;testdata4&#x27;</span>, <span class="hljs-string">&#x27;label4&#x27;</span>],<br>            ]<br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span>(<span class="hljs-params">self, index</span>):</span><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        步骤三：实现__getitem__方法，定义指定index时如何获取数据，并返回单条数据（训练数据，对应的标签）</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        data = self.data[index][<span class="hljs-number">0</span>]<br>        label = self.data[index][<span class="hljs-number">1</span>]<br><br>        <span class="hljs-keyword">return</span> data, label<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        步骤四：实现__len__方法，返回数据集总数目</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.data)<br></code></pre></td></tr></table></figure><h6 id="还有就是训练这块"><a href="#还有就是训练这块" class="headerlink" title="还有就是训练这块"></a>还有就是训练这块</h6><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs clean">######################### torch 版  ############################<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br>model = SeqNet()<br>model.to(device)<br>optimizer = torch.optim.AdamW(model.parameters(), lr=<span class="hljs-number">1e-4</span> ,weight_decay=<span class="hljs-number">5e-4</span>)<br>scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epoch)<br>criterion = nn.BCEWithLogitsLoss()<br><br>for i, (inputs, labels) <span class="hljs-keyword">in</span> (enumerate(trainloader)):<br>    inputs = inputs.to(device)<br>    labels = labels.float().to(device)<br><br>    out_linear = model(inputs).to(device)<br>    loss = criterion(out_linear, labels.unsqueeze(<span class="hljs-number">1</span>))<br><br>    optimizer.zero_grad()<br>    loss.backward()<br>    optimizer.step()<br></code></pre></td></tr></table></figure><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs clean">######################### paddle 版  ############################<br><span class="hljs-keyword">import</span> paddle<br><span class="hljs-keyword">import</span> paddle.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> paddle.optimizer <span class="hljs-keyword">as</span> optim<br><br>model = SeqNet()<br>model.to(device)<br>optimizer = optim.AdamW(learning_rate=<span class="hljs-number">1e-4</span>, parameters=model.parameters(),weight_decay=<span class="hljs-number">5e-4</span>)<br>### optimizer = optim.Adam(parameters=model.parameters(), learning_rate=<span class="hljs-number">1e-4</span>)<br>### paddle 版CosineAnnealingDecay接収的是 learning_rate参数<br>scheduler = optim.lr.CosineAnnealingDecay(<span class="hljs-number">1e-4</span>, T_max=max_epoch)<br>criterion = nn.BCEWithLogitsLoss()<br><br>for i, (inputs, labels) <span class="hljs-keyword">in</span> (enumerate(trainloader)):<br>    # inputs = inputs.to(device)<br>    inputs = inputs.cuda()<br>    # labels = labels.float().to(device)<br>    labels = labels.cuda()<br>    # labels = paddle.reshape(labels, (<span class="hljs-number">30</span>, <span class="hljs-number">1</span>))<br>    labels = paddle.cast(labels, dtype=<span class="hljs-string">&#x27;float32&#x27;</span>)  ## 转换数据类型<br><br>    out_linear = model(inputs)<br>    out_linear = paddle.reshape(out_linear, (batch_size,))<br>    loss = criterion(out_linear, labels)<br>    # loss = criterion(out_linear, labels.unsqueeze(<span class="hljs-number">1</span>))<br><br>    # optimizer.zero_grad()<br>    loss.backward()<br>    optimizer.step()<br>    optimizer.clear_grad()<br></code></pre></td></tr></table></figure><p>其余剩下就是一些小问题了，直接运行debug改就好了。<br>pytorch 完整版地址：<a href="https://github.com/shubihu/coggle_learn/blob/main/baseline/pytorch.ipynb">https://github.com/shubihu/coggle_learn/blob/main/baseline/pytorch.ipynb</a><br>paddle 完整版地址：<a href="https://github.com/shubihu/coggle_learn/blob/main/baseline/paddle.ipynb">https://github.com/shubihu/coggle_learn/blob/main/baseline/paddle.ipynb</a><br>aistudio上项目的地址为：<a href="https://aistudio.baidu.com/aistudio/projectdetail/2724787?contributionType=1">https://aistudio.baidu.com/aistudio/projectdetail/2724787?contributionType=1</a></p>]]></content>
    
    
    <categories>
      
      <category>TroubleShoot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TroubleShoot</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>mac-iTerm2</title>
    <link href="/2021/11/15/mac-iTerm2/"/>
    <url>/2021/11/15/mac-iTerm2/</url>
    
    <content type="html"><![CDATA[<h2 id="mac-air-m1-终端配置记录"><a href="#mac-air-m1-终端配置记录" class="headerlink" title="mac air m1 终端配置记录"></a>mac air m1 终端配置记录</h2><span id="more"></span><h3 id="安装Homebrew"><a href="#安装Homebrew" class="headerlink" title="安装Homebrew"></a>安装Homebrew</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">/bin/</span>bash -c <span class="hljs-string">&quot;$(curl -fsSL https://cdn.jsdelivr.net/gh/ineo6/homebrew-install/install.sh)&quot;</span><br></code></pre></td></tr></table></figure><p>将以上命令粘贴至终端。脚本内置 中科大镜像，所以能让Homebrew安装的更快。</p><h3 id="安装-oh-my-zsh"><a href="#安装-oh-my-zsh" class="headerlink" title="安装 oh-my-zsh"></a>安装 oh-my-zsh</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sh -c <span class="hljs-string">&quot;<span class="hljs-subst">$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)</span>&quot;</span><br></code></pre></td></tr></table></figure><h3 id="配置-oh-my-zsh"><a href="#配置-oh-my-zsh" class="headerlink" title="配置 oh-my-zsh"></a>配置 oh-my-zsh</h3><p>参考 <a href="https://www.dazhuanlan.com/lyuuawa0508/topics/1599354">https://www.dazhuanlan.com/lyuuawa0508/topics/1599354</a><br>注：其中有些命令可能因为版本问题不一致，主要是cask相关，按照提示修改即可<br>比如 安装 iTerm2 的命令是现在这样</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">brew</span> tap homebrew/cask<br><span class="hljs-attribute">brew</span> install iterm<span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><h3 id="brew-安装-nvm"><a href="#brew-安装-nvm" class="headerlink" title="brew 安装 nvm"></a>brew 安装 nvm</h3><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs clean">brew install nvm<br>mkdir ~/.nvm<br>vi ~/.zshrc<br>#################### 将下面内容添加到 ~/.zshrc 中 #############################<br><span class="hljs-keyword">export</span> NVM_DIR=<span class="hljs-string">&quot;$HOME/.nvm&quot;</span><br>[ -s <span class="hljs-string">&quot;/opt/homebrew/opt/nvm/nvm.sh&quot;</span> ] &amp;&amp; . <span class="hljs-string">&quot;/opt/homebrew/opt/nvm/nvm.sh&quot;</span> # This loads nvm<br>[ -s <span class="hljs-string">&quot;/opt/homebrew/opt/nvm/etc/bash_completion.d/nvm&quot;</span> ] &amp;&amp; . <span class="hljs-string">&quot;/opt/homebrew/opt/nvm/etc/bash_completion.d/nvm&quot;</span> # This loads nvm bash_completion<br>###############################################################################<br>source ~/.zshrc<br></code></pre></td></tr></table></figure><h3 id="github-加速"><a href="#github-加速" class="headerlink" title="github 加速"></a>github 加速</h3><p>参考 <a href="https://brew.idayer.com/guide/github">https://brew.idayer.com/guide/github</a></p>]]></content>
    
    
    <categories>
      
      <category>Mac</category>
      
    </categories>
    
    
    <tags>
      
      <tag>玩</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>科学上网</title>
    <link href="/2021/11/07/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"/>
    <url>/2021/11/07/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><h3 id="Mark一下以防不时之需-https-lncn-org"><a href="#Mark一下以防不时之需-https-lncn-org" class="headerlink" title="Mark一下以防不时之需 https://lncn.org/"></a>Mark一下以防不时之需 <a href="https://lncn.org/">https://lncn.org/</a></h3><p>连接该网站方法如下图所示<br><img src="/img/article/ssr.jpg"></p><h3 id="Window-客户端地址"><a href="#Window-客户端地址" class="headerlink" title="Window 客户端地址"></a>Window 客户端地址</h3><p><a href="https://github.com/shadowsocksrr/shadowsocksr-csharp/releases">https://github.com/shadowsocksrr/shadowsocksr-csharp/releases</a></p><h3 id="Mac-OS-客户端地址"><a href="#Mac-OS-客户端地址" class="headerlink" title="Mac OS 客户端地址"></a>Mac OS 客户端地址</h3><p><a href="https://github.com/wzdnzd/ShadowsocksX-NG-R/releases">https://github.com/wzdnzd/ShadowsocksX-NG-R/releases</a></p>]]></content>
    
    
    <categories>
      
      <category>TroubleShoot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>科学上网</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>核酸检测机构地图微信小程序开发</title>
    <link href="/2021/10/20/%E6%A0%B8%E9%85%B8%E6%A3%80%E6%B5%8B%E6%9C%BA%E6%9E%84%E5%9C%B0%E5%9B%BE%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91/"/>
    <url>/2021/10/20/%E6%A0%B8%E9%85%B8%E6%A3%80%E6%B5%8B%E6%9C%BA%E6%9E%84%E5%9C%B0%E5%9B%BE%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91/</url>
    
    <content type="html"><![CDATA[<h2 id="小程序开发学习"><a href="#小程序开发学习" class="headerlink" title="小程序开发学习"></a>小程序开发学习</h2><span id="more"></span><h5 id="开发（玩）背景"><a href="#开发（玩）背景" class="headerlink" title="开发（玩）背景"></a>开发（玩）背景</h5><p>最近需要做核酸检测，于是想找下附件的机构，但是找了好多都是列表形式的（心里嘀咕了句怎么连附近都看不了，就想着自己做下），不过最后还是找到了带附近功能的小程序，竟然还是国务院客户端。果然还是国家想的周到。虽然找到了这样的小程序自己已经没必要再造轮子了，但是本着学习（玩）的心态还是想着如何重现一下。</p><h5 id="这里也推广下国务院客户端小程序"><a href="#这里也推广下国务院客户端小程序" class="headerlink" title="这里也推广下国务院客户端小程序"></a>这里也推广下国务院客户端小程序</h5><p><img src="/img/article/wechat/%E5%9B%BD%E5%8A%A1%E9%99%A2.jpg"></p><h5 id="最后也算基本实现了这样的功能，贴两张图做个对比吧。"><a href="#最后也算基本实现了这样的功能，贴两张图做个对比吧。" class="headerlink" title="最后也算基本实现了这样的功能，贴两张图做个对比吧。"></a>最后也算基本实现了这样的功能，贴两张图做个对比吧。</h5><p>左边的是国务院客户端，右边是自己做的<br><img src="/img/article/wechat/%E6%A0%B8%E9%85%B8%E6%A3%80%E6%B5%8B.jpg"></p><h5 id="最后再说下开发过程踩过的坑吧"><a href="#最后再说下开发过程踩过的坑吧" class="headerlink" title="最后再说下开发过程踩过的坑吧"></a>最后再说下开发过程踩过的坑吧</h5><p>最主要的坑就是标记在地图上的marker（核酸机构）不显示的问题，首先是经纬度，经度（longitude），维度（latitude），最开始标记点一直没显示就是因为自己把经纬度写反了（关键是后台都不报错）导致一直不显示。其次是经纬度的赋值需是数字类型，字符串类型也是不行的。最后就是服务器域名的配置问题，有些域名比如 <a href="https://apis.map.qq.com/">https://apis.map.qq.com</a> 以及 wx.request 的地址都需要进行配置。当然了还有就是文件路径什么的尽量不要用中文命名，反正奇奇怪怪的bug就是这样产生的。<br>作为一个前端小白做这个花了一个多星期时间，才勉强做出这样的功能，真是令人头秃啊。</p><h5 id="完整代码地址-https-github-com-shubihu-Korok-Mask"><a href="#完整代码地址-https-github-com-shubihu-Korok-Mask" class="headerlink" title="完整代码地址 https://github.com/shubihu/Korok-Mask"></a>完整代码地址 <a href="https://github.com/shubihu/Korok-Mask">https://github.com/shubihu/Korok-Mask</a></h5><p>扫描下方二维码直达，第一次加载有点慢，，，，没办法，用的免费的服务器，慢应该是正常的。<br><img src="/img/article/wechat/%E5%85%8B%E6%B4%9B%E6%A0%BC.jpg"><br>参考</p><ul><li><a href="https://www.ruanyifeng.com/blog/2020/10/wechat-miniprogram-tutorial-part-one.html">https://www.ruanyifeng.com/blog/2020/10/wechat-miniprogram-tutorial-part-one.html</a></li><li><a href="https://github.com/zwz888mm/zhang">https://github.com/zwz888mm/zhang</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>微信小程序</category>
      
    </categories>
    
    
    <tags>
      
      <tag>核酸检测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MongoDB基础</title>
    <link href="/2021/10/18/MongoDB%E5%9F%BA%E7%A1%80/"/>
    <url>/2021/10/18/MongoDB%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<h2 id="MongoDB-基础命令"><a href="#MongoDB-基础命令" class="headerlink" title="MongoDB 基础命令"></a>MongoDB 基础命令</h2><span id="more"></span><h5 id="启动本地服务端"><a href="#启动本地服务端" class="headerlink" title="启动本地服务端"></a>启动本地服务端</h5><p>进入mongodb bin目录下打开命令行执行 mongod 启动服务端(存储引擎参数 –storageEngine=mmapv1)</p><figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs taggerscript">.<span class="hljs-symbol">\m</span>ongod.exe --storageEngine=mmapv1 --dbpath E:<span class="hljs-symbol">\D</span>esktop<span class="hljs-symbol">\J</span>ava<span class="hljs-symbol">\J</span>avaSoftware<span class="hljs-symbol">\m</span>ongoDB<span class="hljs-symbol">\d</span>ata\<br></code></pre></td></tr></table></figure><h5 id="启动本地客户端"><a href="#启动本地客户端" class="headerlink" title="启动本地客户端"></a>启动本地客户端</h5><p>进入mongodb bin目录下打开命令行执行 mongo 启动客户端</p><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs livescript">.<span class="hljs-string">\mongo.exe</span><br></code></pre></td></tr></table></figure><h5 id="查看数据库"><a href="#查看数据库" class="headerlink" title="查看数据库"></a>查看数据库</h5><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dart"><span class="hljs-keyword">show</span> dbs<br></code></pre></td></tr></table></figure><h5 id="切换数据库（无需新建，直接引用）"><a href="#切换数据库（无需新建，直接引用）" class="headerlink" title="切换数据库（无需新建，直接引用）"></a>切换数据库（无需新建，直接引用）</h5><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs actionscript"><span class="hljs-keyword">use</span> demo<br></code></pre></td></tr></table></figure><h5 id="插入数据-以创建一个雇员信息表为例"><a href="#插入数据-以创建一个雇员信息表为例" class="headerlink" title="插入数据(以创建一个雇员信息表为例)"></a>插入数据(以创建一个雇员信息表为例)</h5><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">db<span class="hljs-selector-class">.Employee</span><span class="hljs-selector-class">.save</span>(&#123;<span class="hljs-selector-tag">code</span>:<span class="hljs-string">&#x27;E01&#x27;</span>, name:<span class="hljs-string">&#x27;Jacky&#x27;</span>&#125;)<br></code></pre></td></tr></table></figure><h5 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h5><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dart"><span class="hljs-keyword">show</span> collections<br></code></pre></td></tr></table></figure><h5 id="查找数据"><a href="#查找数据" class="headerlink" title="查找数据"></a>查找数据</h5><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">db.<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">Employee</span>.</span></span>find<span class="hljs-literal">()</span><br></code></pre></td></tr></table></figure><h5 id="格式化输出查找数据"><a href="#格式化输出查找数据" class="headerlink" title="格式化输出查找数据"></a>格式化输出查找数据</h5><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">db<span class="hljs-selector-class">.Employee</span><span class="hljs-selector-class">.find</span>()<span class="hljs-selector-class">.pretty</span>()<br></code></pre></td></tr></table></figure><h5 id="添加不同格式数据"><a href="#添加不同格式数据" class="headerlink" title="添加不同格式数据"></a>添加不同格式数据</h5><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">db<span class="hljs-selector-class">.Employee</span><span class="hljs-selector-class">.save</span>(&#123;<span class="hljs-selector-tag">code</span>:<span class="hljs-string">&#x27;E02&#x27;</span>, name:<span class="hljs-string">&#x27;Jim&#x27;</span>, email:<span class="hljs-string">&#x27;test@email.com&#x27;</span>&#125;)<br></code></pre></td></tr></table></figure><p>启动mongodb时，提示Unclean shutdown detected mongodb，解决方法:</p><figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs taggerscript">.<span class="hljs-symbol">\m</span>ongod.exe --repair --dbpath E:<span class="hljs-symbol">\D</span>esktop<span class="hljs-symbol">\J</span>ava<span class="hljs-symbol">\J</span>avaSoftware<span class="hljs-symbol">\m</span>ongoDB<span class="hljs-symbol">\d</span>ata\<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MongoDB</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>iPhone 快捷指令自动打开低电量模式</title>
    <link href="/2021/09/27/iPhone%E5%BF%AB%E6%8D%B7%E6%8C%87%E4%BB%A4%E8%87%AA%E5%8A%A8%E6%89%93%E5%BC%80%E4%BD%8E%E7%94%B5%E9%87%8F%E6%A8%A1%E5%BC%8F/"/>
    <url>/2021/09/27/iPhone%E5%BF%AB%E6%8D%B7%E6%8C%87%E4%BB%A4%E8%87%AA%E5%8A%A8%E6%89%93%E5%BC%80%E4%BD%8E%E7%94%B5%E9%87%8F%E6%A8%A1%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><p>iPhone的电量一直是个软肋，但是其低电量模式续航还真是很可观的。当然一般想起来用低电量模式的时候都是电量剩余不多了的时候，尤其是在外面玩耍的时候，都不能好好地扣手机了。</p><h5 id="具体步骤如下："><a href="#具体步骤如下：" class="headerlink" title="具体步骤如下："></a>具体步骤如下：</h5><p>打开快捷指令，添加自动化，选择 电池电量 ，然后选择 低于50%（这里可以修改，反正我修改成了100%，让手机在99%以下都处于低电量模式以此来延长续航），然后 下一步 ，点击 添加操作，在搜素框搜索低电量，选择设定低电量模式脚本 ，然后再下一步，关掉运行前询问就完成了。</p><h5 id="1"><a href="#1" class="headerlink" title="1"></a>1</h5><p><img src="/img/article/iphone1/1.jpg"></p><h5 id="2"><a href="#2" class="headerlink" title="2"></a>2</h5><p><img src="/img/article/iphone1/2.jpg"></p><h5 id="3"><a href="#3" class="headerlink" title="3"></a>3</h5><p><img src="/img/article/iphone1/3.jpg"></p>]]></content>
    
    
    <categories>
      
      <category>iPhone</category>
      
    </categories>
    
    
    <tags>
      
      <tag>玩</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pyecharts 不同颜色绘制正负柱状图</title>
    <link href="/2021/09/27/Pyecharts%E4%B8%8D%E5%90%8C%E9%A2%9C%E8%89%B2%E7%BB%98%E5%88%B6%E6%AD%A3%E8%B4%9F%E6%9F%B1%E7%8A%B6%E5%9B%BE/"/>
    <url>/2021/09/27/Pyecharts%E4%B8%8D%E5%90%8C%E9%A2%9C%E8%89%B2%E7%BB%98%E5%88%B6%E6%AD%A3%E8%B4%9F%E6%9F%B1%E7%8A%B6%E5%9B%BE/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import akshare as ak<br>import pyecharts.options as opts<br><span class="hljs-keyword">from</span> pyecharts.charts import Bar, Line<br><span class="hljs-keyword">from</span> pyecharts.commons.utils import JsCode<br><br>fund_em_info_df = ak.fund_em_open_fund_info(<span class="hljs-attribute">fund</span>=<span class="hljs-string">&quot;006008&quot;</span>, <span class="hljs-attribute">indicator</span>=<span class="hljs-string">&quot;单位净值走势&quot;</span>)<br><br>fund_name = <span class="hljs-string">&#x27;诺安积极配置混合C&#x27;</span><br>x_data = fund_em_info_df[<span class="hljs-string">&#x27;净值日期&#x27;</span>].tolist()<br>y_data = fund_em_info_df[<span class="hljs-string">&#x27;单位净值&#x27;</span>].tolist()<br>z_data = fund_em_info_df[<span class="hljs-string">&#x27;日增长率&#x27;</span>].tolist()<br><br>background_color_js = (<br>    <span class="hljs-string">&quot;new echarts.graphic.LinearGradient(0, 0, 0, 1, &quot;</span><br>    <span class="hljs-string">&quot;[&#123;offset: 0, color: &#x27;#c86589&#x27;&#125;, &#123;offset: 1, color: &#x27;#06a7ff&#x27;&#125;], false)&quot;</span><br>)<br>area_color_js = (<br>    <span class="hljs-string">&quot;new echarts.graphic.LinearGradient(0, 0, 0, 1, &quot;</span><br>    <span class="hljs-string">&quot;[&#123;offset: 0, color: &#x27;#eb64fb&#x27;&#125;, &#123;offset: 1, color: &#x27;#3fbbff0d&#x27;&#125;], false)&quot;</span><br>)<br><br><br>bar = (<br>    Bar(<span class="hljs-attribute">init_opts</span>=opts.InitOpts(bg_color=JsCode(background_color_js), <span class="hljs-attribute">width</span>=<span class="hljs-string">&#x27;700px&#x27;</span>, <span class="hljs-attribute">height</span>=<span class="hljs-string">&#x27;450px&#x27;</span>))     ## width, height修改画布大小<br>    .add_xaxis(<span class="hljs-attribute">xaxis_data</span>=x_data)<br>    .add_yaxis(<br>        <span class="hljs-attribute">series_name</span>=<span class="hljs-string">&quot;&quot;</span>,<br>        <span class="hljs-attribute">y_axis</span>=z_data,<br>        <span class="hljs-attribute">label_opts</span>=opts.LabelOpts(is_show=False),<br>        <span class="hljs-attribute">itemstyle_opts</span>=opts.ItemStyleOpts(<br>            ### 调用js代码绘制不同颜色<br>            <span class="hljs-attribute">color</span>=JsCode(<br>                <span class="hljs-string">&quot;&quot;</span><span class="hljs-string">&quot;</span><br><span class="hljs-string">                    function(params) &#123;</span><br><span class="hljs-string">                        var colorList;</span><br><span class="hljs-string">                        if (params.data &gt;= 0) &#123;</span><br><span class="hljs-string">                          colorList = &#x27;#FF4500&#x27;;</span><br><span class="hljs-string">                        &#125; else &#123;</span><br><span class="hljs-string">                          colorList = &#x27;#14b143&#x27;;</span><br><span class="hljs-string">                        &#125;</span><br><span class="hljs-string">                        return colorList;</span><br><span class="hljs-string">                    &#125;</span><br><span class="hljs-string">                    &quot;</span><span class="hljs-string">&quot;&quot;</span><br>                )<br>            )<br>        )<br>    .set_global_opts(<br>        <span class="hljs-attribute">title_opts</span>=opts.TitleOpts(<br>            <span class="hljs-attribute">title</span>=fund_name,<br>            <span class="hljs-attribute">pos_bottom</span>=<span class="hljs-string">&quot;90%&quot;</span>,<br>            <span class="hljs-attribute">pos_left</span>=<span class="hljs-string">&quot;center&quot;</span>,<br>            <span class="hljs-attribute">title_textstyle_opts</span>=opts.TextStyleOpts(color=&quot;#fff&quot;, <span class="hljs-attribute">font_size</span>=16),<br>        ),<br>        <span class="hljs-attribute">xaxis_opts</span>=opts.AxisOpts(<br>            <span class="hljs-attribute">type_</span>=<span class="hljs-string">&quot;category&quot;</span>,<br>            <span class="hljs-attribute">boundary_gap</span>=<span class="hljs-literal">False</span>,<br>            <span class="hljs-attribute">axislabel_opts</span>=opts.LabelOpts(margin=30, <span class="hljs-attribute">color</span>=<span class="hljs-string">&quot;#ffffff63&quot;</span>),<br>            <span class="hljs-attribute">axisline_opts</span>=opts.AxisLineOpts(is_show=False),<br>            <span class="hljs-attribute">axistick_opts</span>=opts.AxisTickOpts(<br>                <span class="hljs-attribute">is_show</span>=<span class="hljs-literal">True</span>,<br>                <span class="hljs-attribute">length</span>=25,<br>                <span class="hljs-attribute">linestyle_opts</span>=opts.LineStyleOpts(color=&quot;#ffffff1f&quot;),<br>            ),<br>            <span class="hljs-attribute">splitline_opts</span>=opts.SplitLineOpts(<br>                <span class="hljs-attribute">is_show</span>=<span class="hljs-literal">True</span>, <span class="hljs-attribute">linestyle_opts</span>=opts.LineStyleOpts(color=&quot;#ffffff1f&quot;)<br>            ),<br>        ),<br>        <span class="hljs-attribute">yaxis_opts</span>=opts.AxisOpts(<br>            <span class="hljs-attribute">type_</span>=<span class="hljs-string">&quot;value&quot;</span>,<br>            <span class="hljs-attribute">position</span>=<span class="hljs-string">&quot;left&quot;</span>,<br>            <span class="hljs-attribute">axislabel_opts</span>=opts.LabelOpts(margin=20, <span class="hljs-attribute">color</span>=<span class="hljs-string">&quot;#ffffff63&quot;</span>),<br>            <span class="hljs-attribute">axisline_opts</span>=opts.AxisLineOpts(<br>                <span class="hljs-attribute">linestyle_opts</span>=opts.LineStyleOpts(width=2, <span class="hljs-attribute">color</span>=<span class="hljs-string">&quot;#fff&quot;</span>)<br>            ),<br>            <span class="hljs-attribute">axistick_opts</span>=opts.AxisTickOpts(<br>                <span class="hljs-attribute">is_show</span>=<span class="hljs-literal">True</span>,<br>                <span class="hljs-attribute">length</span>=15,<br>                <span class="hljs-attribute">linestyle_opts</span>=opts.LineStyleOpts(color=&quot;#ffffff1f&quot;),<br>            ),<br>            <span class="hljs-attribute">splitline_opts</span>=opts.SplitLineOpts(<br>                <span class="hljs-attribute">is_show</span>=<span class="hljs-literal">True</span>, <span class="hljs-attribute">linestyle_opts</span>=opts.LineStyleOpts(color=&quot;#ffffff1f&quot;)<br>            ),<br>        ),<br><span class="hljs-comment">#         legend_opts=opts.LegendOpts(is_show=True),</span><br>        datazoom_opts=[opts.DataZoomOpts(), opts.DataZoomOpts(<span class="hljs-attribute">type_</span>=<span class="hljs-string">&quot;inside&quot;</span>)]    ## 时间轴显示并可同通过鼠标滑动<br>    )<br>)<br><br><br>line = (<br>    Line(<span class="hljs-attribute">init_opts</span>=opts.InitOpts(bg_color=JsCode(background_color_js)))<br>    .add_xaxis(<span class="hljs-attribute">xaxis_data</span>=x_data)<br>    .add_yaxis(<br>        <span class="hljs-attribute">series_name</span>=<span class="hljs-string">&quot;&quot;</span>,<br>        y_axis=[round(i * 10, 2) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> y_data],<br>        <span class="hljs-attribute">is_smooth</span>=<span class="hljs-literal">True</span>,<br>        <span class="hljs-attribute">is_symbol_show</span>=<span class="hljs-literal">True</span>,<br>        <span class="hljs-attribute">symbol</span>=<span class="hljs-string">&quot;circle&quot;</span>,<br>        <span class="hljs-attribute">symbol_size</span>=6,<br>        <span class="hljs-attribute">linestyle_opts</span>=opts.LineStyleOpts(color=&quot;#fff&quot;),<br>        <span class="hljs-attribute">label_opts</span>=opts.LabelOpts(is_show=True, <span class="hljs-attribute">position</span>=<span class="hljs-string">&quot;top&quot;</span>, <span class="hljs-attribute">color</span>=<span class="hljs-string">&quot;white&quot;</span>),<br>        <span class="hljs-attribute">itemstyle_opts</span>=opts.ItemStyleOpts(<br>            <span class="hljs-attribute">color</span>=<span class="hljs-string">&quot;red&quot;</span>, <span class="hljs-attribute">border_color</span>=<span class="hljs-string">&quot;#fff&quot;</span>, <span class="hljs-attribute">border_width</span>=3<br>        ),<br>        <span class="hljs-attribute">tooltip_opts</span>=opts.TooltipOpts(is_show=False),<br>        <span class="hljs-attribute">areastyle_opts</span>=opts.AreaStyleOpts(color=JsCode(area_color_js), <span class="hljs-attribute">opacity</span>=1),<br>    )<br>)<br><br>bar.overlap(line)        ## 混合柱状图和线图<br>bar.render_notebook()<br><br></code></pre></td></tr></table></figure><p>结果如下</p><iframe src="/img/bar_line.html" width="100%" height="500" name="topFrame" scrolling="yes"  noresize="noresize" frameborder="0" id="topFrame"></iframe><p>参考</p><ul><li><a href="https://gallery.pyecharts.org/#/Candlestick/professional_kline_chart">https://gallery.pyecharts.org/#/Candlestick/professional_kline_chart</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pyecharts</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch 学习入门</title>
    <link href="/2021/09/16/Pytorch-learning/"/>
    <url>/2021/09/16/Pytorch-learning/</url>
    
    <content type="html"><![CDATA[<h2 id="Pytorch-Learning-Note"><a href="#Pytorch-Learning-Note" class="headerlink" title="Pytorch Learning Note"></a>Pytorch Learning Note</h2><span id="more"></span><h5 id="torch-nn"><a href="#torch-nn" class="headerlink" title="torch.nn"></a>torch.nn</h5><p>Module：创建一个行为类似于函数的可调用对象，但也可以包含状态（例如神经网络层权重）。 它知道其中包含的 Parameter ，并且可以将其所有坡度归零，遍历它们以进行权重更新等。<br>Parameter：张量的包装器，用于告知 Module 具有在反向传播期间需要更新的权重。 仅更新具有require_grad属性集的张量<br>functional：一个模块（通常按照惯例导入到 F 名称空间中），其中包含激活函数，损失函数等。 以及卷积和线性层等层的无状态版本。</p><h5 id="torch-optim"><a href="#torch-optim" class="headerlink" title="torch.optim"></a>torch.optim</h5><p>包含诸如 SGD 的优化程序，这些优化程序在后退步骤</p><h5 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h5><p>更新 Parameter 的权重。 具有__len__和__getitem__的对象，包括 Pytorch 提供的类，例如 TensorDataset</p><h5 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h5><p>获取任何 Dataset 并创建一个迭代器，该迭代器返回批量数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path<br><span class="hljs-keyword">import</span> requests<br><br>DATA_PATH = Path(<span class="hljs-string">&quot;data&quot;</span>)<br>PATH = DATA_PATH / <span class="hljs-string">&quot;mnist&quot;</span><br><br>PATH.mkdir(parents=<span class="hljs-literal">True</span>, exist_ok=<span class="hljs-literal">True</span>)<br><br>URL = <span class="hljs-string">&quot;https://github.com/pytorch/tutorials/raw/master/_static/&quot;</span><br>FILENAME = <span class="hljs-string">&quot;mnist.pkl.gz&quot;</span><br><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> (PATH / FILENAME).exists():<br>        content = requests.get(URL + FILENAME).content<br>        (PATH / FILENAME).<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;wb&quot;</span>).write(content)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">import</span> gzip<br><br><span class="hljs-keyword">with</span> gzip.<span class="hljs-built_in">open</span>((PATH / FILENAME).as_posix(), <span class="hljs-string">&quot;rb&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=<span class="hljs-string">&quot;latin-1&quot;</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>pyplot.imshow(x_train[<span class="hljs-number">0</span>].reshape((<span class="hljs-number">28</span>, <span class="hljs-number">28</span>)), cmap=<span class="hljs-string">&quot;gray&quot;</span>)<br><span class="hljs-built_in">print</span>(x_train.shape)<br></code></pre></td></tr></table></figure><pre><code>(50000, 784)</code></pre><!-- ![png](output_2_1.png) --><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br>x_train, y_train, x_valid, y_valid = <span class="hljs-built_in">map</span>(<br>    torch.tensor, (x_train, y_train, x_valid, y_valid)<br>)<br>n, c = x_train.shape<br>x_train, x_train.shape, y_train.<span class="hljs-built_in">min</span>(), y_train.<span class="hljs-built_in">max</span>()<br><span class="hljs-built_in">print</span>(x_train, y_train)<br><span class="hljs-built_in">print</span>(x_train.shape)<br><span class="hljs-built_in">print</span>(y_train.<span class="hljs-built_in">min</span>(), y_train.<span class="hljs-built_in">max</span>())<br></code></pre></td></tr></table></figure><pre><code>tensor([[0., 0., 0.,  ..., 0., 0., 0.],        [0., 0., 0.,  ..., 0., 0., 0.],        [0., 0., 0.,  ..., 0., 0., 0.],        ...,        [0., 0., 0.,  ..., 0., 0., 0.],        [0., 0., 0.,  ..., 0., 0., 0.],        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])torch.Size([50000, 784])tensor(0) tensor(9)</code></pre><h5 id="从0构建神经网络线性模型"><a href="#从0构建神经网络线性模型" class="headerlink" title="从0构建神经网络线性模型"></a>从0构建神经网络线性模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><br>weights = torch.randn(<span class="hljs-number">784</span>, <span class="hljs-number">10</span>) / math.sqrt(<span class="hljs-number">784</span>)<br>weights.requires_grad_()<br>bias = torch.zeros(<span class="hljs-number">10</span>, requires_grad=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment">## softmax激活函数</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">log_softmax</span>(<span class="hljs-params">x</span>):</span><br>    <span class="hljs-keyword">return</span> x - x.exp().<span class="hljs-built_in">sum</span>(-<span class="hljs-number">1</span>).log().unsqueeze(-<span class="hljs-number">1</span>)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">model</span>(<span class="hljs-params">xb</span>):</span><br>    <span class="hljs-keyword">return</span> log_softmax(xb @ weights + bias)  <span class="hljs-comment">#  @代表点积运算</span><br><br>bs = <span class="hljs-number">64</span>  <span class="hljs-comment"># batch size</span><br><br>xb = x_train[<span class="hljs-number">0</span>:bs]  <span class="hljs-comment"># a mini-batch from x</span><br>preds = model(xb)  <span class="hljs-comment"># predictions</span><br>preds[<span class="hljs-number">0</span>], preds.shape<br><span class="hljs-built_in">print</span>(preds[<span class="hljs-number">0</span>], preds.shape)<br><br><span class="hljs-comment">## 损失函数</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">nll</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, target</span>):</span><br>    <span class="hljs-keyword">return</span> -<span class="hljs-built_in">input</span>[<span class="hljs-built_in">range</span>(target.shape[<span class="hljs-number">0</span>]), target].mean()<br><br>loss_func = nll<br><br>yb = y_train[<span class="hljs-number">0</span>:bs]<br><span class="hljs-built_in">print</span>(loss_func(preds, yb))<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">accuracy</span>(<span class="hljs-params">out, yb</span>):</span><br>    preds = torch.argmax(out, dim=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> (preds == yb).<span class="hljs-built_in">float</span>().mean()<br><br><span class="hljs-built_in">print</span>(accuracy(preds, yb))<br><br><span class="hljs-keyword">from</span> IPython.core.debugger <span class="hljs-keyword">import</span> set_trace<br><br>lr = <span class="hljs-number">0.5</span>  <span class="hljs-comment"># learning rate</span><br>epochs = <span class="hljs-number">2</span>  <span class="hljs-comment"># how many epochs to train for</span><br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((n - <span class="hljs-number">1</span>) // bs + <span class="hljs-number">1</span>):<br>        <span class="hljs-comment">#         set_trace()</span><br>        start_i = i * bs<br>        end_i = start_i + bs<br>        xb = x_train[start_i:end_i]<br>        yb = y_train[start_i:end_i]<br>        pred = model(xb)<br>        loss = loss_func(pred, yb)<br><br>        loss.backward()<br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            weights -= weights.grad * lr<br>            bias -= bias.grad * lr<br>            weights.grad.zero_()<br>            bias.grad.zero_()<br>            <br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb), accuracy(model(xb), yb))<br><br></code></pre></td></tr></table></figure><pre><code>tensor([-2.5487, -2.8346, -2.7262, -2.1794, -2.1199, -2.1041, -1.9327, -2.1947,        -2.5637, -2.2133], grad_fn=&lt;SelectBackward&gt;) torch.Size([64, 10])tensor(2.3308, grad_fn=&lt;NegBackward&gt;)tensor(0.1094)tensor(0.0806, grad_fn=&lt;NegBackward&gt;) tensor(1.)</code></pre><h5 id="使用torch-nn-functional-重构"><a href="#使用torch-nn-functional-重构" class="headerlink" title="使用torch.nn.functional 重构"></a>使用torch.nn.functional 重构</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br>loss_func = F.cross_entropy<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">model</span>(<span class="hljs-params">xb</span>):</span><br>    <span class="hljs-keyword">return</span> xb @ weights + bias<br><br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb), accuracy(model(xb), yb))<br><br></code></pre></td></tr></table></figure><pre><code>tensor(0.0806, grad_fn=&lt;NllLossBackward&gt;) tensor(1.)</code></pre><h5 id="使用nn-Module重构"><a href="#使用nn-Module重构" class="headerlink" title="使用nn.Module重构"></a>使用nn.Module重构</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Mnist_Logistic</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.weights = nn.Parameter(torch.randn(<span class="hljs-number">784</span>, <span class="hljs-number">10</span>) / math.sqrt(<span class="hljs-number">784</span>))<br>        self.bias = nn.Parameter(torch.zeros(<span class="hljs-number">10</span>))<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, xb</span>):</span><br>        <span class="hljs-keyword">return</span> xb @ self.weights + self.bias<br>    <br>model = Mnist_Logistic()<br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb))<br><br>    <br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit</span>():</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((n - <span class="hljs-number">1</span>) // bs + <span class="hljs-number">1</span>):<br>            start_i = i * bs<br>            end_i = start_i + bs<br>            xb = x_train[start_i:end_i]<br>            yb = y_train[start_i:end_i]<br>            pred = model(xb)<br>            loss = loss_func(pred, yb)<br><br>            loss.backward()<br>            <span class="hljs-keyword">with</span> torch.no_grad():<br>                <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> model.parameters():<br>                    p -= p.grad * lr<br>                model.zero_grad()<br><br>fit()<br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb))<br><br></code></pre></td></tr></table></figure><pre><code>tensor(2.4222, grad_fn=&lt;NllLossBackward&gt;)tensor(0.0817, grad_fn=&lt;NllLossBackward&gt;)</code></pre><h5 id="使用nn-Linear重构"><a href="#使用nn-Linear重构" class="headerlink" title="使用nn.Linear重构"></a>使用nn.Linear重构</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Mnist_Logistic</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.lin = nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, xb</span>):</span><br>        <span class="hljs-keyword">return</span> self.lin(xb)<br>    <br>model = Mnist_Logistic()<br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb))<br>fit()<br><br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb))<br></code></pre></td></tr></table></figure><pre><code>tensor(2.3090, grad_fn=&lt;NllLossBackward&gt;)tensor(0.0824, grad_fn=&lt;NllLossBackward&gt;)</code></pre><h5 id="使用optim重构"><a href="#使用optim重构" class="headerlink" title="使用optim重构"></a>使用optim重构</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> optim<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_model</span>():</span><br>    model = Mnist_Logistic()<br>    <span class="hljs-keyword">return</span> model, optim.SGD(model.parameters(), lr=lr)<br><br>model, opt = get_model()<br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb))<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((n - <span class="hljs-number">1</span>) // bs + <span class="hljs-number">1</span>):<br>        start_i = i * bs<br>        end_i = start_i + bs<br>        xb = x_train[start_i:end_i]<br>        yb = y_train[start_i:end_i]<br>        pred = model(xb)<br>        loss = loss_func(pred, yb)<br><br>        loss.backward()<br>        opt.step()<br>        opt.zero_grad()<br><br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb))<br></code></pre></td></tr></table></figure><pre><code>tensor(2.2990, grad_fn=&lt;NllLossBackward&gt;)tensor(0.0805, grad_fn=&lt;NllLossBackward&gt;)</code></pre><h5 id="使用Dataset重构"><a href="#使用Dataset重构" class="headerlink" title="使用Dataset重构"></a>使用Dataset重构</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> TensorDataset<br><br>train_ds = TensorDataset(x_train, y_train)<br>xb,yb = train_ds[i*bs : i*bs+bs]<br>model, opt = get_model()<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((n - <span class="hljs-number">1</span>) // bs + <span class="hljs-number">1</span>):<br>        xb, yb = train_ds[i * bs: i * bs + bs]<br>        pred = model(xb)<br>        loss = loss_func(pred, yb)<br><br>        loss.backward()<br>        opt.step()<br>        opt.zero_grad()<br><br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb))<br></code></pre></td></tr></table></figure><pre><code>tensor(0.0817, grad_fn=&lt;NllLossBackward&gt;)</code></pre><h5 id="使用DataLoader重构"><a href="#使用DataLoader重构" class="headerlink" title="使用DataLoader重构"></a>使用DataLoader重构</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br>train_ds = TensorDataset(x_train, y_train)<br>train_dl = DataLoader(train_ds, batch_size=bs)<br><br>model, opt = get_model()<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>    <span class="hljs-keyword">for</span> xb, yb <span class="hljs-keyword">in</span> train_dl:<br>        pred = model(xb)<br>        loss = loss_func(pred, yb)<br><br>        loss.backward()<br>        opt.step()<br>        opt.zero_grad()<br><br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb))<br></code></pre></td></tr></table></figure><pre><code>tensor(0.0803, grad_fn=&lt;NllLossBackward&gt;)</code></pre><h5 id="添加验证"><a href="#添加验证" class="headerlink" title="添加验证"></a>添加验证</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python">train_ds = TensorDataset(x_train, y_train)<br>train_dl = DataLoader(train_ds, batch_size=bs, shuffle=<span class="hljs-literal">True</span>)<br><br>valid_ds = TensorDataset(x_valid, y_valid)<br>valid_dl = DataLoader(valid_ds, batch_size=bs * <span class="hljs-number">2</span>)<br><br>model, opt = get_model()<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>    model.train()<br>    <span class="hljs-keyword">for</span> xb, yb <span class="hljs-keyword">in</span> train_dl:<br>        pred = model(xb)<br>        loss = loss_func(pred, yb)<br><br>        loss.backward()<br>        opt.step()<br>        opt.zero_grad()<br><br>    model.<span class="hljs-built_in">eval</span>()<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        valid_loss = <span class="hljs-built_in">sum</span>(loss_func(model(xb), yb) <span class="hljs-keyword">for</span> xb, yb <span class="hljs-keyword">in</span> valid_dl)<br><br>    <span class="hljs-built_in">print</span>(epoch, valid_loss / <span class="hljs-built_in">len</span>(valid_dl))<br></code></pre></td></tr></table></figure><pre><code>0 tensor(0.3093)1 tensor(0.3198)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">## 创建fit()和get_data()</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">loss_batch</span>(<span class="hljs-params">model, loss_func, xb, yb, opt=<span class="hljs-literal">None</span></span>):</span><br>    loss = loss_func(model(xb), yb)<br><br>    <span class="hljs-keyword">if</span> opt <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        loss.backward()<br>        opt.step()<br>        opt.zero_grad()<br><br>    <span class="hljs-keyword">return</span> loss.item(), <span class="hljs-built_in">len</span>(xb)<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit</span>(<span class="hljs-params">epochs, model, loss_func, opt, train_dl, valid_dl</span>):</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>        model.train()<br>        <span class="hljs-keyword">for</span> xb, yb <span class="hljs-keyword">in</span> train_dl:<br>            loss_batch(model, loss_func, xb, yb, opt)<br><br>        model.<span class="hljs-built_in">eval</span>()<br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            losses, nums = <span class="hljs-built_in">zip</span>(<br>                *[loss_batch(model, loss_func, xb, yb) <span class="hljs-keyword">for</span> xb, yb <span class="hljs-keyword">in</span> valid_dl]<br>            )<br>        val_loss = np.<span class="hljs-built_in">sum</span>(np.multiply(losses, nums)) / np.<span class="hljs-built_in">sum</span>(nums)<br><br>        <span class="hljs-built_in">print</span>(epoch, val_loss)<br>        <br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_data</span>(<span class="hljs-params">train_ds, valid_ds, bs</span>):</span><br>    <span class="hljs-keyword">return</span> (<br>        DataLoader(train_ds, batch_size=bs, shuffle=<span class="hljs-literal">True</span>),<br>        DataLoader(valid_ds, batch_size=bs * <span class="hljs-number">2</span>),<br>    )<br><br>train_dl, valid_dl = get_data(train_ds, valid_ds, bs)<br>model, opt = get_model()<br>fit(epochs, model, loss_func, opt, train_dl, valid_dl)<br></code></pre></td></tr></table></figure><pre><code>0 0.33136114755868911 0.35820939881801606</code></pre><h5 id="切换到-CNN"><a href="#切换到-CNN" class="headerlink" title="切换到 CNN"></a>切换到 CNN</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Mnist_CNN</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>        self.conv2 = nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>        self.conv3 = nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">10</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, xb</span>):</span><br>        xb = xb.view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>)<br>        xb = F.relu(self.conv1(xb))<br>        xb = F.relu(self.conv2(xb))<br>        xb = F.relu(self.conv3(xb))<br>        xb = F.avg_pool2d(xb, <span class="hljs-number">4</span>)<br>        <span class="hljs-keyword">return</span> xb.view(-<span class="hljs-number">1</span>, xb.size(<span class="hljs-number">1</span>))<br><br>lr = <span class="hljs-number">0.1</span><br><br>model = Mnist_CNN()<br>opt = optim.SGD(model.parameters(), lr=lr, momentum=<span class="hljs-number">0.9</span>)<br><br>fit(epochs, model, loss_func, opt, train_dl, valid_dl)<br></code></pre></td></tr></table></figure><pre><code>0 0.29366704518795011 0.21561954822540283</code></pre><h5 id="nn-Sequential-Sequential对象以顺序方式运行其中包含的每个模块。"><a href="#nn-Sequential-Sequential对象以顺序方式运行其中包含的每个模块。" class="headerlink" title="nn.Sequential   Sequential对象以顺序方式运行其中包含的每个模块。"></a>nn.Sequential   Sequential对象以顺序方式运行其中包含的每个模块。</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Lambda</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, func</span>):</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.func = func<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        <span class="hljs-keyword">return</span> self.func(x)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">preprocess</span>(<span class="hljs-params">x</span>):</span><br>    <span class="hljs-keyword">return</span> x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>)<br><br>model = nn.Sequential(<br>    Lambda(preprocess),<br>    nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<br>    nn.ReLU(),<br>    nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<br>    nn.ReLU(),<br>    nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">10</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<br>    nn.ReLU(),<br>    nn.AvgPool2d(<span class="hljs-number">4</span>),<br>    Lambda(<span class="hljs-keyword">lambda</span> x: x.view(x.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)),<br>)<br><br>opt = optim.SGD(model.parameters(), lr=lr, momentum=<span class="hljs-number">0.9</span>)<br><br>fit(epochs, model, loss_func, opt, train_dl, valid_dl)<br></code></pre></td></tr></table></figure><pre><code>0 0.40379241023063661 0.25595326462984086</code></pre><h5 id="包装DataLoader"><a href="#包装DataLoader" class="headerlink" title="包装DataLoader"></a>包装DataLoader</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">preprocess</span>(<span class="hljs-params">x, y</span>):</span><br>    <span class="hljs-keyword">return</span> x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>), y<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">WrappedDataLoader</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, dl, func</span>):</span><br>        self.dl = dl<br>        self.func = func<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.dl)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__iter__</span>(<span class="hljs-params">self</span>):</span><br>        batches = <span class="hljs-built_in">iter</span>(self.dl)<br>        <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> batches:<br>            <span class="hljs-keyword">yield</span> (self.func(*b))<br><br>train_dl, valid_dl = get_data(train_ds, valid_ds, bs)<br>train_dl = WrappedDataLoader(train_dl, preprocess)<br>valid_dl = WrappedDataLoader(valid_dl, preprocess)<br><br>model = nn.Sequential(<br>    nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<br>    nn.ReLU(),<br>    nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<br>    nn.ReLU(),<br>    nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">10</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<br>    nn.ReLU(),<br>    nn.AdaptiveAvgPool2d(<span class="hljs-number">1</span>),<br>    Lambda(<span class="hljs-keyword">lambda</span> x: x.view(x.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)),<br>)<br><br>opt = optim.SGD(model.parameters(), lr=lr, momentum=<span class="hljs-number">0.9</span>)<br><br>fit(epochs, model, loss_func, opt, train_dl, valid_dl)<br><br></code></pre></td></tr></table></figure><pre><code>0 0.313964178180694551 0.2551067463874817</code></pre><h5 id="使用GPU，，，如果有"><a href="#使用GPU，，，如果有" class="headerlink" title="使用GPU，，，如果有"></a>使用GPU，，，如果有</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(torch.cuda.is_available())<br>dev = torch.device(<br>    <span class="hljs-string">&quot;cuda&quot;</span>) <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">preprocess</span>(<span class="hljs-params">x, y</span>):</span><br>    <span class="hljs-keyword">return</span> x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>).to(dev), y.to(dev)<br><br>train_dl, valid_dl = get_data(train_ds, valid_ds, bs)<br>train_dl = WrappedDataLoader(train_dl, preprocess)<br>valid_dl = WrappedDataLoader(valid_dl, preprocess)<br><br>model.to(dev)<br>opt = optim.SGD(model.parameters(), lr=lr, momentum=<span class="hljs-number">0.9</span>)<br>fit(epochs, model, loss_func, opt, train_dl, valid_dl)<br><br></code></pre></td></tr></table></figure><pre><code>False0 0.223737240695953381 0.2494806985616684</code></pre>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>iPhone 快捷指令上下班半自动打卡</title>
    <link href="/2021/09/10/iPhone/"/>
    <url>/2021/09/10/iPhone/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><p>打工人有时候会忘记打卡，为了能尽量少忘记，有时候会设定闹钟来提醒。在iPhone上还有个稍微半自动化的应用也可以实现，就是快捷指令。为啥是半自动化呢，因为息屏状态下是无法执行的，只是会有提醒，需要解锁后点击才能执行。当然了在不息屏的状态下是完全可以实现自动化的，但是也不可能一直不息屏吧。iPhone的那点点电量就不说了。<br>还有个前提就是提前设置好打卡APP的快捷打卡功能。</p><h6 id="快捷指令APP（一般自带，不小心删了可以去APP-Store重新下载）"><a href="#快捷指令APP（一般自带，不小心删了可以去APP-Store重新下载）" class="headerlink" title="快捷指令APP（一般自带，不小心删了可以去APP Store重新下载）"></a>快捷指令APP（一般自带，不小心删了可以去APP Store重新下载）</h6><p>打开快捷指令app，点击自动化，点击创建个人自动化<br><img src="/img/article/iphone/0.jpg"></p><h5 id="选择特定时间"><a href="#选择特定时间" class="headerlink" title="选择特定时间"></a>选择特定时间</h5><p>这个页面还有其它事件，比如到达、离开等。一般现在企业微信或者钉钉亦或者是公司自己的打卡APP都是基于距离进行定位打卡，所以这里也可以选择到达或者离开，这里以特定时间为例，其它事件可以自行摸索。<br>然后设置上下班时间，可以选择每天，每周（可选周一至周五），按心情选择。<br><img src="/img/article/iphone/1.jpg"></p><h5 id="点击下一步，点击添加操作。"><a href="#点击下一步，点击添加操作。" class="headerlink" title="点击下一步，点击添加操作。"></a>点击下一步，点击添加操作。</h5><p><img src="/img/article/iphone/2.jpg"></p><h5 id="搜索输入：打开app，点击打开app，点击选择。"><a href="#搜索输入：打开app，点击打开app，点击选择。" class="headerlink" title="搜索输入：打开app，点击打开app，点击选择。"></a>搜索输入：打开app，点击打开app，点击选择。</h5><p><img src="/img/article/iphone/3.jpg"></p><h5 id="搜索输入企业微信，点击企业微信，点击下一步。"><a href="#搜索输入企业微信，点击企业微信，点击下一步。" class="headerlink" title="搜索输入企业微信，点击企业微信，点击下一步。"></a>搜索输入企业微信，点击企业微信，点击下一步。</h5><p><img src="/img/article/iphone/4.jpg"></p><h5 id="将运行前询问关闭，点击不询问，点击完成。"><a href="#将运行前询问关闭，点击不询问，点击完成。" class="headerlink" title="将运行前询问关闭，点击不询问，点击完成。"></a>将运行前询问关闭，点击不询问，点击完成。</h5><p><img src="/img/article/iphone/5.jpg"></p><h5 id="题外话"><a href="#题外话" class="headerlink" title="题外话"></a>题外话</h5><p>iPhone的快捷指令有点像编程，所以功能不止这些，网上还有如何实现敲击背面显示健康码等，有兴趣的可以搜来看看。</p>]]></content>
    
    
    <categories>
      
      <category>iPhone</category>
      
    </categories>
    
    
    <tags>
      
      <tag>玩</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python 监控</title>
    <link href="/2021/09/02/python%E7%9B%91%E6%8E%A7/"/>
    <url>/2021/09/02/python%E7%9B%91%E6%8E%A7/</url>
    
    <content type="html"><![CDATA[<h2 id="使用python监控电脑键盘、鼠标并拍照录像"><a href="#使用python监控电脑键盘、鼠标并拍照录像" class="headerlink" title="使用python监控电脑键盘、鼠标并拍照录像"></a>使用python监控电脑键盘、鼠标并拍照录像</h2><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> keyboard<br><span class="hljs-keyword">from</span> cv2 <span class="hljs-keyword">import</span> cv2<br><span class="hljs-comment"># from pynput.mouse import Listener</span><br><span class="hljs-keyword">import</span> pyautogui <span class="hljs-keyword">as</span> pag    <span class="hljs-comment">#监听鼠标</span><br><span class="hljs-comment"># from pynput.keyboard import Key, Listener</span><br><span class="hljs-keyword">from</span> threading <span class="hljs-keyword">import</span> Thread<br><br>x1, y1 = pag.position()<br><span class="hljs-comment"># print(x1, y1)</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">camera</span>():</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    拍照</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    cap = cv2.VideoCapture(<span class="hljs-number">0</span>)<br>    ret,frame = cap.read() <span class="hljs-comment">#读取摄像头内容</span><br>    cv2.imwrite(<span class="hljs-string">&quot;./test.jpg&quot;</span>,frame) <span class="hljs-comment">#保存到磁盘</span><br>    <span class="hljs-comment">#释放摄像头</span><br>    cap.release()<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">record_video</span>():</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    录制视频</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    cap = cv2.VideoCapture(<span class="hljs-number">0</span>)<br>    fps = <span class="hljs-number">30</span><br>    size=(<span class="hljs-built_in">int</span>(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),<span class="hljs-built_in">int</span>(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))<br>    videoWriter=cv2.VideoWriter(<span class="hljs-string">&#x27;./test.avi&#x27;</span>,cv2.VideoWriter_fourcc(<span class="hljs-string">&#x27;X&#x27;</span>,<span class="hljs-string">&#x27;V&#x27;</span>,<span class="hljs-string">&#x27;I&#x27;</span>,<span class="hljs-string">&#x27;D&#x27;</span>),fps,size)<br>    success,frame = cap.read()<br>    numFrameRemaining = <span class="hljs-number">5</span> * fps    <span class="hljs-comment">#摄像头捕获持续时间</span><br>    <span class="hljs-keyword">while</span> success <span class="hljs-keyword">and</span> numFrameRemaining &gt; <span class="hljs-number">0</span>:<br>        videoWriter.write(frame)<br>        success,frame = cap.read()<br>        numFrameRemaining -= <span class="hljs-number">1</span><br><br>    cap.release()<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">display_video</span>():</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    实时窗口</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    face_locations = []<br>    cap = cv2.VideoCapture(<span class="hljs-number">0</span>)<br><br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        <span class="hljs-comment"># Grab a single frame of video</span><br>        ret, frame = cap.read()<br><br>        <span class="hljs-comment"># Convert the image from BGR color (whichOpenCV uses) to RGB color (which face_recognition uses)</span><br>        rgb_frame = frame[:, :, ::-<span class="hljs-number">1</span>]<br><br>        <span class="hljs-comment"># Find all the faces in the current frameof video</span><br>        face_locations = face_recognition.face_locations(rgb_frame)<br><br>        <span class="hljs-comment"># Display the results</span><br>        <span class="hljs-keyword">for</span> top, right, bottom, left <span class="hljs-keyword">in</span> face_locations:<br>            <span class="hljs-comment"># Draw a box around the face</span><br>            cv2.rectangle(frame, (left, top),(right, bottom), (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>), <span class="hljs-number">2</span>)<br><br>        <span class="hljs-comment"># Display the resulting image</span><br>        cv2.imshow(<span class="hljs-string">&#x27;Video&#x27;</span>, frame)<br><br>        <span class="hljs-comment"># Hit &#x27;q&#x27; on the keyboard to quit!</span><br>        <span class="hljs-keyword">if</span> cv2.waitKey(<span class="hljs-number">1</span>) &amp; <span class="hljs-number">0xFF</span> == <span class="hljs-built_in">ord</span>(<span class="hljs-string">&#x27;q&#x27;</span>):<br>            <span class="hljs-keyword">break</span><br><br>    <span class="hljs-comment"># Release handle tothe webcam</span><br>    cap.release()<br>    cv2.destroyAllWindows()<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">display_video2</span>():</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    实时检测</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment">#存储知道人名列表</span><br>    known_names=[<span class="hljs-string">&#x27;yahaha1&#x27;</span>, <span class="hljs-string">&#x27;yahaha2&#x27;</span>] <br>    <span class="hljs-comment">#存储知道的特征值</span><br>    known_faces=[]<br><br>    image1 =face_recognition.load_image_file(<span class="hljs-string">&quot;yahaha2.jpg&quot;</span>)<br>    face_encoding1 =face_recognition.face_encodings(image1)<br><br>    image2 =face_recognition.load_image_file(<span class="hljs-string">&quot;yahaha1.jpg&quot;</span>)<br>    face_encoding2 =face_recognition.face_encodings(image1)<br><br>    <span class="hljs-keyword">if</span> face_encoding1 <span class="hljs-keyword">and</span> face_encoding2:<br>        face_encoding1 = face_encoding1[<span class="hljs-number">0</span>]<br>        face_encoding2 = face_encoding2[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">else</span>:<br>        sys.exit()<br><br>    known_faces = [face_encoding1, face_encoding2]<br><br>    cap = cv2.VideoCapture(<span class="hljs-number">0</span>)<br><br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        <span class="hljs-comment"># Grab a single frame of video</span><br>        ret, frame = cap.read()<br>        <span class="hljs-comment"># Convert the image from BGR color (whichOpenCV uses) to RGB color (which face_recognition uses)</span><br>        rgb_frame = frame[:, :, ::-<span class="hljs-number">1</span>]<br><br>        <span class="hljs-comment"># Find all the faces and face encodings inthe current frame of video</span><br>        face_locations =face_recognition.face_locations(rgb_frame)  <span class="hljs-comment"># 如有gpu可添加参数model=&#x27;cnn&#x27;提升精度</span><br>        face_encodings =face_recognition.face_encodings(rgb_frame, face_locations)<br><br>        face_names = []<br>        <span class="hljs-keyword">for</span> face_encoding <span class="hljs-keyword">in</span> face_encodings:<br>            <span class="hljs-comment"># See if the face is a match for theknown face(s)</span><br>            matches =face_recognition.compare_faces(known_faces, face_encoding, tolerance=<span class="hljs-number">0.60</span>)<br><br>            name = <span class="hljs-literal">None</span><br>            <span class="hljs-comment"># if match[0]:</span><br>            <span class="hljs-comment">#     name = &quot;Yahaha&quot;</span><br>            <span class="hljs-built_in">print</span>(matches)<br>            <span class="hljs-keyword">if</span> <span class="hljs-literal">True</span> <span class="hljs-keyword">in</span> matches:<br>                first_match_index = matches.index(<span class="hljs-literal">True</span>)<br>                name = known_names[first_match_index]<br>            <span class="hljs-keyword">else</span>:<br>                name = <span class="hljs-string">&#x27;Unkonwn&#x27;</span><br><br>            face_names.append(name)<br><br>        <span class="hljs-comment"># Label the results</span><br>        <span class="hljs-keyword">for</span> (top, right, bottom, left), name <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(face_locations, face_names):<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> name:<br>                <span class="hljs-keyword">continue</span><br><br>            <span class="hljs-comment"># Draw a box around the face</span><br>            cv2.rectangle(frame, (left, top),(right, bottom), (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>), <span class="hljs-number">2</span>)<br>            <span class="hljs-comment"># Draw a label with a name below theface</span><br>            cv2.rectangle(frame, (left, bottom -<span class="hljs-number">25</span>), (right, bottom), (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>), cv2.FILLED)<br>            font = cv2.FONT_HERSHEY_DUPLEX<br>            cv2.putText(frame, name, (left + <span class="hljs-number">6</span>,bottom - <span class="hljs-number">6</span>), font, <span class="hljs-number">0.5</span>, (<span class="hljs-number">255</span>, <span class="hljs-number">255</span>, <span class="hljs-number">255</span>), <span class="hljs-number">1</span>)<br><br>        cv2.imshow(<span class="hljs-string">&#x27;Video&#x27;</span>, frame)<br><br>        <span class="hljs-comment"># Hit &#x27;q&#x27; on the keyboard to quit!</span><br>        <span class="hljs-keyword">if</span> cv2.waitKey(<span class="hljs-number">1</span>) &amp; <span class="hljs-number">0xFF</span> == <span class="hljs-built_in">ord</span>(<span class="hljs-string">&#x27;q&#x27;</span>):<br>            <span class="hljs-keyword">break</span><br>    <span class="hljs-comment"># All done!</span><br>    cap.release()<br>    cv2.destroyAllWindows()<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">proof</span>(<span class="hljs-params">x</span>):</span><br>    <span class="hljs-comment"># print(x)</span><br>    <span class="hljs-comment"># record_video()</span><br>    camera()<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">monitor_keyboard</span>():</span><br>    keyboard.hook(proof)<br>    <span class="hljs-comment">#按下任何按键时，都会调用proof，其中一定会传一个值，就是键盘事件</span><br>    keyboard.wait()<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">monitor_mouse</span>():</span><br>    x2, y2 = pag.position()<br>    <span class="hljs-keyword">while</span> x1 == x2:<br>        x2, y2 = pag.position()<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># record_video()</span><br>        camera()<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    k = Thread(target=monitor_keyboard, args=())<br>    m = Thread(target=monitor_mouse, args=())<br>    k.start()<br>    m.start()<br>    k.join()<br>    m.join()<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>玩</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>We Are SVIP</title>
    <link href="/2021/08/20/WeAreSVIP/"/>
    <url>/2021/08/20/WeAreSVIP/</url>
    
    <content type="html"><![CDATA[<h2 id="薅各大厂视频羊毛"><a href="#薅各大厂视频羊毛" class="headerlink" title="薅各大厂视频羊毛"></a>薅各大厂视频羊毛</h2><span id="more"></span><p>周末了又可以追剧了，最近在看扫黑风暴，但是吧，现在各大视频网站都是需要VIP才能看，有的甚至更可恶，还要超前点播。这嘴脸真的是穷凶极恶。都是大厂了，说好的回报社会呢，，，就这样回报社会呢。人家（我没有）都已经忍痛购买你的VIP了，还不满足。算了，你有张良计，我有过墙梯。<br>今天就给大家分享个可以薅他们VIP的插件——油猴，确切的说是各路大神开发的脚本，油猴只是个脚本管家。如果能上google的话就方便很多，直接搜索油猴插件进行安装。但是国内吧，，，，可能很多人都无法上谷歌。这里就介绍下本地安装油猴插件的方法。</p><h5 id="No-1"><a href="#No-1" class="headerlink" title="No.1"></a>No.1</h5><p>首先先下载下油猴，链接在此：<a href="https://pan.baidu.com/s/1FQZBBjqr2s8f-9idizxI6w">https://pan.baidu.com/s/1FQZBBjqr2s8f-9idizxI6w</a> ;提取码：<span  style="color: #519D9E; ">8fmu</span><br>下载完成后直接解压到该文件夹。<br>然后打开我们的谷歌浏览器，在搜索地址栏输入：<span  style="color: #519D9E; ">chrome://extensions/</span>，进入扩展程序界面，<span  style="color: #519D9E; ">打开右上角的开发者模式</span>。接着选择<span  style="color: #519D9E; ">左上角的加载已解压的扩展程序</span>，然后选择我们刚刚解压过的油猴的目录即可，到这里油猴插件就完成了。接下来就是安装脚本了。</p><h5 id="No-2"><a href="#No-2" class="headerlink" title="No.2"></a>No.2</h5><p>然后进入这个网站：<a href="https://greasyfork.org/zh-CN">https://greasyfork.org/zh-CN</a> ，搜索VIP，会出现很多个脚本，自行选择就好。我选择的是 <a href="https://greasyfork.org/zh-CN/scripts/370634-%E6%87%92%E4%BA%BA%E4%B8%93%E7%94%A8-%E5%85%A8%E7%BD%91vip%E8%A7%86%E9%A2%91%E5%85%8D%E8%B4%B9%E7%A0%B4%E8%A7%A3%E5%8E%BB%E5%B9%BF%E5%91%8A-%E5%85%A8%E7%BD%91%E9%9F%B3%E4%B9%90%E7%9B%B4%E6%8E%A5%E4%B8%8B%E8%BD%BD-%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98%E7%9B%B4%E6%8E%A5%E4%B8%8B%E8%BD%BD%E7%AD%89%E5%A4%9A%E5%90%88%E4%B8%80%E7%89%88-%E9%95%BF%E6%9C%9F%E6%9B%B4%E6%96%B0-%E6%94%BE%E5%BF%83%E4%BD%BF%E7%94%A8">https://greasyfork.org/zh-CN/scripts/370634-%E6%87%92%E4%BA%BA%E4%B8%93%E7%94%A8-%E5%85%A8%E7%BD%91vip%E8%A7%86%E9%A2%91%E5%85%8D%E8%B4%B9%E7%A0%B4%E8%A7%A3%E5%8E%BB%E5%B9%BF%E5%91%8A-%E5%85%A8%E7%BD%91%E9%9F%B3%E4%B9%90%E7%9B%B4%E6%8E%A5%E4%B8%8B%E8%BD%BD-%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98%E7%9B%B4%E6%8E%A5%E4%B8%8B%E8%BD%BD%E7%AD%89%E5%A4%9A%E5%90%88%E4%B8%80%E7%89%88-%E9%95%BF%E6%9C%9F%E6%9B%B4%E6%96%B0-%E6%94%BE%E5%BF%83%E4%BD%BF%E7%94%A8</a> 这个，觉得还是比较好用的。之后点击安装就大功告成啦。</p><h4 id="No-3"><a href="#No-3" class="headerlink" title="No.3"></a>No.3</h4><p>利器有了，就可以去各大视频网站薅一波了，超前点播也可以薅哦。油猴这个插件及其脚本的功能不仅限于此，有兴趣可以自行摸索。</p>]]></content>
    
    
    <categories>
      
      <category>TroubleShoot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>薅羊毛</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>水一篇</title>
    <link href="/2021/08/20/%E6%B0%B4%E4%B8%80%E7%AF%87/"/>
    <url>/2021/08/20/%E6%B0%B4%E4%B8%80%E7%AF%87/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><p>虽然参照这篇文章设置了，但还是站点地图显示无法获取，不知道是不是时间的问题，等等吧。</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs applescript"><span class="hljs-comment">## 创建sitemap.xml</span><br>npm install hexo-generator-sitemap <span class="hljs-comment">--save</span><br></code></pre></td></tr></table></figure><iframe src="https://www.gongsunqi.xyz/2021/08/14/%E8%AE%A9%E8%87%AA%E5%B7%B1%E9%80%9A%E8%BF%87Hexo%E5%BB%BA%E7%AB%8B%E7%9A%84%E5%8D%9A%E5%AE%A2%E8%A2%AB%E8%B0%B7%E6%AD%8C%E6%90%9C%E7%B4%A2%E5%88%B0/" width="100%" height="500" name="topFrame" scrolling="yes"  noresize="noresize" frameborder="0" id="topFrame"></iframe>]]></content>
    
    
    <categories>
      
      <category>Working</category>
      
    </categories>
    
    
    <tags>
      
      <tag>划水摸鱼</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Trouble No Shoot</title>
    <link href="/2021/08/20/TroubleNoShoot/"/>
    <url>/2021/08/20/TroubleNoShoot/</url>
    
    <content type="html"><![CDATA[<h2 id="升级hexo遇到的问题"><a href="#升级hexo遇到的问题" class="headerlink" title="升级hexo遇到的问题"></a>升级hexo遇到的问题</h2><span id="more"></span><p>hexo的一个插件需要5.0以上的版本，看了下自己安装的是4.3的版本，所以想着升级一下。查了半天也没找到有效的方法。之后又查看了node的版本看着也很低，想升级的心又来了。折腾了半天愣是没升级成功，还把系统搞坏了，apt、dpkg这些也都没法用了。网上的资料有时候也不能盲目跟着做，还是用root账户删的，真是细思极恐，这要是公司的生产环境，这估计是要被祭天的。估计我也是仗着这是自己电脑里的子系统才敢这么胡作非为。系统坏了，本来想挽救一下的，发现越挽救问题越大。顺放弃。。。于是重新卸载Linux子系统，再重新安装，前后没花10分钟。果然还是微软baba的子系统安装卸载方便啊。<br>系统重新安装了，很多东西就要重新配置，比如github的免密提交等，这里也简单记录下。</p><h5 id="首先配置github及生成ssh秘钥，执行"><a href="#首先配置github及生成ssh秘钥，执行" class="headerlink" title="首先配置github及生成ssh秘钥，执行"></a>首先配置github及生成ssh秘钥，执行</h5><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs verilog">git <span class="hljs-keyword">config</span> --<span class="hljs-keyword">global</span> user<span class="hljs-variable">.email</span> <span class="hljs-string">&quot;you@example.com&quot;</span>    ## 我的 git <span class="hljs-keyword">config</span> --<span class="hljs-keyword">global</span> user<span class="hljs-variable">.email</span> <span class="hljs-string">&quot;jrwjb@sina.com&quot;</span>   <br>git <span class="hljs-keyword">config</span> --<span class="hljs-keyword">global</span> user<span class="hljs-variable">.name</span> <span class="hljs-string">&quot;Your Name&quot;</span>  ## 我的 git <span class="hljs-keyword">config</span> --<span class="hljs-keyword">global</span> user<span class="hljs-variable">.name</span> <span class="hljs-string">&quot;shubihu&quot;</span><br>ssh-keygen        ## 一路回车即可<br></code></pre></td></tr></table></figure><p>执行完后会在家目录的.ssh下生成下面几个文件</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs clean">id_rsa   ## 私钥<br>id_rsa.pub  ## 共钥<br></code></pre></td></tr></table></figure><p>然后把公钥的内容添加到github上即可。<br><img src="/img/article/gitssh.jpg"></p><h5 id="回到最开始的问题，升级hexo、node。"><a href="#回到最开始的问题，升级hexo、node。" class="headerlink" title="回到最开始的问题，升级hexo、node。"></a>回到最开始的问题，升级hexo、node。</h5><p>因为是新系统，所以相对简单些，直接安装新版的node，可以从官网下载最新的稳定版进行安装，不过我嫌麻烦懒得去下载，所以参考了这篇文章进行安装。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">## 使用nvm进行安装</span><br>curl -o- https:<span class="hljs-regexp">//</span>raw.githubusercontent.com<span class="hljs-regexp">/nvm-sh/</span>nvm<span class="hljs-regexp">/v0.35.3/i</span>nstall.sh | bash<br>nvm install node<br></code></pre></td></tr></table></figure><!-- <iframe src="https://www.myfreax.com/how-to-install-node-js-on-ubuntu-18-04/" width="100%" height="500" name="topFrame" scrolling="yes"  noresize="noresize" frameborder="0" id="topFrame"></iframe> --><h5 id="最后是升级hexo"><a href="#最后是升级hexo" class="headerlink" title="最后是升级hexo"></a>最后是升级hexo</h5><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs coffeescript"><span class="hljs-comment"># 使用淘宝源的 cnpm 替换 npm</span><br><span class="hljs-built_in">npm</span> install -g cnpm --registry=https://registry.<span class="hljs-built_in">npm</span>.taobao.org<br><br>cnpm install -g cnpm                 <span class="hljs-comment"># 升级 npm</span><br>cnpm cache clean -f                 <span class="hljs-comment"># 清除 npm 缓存</span><br><br>===更新 hexo: 进入 blog 目录，执行如下命令=== <br><span class="hljs-comment"># 更新 package.json 中的 hexo 及个插件版本</span><br>cnpm install -g <span class="hljs-built_in">npm</span>-check           <span class="hljs-comment"># 检查之前安装的插件，都有哪些是可以升级的 </span><br>cnpm install -g <span class="hljs-built_in">npm</span>-upgrade         <span class="hljs-comment"># 升级系统中的插件</span><br><span class="hljs-built_in">npm</span>-check<br><span class="hljs-built_in">npm</span>-upgrade<br><br><span class="hljs-comment"># 更新 hexo 及所有插件</span><br>cnpm update<br><br><span class="hljs-comment"># 确认 hexo 已经更新</span><br>hexo -v<br></code></pre></td></tr></table></figure><!-- <iframe src="https://xmuli.tech/posts/cb1e6c4f/" width="100%" height="500" name="topFrame" scrolling="yes"  noresize="noresize" frameborder="0" id="topFrame"></iframe> --><p>参考</p><ul><li><a href="https://xmuli.tech/posts/cb1e6c4f">https://xmuli.tech/posts/cb1e6c4f</a></li><li><a href="https://www.myfreax.com/how-to-install-node-js-on-ubuntu-18-04">https://www.myfreax.com/how-to-install-node-js-on-ubuntu-18-04</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>TroubleShoot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TroubleShoot</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python Sort Algorithm</title>
    <link href="/2021/08/16/PythonSortAlgorithm/"/>
    <url>/2021/08/16/PythonSortAlgorithm/</url>
    
    <content type="html"><![CDATA[<h2 id="Python常用排序算法"><a href="#Python常用排序算法" class="headerlink" title="Python常用排序算法"></a>Python常用排序算法</h2><span id="more"></span><h5 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sql">def quick_sort(<span class="hljs-keyword">array</span>):<br>    if len(<span class="hljs-keyword">array</span>) <span class="hljs-operator">&lt;=</span> <span class="hljs-number">1</span>:  # 递归跳出条件<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">array</span><br>    pivot <span class="hljs-operator">=</span> <span class="hljs-keyword">array</span>[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">left</span> <span class="hljs-operator">=</span> [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-keyword">array</span>[<span class="hljs-number">1</span>:] if i <span class="hljs-operator">&lt;</span> pivot]<br>    <span class="hljs-keyword">right</span> <span class="hljs-operator">=</span> [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-keyword">array</span>[<span class="hljs-number">1</span>:] if i <span class="hljs-operator">&gt;=</span> pivot]<br>    <span class="hljs-keyword">return</span> quick_sort(<span class="hljs-keyword">left</span>) <span class="hljs-operator">+</span> [pivot] <span class="hljs-operator">+</span> quick_sort(<span class="hljs-keyword">right</span>)<br></code></pre></td></tr></table></figure><h5 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h5><figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sas">def bubble_sort(<span class="hljs-meta">array</span>):<br>    for i <span class="hljs-meta">in</span><span class="hljs-meta"> range(</span>l<span class="hljs-meta">en(</span><span class="hljs-meta">array</span>) - 1):<br>        for j <span class="hljs-meta">in</span><span class="hljs-meta"> range(</span>l<span class="hljs-meta">en(</span><span class="hljs-meta">array</span>) - i -1): # 已排序好的部分不需再遍历<br>            <span class="hljs-meta">if</span> <span class="hljs-meta">array</span>[j] &gt; <span class="hljs-meta">array</span>[j+1]:<br>                <span class="hljs-meta">array</span>[j], <span class="hljs-meta">array</span>[j+1] = <span class="hljs-meta">array</span>[j+1], <span class="hljs-meta">array</span>[j]<br>    <span class="hljs-meta">return</span> <span class="hljs-meta">array</span><br></code></pre></td></tr></table></figure><h5 id="桶排"><a href="#桶排" class="headerlink" title="桶排"></a>桶排</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs sql">def bucker_sort(<span class="hljs-keyword">array</span>):<br>    <span class="hljs-keyword">result</span> <span class="hljs-operator">=</span> []<br>    minVal, maxVal <span class="hljs-operator">=</span> <span class="hljs-built_in">min</span>(<span class="hljs-keyword">array</span>), <span class="hljs-built_in">max</span>(<span class="hljs-keyword">array</span>)<br>    bucket <span class="hljs-operator">=</span> [<span class="hljs-number">0</span>] <span class="hljs-operator">*</span> (maxVal <span class="hljs-operator">-</span> minVal <span class="hljs-operator">+</span> <span class="hljs-number">1</span>)  # 所需的桶数<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-keyword">array</span>:<br>        bucket[i <span class="hljs-operator">-</span> minVal] <span class="hljs-operator">+</span><span class="hljs-operator">=</span> <span class="hljs-number">1</span>     # 每个数字出现的次数<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-keyword">range</span>(len(bucket)):<br>        if bucket[i]:<br>            <span class="hljs-keyword">result</span> <span class="hljs-operator">+</span><span class="hljs-operator">=</span> [i <span class="hljs-operator">+</span> minVal] <span class="hljs-operator">*</span> bucket[i]<br>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">result</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux One Line Command</title>
    <link href="/2021/08/13/OneLineCommand/"/>
    <url>/2021/08/13/OneLineCommand/</url>
    
    <content type="html"><![CDATA[<h2 id="Linux-常用命令"><a href="#Linux-常用命令" class="headerlink" title="Linux 常用命令"></a>Linux 常用命令</h2><span id="more"></span><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs clean">sh -n ##判断是否有语法错误<br>sh -x ##执行详细过程<br>## 修改目录颜色<br>dircolors -p &gt; ~/.dircolors   ## 编辑 ~/.dircolors 修改<br>## 忽略大小写<br>echo <span class="hljs-string">&#x27;set completion-ignore-case on&#x27;</span> &gt; ~/.inputrc<br></code></pre></td></tr></table></figure><h5 id="Linux-两个文件求交集、并集、差集"><a href="#Linux-两个文件求交集、并集、差集" class="headerlink" title="Linux 两个文件求交集、并集、差集"></a>Linux 两个文件求交集、并集、差集</h5><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver"><span class="hljs-built_in">sort</span> <span class="hljs-keyword">a</span>.txt b.txt | uniq -d   <span class="hljs-comment">### 交集</span><br><span class="hljs-built_in">sort</span> <span class="hljs-keyword">a</span>.txt b.txt | uniq   <span class="hljs-comment">###并集 </span><br><span class="hljs-built_in">sort</span> <span class="hljs-keyword">a</span>.txt b.txt b.txt | uniq -u  <span class="hljs-comment">## 差集 a-b</span><br><span class="hljs-built_in">sort</span> b.txt <span class="hljs-keyword">a</span>.txt <span class="hljs-keyword">a</span>.txt | uniq -u  <span class="hljs-comment">## 差集 b-a</span><br></code></pre></td></tr></table></figure><p>使用sort可以将文件进行排序，可以使用sort后面的玲玲，例如 -n 按照数字格式排序，例如 -i 忽略大小写，例如使用-r 为逆序输出等<br>uniq为删除文件中重复的行，得到文件中唯一的行，后面的命令 -d 表示的是输出出现次数大于1的内容 -u表示的是输出出现次数为1的内容，那么对于上述的求交集并集差集的命令做如下的解释：</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs less"><span class="hljs-selector-tag">sort</span> <span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.txt</span> <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt</span> | <span class="hljs-selector-tag">uniq</span> <span class="hljs-selector-tag">-d</span> #将<span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.txt</span> <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt</span>文件进行排序，<span class="hljs-selector-tag">uniq</span>使得两个文件中的内容为唯一的，使用<span class="hljs-selector-tag">-d</span>输出两个文件中次数大于<span class="hljs-selector-tag">1</span>的内容，即是得到交集<br><span class="hljs-selector-tag">sort</span> <span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.txt</span> <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt</span> | <span class="hljs-selector-tag">uniq</span>  #将<span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.txt</span> <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt</span>文件进行排序，<span class="hljs-selector-tag">uniq</span>使得两个文件中的内容为唯一的，即可得到两个文件的并集<br><span class="hljs-selector-tag">sort</span> <span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.txt</span> <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt</span> <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt</span> | <span class="hljs-selector-tag">uniq</span> <span class="hljs-selector-tag">-u</span> #将两个文件排序，最后输出<span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.txt</span> <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt</span> <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt</span>文件中只出现过一次的内容，因为有两个<span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt</span>所以只会输出只在<span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.txt</span>出现过一次的内容，即是<span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.txt-b</span><span class="hljs-selector-class">.txt</span>差集<br>#对于<span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt-a</span><span class="hljs-selector-class">.txt</span>为同理<br></code></pre></td></tr></table></figure><h5 id="grep-命令是常用的搜索文本内容的，要找交集，如下即可："><a href="#grep-命令是常用的搜索文本内容的，要找交集，如下即可：" class="headerlink" title="grep 命令是常用的搜索文本内容的，要找交集，如下即可："></a>grep 命令是常用的搜索文本内容的，要找交集，如下即可：</h5><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">grep <span class="hljs-operator">-F</span> <span class="hljs-operator">-f</span> a.txt b.txt | <span class="hljs-built_in">sort</span> | uniq<br></code></pre></td></tr></table></figure><h5 id="差集"><a href="#差集" class="headerlink" title="差集:"></a>差集:</h5><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">grep -F -v -f <span class="hljs-keyword">a</span>.txt b.txt | <span class="hljs-built_in">sort</span> | uniq<br>grep -F -v -f b.txt <span class="hljs-keyword">a</span>.txt | <span class="hljs-built_in">sort</span> | uniq<br><span class="hljs-comment">#第一行结果为b-a；第二行为a-b。注意顺序很重要</span><br></code></pre></td></tr></table></figure><h5 id="根据id提取fastq"><a href="#根据id提取fastq" class="headerlink" title="根据id提取fastq"></a>根据id提取fastq</h5><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs clean">grep -f id -A <span class="hljs-number">3</span> BC01.fq &gt; test.fq   ### -f 参数为ID文件<br></code></pre></td></tr></table></figure><h5 id="批量重命名文件"><a href="#批量重命名文件" class="headerlink" title="批量重命名文件"></a>批量重命名文件</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#只更改户后缀</span><br>rename <span class="hljs-string">&#x27;s/.txt/.log/&#x27;</span> *.txt   <span class="hljs-comment">#### 把txt后缀改为log</span><br><span class="hljs-comment">#小写变大写</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> `ls`;<span class="hljs-keyword">do</span> mv -f <span class="hljs-variable">$i</span> `<span class="hljs-built_in">echo</span> <span class="hljs-variable">$i</span> | tr a-z A-Z`;<span class="hljs-keyword">done</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> `ls`;<span class="hljs-keyword">do</span> mv -f <span class="hljs-variable">$i</span> `<span class="hljs-built_in">echo</span> <span class="hljs-variable">$i</span> | sed <span class="hljs-string">&#x27;s/..../..../&#x27;</span>`;<span class="hljs-keyword">done</span>  <span class="hljs-comment">##使用sed替换q</span><br>rename <span class="hljs-string">&#x27;s/small/large/&#x27;</span> image_*.png<br></code></pre></td></tr></table></figure><h5 id="删除空行"><a href="#删除空行" class="headerlink" title="删除空行"></a>删除空行</h5><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs vim">sed -i <span class="hljs-string">&#x27;/^$/d&#x27;</span> <span class="hljs-keyword">file</span><br><span class="hljs-keyword">grep</span> -v <span class="hljs-string">&#x27;^$&#x27;</span> <span class="hljs-keyword">file</span>   或  sed <span class="hljs-string">&#x27;/^$/d&#x27;</span> <span class="hljs-keyword">file</span> 或 sed -n <span class="hljs-string">&#x27;/./p&#x27;</span> <span class="hljs-keyword">file</span><br>awk <span class="hljs-string">&#x27;/./&#123;print&#125;&#x27;</span> <span class="hljs-keyword">file</span> 或  <span class="hljs-keyword">tr</span> -s <span class="hljs-string">&#x27;n&#x27;</span><br>#删除最后一列<br>sed -r -<span class="hljs-keyword">e</span> <span class="hljs-string">&#x27;s/\t[^\t]*$//g&#x27;</span> <span class="hljs-keyword">file</span>   <br></code></pre></td></tr></table></figure><h5 id="统计文件大小"><a href="#统计文件大小" class="headerlink" title="统计文件大小"></a>统计文件大小</h5><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim">du -<span class="hljs-keyword">sh</span> * 或者 du -h --<span class="hljs-built_in">max</span>-depth=<span class="hljs-number">1</span>  或 du -<span class="hljs-keyword">sh</span> * | <span class="hljs-keyword">grep</span> [GM] | <span class="hljs-keyword">sort</span> 提取G 和 M的文件并排序<br></code></pre></td></tr></table></figure><h5 id="计算reads数"><a href="#计算reads数" class="headerlink" title="计算reads数"></a>计算reads数</h5><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">expr <span class="hljs-constructor">$(<span class="hljs-params">wc</span> -<span class="hljs-params">l</span> &lt; <span class="hljs-operator">*</span>.<span class="hljs-params">fastq</span>)</span><span class="hljs-operator"> / </span><span class="hljs-number">4</span><br>expr <span class="hljs-constructor">$(<span class="hljs-params">zcat</span> <span class="hljs-params">test</span><span class="hljs-operator">/</span>1.R1.<span class="hljs-params">fq</span>.<span class="hljs-params">gz</span> | <span class="hljs-params">wc</span> -<span class="hljs-params">l</span>)</span><span class="hljs-operator"> / </span><span class="hljs-number">4</span><br></code></pre></td></tr></table></figure><h5 id="fastq-转-fasta"><a href="#fastq-转-fasta" class="headerlink" title="fastq 转 fasta"></a>fastq 转 fasta</h5><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">awk</span> &#x27;&#123;if(NR%<span class="hljs-number">4</span> == <span class="hljs-number">1</span>)&#123;print <span class="hljs-string">&quot;&gt;&quot;</span> substr($<span class="hljs-number">0</span>, <span class="hljs-number">2</span>)&#125;&#125;&#123;if(NR%<span class="hljs-number">4</span> == <span class="hljs-number">2</span>)&#123;print&#125;&#125;&#x27; xx.fastq &gt;xx.fasta<br><span class="hljs-attribute">awk</span> &#x27;&#123;if(NR%<span class="hljs-number">4</span> == <span class="hljs-number">1</span>)&#123;print <span class="hljs-string">&quot;&gt;&quot;</span> <span class="hljs-string">&quot;&#x27;$j&#x27;&quot;</span><span class="hljs-string">&quot;_&quot;</span>NR&#125;&#125;&#123;if(NR%<span class="hljs-number">4</span> == <span class="hljs-number">2</span>)&#123;print&#125;&#125;&#x27;    #   <span class="hljs-string">&quot;&#x27;$j&#x27;&quot;</span> awk中引用外部变量<br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">sort</span> -k<span class="hljs-number">1</span>,<span class="hljs-number">1</span>V -k<span class="hljs-number">2</span>,<span class="hljs-number">2</span>n file   ## V 参数忽略第一列中的文本按数字排序<br><span class="hljs-attribute">awk</span> &#x27;$<span class="hljs-number">1</span> ~ /chr<span class="hljs-number">1</span>|chr<span class="hljs-number">3</span>/&#x27; file ## 第一列匹配chr<span class="hljs-number">1</span>或chr<span class="hljs-number">3</span><br><span class="hljs-attribute">awk</span> &#x27;NR &gt; <span class="hljs-number">3</span>&#x27; file ## 取出第四行以后<br><span class="hljs-attribute">sed</span> -n &#x27;<span class="hljs-number">20</span>,<span class="hljs-number">50</span>p&#x27; file # 取出<span class="hljs-number">20</span>到<span class="hljs-number">50</span>行<br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">paste</span> file<span class="hljs-number">1</span> file<span class="hljs-number">2</span>  # 横向拼接文件，拼接前可用dos<span class="hljs-number">2</span>unix转换文件类型<br></code></pre></td></tr></table></figure><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs clean"><span class="hljs-string">&#x27;%&#x27;</span> 从后向前删除, <span class="hljs-string">&#x27;#&#x27;</span> 从前向后删除<br>sed 替换每行最后一个匹配的字符<br>sed <span class="hljs-string">&#x27;s/\(.*\)src_str\(.*\)/\1dst_str\2/&#x27;</span>  yourfile   ##  src_str：要匹配的字符  dst_str: 要替换的字符<br></code></pre></td></tr></table></figure><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">biom</span>=<span class="hljs-variable">$&#123;i##*/&#125;</span>    <span class="hljs-comment">#返回 / 后的字符</span><br><span class="hljs-attr">biom</span>=<span class="hljs-variable">$&#123;i%/*&#125;</span>     <span class="hljs-comment">#返回最后 / 前的字符</span><br></code></pre></td></tr></table></figure><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">ls -<span class="hljs-keyword">ld</span> 列出文件全路径<br></code></pre></td></tr></table></figure><h5 id="使用-wget-完成批量下载"><a href="#使用-wget-完成批量下载" class="headerlink" title="使用 wget 完成批量下载"></a>使用 wget 完成批量下载</h5><p>如果想下载一个网站上目录中的所有文件, 我需要执行一长串wget命令, 但这样做会更好:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">wget -nd -r -l1 --no-parent http:<span class="hljs-regexp">//</span>www.foo.com<span class="hljs-regexp">/mp3/</span><br></code></pre></td></tr></table></figure><p>这条命令可以执行的很好, 但有时会下载像 index.@xx 这样一些我不想要的文件. 如果你知道想要文件的格式, 可以用下面的命令来避免下载那些多余的文件:</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">wget -nd -r -l1 --no-parent -<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">A</span>.</span></span>mp3 -<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">A</span>.</span></span>wma http:<span class="hljs-comment">//www.foo.com/mp3/</span><br></code></pre></td></tr></table></figure><p>我来简单的介绍一下命令中指定选项的作用.<br>-nd 不创建目录, wget默认会创建一个目录<br>-r 递归下载<br>-l1 (L one) 递归一层,只下载指定文件夹中的内容, 不下载下一级目录中的.<br>–no-parent 不下载父目录中的文件</p><h5 id="rsync可视化复制文件时的进度"><a href="#rsync可视化复制文件时的进度" class="headerlink" title="rsync可视化复制文件时的进度"></a>rsync可视化复制文件时的进度</h5><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">rsync</span> -avPh 源文件 目标文件<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>知网羊毛</title>
    <link href="/2021/08/12/%E7%9F%A5%E7%BD%91%E7%BE%8A%E6%AF%9B/"/>
    <url>/2021/08/12/%E7%9F%A5%E7%BD%91%E7%BE%8A%E6%AF%9B/</url>
    
    <content type="html"><![CDATA[<h2 id="薅社会主义羊毛-知网"><a href="#薅社会主义羊毛-知网" class="headerlink" title="薅社会主义羊毛-知网"></a>薅社会主义羊毛-知网</h2><span id="more"></span><p>工作中经常会受到同事、朋友的求助帮忙下载论文，中文的、外文的都遇到过。外文文献一般都在Sci_hub(<a href="https://tool.yovisun.com/scihub/">https://tool.yovisun.com/scihub/</a>) 上查找，当然也会有些找不到。中文的文献莫过于知网了，但是知网也是收费模式的。于是在网上挖了下，找到了两三个相对靠谱的可以薅知网羊毛的方法，但是也是有些限制的。</p><h5 id="iData-https-www-cn-ki-net"><a href="#iData-https-www-cn-ki-net" class="headerlink" title="iData(https://www.cn-ki.net/)"></a>iData(<a href="https://www.cn-ki.net/">https://www.cn-ki.net/</a>)</h5><p>直接注册便可使用，缺点就是每天只能下载几篇吧</p><h5 id="80图书馆-官网-http-www-80lib-com-知网-http-www-80lib-com-cnki"><a href="#80图书馆-官网-http-www-80lib-com-知网-http-www-80lib-com-cnki" class="headerlink" title="80图书馆(官网:http://www.80lib.com/ 知网:http://www.80lib.com/cnki/)"></a>80图书馆(官网:<a href="http://www.80lib.com/">http://www.80lib.com/</a> 知网:<a href="http://www.80lib.com/cnki/">http://www.80lib.com/cnki/</a>)</h5><p>优点是无限篇下载，缺点就是只有三天试用，不过应该可以换个邮箱再注册。还有个缺点就是使用相对麻烦，需要使用谷歌浏览器以及对应的插件，不过好在官网都提供了详细的步骤，这里不再赘述。</p><h5 id="科研通-www-ablesci-com"><a href="#科研通-www-ablesci-com" class="headerlink" title="科研通(www.ablesci.com)"></a>科研通(<a href="http://www.ablesci.com/">www.ablesci.com</a>)</h5><p>类似于百度文献互助</p><h5 id="百度文献互助-备用"><a href="#百度文献互助-备用" class="headerlink" title="百度文献互助(备用)"></a>百度文献互助(备用)</h5><p>缺点每天两篇，时间长，还不一定成功。</p><p>其他可用方法可参考：<br><a href="https://zhuanlan.zhihu.com/p/138142587">https://zhuanlan.zhihu.com/p/138142587</a></p>]]></content>
    
    
    <categories>
      
      <category>TroubleShoot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TroubleShoot</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python 异步</title>
    <link href="/2021/08/11/Python_%E5%BC%82%E6%AD%A5/"/>
    <url>/2021/08/11/Python_%E5%BC%82%E6%AD%A5/</url>
    
    <content type="html"><![CDATA[<h2 id="Python中异步、同步、多进程及多线程的比较"><a href="#Python中异步、同步、多进程及多线程的比较" class="headerlink" title="Python中异步、同步、多进程及多线程的比较"></a>Python中异步、同步、多进程及多线程的比较</h2><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> urllib <span class="hljs-keyword">import</span> request<br><span class="hljs-keyword">from</span> urllib <span class="hljs-keyword">import</span> parse<br><span class="hljs-keyword">from</span> urllib.request <span class="hljs-keyword">import</span> urlopen<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-comment"># 用于多进程</span><br><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Process<br><span class="hljs-comment"># 用于多线程</span><br><span class="hljs-keyword">from</span> threading <span class="hljs-keyword">import</span> Thread<br><span class="hljs-comment"># 用于协程+异步</span><br><span class="hljs-keyword">import</span> aiohttp<br><span class="hljs-keyword">import</span> asyncio<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">aiohttp:异步发送POST请求</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">city_rule_asy</span>():</span><br>    data = &#123;<span class="hljs-string">&quot;key&quot;</span>: <span class="hljs-string">&quot;&quot;</span>&#125;<br>    myPostUrl = <span class="hljs-string">&quot;http://api.chinadatapay.com/government/traffic/2299&quot;</span><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> aiohttp.ClientSession() <span class="hljs-keyword">as</span> session:<br>        <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> session.post(myPostUrl, data=data) <span class="hljs-keyword">as</span> res:<br>            <span class="hljs-comment"># print(res.status)</span><br>            <span class="hljs-keyword">return</span> json.loads(<span class="hljs-keyword">await</span> res.text())<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span>():</span><br>    tasks = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>        task = asyncio.ensure_future(city_rule_asy())<br>        tasks.append(task)<br>    loop = asyncio.get_event_loop()<br>    result = loop.run_until_complete(asyncio.gather(*tasks))<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;city_rules.txt&#x27;</span>, <span class="hljs-string">&#x27;a+&#x27;</span>) <span class="hljs-keyword">as</span> fw:<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> response[<span class="hljs-string">&#x27;data&#x27;</span>]:<br>           <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> i[<span class="hljs-string">&#x27;cities&#x27;</span>]:<br>                fw.write(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;city&#x27;</span>]&#125;</span>\t<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;engine&#x27;</span>]&#125;</span>\t<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;prefix&#x27;</span>]&#125;</span>\t<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;vin&#x27;</span>]&#125;</span>\t<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;model&#x27;</span>]&#125;</span>\n&quot;</span>)<br><span class="hljs-comment">#### ============================================ ###</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">city_rule</span>():</span><br>    myPostUrl = <span class="hljs-string">&quot;http://api.chinadatapay.com/government/traffic/2299&quot;</span><br>    data = &#123;<span class="hljs-string">&quot;key&quot;</span>: <span class="hljs-string">&quot;&quot;</span>&#125;<br>    params = parse.urlencode(data).encode(<span class="hljs-string">&#x27;utf-8&#x27;</span>)  <span class="hljs-comment"># 提交类型不能为str，需要为byte类型</span><br>    req = request.Request(myPostUrl, params)<br>    response = json.loads(urlopen(req).read().decode())<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;city_rules.txt&#x27;</span>, <span class="hljs-string">&#x27;a+&#x27;</span>) <span class="hljs-keyword">as</span> fw:<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> response[<span class="hljs-string">&#x27;data&#x27;</span>]:<br>           <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> i[<span class="hljs-string">&#x27;cities&#x27;</span>]:<br>                fw.write(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;city&#x27;</span>]&#125;</span>\t<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;engine&#x27;</span>]&#125;</span>\t<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;prefix&#x27;</span>]&#125;</span>\t<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;vin&#x27;</span>]&#125;</span>\t<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;model&#x27;</span>]&#125;</span>\n&quot;</span>)<br><span class="hljs-comment">## 单进程单线程同步</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">single_process</span>():</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>        city_rule()<br><span class="hljs-comment"># 多进程并行</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mul_process</span>():</span><br>    processes = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>        p = Process(target=city_rule, args=())     <span class="hljs-comment"># 一个参数 args=(prameter,)</span><br>        processes.append(p)<br>        p.start()<br>    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> processes:<br>        p.join()<br><span class="hljs-comment"># 多线程并发</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mul_thead</span>():</span><br>    threads = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>        t = Thread(target=city_rule, args=())<br>        threads.append(t)<br>        t.start()<br>    <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> threads:<br>        t.join()<br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-comment"># 异步</span><br>    run()<br>    <span class="hljs-comment"># 同步</span><br>    single_process()<br>    <span class="hljs-comment"># 多进程</span><br>    mul_process()<br>    <span class="hljs-comment">#多线程</span><br>    mul_thead()<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python Notes</title>
    <link href="/2021/02/02/Python-Notes/"/>
    <url>/2021/02/02/Python-Notes/</url>
    
    <content type="html"><![CDATA[<h2 id="Python学习随笔"><a href="#Python学习随笔" class="headerlink" title="Python学习随笔"></a>Python学习随笔</h2><span id="more"></span><h3 id="字典转dataframe"><a href="#字典转dataframe" class="headerlink" title="字典转dataframe"></a>字典转dataframe</h3><p>不定义列名时：pd.DataFrame.from_dict(data, orient=’index’)<br>定义列名时：pd.DataFrame.from_dict(data, orient=’index’, columns=[‘A’, ‘B’, ‘C’, ‘D’])</p><h3 id="pandas筛选"><a href="#pandas筛选" class="headerlink" title="pandas筛选"></a>pandas筛选</h3><h4 id="选取某列值等于某些值的行用-，不等于用-！-，data-loc-data-‘a’-‘one’"><a href="#选取某列值等于某些值的行用-，不等于用-！-，data-loc-data-‘a’-‘one’" class="headerlink" title="选取某列值等于某些值的行用 == ，不等于用 ！= ，data.loc[data[‘a’] == ‘one’]"></a>选取某列值等于某些值的行用 == ，不等于用 ！= ，data.loc[data[‘a’] == ‘one’]</h4><h4 id="选取某列值是否是某一类型的数值用-isin-取反用"><a href="#选取某列值是否是某一类型的数值用-isin-取反用" class="headerlink" title="选取某列值是否是某一类型的数值用 isin ,取反用 ~"></a>选取某列值是否是某一类型的数值用 isin ,取反用 ~</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs language">data.loc[data[&#x27;a&#x27;].isin([&#x27;one&#x27;, &#x27;two&#x27;])]<br>data.loc[~data[&#x27;a&#x27;].isin([&#x27;one&#x27;, &#x27;two&#x27;])]<br></code></pre></td></tr></table></figure><h4 id="多种条件的选取用-amp-data-loc-data-‘a’-‘one’-amp-data-‘b’-‘two’"><a href="#多种条件的选取用-amp-data-loc-data-‘a’-‘one’-amp-data-‘b’-‘two’" class="headerlink" title="多种条件的选取用 &amp; , data.loc[(data[‘a’] == ‘one’) &amp; (data[‘b’] == ‘two’)]"></a>多种条件的选取用 &amp; , data.loc[(data[‘a’] == ‘one’) &amp; (data[‘b’] == ‘two’)]</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs language">np.linspace(start, stop, num) ##参数为起点，终点，点数，num默认为50<br></code></pre></td></tr></table></figure><h3 id="把某列值设为index，df-set-index-‘columns’-df-reset-index-重置索引"><a href="#把某列值设为index，df-set-index-‘columns’-df-reset-index-重置索引" class="headerlink" title="把某列值设为index，df.set_index(‘columns’)  (df.reset_index()重置索引)"></a>把某列值设为index，df.set_index(‘columns’)  (df.reset_index()重置索引)</h3><p>df中merge函数按 键 合并，concat函数按 轴 合并</p><h3 id="按键-key-合并可以分「单键合并」和「多键合并」"><a href="#按键-key-合并可以分「单键合并」和「多键合并」" class="headerlink" title="按键 (key) 合并可以分「单键合并」和「多键合并」"></a>按键 (key) 合并可以分「单键合并」和「多键合并」</h3><h3 id="单键合并："><a href="#单键合并：" class="headerlink" title="单键合并："></a>单键合并：</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs language">pd.merge(df1, df2, how=s, on=c ) ##c 是 df1 和 df2 共有的一栏，合并方式 (how=s) 有四种：<br></code></pre></td></tr></table></figure><h6 id="左连接-left-：合并之后显示-df1-的所有行"><a href="#左连接-left-：合并之后显示-df1-的所有行" class="headerlink" title="左连接 (left)：合并之后显示 df1 的所有行"></a>左连接 (left)：合并之后显示 df1 的所有行</h6><h6 id="右连接-right-：合并之后显示-df2-的所有行"><a href="#右连接-right-：合并之后显示-df2-的所有行" class="headerlink" title="右连接 (right)：合并之后显示 df2 的所有行"></a>右连接 (right)：合并之后显示 df2 的所有行</h6><h6 id="外连接-outer-：合并-df1-和-df2-共有的所有行"><a href="#外连接-outer-：合并-df1-和-df2-共有的所有行" class="headerlink" title="外连接 (outer)：合并 df1 和 df2 共有的所有行"></a>外连接 (outer)：合并 df1 和 df2 共有的所有行</h6><h6 id="内连接-inner-：只保留两个表中公共部分的信息-默认情况"><a href="#内连接-inner-：只保留两个表中公共部分的信息-默认情况" class="headerlink" title="内连接 (inner)：只保留两个表中公共部分的信息 (默认情况)"></a>内连接 (inner)：只保留两个表中公共部分的信息 (默认情况)</h6><h6 id="多键合并-俩组数据均有该列"><a href="#多键合并-俩组数据均有该列" class="headerlink" title="多键合并(俩组数据均有该列)"></a>多键合并(俩组数据均有该列)</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs language">pd.merge( df1, df2, how=s, on=c )  ## c 是多栏（如一个列表<br></code></pre></td></tr></table></figure><h3 id="多键合并-两组数据不同的列名）"><a href="#多键合并-两组数据不同的列名）" class="headerlink" title="多键合并(两组数据不同的列名）"></a>多键合并(两组数据不同的列名）</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs language">pd.merge(df1, df2, left_on = &#x27;key1&#x27;, right_on = &#x27;key2&#x27;)<br></code></pre></td></tr></table></figure><h3 id="插入列：除在最右侧插入用标签直接创建外，其他列用-insert-方法进行插入，比如table-insert-0-’date’-date"><a href="#插入列：除在最右侧插入用标签直接创建外，其他列用-insert-方法进行插入，比如table-insert-0-’date’-date" class="headerlink" title="插入列：除在最右侧插入用标签直接创建外，其他列用.insert()方法进行插入，比如table.insert(0,’date’,date)"></a>插入列：除在最右侧插入用标签直接创建外，其他列用.insert()方法进行插入，比如table.insert(0,’date’,date)</h3><p>当 df1 和 df2 有两个相同的列 (Asset 和 Instrument) 时，单单只对一列 (Asset) 做合并产出的 DataFrame 会有另一列 (Instrument) 重复的名称。<br>这时 merge 函数给重复的名称加个后缀 _x, _y，也可以设定 suffixes 来改后缀</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs language">pd.concat([df1,df2], axis=0, ignore_index=True)  # 默认axis=0（行连接）<br></code></pre></td></tr></table></figure><h3 id="列索引-→-行索引，用-stack-函数-行索引-→-列索引，用-unstack-函数"><a href="#列索引-→-行索引，用-stack-函数-行索引-→-列索引，用-unstack-函数" class="headerlink" title="列索引 → 行索引，用 stack 函数;行索引 → 列索引，用 unstack 函数"></a>列索引 → 行索引，用 stack 函数;行索引 → 列索引，用 unstack 函数</h3><h3 id="数据透视："><a href="#数据透视：" class="headerlink" title="数据透视："></a>数据透视：</h3><p>用 pivot 函数将「一张长表」变「多张宽表」，<br>用 melt 函数将「多张宽表」变「一张长表」  # 函数 melt 实际是将「源表」转化成 id-variable 类型的 DataFrame</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">data_pivot = data.pivot(index=<span class="hljs-string">&#x27;Date&#x27;</span>,columns=<span class="hljs-string">&#x27;Symbol&#x27;</span>,values=<span class="hljs-string">&#x27;Adj Close&#x27;</span>) <span class="hljs-comment">#若不设置value参数，剩下的列都用来透视</span><br>melted_data = pd.melt(data, id_vars=[<span class="hljs-string">&#x27;Date&#x27;</span>,<span class="hljs-string">&#x27;Symbol&#x27;</span>])<br><span class="hljs-built_in">sorted</span>(<span class="hljs-built_in">set</span>(<span class="hljs-built_in">list</span>), key=<span class="hljs-built_in">list</span>.index)  <span class="hljs-comment">## 消除重复元素不改变原始数据顺序</span><br><span class="hljs-built_in">sorted</span>(<span class="hljs-built_in">dict</span>.items(),key=<span class="hljs-keyword">lambda</span> x:x[<span class="hljs-number">1</span>],reverse=<span class="hljs-literal">True</span>)  <span class="hljs-comment">## 对字典按值反向排序（x[0]按键排序）</span><br></code></pre></td></tr></table></figure><h3 id="pandas-删除列"><a href="#pandas-删除列" class="headerlink" title="pandas 删除列"></a>pandas 删除列</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">df = df.drop([<span class="hljs-string">&#x27;c&#x27;</span>, <span class="hljs-string">&#x27;e&#x27;</span>], <span class="hljs-attribute">axis</span>=1)<br><span class="hljs-comment">#或者</span><br>df.drop([<span class="hljs-string">&#x27;c&#x27;</span>, <span class="hljs-string">&#x27;e&#x27;</span>], <span class="hljs-attribute">axis</span>=1, <span class="hljs-attribute">inplace</span>=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><h3 id="对行-z-score-标准化"><a href="#对行-z-score-标准化" class="headerlink" title="对行 z-score 标准化"></a>对行 z-score 标准化</h3><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs maxima">df.<span class="hljs-built_in">apply</span>(<span class="hljs-built_in">lambda</span> x: (x - <span class="hljs-built_in">np</span>.<span class="hljs-built_in">mean</span>(x)) / (<span class="hljs-built_in">np</span>.<span class="hljs-built_in">std</span>(x,ddof=<span class="hljs-number">1</span>)), axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><h3 id="对-Majority-protein-IDs-列转成多行"><a href="#对-Majority-protein-IDs-列转成多行" class="headerlink" title="对 Majority protein IDs 列转成多行"></a>对 Majority protein IDs 列转成多行</h3><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">df = df[~df[<span class="hljs-string">&#x27;Majority protein IDs&#x27;</span>].str.contains(<span class="hljs-string">&#x27;CON|REV&#x27;</span>, regex=<span class="hljs-keyword">True</span>)]<br>df = df.<span class="hljs-keyword">drop</span>(<span class="hljs-string">&#x27;Majority protein IDs&#x27;</span>, axis=<span class="hljs-number">1</span>).<span class="hljs-keyword">join</span>(df[<span class="hljs-string">&#x27;Majority protein IDs&#x27;</span>].str.split(<span class="hljs-string">&#x27;;&#x27;</span>, expand=<span class="hljs-keyword">True</span>).stack().reset_index(<span class="hljs-keyword">level</span>=<span class="hljs-number">1</span>, <span class="hljs-keyword">drop</span>=<span class="hljs-keyword">True</span>).<span class="hljs-keyword">rename</span>(<span class="hljs-string">&#x27;Majority protein IDs&#x27;</span>))<br><br>def ab(df): <br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;;&#x27;</span>.<span class="hljs-keyword">join</span>(df.<span class="hljs-keyword">values</span>)<br>newcolumns = df_merge.<span class="hljs-keyword">columns</span>.tolist()<br>newcolumns.remove(<span class="hljs-string">&#x27;Majority protein IDs&#x27;</span>)<br>newdf = df_merge.groupby(newcolumns)[<span class="hljs-string">&#x27;Majority protein IDs&#x27;</span>].apply(ab)   ## 多行合并一行<br></code></pre></td></tr></table></figure><h3 id="for、while循环中的else扩展用法"><a href="#for、while循环中的else扩展用法" class="headerlink" title="for、while循环中的else扩展用法"></a>for、while循环中的else扩展用法</h3><p>else中的程序只在一种条件下执行，即循环正常遍历所有内容或者由于条件不成立而结束循环，没有因break或者return而退出循环。continue对else没影响</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs language">for i in range(10):<br>    if i==5:<br>        break<br>    print(&#x27;i=&#x27;,i,end=&#x27;,&#x27;)<br>else:<br>    print(&#x27;success&#x27;)#不输出   在for循环中含有break时则直接终止循环，并不会执行else子句。<br><br>for i in range(10):<br>    if i==5:<br>        continue<br>    print(&#x27;i=&#x27;,i,end=&#x27;,&#x27;)<br>else:<br>    print(&#x27;success&#x27;)#输出<br></code></pre></td></tr></table></figure><h3 id="展平嵌套列表"><a href="#展平嵌套列表" class="headerlink" title="展平嵌套列表"></a>展平嵌套列表</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs language">newlist = [item for items in newlist for item in items]<br>#或者您可以像这样从chain中使用itertools<br>from itertools import chain<br>newlist = list(chain(*newlist))<br>#或者您可以使用chain.from_iterable，其中无需解压缩列表<br>from itertools import chain<br>newlist = list(chain.from_iterable(newlist)) #效率更高<br></code></pre></td></tr></table></figure><h3 id="生成requirements-txt"><a href="#生成requirements-txt" class="headerlink" title="生成requirements.txt"></a>生成requirements.txt</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs language">pipreqs ./ --encoding=utf-8 --force<br></code></pre></td></tr></table></figure><h3 id="单例"><a href="#单例" class="headerlink" title="单例"></a>单例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs language">class Singleton(object):<br>    __instance = None<br><br>    def __new__(cls, age, name):<br>        if not cls.__instance:<br>            cls.__instance = object.__new__(cls)<br>        return cls.__instance<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
