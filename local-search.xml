<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Pytorch学习笔记3-动态计算图</title>
    <link href="/2022/01/18/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03-%E5%8A%A8%E6%80%81%E8%AE%A1%E7%AE%97%E5%9B%BE/"/>
    <url>/2022/01/18/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03-%E5%8A%A8%E6%80%81%E8%AE%A1%E7%AE%97%E5%9B%BE/</url>
    
    <content type="html"><![CDATA[<h2 id="动态计算图"><a href="#动态计算图" class="headerlink" title="动态计算图"></a>动态计算图</h2><span id="more"></span><h5 id="Pytorch的动态计算图"><a href="#Pytorch的动态计算图" class="headerlink" title="Pytorch的动态计算图"></a>Pytorch的动态计算图</h5><p>包括：</p><ul><li>动态计算图简介</li><li>计算图中的Function</li><li>计算图和反向传播</li><li>叶子节点和非叶子节点</li><li>计算图在TensorBoard中的可视化</li></ul><h5 id="动态计算图简介"><a href="#动态计算图简介" class="headerlink" title="动态计算图简介"></a>动态计算图简介</h5><p>Pytorch的计算图由节点和边组成，节点表示张量或者Function，边表示张量和Function之间的依赖关系。<br>Pytorch中的计算图是动态图。这里的动态主要有两重含义。<br>第一层含义是：计算图的正向传播是立即执行的。无需等待完整的计算图创建完毕，每条语句都会在计算图中动态添加节点和边，并立即执行正向传播得到计算结果。<br>第二层含义是：计算图在反向传播后立即销毁。下次调用需要重新构建计算图。如果在程序中使用了backward方法执行了反向传播，或者利用torch.autograd.grad方法计算了梯度，那么创建的计算图会被立即销毁，释放存储空间，下次调用需要重新创建。</p><h6 id="计算图的正向传播是立即执行的。"><a href="#计算图的正向传播是立即执行的。" class="headerlink" title="计算图的正向传播是立即执行的。"></a>计算图的正向传播是立即执行的。</h6><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">import torch <br>w = torch.tensor([[3.0,1.0]],requires<span class="hljs-emphasis">_grad=True)</span><br><span class="hljs-emphasis">b = torch.tensor([[3.0]],requires_grad=True)</span><br><span class="hljs-emphasis">X = torch.randn(10,2)</span><br><span class="hljs-emphasis">Y = torch.randn(10,1)</span><br><span class="hljs-emphasis">Y_hat = X@w.t() + b  # Y_hat定义后其正向传播被立即执行，与其后面的loss创建语句无关</span><br><span class="hljs-emphasis">loss = torch.mean(torch.pow(Y_</span>hat-Y,2))<br><br>print(loss.data)<br>print(Y_hat.data)<br><br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor(16.8885)</span><br><span class="hljs-code">tensor([[ 3.3509],</span><br><span class="hljs-code">        [-2.5233],</span><br><span class="hljs-code">        [ 5.1586],</span><br><span class="hljs-code">        [ 4.9135],</span><br><span class="hljs-code">        [ 1.0449],</span><br><span class="hljs-code">        [ 8.0712],</span><br><span class="hljs-code">        [ 5.0686],</span><br><span class="hljs-code">        [ 0.5840],</span><br><span class="hljs-code">        [-0.0614],</span><br><span class="hljs-code">        [ 2.7492]])</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><h6 id="计算图在反向传播后立即销毁。"><a href="#计算图在反向传播后立即销毁。" class="headerlink" title="计算图在反向传播后立即销毁。"></a>计算图在反向传播后立即销毁。</h6><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> torch <br><span class="hljs-attribute">w</span> = torch.tensor([[<span class="hljs-number">3</span>.<span class="hljs-number">0</span>,<span class="hljs-number">1</span>.<span class="hljs-number">0</span>]],requires_grad=True)<br><span class="hljs-attribute">b</span> = torch.tensor([[<span class="hljs-number">3</span>.<span class="hljs-number">0</span>]],requires_grad=True)<br><span class="hljs-attribute">X</span> = torch.randn(<span class="hljs-number">10</span>,<span class="hljs-number">2</span>)<br><span class="hljs-attribute">Y</span> = torch.randn(<span class="hljs-number">10</span>,<span class="hljs-number">1</span>)<br><span class="hljs-attribute">Y_hat</span> = X@w.t() + b  # Y_hat定义后其正向传播被立即执行，与其后面的loss创建语句无关<br><span class="hljs-attribute">loss</span> = torch.mean(torch.pow(Y_hat-Y,<span class="hljs-number">2</span>))<br><br><span class="hljs-comment">#计算图在反向传播后立即销毁，如果需要保留计算图, 需要设置retain_graph = True</span><br><span class="hljs-attribute">loss</span>.backward()  #loss.backward(retain_graph = True) <br><br><span class="hljs-comment">#loss.backward() #如果再次执行反向传播将报错</span><br></code></pre></td></tr></table></figure><h5 id="计算图中的Function"><a href="#计算图中的Function" class="headerlink" title="计算图中的Function"></a>计算图中的Function</h5><p>计算图中的 张量我们已经比较熟悉了, 计算图中的另外一种节点是Function, 实际上就是 Pytorch中各种对张量操作的函数。<br>这些Function和我们Python中的函数有一个较大的区别，那就是它同时包括正向计算逻辑和反向传播的逻辑。<br>我们可以通过继承torch.autograd.Function来创建这种支持反向传播的Function</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch <br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyReLU</span>(<span class="hljs-params">torch.autograd.Function</span>):</span><br>   <br>    <span class="hljs-comment">#正向传播逻辑，可以用ctx存储一些值，供反向传播使用。</span><br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">ctx, <span class="hljs-built_in">input</span></span>):</span><br>        ctx.save_for_backward(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">input</span>.clamp(<span class="hljs-built_in">min</span>=<span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment">#反向传播逻辑</span><br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">backward</span>(<span class="hljs-params">ctx, grad_output</span>):</span><br>        <span class="hljs-built_in">input</span>, = ctx.saved_tensors<br>        grad_input = grad_output.clone()<br>        grad_input[<span class="hljs-built_in">input</span> &lt; <span class="hljs-number">0</span>] = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">return</span> grad_input<br><br><br>w = torch.tensor([[<span class="hljs-number">3.0</span>,<span class="hljs-number">1.0</span>]],requires_grad=<span class="hljs-literal">True</span>)<br>b = torch.tensor([[<span class="hljs-number">3.0</span>]],requires_grad=<span class="hljs-literal">True</span>)<br>X = torch.tensor([[-<span class="hljs-number">1.0</span>,-<span class="hljs-number">1.0</span>],[<span class="hljs-number">1.0</span>,<span class="hljs-number">1.0</span>]])<br>Y = torch.tensor([[<span class="hljs-number">2.0</span>,<span class="hljs-number">3.0</span>]])<br><br>relu = MyReLU.apply <span class="hljs-comment"># relu现在也可以具有正向传播和反向传播功能</span><br>Y_hat = relu(X@w.t() + b)<br>loss = torch.mean(torch.<span class="hljs-built_in">pow</span>(Y_hat-Y,<span class="hljs-number">2</span>))<br><br>loss.backward()<br><br><span class="hljs-built_in">print</span>(w.grad)<br><span class="hljs-built_in">print</span>(b.grad)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">tensor([[4.5000, 4.5000]])</span><br><span class="hljs-string">tensor([[4.5000]])</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"># Y<span class="hljs-emphasis">_hat的梯度函数即是我们自己所定义的 MyReLU.backward</span><br><span class="hljs-emphasis">print(Y_hat.grad_</span>fn)<br>&#x27;&#x27;&#x27;<br><span class="hljs-code">&lt;torch.autograd.function.MyReLUBackward object at 0x7efe582c7ba8&gt;</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><h5 id="计算图与反向传播"><a href="#计算图与反向传播" class="headerlink" title="计算图与反向传播"></a>计算图与反向传播</h5><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> torch <br><br><span class="hljs-attribute">x</span> = torch.tensor(<span class="hljs-number">3</span>.<span class="hljs-number">0</span>,requires_grad=True)<br><span class="hljs-attribute">y1</span> = x + <span class="hljs-number">1</span><br><span class="hljs-attribute">y2</span> = <span class="hljs-number">2</span>*x<br><span class="hljs-attribute">loss</span> = (y<span class="hljs-number">1</span>-y<span class="hljs-number">2</span>)**<span class="hljs-number">2</span><br><br><span class="hljs-attribute">loss</span>.backward()<br></code></pre></td></tr></table></figure><p>loss.backward()语句调用后，依次发生以下计算过程。</p><ul><li>1，loss自己的grad梯度赋值为1，即对自身的梯度为1。</li><li>2，loss根据其自身梯度以及关联的backward方法，计算出其对应的自变量即y1和y2的梯度，将该值赋值到y1.grad和y2.grad。</li><li>3，y2和y1根据其自身梯度以及关联的backward方法, 分别计算出其对应的自变量x的梯度，x.grad将其收到的多个梯度值累加。<br>（注意，1,2,3步骤的求梯度顺序和对多个梯度值的累加规则恰好是求导链式法则的程序表述）<br>正因为求导链式法则衍生的梯度累加规则，张量的grad梯度不会自动清零，在需要的时候需要手动置零。</li></ul><h5 id="叶子节点和非叶子节点"><a href="#叶子节点和非叶子节点" class="headerlink" title="叶子节点和非叶子节点"></a>叶子节点和非叶子节点</h5><p>执行下面代码，我们会发现 loss.grad并不是我们期望的1,而是 None。类似地 y1.grad 以及 y2.grad也是 None.<br>这是为什么呢？这是由于它们不是叶子节点张量。<br>在反向传播过程中，只有 is_leaf=True 的叶子节点，需要求导的张量的导数结果才会被最后保留下来。<br>那么什么是叶子节点张量呢？叶子节点张量需要满足两个条件。</p><ul><li>1，叶子节点张量是由用户直接创建的张量，而非由某个Function通过计算得到的张量。</li><li>2，叶子节点张量的 requires_grad属性必须为True.<br>Pytorch设计这样的规则主要是为了节约内存或者显存空间，因为几乎所有的时候，用户只会关心他自己直接创建的张量的梯度。<br>所有依赖于叶子节点张量的张量, 其requires_grad 属性必定是True的，但其梯度值只在计算过程中被用到，不会最终存储到grad属性中。<br>如果需要保留中间计算结果的梯度到grad属性中，可以使用 retain_grad方法。<br>如果仅仅是为了调试代码查看梯度值，可以利用register_hook打印日志。</li></ul><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">import torch <br><br>x = torch.tensor(3.0,requires_grad=True)<br>y1 = x + 1<br>y2 = 2*x<br>loss = (y1-y2)**2<br><br>loss.backward()<br>print(&quot;loss.grad:&quot;, loss.grad)<br>print(&quot;y1.grad:&quot;, y1.grad)<br>print(&quot;y2.grad:&quot;, y2.grad)<br>print(x.grad)<br><br>&#x27;&#x27;&#x27;<br><span class="hljs-code">loss.grad: None</span><br><span class="hljs-code">y1.grad: None</span><br><span class="hljs-code">y2.grad: None</span><br><span class="hljs-code">tensor(4.)</span><br>&#x27;&#x27;&#x27;<br><br>print(x.is<span class="hljs-emphasis">_leaf)</span><br><span class="hljs-emphasis">print(y1.is_leaf)</span><br><span class="hljs-emphasis">print(y2.is_leaf)</span><br><span class="hljs-emphasis">print(loss.is_</span>leaf)<br><br>&#x27;&#x27;&#x27;<br><span class="hljs-code">True</span><br><span class="hljs-code">False</span><br><span class="hljs-code">False</span><br><span class="hljs-code">False</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><p>利用retain_grad可以保留非叶子节点的梯度值，利用register_hook可以查看非叶子节点的梯度值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch <br><br><span class="hljs-comment">#正向传播</span><br>x = torch.tensor(<span class="hljs-number">3.0</span>,requires_grad=<span class="hljs-literal">True</span>)<br>y1 = x + <span class="hljs-number">1</span><br>y2 = <span class="hljs-number">2</span>*x<br>loss = (y1-y2)**<span class="hljs-number">2</span><br><br><span class="hljs-comment">#非叶子节点梯度显示控制</span><br>y1.register_hook(<span class="hljs-keyword">lambda</span> grad: <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;y1 grad: &#x27;</span>, grad))<br>y2.register_hook(<span class="hljs-keyword">lambda</span> grad: <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;y2 grad: &#x27;</span>, grad))<br>loss.retain_grad()<br><br><span class="hljs-comment">#反向传播</span><br>loss.backward()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;loss.grad:&quot;</span>, loss.grad)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x.grad:&quot;</span>, x.grad)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">y2 grad:  tensor(4.)</span><br><span class="hljs-string">y1 grad:  tensor(-4.)</span><br><span class="hljs-string">loss.grad: tensor(1.)</span><br><span class="hljs-string">x.grad: tensor(4.)</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><h5 id="计算图在TensorBoard中的可视化"><a href="#计算图在TensorBoard中的可视化" class="headerlink" title="计算图在TensorBoard中的可视化"></a>计算图在TensorBoard中的可视化</h5><p>可以利用 torch.utils.tensorboard 将计算图导出到 TensorBoard进行可视化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn <br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Net</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(Net, self).__init__()<br>        self.w = nn.Parameter(torch.randn(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>))<br>        self.b = nn.Parameter(torch.zeros(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>))<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        y = x@self.w + self.b<br>        <span class="hljs-keyword">return</span> y<br><br>net = Net()<br><br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br>writer = SummaryWriter(<span class="hljs-string">&#x27;./data/tensorboard&#x27;</span>)<br>writer.add_graph(net,input_to_model = torch.rand(<span class="hljs-number">10</span>,<span class="hljs-number">2</span>))<br>writer.close()<br><br>%load_ext tensorboard<br><span class="hljs-comment">#%tensorboard --logdir ./data/tensorboard</span><br><br><span class="hljs-keyword">from</span> tensorboard <span class="hljs-keyword">import</span> notebook<br>notebook.<span class="hljs-built_in">list</span>()<br><br><span class="hljs-comment">#在tensorboard中查看模型</span><br>notebook.start(<span class="hljs-string">&quot;--logdir ./data/tensorboard&quot;</span>)<br></code></pre></td></tr></table></figure><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记2-自动微分机制</title>
    <link href="/2022/01/18/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02-%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86%E6%9C%BA%E5%88%B6/"/>
    <url>/2022/01/18/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02-%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h2 id="自动微分机制"><a href="#自动微分机制" class="headerlink" title="自动微分机制"></a>自动微分机制</h2><span id="more"></span><p>神经网络通常依赖反向传播求梯度来更新网络参数，求梯度过程通常是一件非常复杂而容易出错的事情。而深度学习框架可以帮助我们自动地完成这种求梯度运算。<br>Pytorch一般通过反向传播 backward 方法 实现这种求梯度计算。该方法求得的梯度将存在对应自变量张量的grad属性下。除此之外，也能够调用torch.autograd.grad 函数来实现求梯度计算。这就是Pytorch的自动微分机制。</p><h5 id="利用backward方法求导数"><a href="#利用backward方法求导数" class="headerlink" title="利用backward方法求导数"></a>利用backward方法求导数</h5><p>backward 方法通常在一个标量张量上调用，该方法求得的梯度将存在对应自变量张量的grad属性下。如果调用的张量非标量，则要传入一个和它同形状 的gradient参数张量。相当于用该gradient参数张量与调用张量作向量点乘，得到的标量结果再反向传播。</p><h6 id="标量的反向传播"><a href="#标量的反向传播" class="headerlink" title="标量的反向传播"></a>标量的反向传播</h6><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">import numpy as np <br>import torch <br><br># f(x) = a*x**2 <span class="hljs-code">+ b*x +</span> c的导数<br><br>x = torch.tensor(0.0,requires_grad = True) # x需要被求导<br>a = torch.tensor(1.0)<br>b = torch.tensor(-2.0)<br>c = torch.tensor(1.0)<br>y = a*torch.pow(x,2) <span class="hljs-code">+ b*x +</span> c <br><br>y.backward()<br>dy<span class="hljs-emphasis">_dx = x.grad</span><br><span class="hljs-emphasis">print(dy_</span>dx)<br><br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor(-2.)</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><h6 id="非标量的反向传播"><a href="#非标量的反向传播" class="headerlink" title="非标量的反向传播"></a>非标量的反向传播</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><span class="hljs-keyword">import</span> torch <br><br><span class="hljs-comment"># f(x) = a*x**2 + b*x + c</span><br><br>x = torch.tensor([[<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>],[<span class="hljs-number">1.0</span>,<span class="hljs-number">2.0</span>]],requires_grad = <span class="hljs-literal">True</span>) <span class="hljs-comment"># x需要被求导</span><br>a = torch.tensor(<span class="hljs-number">1.0</span>)<br>b = torch.tensor(-<span class="hljs-number">2.0</span>)<br>c = torch.tensor(<span class="hljs-number">1.0</span>)<br>y = a*torch.<span class="hljs-built_in">pow</span>(x,<span class="hljs-number">2</span>) + b*x + c <br><br>gradient = torch.tensor([[<span class="hljs-number">1.0</span>,<span class="hljs-number">1.0</span>],[<span class="hljs-number">1.0</span>,<span class="hljs-number">1.0</span>]])<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x:\n&quot;</span>,x)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y:\n&quot;</span>,y)<br>y.backward(gradient = gradient)<br>x_grad = x.grad<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x_grad:\n&quot;</span>,x_grad)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">x:</span><br><span class="hljs-string"> tensor([[0., 0.],</span><br><span class="hljs-string">        [1., 2.]], requires_grad=True)</span><br><span class="hljs-string">y:</span><br><span class="hljs-string"> tensor([[1., 1.],</span><br><span class="hljs-string">        [0., 1.]], grad_fn=&lt;AddBackward0&gt;)</span><br><span class="hljs-string">x_grad:</span><br><span class="hljs-string"> tensor([[-2., -2.],</span><br><span class="hljs-string">        [ 0.,  2.]])</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><h6 id="非标量的反向传播可以用标量的反向传播实现"><a href="#非标量的反向传播可以用标量的反向传播实现" class="headerlink" title="非标量的反向传播可以用标量的反向传播实现"></a>非标量的反向传播可以用标量的反向传播实现</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><span class="hljs-keyword">import</span> torch <br><br><span class="hljs-comment"># f(x) = a*x**2 + b*x + c</span><br><br>x = torch.tensor([[<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>],[<span class="hljs-number">1.0</span>,<span class="hljs-number">2.0</span>]],requires_grad = <span class="hljs-literal">True</span>) <span class="hljs-comment"># x需要被求导</span><br>a = torch.tensor(<span class="hljs-number">1.0</span>)<br>b = torch.tensor(-<span class="hljs-number">2.0</span>)<br>c = torch.tensor(<span class="hljs-number">1.0</span>)<br>y = a*torch.<span class="hljs-built_in">pow</span>(x,<span class="hljs-number">2</span>) + b*x + c <br><br>gradient = torch.tensor([[<span class="hljs-number">1.0</span>,<span class="hljs-number">1.0</span>],[<span class="hljs-number">1.0</span>,<span class="hljs-number">1.0</span>]])<br>z = torch.<span class="hljs-built_in">sum</span>(y*gradient)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x:&quot;</span>,x)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y:&quot;</span>,y)<br>z.backward()<br>x_grad = x.grad<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x_grad:\n&quot;</span>,x_grad)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">x: tensor([[0., 0.],</span><br><span class="hljs-string">        [1., 2.]], requires_grad=True)</span><br><span class="hljs-string">y: tensor([[1., 1.],</span><br><span class="hljs-string">        [0., 1.]], grad_fn=&lt;AddBackward0&gt;)</span><br><span class="hljs-string">x_grad:</span><br><span class="hljs-string"> tensor([[-2., -2.],</span><br><span class="hljs-string">        [ 0.,  2.]])</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><h5 id="利用autograd-grad方法求导数"><a href="#利用autograd-grad方法求导数" class="headerlink" title="利用autograd.grad方法求导数"></a>利用autograd.grad方法求导数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><span class="hljs-keyword">import</span> torch <br><br><span class="hljs-comment"># f(x) = a*x**2 + b*x + c的导数</span><br><br>x = torch.tensor(<span class="hljs-number">0.0</span>,requires_grad = <span class="hljs-literal">True</span>) <span class="hljs-comment"># x需要被求导</span><br>a = torch.tensor(<span class="hljs-number">1.0</span>)<br>b = torch.tensor(-<span class="hljs-number">2.0</span>)<br>c = torch.tensor(<span class="hljs-number">1.0</span>)<br>y = a*torch.<span class="hljs-built_in">pow</span>(x,<span class="hljs-number">2</span>) + b*x + c<br><br><br><span class="hljs-comment"># create_graph 设置为 True 将允许创建更高阶的导数 </span><br>dy_dx = torch.autograd.grad(y,x,create_graph=<span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>]<br><span class="hljs-built_in">print</span>(dy_dx.data)<br><br><span class="hljs-comment"># 求二阶导数</span><br>dy2_dx2 = torch.autograd.grad(dy_dx,x)[<span class="hljs-number">0</span>] <br><br><span class="hljs-built_in">print</span>(dy2_dx2.data)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">tensor(-2.)</span><br><span class="hljs-string">tensor(2.)</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">import numpy as np <br>import torch <br><br>x1 = torch.tensor(1.0,requires<span class="hljs-emphasis">_grad = True) # x需要被求导</span><br><span class="hljs-emphasis">x2 = torch.tensor(2.0,requires_</span>grad = True)<br><br>y1 = x1*x2<br>y2 = x1+x2<br><br><br># 允许同时对多个自变量求导数<br>(dy1<span class="hljs-emphasis">_dx1,dy1_dx2) = torch.autograd.grad(outputs=y1,inputs = [x1,x2],retain_graph = True)</span><br><span class="hljs-emphasis">print(dy1_dx1,dy1_</span>dx2)<br><br># 如果有多个因变量，相当于把多个因变量的梯度结果求和<br>(dy12<span class="hljs-emphasis">_dx1,dy12_dx2) = torch.autograd.grad(outputs=[y1,y2],inputs = [x1,x2])</span><br><span class="hljs-emphasis">print(dy12_dx1,dy12_</span>dx2)<br><br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor(2.) tensor(1.)</span><br><span class="hljs-code">tensor(3.) tensor(2.)</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><h5 id="利用自动微分和优化器求最小值"><a href="#利用自动微分和优化器求最小值" class="headerlink" title="利用自动微分和优化器求最小值"></a>利用自动微分和优化器求最小值</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><span class="hljs-keyword">import</span> torch <br><br><span class="hljs-comment"># f(x) = a*x**2 + b*x + c的最小值</span><br><br>x = torch.tensor(<span class="hljs-number">0.0</span>,requires_grad = <span class="hljs-literal">True</span>) <span class="hljs-comment"># x需要被求导</span><br>a = torch.tensor(<span class="hljs-number">1.0</span>)<br>b = torch.tensor(-<span class="hljs-number">2.0</span>)<br>c = torch.tensor(<span class="hljs-number">1.0</span>)<br><br>optimizer = torch.optim.SGD(params=[x],lr = <span class="hljs-number">0.01</span>)<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">f</span>(<span class="hljs-params">x</span>):</span><br>    result = a*torch.<span class="hljs-built_in">pow</span>(x,<span class="hljs-number">2</span>) + b*x + c <br>    <span class="hljs-keyword">return</span>(result)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">500</span>):<br>    optimizer.zero_grad()<br>    y = f(x)<br>    y.backward()<br>    optimizer.step()<br>   <br>    <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y=&quot;</span>,f(x).data,<span class="hljs-string">&quot;;&quot;</span>,<span class="hljs-string">&quot;x=&quot;</span>,x.data)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">y= tensor(0.) ; x= tensor(1.0000)</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch学习笔记1-张量数据结构</title>
    <link href="/2022/01/18/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01-%E5%BC%A0%E9%87%8F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <url>/2022/01/18/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01-%E5%BC%A0%E9%87%8F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
    
    <content type="html"><![CDATA[<h2 id="张量的数据类型、张量的维度、张量的尺寸、张量和numpy数组等"><a href="#张量的数据类型、张量的维度、张量的尺寸、张量和numpy数组等" class="headerlink" title="张量的数据类型、张量的维度、张量的尺寸、张量和numpy数组等"></a>张量的数据类型、张量的维度、张量的尺寸、张量和numpy数组等</h2><span id="more"></span><p>Pytorch的基本数据结构是张量Tensor。张量即多维数组。Pytorch的张量和numpy中的array很类似。</p><h5 id="张量的数据类型"><a href="#张量的数据类型" class="headerlink" title="张量的数据类型"></a>张量的数据类型</h5><p>张量的数据类型和numpy.array基本一一对应，但是不支持str类型。包括:</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs angelscript">torch.<span class="hljs-built_in">float</span>64(torch.<span class="hljs-built_in">double</span>),<br><br>torch.<span class="hljs-built_in">float</span>32(torch.<span class="hljs-built_in">float</span>),<br><br>torch.<span class="hljs-built_in">float</span>16,<br><br>torch.<span class="hljs-built_in">int</span>64(torch.long),<br><br>torch.<span class="hljs-built_in">int</span>32(torch.<span class="hljs-built_in">int</span>),<br><br>torch.<span class="hljs-built_in">int</span>16,<br><br>torch.<span class="hljs-built_in">int</span>8,<br><br>torch.<span class="hljs-built_in">uint</span>8,<br><br>torch.<span class="hljs-built_in">bool</span><br></code></pre></td></tr></table></figure><p>一般神经网络建模使用的都是torch.float32类型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch <br><br><span class="hljs-comment"># 自动推断数据类型</span><br>i = torch.tensor(<span class="hljs-number">1</span>);<span class="hljs-built_in">print</span>(i,i.dtype)<br>x = torch.tensor(<span class="hljs-number">2.0</span>);<span class="hljs-built_in">print</span>(x,x.dtype)<br>b = torch.tensor(<span class="hljs-literal">True</span>);<span class="hljs-built_in">print</span>(b,b.dtype)<br><span class="hljs-string">&#x27;&#x27;&#x27; # 输出</span><br><span class="hljs-string">tensor(1) torch.int64</span><br><span class="hljs-string">tensor(2.) torch.float32</span><br><span class="hljs-string">tensor(True) torch.bool</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment"># 指定数据类型</span><br>i = torch.tensor(<span class="hljs-number">1</span>,dtype = torch.int32);<span class="hljs-built_in">print</span>(i,i.dtype)<br>x = torch.tensor(<span class="hljs-number">2.0</span>,dtype = torch.double);<span class="hljs-built_in">print</span>(x,x.dtype)<br>‘’‘<br>tensor(<span class="hljs-number">1</span>, dtype=torch.int32) torch.int32<br>tensor(<span class="hljs-number">2.</span>, dtype=torch.float64) torch.float64<br>’‘’<br><br><span class="hljs-comment"># 使用特定类型构造函数</span><br>i = torch.IntTensor(<span class="hljs-number">1</span>);<span class="hljs-built_in">print</span>(i,i.dtype)<br>x = torch.Tensor(np.array(<span class="hljs-number">2.0</span>));<span class="hljs-built_in">print</span>(x,x.dtype) <span class="hljs-comment">#等价于torch.FloatTensor</span><br>b = torch.BoolTensor(np.array([<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>])); <span class="hljs-built_in">print</span>(b,b.dtype)<br>‘’‘<br>tensor([<span class="hljs-number">1266789664</span>], dtype=torch.int32) torch.int32<br>tensor(<span class="hljs-number">2.</span>) torch.float32<br>tensor([ <span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>,  <span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>]) torch.<span class="hljs-built_in">bool</span><br>’‘’<br><br><span class="hljs-comment"># 不同类型进行转换</span><br>i = torch.tensor(<span class="hljs-number">1</span>); <span class="hljs-built_in">print</span>(i,i.dtype)<br>x = i.<span class="hljs-built_in">float</span>(); <span class="hljs-built_in">print</span>(x,x.dtype) <span class="hljs-comment">#调用 float方法转换成浮点类型</span><br>y = i.<span class="hljs-built_in">type</span>(torch.<span class="hljs-built_in">float</span>); <span class="hljs-built_in">print</span>(y,y.dtype) <span class="hljs-comment">#使用type函数转换成浮点类型</span><br>z = i.type_as(x);<span class="hljs-built_in">print</span>(z,z.dtype) <span class="hljs-comment">#使用type_as方法转换成某个Tensor相同类型</span><br>‘’‘<br>tensor(<span class="hljs-number">1</span>) torch.int64<br>tensor(<span class="hljs-number">1.</span>) torch.float32<br>tensor(<span class="hljs-number">1.</span>) torch.float32<br>tensor(<span class="hljs-number">1.</span>) torch.float32<br>’‘’<br></code></pre></td></tr></table></figure><h5 id="张量的维度"><a href="#张量的维度" class="headerlink" title="张量的维度"></a>张量的维度</h5><p>不同类型的数据可以用不同维度(dimension)的张量来表示。标量为0维张量，向量为1维张量，矩阵为2维张量。彩色图像有rgb三个通道，可以表示为3维张量。视频还有时间维，可以表示为4维张量。<br>可以简单地总结为：有几层中括号，就是多少维的张量。</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">scalar = torch.tensor(True)<br>print(scalar)<br>print(scalar.dim())  # 标量，0维张量<br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor(True)</span><br><span class="hljs-code">0</span><br>&#x27;&#x27;&#x27;<br><br>vector = torch.tensor([1.0,2.0,3.0,4.0]) #向量，1维张量<br>print(vector)<br>print(vector.dim())<br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor([1., 2., 3., 4.])</span><br><span class="hljs-code">1</span><br>&#x27;&#x27;&#x27;<br><br>matrix = torch.tensor([[1.0,2.0],[3.0,4.0]]) #矩阵, 2维张量<br>print(matrix)<br>print(matrix.dim())<br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor([[1., 2.],</span><br><span class="hljs-code">        [3., 4.]])</span><br><span class="hljs-code">2</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><h5 id="张量的尺寸"><a href="#张量的尺寸" class="headerlink" title="张量的尺寸"></a>张量的尺寸</h5><p>可以使用 shape属性或者 size()方法查看张量在每一维的长度.可以使用 view 方法改变张量的尺寸。<br>如果view方法改变尺寸失败，可以使用reshape方法.</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"># 使用view可以改变张量尺寸<br>vector = torch.arange(0,12)<br>print(vector)<br>print(vector.shape)<br><br>matrix34 = vector.view(3,4)<br>print(matrix34)<br>print(matrix34.shape)<br><br>matrix43 = vector.view(4,-1) #-1表示该位置长度由程序自动推断<br>print(matrix43)<br>print(matrix43.shape)<br><br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])</span><br><span class="hljs-code">torch.Size([12])</span><br><span class="hljs-code">tensor([[ 0,  1,  2,  3],</span><br><span class="hljs-code">        [ 4,  5,  6,  7],</span><br><span class="hljs-code">        [ 8,  9, 10, 11]])</span><br><span class="hljs-code">torch.Size([3, 4])</span><br><span class="hljs-code">tensor([[ 0,  1,  2],</span><br><span class="hljs-code">        [ 3,  4,  5],</span><br><span class="hljs-code">        [ 6,  7,  8],</span><br><span class="hljs-code">        [ 9, 10, 11]])</span><br><span class="hljs-code">torch.Size([4, 3])</span><br>&#x27;&#x27;&#x27;<br><br># 有些操作会让张量存储结构扭曲，直接使用view会失败，可以用reshape方法<br>matrix26 = torch.arange(0,12).view(2,6)<br>print(matrix26)<br>print(matrix26.shape)<br><br># 转置操作让张量存储结构扭曲<br>matrix62 = matrix26.t()<br>print(matrix62.is_contiguous())<br><br># 直接使用view方法会失败，可以使用reshape方法<br>#matrix34 = matrix62.view(3,4) #error!<br>matrix34 = matrix62.reshape(3,4) #等价于matrix34 = matrix62.contiguous().view(3,4)<br>print(matrix34)<br><br>&#x27;&#x27;&#x27;<br><span class="hljs-code">tensor([[ 0,  1,  2,  3,  4,  5],</span><br><span class="hljs-code">        [ 6,  7,  8,  9, 10, 11]])</span><br><span class="hljs-code">torch.Size([2, 6])</span><br><span class="hljs-code">False</span><br><span class="hljs-code">tensor([[ 0,  6,  1,  7],</span><br><span class="hljs-code">        [ 2,  8,  3,  9],</span><br><span class="hljs-code">        [ 4, 10,  5, 11]])</span><br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><h5 id="张量和numpy数组"><a href="#张量和numpy数组" class="headerlink" title="张量和numpy数组"></a>张量和numpy数组</h5><p>可以用numpy方法从Tensor得到numpy数组，也可以用torch.from_numpy从numpy数组得到Tensor。这两种方法关联的Tensor和numpy数组是共享数据内存的。如果改变其中一个，另外一个的值也会发生改变。如果有需要，可以用张量的clone方法拷贝张量，中断这种关联。<br>此外，还可以使用item方法从标量张量得到对应的Python数值。使用tolist方法从张量得到对应的Python数值列表。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#torch.from_numpy函数从numpy数组得到Tensor</span><br>arr = np.zeros(<span class="hljs-number">3</span>)<br>tensor = torch.from_numpy(arr)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;before add 1:&quot;</span>)<br><span class="hljs-built_in">print</span>(arr)<br><span class="hljs-built_in">print</span>(tensor)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nafter add 1:&quot;</span>)<br>np.add(arr,<span class="hljs-number">1</span>, out = arr) <span class="hljs-comment">#给 arr增加1，tensor也随之改变</span><br><span class="hljs-built_in">print</span>(arr)<br><span class="hljs-built_in">print</span>(tensor)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">before add 1:</span><br><span class="hljs-string">[0. 0. 0.]</span><br><span class="hljs-string">tensor([0., 0., 0.], dtype=torch.float64)</span><br><span class="hljs-string"></span><br><span class="hljs-string">after add 1:</span><br><span class="hljs-string">[1. 1. 1.]</span><br><span class="hljs-string">tensor([1., 1., 1.], dtype=torch.float64)</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment"># numpy方法从Tensor得到numpy数组</span><br>tensor = torch.zeros(<span class="hljs-number">3</span>)<br>arr = tensor.numpy()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;before add 1:&quot;</span>)<br><span class="hljs-built_in">print</span>(tensor)<br><span class="hljs-built_in">print</span>(arr)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nafter add 1:&quot;</span>)<br><span class="hljs-comment">#使用带下划线的方法表示计算结果会返回给调用 张量</span><br>tensor.add_(<span class="hljs-number">1</span>) <span class="hljs-comment">#给 tensor增加1，arr也随之改变 </span><br><span class="hljs-comment">#或： torch.add(tensor,1,out = tensor)</span><br><span class="hljs-built_in">print</span>(tensor)<br><span class="hljs-built_in">print</span>(arr)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">before add 1:</span><br><span class="hljs-string">tensor([0., 0., 0.])</span><br><span class="hljs-string">[0. 0. 0.]</span><br><span class="hljs-string"></span><br><span class="hljs-string">after add 1:</span><br><span class="hljs-string">tensor([1., 1., 1.])</span><br><span class="hljs-string">[1. 1. 1.]</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment"># 可以用clone() 方法拷贝张量，中断这种关联</span><br>tensor = torch.zeros(<span class="hljs-number">3</span>)<br><br><span class="hljs-comment">#使用clone方法拷贝张量, 拷贝后的张量和原始张量内存独立</span><br>arr = tensor.clone().numpy() <span class="hljs-comment"># 也可以使用tensor.data.numpy()</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;before add 1:&quot;</span>)<br><span class="hljs-built_in">print</span>(tensor)<br><span class="hljs-built_in">print</span>(arr)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nafter add 1:&quot;</span>)<br><span class="hljs-comment">#使用 带下划线的方法表示计算结果会返回给调用 张量</span><br>tensor.add_(<span class="hljs-number">1</span>) <span class="hljs-comment">#给 tensor增加1，arr不再随之改变</span><br><span class="hljs-built_in">print</span>(tensor)<br><span class="hljs-built_in">print</span>(arr)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">before add 1:</span><br><span class="hljs-string">tensor([0., 0., 0.])</span><br><span class="hljs-string">[0. 0. 0.]</span><br><span class="hljs-string"></span><br><span class="hljs-string">after add 1:</span><br><span class="hljs-string">tensor([1., 1., 1.])</span><br><span class="hljs-string">[0. 0. 0.]</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment"># item方法和tolist方法可以将张量转换成Python数值和数值列表</span><br>scalar = torch.tensor(<span class="hljs-number">1.0</span>)<br>s = scalar.item()<br><span class="hljs-built_in">print</span>(s)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(s))<br><br>tensor = torch.rand(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)<br>t = tensor.tolist()<br><span class="hljs-built_in">print</span>(t)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(t))<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">1.0</span><br><span class="hljs-string">&lt;class &#x27;float&#x27;&gt;</span><br><span class="hljs-string">[[0.5526873469352722, 0.46957558393478394], [0.6724914312362671, 0.26923561096191406]]</span><br><span class="hljs-string">&lt;class &#x27;list&#x27;&gt;</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><p>搬运自：</p><ul><li><a href="https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1">https://www.heywhale.com/home/competition/61bff9a84b63a700179b7f8d/content/1</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第一个python包</title>
    <link href="/2021/12/29/%E7%AC%AC%E4%B8%80%E4%B8%AApython%E5%8C%85/"/>
    <url>/2021/12/29/%E7%AC%AC%E4%B8%80%E4%B8%AApython%E5%8C%85/</url>
    
    <content type="html"><![CDATA[<h2 id="Senior-Data-Structure-Tools–SDStools"><a href="#Senior-Data-Structure-Tools–SDStools" class="headerlink" title="Senior Data Structure Tools–SDStools"></a>Senior Data Structure Tools–SDStools</h2><span id="more"></span><p>python标准库中没有链表、树、图等高级数据结构，所以整理了一些网上的代码到这个库中。</p><h5 id="链表："><a href="#链表：" class="headerlink" title="链表："></a>链表：</h5><ul><li><a href="https://zhuanlan.zhihu.com/p/60057180">https://zhuanlan.zhihu.com/p/60057180</a></li><li><a href="https://jackkuo666.github.io/Data_Structure_with_Python_book/chapter3/section1.html">https://jackkuo666.github.io/Data_Structure_with_Python_book/chapter3/section1.html</a></li></ul><h5 id="如何发布包到pypi"><a href="#如何发布包到pypi" class="headerlink" title="如何发布包到pypi"></a>如何发布包到pypi</h5><p>我的项目目录结构如下：<br><img src="/img/article/py.jpg"></p><p>打包主要就是setup的编写</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs clean">setup(<br>    name=NAME,<br>    version=about[<span class="hljs-string">&#x27;__version__&#x27;</span>],<br>    description=DESCRIPTION,<br>    long_description=long_description,<br>    long_description_content_type=<span class="hljs-string">&#x27;text/markdown&#x27;</span>,<br>    author=AUTHOR,<br>    author_email=EMAIL,<br>    python_requires=REQUIRES_PYTHON,<br>    url=URL,<br>    packages=find_packages(),                ## 必须，如果需要打包test文件夹或其他可参考下面格式进行添加<br>    # packages=find_packages(exclude=[<span class="hljs-string">&quot;tests&quot;</span>, <span class="hljs-string">&quot;*.tests&quot;</span>, <span class="hljs-string">&quot;*.tests.*&quot;</span>, <span class="hljs-string">&quot;tests.*&quot;</span>]),<br>    # If your package is a single <span class="hljs-keyword">module</span>, use this instead <span class="hljs-keyword">of</span> <span class="hljs-string">&#x27;packages&#x27;</span>:<br>    # py_modules=[<span class="hljs-string">&#x27;SDStools&#x27;</span>],<br><br>    # entry_points=&#123;<br>    #     <span class="hljs-string">&#x27;console_scripts&#x27;</span>: [<span class="hljs-string">&#x27;mycli=mymodule:cli&#x27;</span>],<br>    # &#125;,<br>    install_requires=REQUIRED,<br>    extras_require=EXTRAS,<br>    # package_data=&#123;<br>    #     # include json and pkl files<br>    #     <span class="hljs-string">&#x27;&#x27;</span>: [<span class="hljs-string">&#x27;*.json&#x27;</span>, <span class="hljs-string">&#x27;models/*.pkl&#x27;</span>, <span class="hljs-string">&#x27;models/*.json&#x27;</span>],<br>    # &#125;,<br>    include_package_data=<span class="hljs-literal">True</span>,<br>    license=<span class="hljs-string">&#x27;MIT&#x27;</span>,<br>    classifiers=[<br>        # Trove classifiers<br>        # Full list: https:<span class="hljs-comment">//pypi.python.org/pypi?%3Aaction=list_classifiers</span><br>        <span class="hljs-string">&#x27;License :: OSI Approved :: MIT License&#x27;</span>,<br>        <span class="hljs-string">&#x27;Programming Language :: Python&#x27;</span>,<br>        <span class="hljs-string">&#x27;Programming Language :: Python :: 3&#x27;</span>,<br>        <span class="hljs-string">&#x27;Programming Language :: Python :: 3.6&#x27;</span>,<br>        <span class="hljs-string">&#x27;Programming Language :: Python :: Implementation :: CPython&#x27;</span>,<br>        <span class="hljs-string">&#x27;Programming Language :: Python :: Implementation :: PyPy&#x27;</span><br>    ],<br>    # $ setup.py publish support.<br>    cmdclass=&#123;<br>        <span class="hljs-string">&#x27;upload&#x27;</span>: UploadCommand,<br>    &#125;,<br>)<br></code></pre></td></tr></table></figure><p>编写完可以进行本地打包安装测试：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">python setup.py <span class="hljs-keyword">build </span>    <span class="hljs-comment"># 执行构建, 会将包的内容构建到 build 文件夹下。</span><br></code></pre></td></tr></table></figure><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">python setup.py <span class="hljs-keyword">install</span>  <span class="hljs-comment"># 会将包直接安装到当前解释器的 site-packages 下，安装完成后即可以使用 pip list 命令查看到。</span><br></code></pre></td></tr></table></figure><p>如果没什么问题的话就可以提交到pypi了。</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">python</span> setup.<span class="hljs-keyword">py</span> sdist  ## 打包<br>twine upload dist/*    ## 发布<br># <span class="hljs-keyword">python</span> setup.<span class="hljs-keyword">py</span> upload   ## 如果setup.<span class="hljs-keyword">py</span>里有upload命令也可一键执行打包发布<br></code></pre></td></tr></table></figure><p>参考：</p><ul><li><a href="https://www.jiqizhixin.com/articles/19060901">https://www.jiqizhixin.com/articles/19060901</a></li><li><a href="https://zhuanlan.zhihu.com/p/66603015">https://zhuanlan.zhihu.com/p/66603015</a></li><li><a href="https://zhuanlan.zhihu.com/p/66603015">https://zhuanlan.zhihu.com/p/66603015</a></li></ul><h5 id="源码地址"><a href="#源码地址" class="headerlink" title="源码地址"></a>源码地址</h5><ul><li><a href="https://github.com/shubihu/SDSTools">https://github.com/shubihu/SDSTools</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LeetCode</title>
    <link href="/2021/12/28/leetcode/"/>
    <url>/2021/12/28/leetcode/</url>
    
    <content type="html"><![CDATA[<h2 id="力扣笔记"><a href="#力扣笔记" class="headerlink" title="力扣笔记"></a>力扣笔记</h2><span id="more"></span><h5 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a>题目描述：</h5><p>给定一个字符串 s ，其中包含字母顺序打乱的用英文单词表示的若干数字（0-9）。按 升序 返回原始的数字。例如：输入：s = “owoztneoer”，输出：”012”。<br>原题地址：<a href="https://leetcode-cn.com/problems/reconstruct-original-digits-from-english/">https://leetcode-cn.com/problems/reconstruct-original-digits-from-english/</a></p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs vim">### 我的方案，使用了递归，，但依然很惨，没通过力扣的检验（超出时间限制）<br><br>def originalDigits(s):<br>    en_num = &#123;<span class="hljs-string">&#x27;zero&#x27;</span>:<span class="hljs-number">0</span>, <span class="hljs-string">&#x27;one&#x27;</span>:<span class="hljs-number">1</span>,<span class="hljs-string">&#x27;two&#x27;</span>:<span class="hljs-number">2</span>, <span class="hljs-string">&#x27;three&#x27;</span>:<span class="hljs-number">3</span>,<span class="hljs-string">&#x27;four&#x27;</span>:<span class="hljs-number">4</span>,<span class="hljs-string">&#x27;five&#x27;</span>:<span class="hljs-number">5</span>,<span class="hljs-string">&#x27;six&#x27;</span>:<span class="hljs-number">6</span>,<span class="hljs-string">&#x27;seven&#x27;</span>:<span class="hljs-number">7</span>,<br>    <span class="hljs-string">&#x27;eight&#x27;</span>:<span class="hljs-number">8</span>,<span class="hljs-string">&#x27;nine&#x27;</span>:<span class="hljs-number">9</span>&#125;<br><br>    ss = []<br>    <span class="hljs-keyword">for</span> <span class="hljs-keyword">k</span>, v in en_num.<span class="hljs-built_in">items</span>():<br>        <span class="hljs-keyword">l</span> = <span class="hljs-built_in">len</span>(<span class="hljs-keyword">k</span>)<br>        <span class="hljs-keyword">c</span> = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i in <span class="hljs-keyword">k</span>:<br>            <span class="hljs-keyword">if</span> i in <span class="hljs-variable">s:</span><br>                <span class="hljs-keyword">c</span> += <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">c</span> == <span class="hljs-variable">l:</span><br>            ss.<span class="hljs-keyword">append</span>(str(v))<br>            <span class="hljs-keyword">for</span> <span class="hljs-keyword">j</span> in <span class="hljs-keyword">k</span>:<br>                s = s.replace(<span class="hljs-keyword">j</span>, <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">if</span> <span class="hljs-variable">s:</span><br>        ss.<span class="hljs-keyword">append</span>(originalDigits(s))<br>        ss.<span class="hljs-keyword">sort</span>()<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;&#x27;</span>.<span class="hljs-keyword">join</span>(ss)<br>    <span class="hljs-keyword">else</span>:<br>        ss.<span class="hljs-keyword">sort</span>()<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;&#x27;</span>.<span class="hljs-keyword">join</span>(ss)<br></code></pre></td></tr></table></figure><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs prolog">## 力扣方案<br><br>class <span class="hljs-symbol">Solution</span>:<br>    def originalDigits(self, s: str) -&gt; str:<br>        c = <span class="hljs-symbol">Counter</span>(s)<br><br>        cnt = [<span class="hljs-number">0</span>] * <span class="hljs-number">10</span><br>        cnt[<span class="hljs-number">0</span>] = c[<span class="hljs-string">&quot;z&quot;</span>]<br>        cnt[<span class="hljs-number">2</span>] = c[<span class="hljs-string">&quot;w&quot;</span>]<br>        cnt[<span class="hljs-number">4</span>] = c[<span class="hljs-string">&quot;u&quot;</span>]<br>        cnt[<span class="hljs-number">6</span>] = c[<span class="hljs-string">&quot;x&quot;</span>]<br>        cnt[<span class="hljs-number">8</span>] = c[<span class="hljs-string">&quot;g&quot;</span>]<br><br>        cnt[<span class="hljs-number">3</span>] = c[<span class="hljs-string">&quot;h&quot;</span>] - cnt[<span class="hljs-number">8</span>]<br>        cnt[<span class="hljs-number">5</span>] = c[<span class="hljs-string">&quot;f&quot;</span>] - cnt[<span class="hljs-number">4</span>]<br>        cnt[<span class="hljs-number">7</span>] = c[<span class="hljs-string">&quot;s&quot;</span>] - cnt[<span class="hljs-number">6</span>]<br>        <br>        cnt[<span class="hljs-number">1</span>] = c[<span class="hljs-string">&quot;o&quot;</span>] - cnt[<span class="hljs-number">0</span>] - cnt[<span class="hljs-number">2</span>] - cnt[<span class="hljs-number">4</span>]<br><br>        cnt[<span class="hljs-number">9</span>] = c[<span class="hljs-string">&quot;i&quot;</span>] - cnt[<span class="hljs-number">5</span>] - cnt[<span class="hljs-number">6</span>] - cnt[<span class="hljs-number">8</span>]<br><br>        return <span class="hljs-string">&quot;&quot;</span>.join(str(x) * cnt[x] for x in range(<span class="hljs-number">10</span>))<br></code></pre></td></tr></table></figure><p>如果单看这个代码的话我依然看不懂，还是要看解释，解释在上面的网址里都有。反正这个题确实挺考验智商的吧，我这智商还是洗洗睡了。</p><h5 id="题目描述：-1"><a href="#题目描述：-1" class="headerlink" title="题目描述："></a>题目描述：</h5><p>无重复字符串的排列组合。编写一种方法，计算某字符串的所有排列组合，字符串每个字符均不相同。<br>例如输入字符串abc,则打印出由字符a,b,c所能排列出来的所有字符串abc,acb,bac,bca,cab和cba。<br>原题地址：<a href="https://leetcode-cn.com/problems/permutation-i-lcci/">https://leetcode-cn.com/problems/permutation-i-lcci/</a><br>python的itertools包中的permutations函数可以实现。</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs maxima">### itertools.<span class="hljs-built_in">permutations</span>函数源码如下<br><br>def <span class="hljs-built_in">permutation</span>(iterable, r=None):<br>    #  r:<span class="hljs-built_in">length</span> <span class="hljs-built_in">permutations</span> of elements <span class="hljs-keyword">in</span> the iterable<br>    # <span class="hljs-built_in">permutations</span>(&#x27;ABCD&#x27;, <span class="hljs-number">2</span>) --&gt; AB AC AD BA BC BD CA CB CD DA DB DC<br>    # <span class="hljs-built_in">permutations</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>)) --&gt; <span class="hljs-number">012</span> <span class="hljs-number">021</span> <span class="hljs-number">102</span> <span class="hljs-number">120</span> <span class="hljs-number">201</span> <span class="hljs-number">210</span><br>    pool = tuple(iterable)<br>    n = len(pool)<br>    r = n <span class="hljs-keyword">if</span> r <span class="hljs-built_in">is</span> None <span class="hljs-keyword">else</span> r<br>    <span class="hljs-keyword">if</span> r &gt; n:<br>        <span class="hljs-built_in">return</span><br>    <span class="hljs-built_in">indices</span> = list(<span class="hljs-built_in">range</span>(n))<br>    cycles = list(<span class="hljs-built_in">range</span>(n, n-r, -<span class="hljs-number">1</span>))<br>    yield tuple(pool[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">indices</span>[:r])<br>    <span class="hljs-keyword">while</span> n:<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> reversed(<span class="hljs-built_in">range</span>(r)):<br>            cycles[i] -= <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> cycles[i] == <span class="hljs-number">0</span>:<br>                <span class="hljs-built_in">indices</span>[i:] = <span class="hljs-built_in">indices</span>[i+<span class="hljs-number">1</span>:] + <span class="hljs-built_in">indices</span>[i:i+<span class="hljs-number">1</span>]<br>                cycles[i] = n - i<br>            <span class="hljs-keyword">else</span>:<br>                j = cycles[i]<br>                <span class="hljs-built_in">indices</span>[i], <span class="hljs-built_in">indices</span>[-j] = <span class="hljs-built_in">indices</span>[-j], <span class="hljs-built_in">indices</span>[i]<br>                yield tuple(pool[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">indices</span>[:r])<br>                <span class="hljs-built_in">break</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-built_in">return</span><br></code></pre></td></tr></table></figure><p>源码还是挺复杂的，，，，，</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs go">### 力扣方法，也是递归<br><br>def permutation(S):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(S)==<span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">return</span> [S]<br>        ans=[]<br>        <span class="hljs-keyword">for</span> i in <span class="hljs-keyword">range</span>(<span class="hljs-built_in">len</span>(S)):<br>            s=S[:i]+S[i+<span class="hljs-number">1</span>:]              <br>            <span class="hljs-keyword">for</span> <span class="hljs-keyword">string</span> in permutation(s):<br>                ans.<span class="hljs-built_in">append</span>(S[i]+<span class="hljs-keyword">string</span>)<br>        <span class="hljs-keyword">return</span> ans<br></code></pre></td></tr></table></figure><h5 id="题目描述：-2"><a href="#题目描述：-2" class="headerlink" title="题目描述："></a>题目描述：</h5><p>给定两个单词 word1 和 word2，请计算出 word1 与 word2 的最长公共字串长度。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">word1</span> = &#x27;abcfdg&#x27;<br><span class="hljs-attribute">word2</span> = &#x27;bcfdkhi&#x27;<br><br><span class="hljs-attribute">def</span> comm_len(word<span class="hljs-number">1</span>, word<span class="hljs-number">2</span>):<br>    <span class="hljs-attribute">c</span> = <span class="hljs-number">0</span><br>    <span class="hljs-attribute">for</span> i in range(len(word<span class="hljs-number">1</span>)):<br>        <span class="hljs-attribute">if</span> word[i-c:i+<span class="hljs-number">1</span>] in word<span class="hljs-number">2</span>:<br>            <span class="hljs-attribute">c</span> += <span class="hljs-number">1</span><br><br>    <span class="hljs-attribute">return</span> c<br><br></code></pre></td></tr></table></figure><h5 id="题目描述：-3"><a href="#题目描述：-3" class="headerlink" title="题目描述："></a>题目描述：</h5><p>快速排序</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">arr = <span class="hljs-literal">[<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">12</span>, <span class="hljs-number">32</span>, <span class="hljs-number">198</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">15</span>, <span class="hljs-number">112</span>, <span class="hljs-number">132</span>]</span><br><br>def quick<span class="hljs-constructor">_sort(<span class="hljs-params">arr</span>)</span>:<br>    <span class="hljs-keyword">if</span> len(arr) &lt;= <span class="hljs-number">1</span>:<br>        return arr<br>    tmp = arr<span class="hljs-literal">[<span class="hljs-number">0</span>]</span><br>    left = <span class="hljs-literal">[<span class="hljs-identifier">i</span> <span class="hljs-identifier">for</span> <span class="hljs-identifier">i</span> <span class="hljs-identifier">in</span> <span class="hljs-identifier">arr</span>[<span class="hljs-number">1</span>:]</span> <span class="hljs-keyword">if</span> i &lt; tmp]<br>    right = <span class="hljs-literal">[<span class="hljs-identifier">i</span> <span class="hljs-identifier">for</span> <span class="hljs-identifier">i</span> <span class="hljs-identifier">in</span> <span class="hljs-identifier">arr</span>[<span class="hljs-number">1</span>:]</span> <span class="hljs-keyword">if</span> i &gt; tmp]<br>    return quick<span class="hljs-constructor">_sort(<span class="hljs-params">left</span>)</span> + <span class="hljs-literal">[<span class="hljs-identifier">tmp</span>]</span> + quick<span class="hljs-constructor">_sort(<span class="hljs-params">right</span>)</span><br><br>print(quick<span class="hljs-constructor">_sort(<span class="hljs-params">arr</span>)</span>)<br></code></pre></td></tr></table></figure><h5 id="题目描述：-4"><a href="#题目描述：-4" class="headerlink" title="题目描述："></a>题目描述：</h5><p>归并排序应用：将两个有序数组合并成一个有序数组</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver"><span class="hljs-keyword">a</span> = [<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">5</span>,<span class="hljs-number">7</span>]<br>b = [<span class="hljs-number">2</span>,<span class="hljs-number">6</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>]<br><br>def <span class="hljs-built_in">merge</span>(left, <span class="hljs-literal">right</span>):<br>    <span class="hljs-string">&#x27;&#x27;</span><span class="hljs-string">&#x27;合并操作，将两个有序数组left[]和right[]合并成一个大的有序数组&#x27;</span><span class="hljs-string">&#x27;&#x27;</span><br>    <span class="hljs-comment">#left与right的下标指针</span><br>    l, r = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>    <span class="hljs-built_in">result</span> = []<br>    <span class="hljs-keyword">while</span> l&lt;<span class="hljs-built_in">len</span>(left) <span class="hljs-keyword">and</span> r&lt;<span class="hljs-built_in">len</span>(<span class="hljs-literal">right</span>):<br>        <span class="hljs-keyword">if</span> left[l] &lt; <span class="hljs-literal">right</span>[r]:<br>            <span class="hljs-built_in">result</span>.append(left[l])<br>            l += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-built_in">result</span>.append(<span class="hljs-literal">right</span>[r])<br>            r += <span class="hljs-number">1</span><br>    <span class="hljs-built_in">result</span> += left[l:]<br>    <span class="hljs-built_in">result</span> += <span class="hljs-literal">right</span>[r:]<br>    <span class="hljs-literal">return</span> <span class="hljs-built_in">result</span><br><br>print(<span class="hljs-built_in">merge</span>(<span class="hljs-keyword">a</span>, b))<br></code></pre></td></tr></table></figure><h5 id="题目描述：-5"><a href="#题目描述：-5" class="headerlink" title="题目描述："></a>题目描述：</h5><p>输出单向链表中倒数第k个结点</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Node</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, val=<span class="hljs-number">0</span></span>):</span><br>        self.val = val<br>        self.<span class="hljs-built_in">next</span> = <span class="hljs-literal">None</span><br><br><br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    <span class="hljs-keyword">try</span>:<br>        l, s, k, head = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>()), <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, <span class="hljs-built_in">input</span>().split())), <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>()), Node()<br>        <span class="hljs-keyword">while</span> k:<br>            head.<span class="hljs-built_in">next</span> = Node(s.pop())<br>            head = head.<span class="hljs-built_in">next</span><br>            k -= <span class="hljs-number">1</span><br>        <span class="hljs-built_in">print</span>(head.val)<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure><h5 id="题目描述：-6"><a href="#题目描述：-6" class="headerlink" title="题目描述："></a>题目描述：</h5><p>给定两个单词 word1 和 word2，请计算出将 word1 转换成 word2 所使用的最少操作数。<br>参考：<a href="https://www.jianshu.com/p/9a53f32cf62b">https://www.jianshu.com/p/9a53f32cf62b</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">editDistance</span>(<span class="hljs-params">str1, str2</span>):</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    计算字符串str1和str2的编辑距离</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    edit = [[i+j <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(str2)+<span class="hljs-number">1</span>)] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(str1)+<span class="hljs-number">1</span>)]<br>    <span class="hljs-built_in">print</span>(edit)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(str1)+<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(str2)+<span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">if</span> str1[i-<span class="hljs-number">1</span>] == str2[j-<span class="hljs-number">1</span>]:<br>                d = <span class="hljs-number">0</span><br>            <span class="hljs-keyword">else</span>:<br>                d = <span class="hljs-number">1</span><br>            edit[i][j] = <span class="hljs-built_in">min</span>(edit[i-<span class="hljs-number">1</span>][j]+<span class="hljs-number">1</span>,edit[i][j-<span class="hljs-number">1</span>]+<span class="hljs-number">1</span>,edit[i-<span class="hljs-number">1</span>][j-<span class="hljs-number">1</span>]+d)<br>    <span class="hljs-keyword">return</span> edit[<span class="hljs-built_in">len</span>(str1)][<span class="hljs-built_in">len</span>(str2)]<br><br>editDistance(<span class="hljs-string">&#x27;python&#x27;</span>, <span class="hljs-string">&#x27;pyton&#x27;</span>)<br></code></pre></td></tr></table></figure><h5 id="题目描述：-7"><a href="#题目描述：-7" class="headerlink" title="题目描述："></a>题目描述：</h5><p>最长回文字串</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs stylus">s = <span class="hljs-selector-tag">input</span>()<br>win_len = <span class="hljs-number">2</span><br>s_list = <span class="hljs-selector-attr">[]</span><br><span class="hljs-keyword">for</span> <span class="hljs-selector-tag">i</span> <span class="hljs-keyword">in</span> range(len(s)):<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(i+<span class="hljs-number">1</span>, len(s) + <span class="hljs-number">1</span>):<br>        ss = s<span class="hljs-selector-attr">[i:j]</span><br>        <span class="hljs-keyword">if</span> ss == ss<span class="hljs-selector-attr">[::-1]</span>:<br>            s_list<span class="hljs-selector-class">.append</span>(len(ss))<br>            <br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(max(s_list)</span></span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>leetcode</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VIP视频解析手机端</title>
    <link href="/2021/12/24/VIP%E8%A7%86%E9%A2%91%E8%A7%A3%E6%9E%90%E6%89%8B%E6%9C%BA%E7%AB%AF/"/>
    <url>/2021/12/24/VIP%E8%A7%86%E9%A2%91%E8%A7%A3%E6%9E%90%E6%89%8B%E6%9C%BA%E7%AB%AF/</url>
    
    <content type="html"><![CDATA[<h2 id="薅各大厂视频羊毛——手机端"><a href="#薅各大厂视频羊毛——手机端" class="headerlink" title="薅各大厂视频羊毛——手机端"></a>薅各大厂视频羊毛——手机端</h2><span id="more"></span><p>以前都是用电脑端Chrome浏览器安装油猴插件及其相应的脚本看视频，但是如果想用电视看视频，用电脑投屏终究是有点麻烦。找了许久还是让我找到了手机端可以使用脚本的浏览器。<br>使用方法也可以直接跳转该地址：<br><a href="https://blog.csdn.net/qq_37759464/article/details/121903038?utm_source=app&amp;app_version=4.20.0&amp;code=app_1562916241&amp;uLinkId=usr1mkqgl919blen">https://blog.csdn.net/qq_37759464/article/details/121903038?utm_source=app&amp;app_version=4.20.0&amp;code=app_1562916241&amp;uLinkId=usr1mkqgl919blen</a></p><p>个人推荐的话：安卓可以使用Via浏览器，真的很简约，官网也一样的简约（<a href="https://viayoo.com/zh-cn/%EF%BC%89%EF%BC%8C%E8%80%8C%E4%B8%94%E4%BA%B2%E6%B5%8B%E5%8F%AF%E4%BB%A5%E5%AE%9E%E7%8E%B0VIP%E8%A7%86%E9%A2%91%E8%A7%A3%E6%9E%90%E3%80%82%E8%8B%B9%E6%9E%9CIOS%E7%AB%AF%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8Alook%EF%BC%8C%E4%B8%8D%E8%BF%87%E8%BF%99%E4%B8%AA%E8%BD%AF%E4%BB%B6%E4%B8%8D%E6%98%AF%E5%85%8D%E8%B4%B9%E7%9A%84%EF%BC%88%E7%8E%B0%E5%9C%A8%E7%96%AB%E6%83%85%E6%90%9E%E5%8D%8A%E4%BB%B7%E6%B4%BB%E5%8A%A86%E5%85%83%EF%BC%8C%E4%B8%8D%E8%BF%87%E6%94%AF%E4%BB%98%E5%AE%9D%E6%9C%89%E6%97%B6%E5%80%99%E4%BC%9A%E6%9C%89%E8%8B%B9%E6%9E%9CAppstore%E6%B6%88%E8%B4%B9%E5%88%B8%EF%BC%8C%E6%AF%94%E5%A6%82%E4%BF%BA%E4%BB%8A%E5%A4%A9%E9%A2%86%E4%BA%869%E5%85%83%EF%BC%8C%E6%9E%9C%E6%96%AD%E5%85%A5%E6%89%8B%E7%99%BD%E6%8D%A1%E4%BA%86%E8%BF%99%E4%B8%AA%E6%B5%8F%E8%A7%88%E5%99%A8%EF%BC%89%E3%80%82">https://viayoo.com/zh-cn/），而且亲测可以实现VIP视频解析。苹果IOS端可以使用Alook，不过这个软件不是免费的（现在疫情搞半价活动6元，不过支付宝有时候会有苹果Appstore消费券，比如俺今天领了9元，果断入手白捡了这个浏览器）。</a></p><p>安装好浏览器后就是安装脚本了，上面的地址里有详细的方法，脚本的地址在此：<br><a href="https://greasyfork.org/zh-CN/scripts/435698-%E5%85%A8%E7%BD%91vip%E8%A7%86%E9%A2%91%E8%87%AA%E5%8A%A8%E8%A7%A3%E6%9E%90%E6%92%AD%E6%94%BE%E5%99%A8-%E5%B7%B2%E9%80%82%E9%85%8D%E6%89%8B%E6%9C%BA%E3%80%82">https://greasyfork.org/zh-CN/scripts/435698-%E5%85%A8%E7%BD%91vip%E8%A7%86%E9%A2%91%E8%87%AA%E5%8A%A8%E8%A7%A3%E6%9E%90%E6%92%AD%E6%94%BE%E5%99%A8-%E5%B7%B2%E9%80%82%E9%85%8D%E6%89%8B%E6%9C%BA。</a></p><p>说下我安装过程中遇到的问题吧，就是全选复制那块，不知道为啥就是不能全选，没办法只能慢慢拖拽光标进行全选然后复制（脚本是真长）。</p><p>手机投屏的话，安卓可以用乐播投屏，苹果的话直接用自带的屏幕镜像进行投屏就OK了。</p><p>当然了如果有钱开VIP就可以直接忽略本文啦，不过爱奇艺又要涨价了。</p>]]></content>
    
    
    <categories>
      
      <category>TroubleShoot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>薅羊毛</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JupyterNotebook远程云服务器</title>
    <link href="/2021/11/30/jupyter/"/>
    <url>/2021/11/30/jupyter/</url>
    
    <content type="html"><![CDATA[<h2 id="搭建Jupyter-Notebook远程云服务器"><a href="#搭建Jupyter-Notebook远程云服务器" class="headerlink" title="搭建Jupyter Notebook远程云服务器"></a>搭建Jupyter Notebook远程云服务器</h2><span id="more"></span><h5 id="安装Jupyter"><a href="#安装Jupyter" class="headerlink" title="安装Jupyter"></a>安装Jupyter</h5><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs verilog">pip install Jupyter<br>jupyter notebook --<span class="hljs-keyword">generate</span>-<span class="hljs-keyword">config</span><br></code></pre></td></tr></table></figure><h5 id="设置密码用于设置服务器配置，以及登录Jupyter。打开Python终端，输入以下："><a href="#设置密码用于设置服务器配置，以及登录Jupyter。打开Python终端，输入以下：" class="headerlink" title="设置密码用于设置服务器配置，以及登录Jupyter。打开Python终端，输入以下："></a>设置密码用于设置服务器配置，以及登录Jupyter。打开Python终端，输入以下：</h5><figure class="highlight ldif"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs ldif"><span class="hljs-attribute">In [1]</span>: from IPython.lib import passwd<br><span class="hljs-attribute">In [2]</span>: passwd()<br><span class="hljs-attribute">Enter password</span>: <br><span class="hljs-attribute">Verify password</span>: <br><span class="hljs-attribute">Out[2]</span>: &#x27;这里是密码&#x27;<br></code></pre></td></tr></table></figure><h5 id="设置服务器配置文件"><a href="#设置服务器配置文件" class="headerlink" title="设置服务器配置文件"></a>设置服务器配置文件</h5><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arcade">vim ~<span class="hljs-regexp">/.jupyter/</span>jupyter_notebook_config.py<br></code></pre></td></tr></table></figure><p>在末尾增加以下几行配置信息</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">c.NotebookApp.ip</span> = <span class="hljs-string">&#x27;*&#x27;</span> <span class="hljs-comment">#所有绑定服务器的IP都能访问，若想只在特定ip访问，输入ip地址即可</span><br><span class="hljs-attr">c.NotebookApp.port</span> = <span class="hljs-number">8888</span> <span class="hljs-comment">#将端口设置为自己喜欢的吧，默认是8888</span><br><span class="hljs-attr">c.NotebookApp.open_browser</span> = <span class="hljs-literal">False</span> <span class="hljs-comment">#我们并不想在服务器上直接打开Jupyter Notebook，所以设置成False</span><br><span class="hljs-attr">c.NotebookApp.notebook_dir</span> = <span class="hljs-string">&#x27;/root/jupyter_projects&#x27;</span> <span class="hljs-comment">#这里是设置Jupyter的根目录，若不设置将默认root的根目录，不安全</span><br><span class="hljs-attr">c.NotebookApp.allow_root</span> = <span class="hljs-literal">True</span> <span class="hljs-comment"># 为了安全，Jupyter默认不允许以root权限启动jupyter </span><br></code></pre></td></tr></table></figure><h5 id="启动Jupyter-远程服务器"><a href="#启动Jupyter-远程服务器" class="headerlink" title="启动Jupyter 远程服务器"></a>启动Jupyter 远程服务器</h5><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">jupyter notebook</span><br></code></pre></td></tr></table></figure><p>至此，Jupyter远程服务器以搭建完毕。在本地浏览器上，输入 ip地址:8888，将会打开远程Jupyter。接下来就可以像在本地一样使用服务器上的Jupyter。</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>jupyter</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch模型转paddle模型踩坑记录</title>
    <link href="/2021/11/29/pytorch2paddle/"/>
    <url>/2021/11/29/pytorch2paddle/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><h5 id="踩坑1"><a href="#踩坑1" class="headerlink" title="踩坑1"></a>踩坑1</h5><p>网上有很多使用x2paddle把pytorch转paddle的文章，不过大不部分也都是采用的迂回路线，就是先转ONNX，再转paddle，试了下水，果然没有那么简单的事情，一直报错，最后好像报了个 model not support，，，，遂放弃。</p><h5 id="踩坑2"><a href="#踩坑2" class="headerlink" title="踩坑2"></a>踩坑2</h5><p>使用工具不行只有一步一步慢慢转，这也是最开始使用的方法，起初报错没解决才找到x2paddle的，没想到又回归到最原始的方法了。<br>转换的过程一直卡在网络这块，所以就先把网络这块拿出来记录下。</p><h6 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h6><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs clean">######################### torch 版  ############################<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> SeqNet(nn.Module):<br>    def __init__(self):<br>        super(SeqNet, self).__init__()<br>        # input <br>        self.conv1 = nn.Conv1d(<span class="hljs-number">12</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)<br>        self.conv2 = nn.Conv1d(<span class="hljs-number">12</span>, <span class="hljs-number">10</span>, <span class="hljs-number">200</span>)<br>        self.conv3 = nn.Conv1d(<span class="hljs-number">12</span>, <span class="hljs-number">10</span>, <span class="hljs-number">500</span>)<br>        self.conv4 = nn.Conv1d(<span class="hljs-number">12</span>, <span class="hljs-number">10</span>, <span class="hljs-number">1000</span>)<br>        self.pooling = nn.MaxPool2d((<span class="hljs-number">1</span>, <span class="hljs-number">200</span>))<br>        self.fc1 = nn.Linear(<span class="hljs-number">900</span>, <span class="hljs-number">64</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">1</span>)<br><br>    def forward(self, x):<br>        batch_size = x.size(<span class="hljs-number">0</span>)<br>        <br>        out1 = self.pooling(F.relu(self.conv1(x)))<br>        out2 = self.pooling(F.relu(self.conv2(x)))<br>        out3 = self.pooling(F.relu(self.conv3(x)))<br>        out4 = self.pooling(F.relu(self.conv4(x)))<br><br>        out = torch.cat([out1, out2, out3, out4], <span class="hljs-number">2</span>)<br>        out = out.view(batch_size, <span class="hljs-number">-1</span>)<br>        out = self.fc1(out)<br>        out = F.relu(out)<br>        # out = F.dropout(out, p=<span class="hljs-number">0.2</span>)<br>        out = self.fc2(out)<br>        return out<br></code></pre></td></tr></table></figure><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs clean">######################### paddle 版  ############################<br><span class="hljs-keyword">import</span> paddle<br><span class="hljs-keyword">import</span> paddle.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> paddle.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> SeqNet(nn.Layer):<br>    def __init__(self):<br>        super(SeqNet, self).__init__()<br>        # input <br>        self.conv1 = nn.Conv1D(<span class="hljs-number">12</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)<br>        self.conv2 = nn.Conv1D(<span class="hljs-number">12</span>, <span class="hljs-number">10</span>, <span class="hljs-number">200</span>)<br>        self.conv3 = nn.Conv1D(<span class="hljs-number">12</span>, <span class="hljs-number">10</span>, <span class="hljs-number">500</span>)<br>        self.conv4 = nn.Conv1D(<span class="hljs-number">12</span>, <span class="hljs-number">10</span>, <span class="hljs-number">1000</span>)<br>        # self.pooling = nn.MaxPool2D((<span class="hljs-number">1</span>, <span class="hljs-number">200</span>))   <br>        ### torch版的 nn.MaxPool2D 输入数剧格式为（NCHW 或 CHW）,paddle版的 nn.MaxPool2D 输入数据格式只有 NCHW<br>        ### N代表batch_size， C代表channel，H代表高度，W代表宽度<br>        ### 所以这里用 paddle 的 nn.MaxPool1D 替换了 torch 的 nn.MaxPool2D<br>        self.pooling = nn.MaxPool1D(<span class="hljs-number">200</span>)<br>        self.fc1 = nn.Linear(<span class="hljs-number">900</span>, <span class="hljs-number">64</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">1</span>)<br><br>    def forward(self, x):<br>        ### torch.tensor.size 对应 paddle.tensor.shape<br>        batch_size = x.shape[<span class="hljs-number">0</span>]   <br>        <br>        out1 = self.pooling(F.relu(self.conv1(x)))<br>        out2 = self.pooling(F.relu(self.conv2(x)))<br>        out3 = self.pooling(F.relu(self.conv3(x)))<br>        out4 = self.pooling(F.relu(self.conv4(x)))<br>        <br>        ### torch.cat 对应 paddle.concat<br>        # out = torch.cat([out1, out2, out3, out4], <span class="hljs-number">2</span>)  <br>        out = paddle.concat([out1, out2, out3, out4], <span class="hljs-number">2</span>)<br>        ### torch.tensor.view 对应 paddle.tensor.reshape<br>        # out = out.view(batch_size, <span class="hljs-number">-1</span>)<br>        out = paddle.reshape(out, [batch_size, <span class="hljs-number">-1</span>])<br>        out = self.fc1(out)<br>        out = F.relu(out)<br>        # out = F.dropout(out, p=<span class="hljs-number">0.2</span>)<br>        out = self.fc2(out)<br><br>        return out<br></code></pre></td></tr></table></figure><h6 id="对于自定义数据集-paddle和pytorch实现的方法类似"><a href="#对于自定义数据集-paddle和pytorch实现的方法类似" class="headerlink" title="对于自定义数据集 paddle和pytorch实现的方法类似"></a>对于自定义数据集 paddle和pytorch实现的方法类似</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> paddle.io <span class="hljs-keyword">import</span> Dataset<br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyDataset</span>(<span class="hljs-params">Dataset</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    步骤一：继承paddle.io.Dataset类</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, mode=<span class="hljs-string">&#x27;train&#x27;</span></span>):</span><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        步骤二：实现构造函数，定义数据读取方式，划分训练和测试数据集</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(MyDataset, self).__init__()<br><br>        <span class="hljs-keyword">if</span> mode == <span class="hljs-string">&#x27;train&#x27;</span>:<br>            self.data = [<br>                [<span class="hljs-string">&#x27;traindata1&#x27;</span>, <span class="hljs-string">&#x27;label1&#x27;</span>],<br>                [<span class="hljs-string">&#x27;traindata2&#x27;</span>, <span class="hljs-string">&#x27;label2&#x27;</span>],<br>                [<span class="hljs-string">&#x27;traindata3&#x27;</span>, <span class="hljs-string">&#x27;label3&#x27;</span>],<br>                [<span class="hljs-string">&#x27;traindata4&#x27;</span>, <span class="hljs-string">&#x27;label4&#x27;</span>],<br>            ]<br>        <span class="hljs-keyword">else</span>:<br>            self.data = [<br>                [<span class="hljs-string">&#x27;testdata1&#x27;</span>, <span class="hljs-string">&#x27;label1&#x27;</span>],<br>                [<span class="hljs-string">&#x27;testdata2&#x27;</span>, <span class="hljs-string">&#x27;label2&#x27;</span>],<br>                [<span class="hljs-string">&#x27;testdata3&#x27;</span>, <span class="hljs-string">&#x27;label3&#x27;</span>],<br>                [<span class="hljs-string">&#x27;testdata4&#x27;</span>, <span class="hljs-string">&#x27;label4&#x27;</span>],<br>            ]<br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span>(<span class="hljs-params">self, index</span>):</span><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        步骤三：实现__getitem__方法，定义指定index时如何获取数据，并返回单条数据（训练数据，对应的标签）</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        data = self.data[index][<span class="hljs-number">0</span>]<br>        label = self.data[index][<span class="hljs-number">1</span>]<br><br>        <span class="hljs-keyword">return</span> data, label<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        步骤四：实现__len__方法，返回数据集总数目</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.data)<br></code></pre></td></tr></table></figure><h6 id="还有就是训练这块"><a href="#还有就是训练这块" class="headerlink" title="还有就是训练这块"></a>还有就是训练这块</h6><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs clean">######################### torch 版  ############################<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br>model = SeqNet()<br>model.to(device)<br>optimizer = torch.optim.AdamW(model.parameters(), lr=<span class="hljs-number">1e-4</span> ,weight_decay=<span class="hljs-number">5e-4</span>)<br>scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epoch)<br>criterion = nn.BCEWithLogitsLoss()<br><br>for i, (inputs, labels) <span class="hljs-keyword">in</span> (enumerate(trainloader)):<br>    inputs = inputs.to(device)<br>    labels = labels.float().to(device)<br><br>    out_linear = model(inputs).to(device)<br>    loss = criterion(out_linear, labels.unsqueeze(<span class="hljs-number">1</span>))<br><br>    optimizer.zero_grad()<br>    loss.backward()<br>    optimizer.step()<br></code></pre></td></tr></table></figure><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs clean">######################### paddle 版  ############################<br><span class="hljs-keyword">import</span> paddle<br><span class="hljs-keyword">import</span> paddle.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> paddle.optimizer <span class="hljs-keyword">as</span> optim<br><br>model = SeqNet()<br>model.to(device)<br>optimizer = optim.AdamW(learning_rate=<span class="hljs-number">1e-4</span>, parameters=model.parameters(),weight_decay=<span class="hljs-number">5e-4</span>)<br>### optimizer = optim.Adam(parameters=model.parameters(), learning_rate=<span class="hljs-number">1e-4</span>)<br>### paddle 版CosineAnnealingDecay接収的是 learning_rate参数<br>scheduler = optim.lr.CosineAnnealingDecay(<span class="hljs-number">1e-4</span>, T_max=max_epoch)<br>criterion = nn.BCEWithLogitsLoss()<br><br>for i, (inputs, labels) <span class="hljs-keyword">in</span> (enumerate(trainloader)):<br>    # inputs = inputs.to(device)<br>    inputs = inputs.cuda()<br>    # labels = labels.float().to(device)<br>    labels = labels.cuda()<br>    # labels = paddle.reshape(labels, (<span class="hljs-number">30</span>, <span class="hljs-number">1</span>))<br>    labels = paddle.cast(labels, dtype=<span class="hljs-string">&#x27;float32&#x27;</span>)  ## 转换数据类型<br><br>    out_linear = model(inputs)<br>    out_linear = paddle.reshape(out_linear, (batch_size,))<br>    loss = criterion(out_linear, labels)<br>    # loss = criterion(out_linear, labels.unsqueeze(<span class="hljs-number">1</span>))<br><br>    # optimizer.zero_grad()<br>    loss.backward()<br>    optimizer.step()<br>    optimizer.clear_grad()<br></code></pre></td></tr></table></figure><p>其余剩下就是一些小问题了，直接运行debug改就好了。<br>pytorch 完整版地址：<a href="https://github.com/shubihu/coggle_learn/blob/main/baseline/pytorch.ipynb">https://github.com/shubihu/coggle_learn/blob/main/baseline/pytorch.ipynb</a><br>paddle 完整版地址：<a href="https://github.com/shubihu/coggle_learn/blob/main/baseline/paddle.ipynb">https://github.com/shubihu/coggle_learn/blob/main/baseline/paddle.ipynb</a><br>aistudio上项目的地址为：<a href="https://aistudio.baidu.com/aistudio/projectdetail/2724787?contributionType=1">https://aistudio.baidu.com/aistudio/projectdetail/2724787?contributionType=1</a></p>]]></content>
    
    
    <categories>
      
      <category>TroubleShoot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TroubleShoot</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>mac-iTerm2</title>
    <link href="/2021/11/15/mac-iTerm2/"/>
    <url>/2021/11/15/mac-iTerm2/</url>
    
    <content type="html"><![CDATA[<h2 id="mac-air-m1-终端配置记录"><a href="#mac-air-m1-终端配置记录" class="headerlink" title="mac air m1 终端配置记录"></a>mac air m1 终端配置记录</h2><span id="more"></span><h3 id="安装Homebrew"><a href="#安装Homebrew" class="headerlink" title="安装Homebrew"></a>安装Homebrew</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">/bin/</span>bash -c <span class="hljs-string">&quot;$(curl -fsSL https://cdn.jsdelivr.net/gh/ineo6/homebrew-install/install.sh)&quot;</span><br></code></pre></td></tr></table></figure><p>将以上命令粘贴至终端。脚本内置 中科大镜像，所以能让Homebrew安装的更快。</p><h3 id="安装-oh-my-zsh"><a href="#安装-oh-my-zsh" class="headerlink" title="安装 oh-my-zsh"></a>安装 oh-my-zsh</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sh -c <span class="hljs-string">&quot;<span class="hljs-subst">$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)</span>&quot;</span><br></code></pre></td></tr></table></figure><h3 id="配置-oh-my-zsh"><a href="#配置-oh-my-zsh" class="headerlink" title="配置 oh-my-zsh"></a>配置 oh-my-zsh</h3><p>参考 <a href="https://www.dazhuanlan.com/lyuuawa0508/topics/1599354">https://www.dazhuanlan.com/lyuuawa0508/topics/1599354</a><br>注：其中有些命令可能因为版本问题不一致，主要是cask相关，按照提示修改即可<br>比如 安装 iTerm2 的命令是现在这样</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">brew</span> tap homebrew/cask<br><span class="hljs-attribute">brew</span> install iterm<span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><h3 id="brew-安装-nvm"><a href="#brew-安装-nvm" class="headerlink" title="brew 安装 nvm"></a>brew 安装 nvm</h3><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs clean">brew install nvm<br>mkdir ~/.nvm<br>vi ~/.zshrc<br>#################### 将下面内容添加到 ~/.zshrc 中 #############################<br><span class="hljs-keyword">export</span> NVM_DIR=<span class="hljs-string">&quot;$HOME/.nvm&quot;</span><br>[ -s <span class="hljs-string">&quot;/opt/homebrew/opt/nvm/nvm.sh&quot;</span> ] &amp;&amp; . <span class="hljs-string">&quot;/opt/homebrew/opt/nvm/nvm.sh&quot;</span> # This loads nvm<br>[ -s <span class="hljs-string">&quot;/opt/homebrew/opt/nvm/etc/bash_completion.d/nvm&quot;</span> ] &amp;&amp; . <span class="hljs-string">&quot;/opt/homebrew/opt/nvm/etc/bash_completion.d/nvm&quot;</span> # This loads nvm bash_completion<br>###############################################################################<br>source ~/.zshrc<br></code></pre></td></tr></table></figure><h3 id="github-加速"><a href="#github-加速" class="headerlink" title="github 加速"></a>github 加速</h3><p>参考 <a href="https://brew.idayer.com/guide/github">https://brew.idayer.com/guide/github</a></p>]]></content>
    
    
    <categories>
      
      <category>Mac</category>
      
    </categories>
    
    
    <tags>
      
      <tag>玩</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>科学上网</title>
    <link href="/2021/11/07/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"/>
    <url>/2021/11/07/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><h3 id="Mark一下以防不时之需-https-lncn-org"><a href="#Mark一下以防不时之需-https-lncn-org" class="headerlink" title="Mark一下以防不时之需 https://lncn.org/"></a>Mark一下以防不时之需 <a href="https://lncn.org/">https://lncn.org/</a></h3><p>连接该网站方法如下图所示<br><img src="/img/article/ssr.jpg"></p><h3 id="Window-客户端地址"><a href="#Window-客户端地址" class="headerlink" title="Window 客户端地址"></a>Window 客户端地址</h3><p><a href="https://github.com/shadowsocksrr/shadowsocksr-csharp/releases">https://github.com/shadowsocksrr/shadowsocksr-csharp/releases</a></p><h3 id="Mac-OS-客户端地址"><a href="#Mac-OS-客户端地址" class="headerlink" title="Mac OS 客户端地址"></a>Mac OS 客户端地址</h3><p><a href="https://github.com/wzdnzd/ShadowsocksX-NG-R/releases">https://github.com/wzdnzd/ShadowsocksX-NG-R/releases</a></p>]]></content>
    
    
    <categories>
      
      <category>TroubleShoot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>科学上网</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>核酸检测机构地图微信小程序开发</title>
    <link href="/2021/10/20/%E6%A0%B8%E9%85%B8%E6%A3%80%E6%B5%8B%E6%9C%BA%E6%9E%84%E5%9C%B0%E5%9B%BE%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91/"/>
    <url>/2021/10/20/%E6%A0%B8%E9%85%B8%E6%A3%80%E6%B5%8B%E6%9C%BA%E6%9E%84%E5%9C%B0%E5%9B%BE%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91/</url>
    
    <content type="html"><![CDATA[<h2 id="小程序开发学习"><a href="#小程序开发学习" class="headerlink" title="小程序开发学习"></a>小程序开发学习</h2><span id="more"></span><h5 id="开发（玩）背景"><a href="#开发（玩）背景" class="headerlink" title="开发（玩）背景"></a>开发（玩）背景</h5><p>最近需要做核酸检测，于是想找下附件的机构，但是找了好多都是列表形式的（心里嘀咕了句怎么连附近都看不了，就想着自己做下），不过最后还是找到了带附近功能的小程序，竟然还是国务院客户端。果然还是国家想的周到。虽然找到了这样的小程序自己已经没必要再造轮子了，但是本着学习（玩）的心态还是想着如何重现一下。</p><h5 id="这里也推广下国务院客户端小程序"><a href="#这里也推广下国务院客户端小程序" class="headerlink" title="这里也推广下国务院客户端小程序"></a>这里也推广下国务院客户端小程序</h5><p><img src="/img/article/wechat/%E5%9B%BD%E5%8A%A1%E9%99%A2.jpg"></p><h5 id="最后也算基本实现了这样的功能，贴两张图做个对比吧。"><a href="#最后也算基本实现了这样的功能，贴两张图做个对比吧。" class="headerlink" title="最后也算基本实现了这样的功能，贴两张图做个对比吧。"></a>最后也算基本实现了这样的功能，贴两张图做个对比吧。</h5><p>左边的是国务院客户端，右边是自己做的<br><img src="/img/article/wechat/%E6%A0%B8%E9%85%B8%E6%A3%80%E6%B5%8B.jpg"></p><h5 id="最后再说下开发过程踩过的坑吧"><a href="#最后再说下开发过程踩过的坑吧" class="headerlink" title="最后再说下开发过程踩过的坑吧"></a>最后再说下开发过程踩过的坑吧</h5><p>最主要的坑就是标记在地图上的marker（核酸机构）不显示的问题，首先是经纬度，经度（longitude），维度（latitude），最开始标记点一直没显示就是因为自己把经纬度写反了（关键是后台都不报错）导致一直不显示。其次是经纬度的赋值需是数字类型，字符串类型也是不行的。最后就是服务器域名的配置问题，有些域名比如 <a href="https://apis.map.qq.com/">https://apis.map.qq.com</a> 以及 wx.request 的地址都需要进行配置。当然了还有就是文件路径什么的尽量不要用中文命名，反正奇奇怪怪的bug就是这样产生的。<br>作为一个前端小白做这个花了一个多星期时间，才勉强做出这样的功能，真是令人头秃啊。</p><h5 id="完整代码地址-https-github-com-shubihu-Korok-Mask"><a href="#完整代码地址-https-github-com-shubihu-Korok-Mask" class="headerlink" title="完整代码地址 https://github.com/shubihu/Korok-Mask"></a>完整代码地址 <a href="https://github.com/shubihu/Korok-Mask">https://github.com/shubihu/Korok-Mask</a></h5><p>扫描下方二维码直达，第一次加载有点慢，，，，没办法，用的免费的服务器，慢应该是正常的。<br><img src="/img/article/wechat/%E5%85%8B%E6%B4%9B%E6%A0%BC.jpg"><br>参考</p><ul><li><a href="https://www.ruanyifeng.com/blog/2020/10/wechat-miniprogram-tutorial-part-one.html">https://www.ruanyifeng.com/blog/2020/10/wechat-miniprogram-tutorial-part-one.html</a></li><li><a href="https://github.com/zwz888mm/zhang">https://github.com/zwz888mm/zhang</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>微信小程序</category>
      
    </categories>
    
    
    <tags>
      
      <tag>核酸检测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MongoDB基础</title>
    <link href="/2021/10/18/MongoDB%E5%9F%BA%E7%A1%80/"/>
    <url>/2021/10/18/MongoDB%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<h2 id="MongoDB-基础命令"><a href="#MongoDB-基础命令" class="headerlink" title="MongoDB 基础命令"></a>MongoDB 基础命令</h2><span id="more"></span><h5 id="启动本地服务端"><a href="#启动本地服务端" class="headerlink" title="启动本地服务端"></a>启动本地服务端</h5><p>进入mongodb bin目录下打开命令行执行 mongod 启动服务端(存储引擎参数 –storageEngine=mmapv1)</p><figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs taggerscript">.<span class="hljs-symbol">\m</span>ongod.exe --storageEngine=mmapv1 --dbpath E:<span class="hljs-symbol">\D</span>esktop<span class="hljs-symbol">\J</span>ava<span class="hljs-symbol">\J</span>avaSoftware<span class="hljs-symbol">\m</span>ongoDB<span class="hljs-symbol">\d</span>ata\<br></code></pre></td></tr></table></figure><h5 id="启动本地客户端"><a href="#启动本地客户端" class="headerlink" title="启动本地客户端"></a>启动本地客户端</h5><p>进入mongodb bin目录下打开命令行执行 mongo 启动客户端</p><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs livescript">.<span class="hljs-string">\mongo.exe</span><br></code></pre></td></tr></table></figure><h5 id="查看数据库"><a href="#查看数据库" class="headerlink" title="查看数据库"></a>查看数据库</h5><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dart"><span class="hljs-keyword">show</span> dbs<br></code></pre></td></tr></table></figure><h5 id="切换数据库（无需新建，直接引用）"><a href="#切换数据库（无需新建，直接引用）" class="headerlink" title="切换数据库（无需新建，直接引用）"></a>切换数据库（无需新建，直接引用）</h5><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs actionscript"><span class="hljs-keyword">use</span> demo<br></code></pre></td></tr></table></figure><h5 id="插入数据-以创建一个雇员信息表为例"><a href="#插入数据-以创建一个雇员信息表为例" class="headerlink" title="插入数据(以创建一个雇员信息表为例)"></a>插入数据(以创建一个雇员信息表为例)</h5><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">db<span class="hljs-selector-class">.Employee</span><span class="hljs-selector-class">.save</span>(&#123;<span class="hljs-selector-tag">code</span>:<span class="hljs-string">&#x27;E01&#x27;</span>, name:<span class="hljs-string">&#x27;Jacky&#x27;</span>&#125;)<br></code></pre></td></tr></table></figure><h5 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h5><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dart"><span class="hljs-keyword">show</span> collections<br></code></pre></td></tr></table></figure><h5 id="查找数据"><a href="#查找数据" class="headerlink" title="查找数据"></a>查找数据</h5><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">db.<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">Employee</span>.</span></span>find<span class="hljs-literal">()</span><br></code></pre></td></tr></table></figure><h5 id="格式化输出查找数据"><a href="#格式化输出查找数据" class="headerlink" title="格式化输出查找数据"></a>格式化输出查找数据</h5><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">db<span class="hljs-selector-class">.Employee</span><span class="hljs-selector-class">.find</span>()<span class="hljs-selector-class">.pretty</span>()<br></code></pre></td></tr></table></figure><h5 id="添加不同格式数据"><a href="#添加不同格式数据" class="headerlink" title="添加不同格式数据"></a>添加不同格式数据</h5><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">db<span class="hljs-selector-class">.Employee</span><span class="hljs-selector-class">.save</span>(&#123;<span class="hljs-selector-tag">code</span>:<span class="hljs-string">&#x27;E02&#x27;</span>, name:<span class="hljs-string">&#x27;Jim&#x27;</span>, email:<span class="hljs-string">&#x27;test@email.com&#x27;</span>&#125;)<br></code></pre></td></tr></table></figure><p>启动mongodb时，提示Unclean shutdown detected mongodb，解决方法:</p><figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs taggerscript">.<span class="hljs-symbol">\m</span>ongod.exe --repair --dbpath E:<span class="hljs-symbol">\D</span>esktop<span class="hljs-symbol">\J</span>ava<span class="hljs-symbol">\J</span>avaSoftware<span class="hljs-symbol">\m</span>ongoDB<span class="hljs-symbol">\d</span>ata\<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MongoDB</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>iPhone 快捷指令自动打开低电量模式</title>
    <link href="/2021/09/27/iPhone%E5%BF%AB%E6%8D%B7%E6%8C%87%E4%BB%A4%E8%87%AA%E5%8A%A8%E6%89%93%E5%BC%80%E4%BD%8E%E7%94%B5%E9%87%8F%E6%A8%A1%E5%BC%8F/"/>
    <url>/2021/09/27/iPhone%E5%BF%AB%E6%8D%B7%E6%8C%87%E4%BB%A4%E8%87%AA%E5%8A%A8%E6%89%93%E5%BC%80%E4%BD%8E%E7%94%B5%E9%87%8F%E6%A8%A1%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><p>iPhone的电量一直是个软肋，但是其低电量模式续航还真是很可观的。当然一般想起来用低电量模式的时候都是电量剩余不多了的时候，尤其是在外面玩耍的时候，都不能好好地扣手机了。</p><h5 id="具体步骤如下："><a href="#具体步骤如下：" class="headerlink" title="具体步骤如下："></a>具体步骤如下：</h5><p>打开快捷指令，添加自动化，选择 电池电量 ，然后选择 低于50%（这里可以修改，反正我修改成了100%，让手机在99%以下都处于低电量模式以此来延长续航），然后 下一步 ，点击 添加操作，在搜素框搜索低电量，选择设定低电量模式脚本 ，然后再下一步，关掉运行前询问就完成了。</p><h5 id="1"><a href="#1" class="headerlink" title="1"></a>1</h5><p><img src="/img/article/iphone1/1.jpg"></p><h5 id="2"><a href="#2" class="headerlink" title="2"></a>2</h5><p><img src="/img/article/iphone1/2.jpg"></p><h5 id="3"><a href="#3" class="headerlink" title="3"></a>3</h5><p><img src="/img/article/iphone1/3.jpg"></p>]]></content>
    
    
    <categories>
      
      <category>iPhone</category>
      
    </categories>
    
    
    <tags>
      
      <tag>玩</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pyecharts 不同颜色绘制正负柱状图</title>
    <link href="/2021/09/27/Pyecharts%E4%B8%8D%E5%90%8C%E9%A2%9C%E8%89%B2%E7%BB%98%E5%88%B6%E6%AD%A3%E8%B4%9F%E6%9F%B1%E7%8A%B6%E5%9B%BE/"/>
    <url>/2021/09/27/Pyecharts%E4%B8%8D%E5%90%8C%E9%A2%9C%E8%89%B2%E7%BB%98%E5%88%B6%E6%AD%A3%E8%B4%9F%E6%9F%B1%E7%8A%B6%E5%9B%BE/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import akshare as ak<br>import pyecharts.options as opts<br><span class="hljs-keyword">from</span> pyecharts.charts import Bar, Line<br><span class="hljs-keyword">from</span> pyecharts.commons.utils import JsCode<br><br>fund_em_info_df = ak.fund_em_open_fund_info(<span class="hljs-attribute">fund</span>=<span class="hljs-string">&quot;006008&quot;</span>, <span class="hljs-attribute">indicator</span>=<span class="hljs-string">&quot;单位净值走势&quot;</span>)<br><br>fund_name = <span class="hljs-string">&#x27;诺安积极配置混合C&#x27;</span><br>x_data = fund_em_info_df[<span class="hljs-string">&#x27;净值日期&#x27;</span>].tolist()<br>y_data = fund_em_info_df[<span class="hljs-string">&#x27;单位净值&#x27;</span>].tolist()<br>z_data = fund_em_info_df[<span class="hljs-string">&#x27;日增长率&#x27;</span>].tolist()<br><br>background_color_js = (<br>    <span class="hljs-string">&quot;new echarts.graphic.LinearGradient(0, 0, 0, 1, &quot;</span><br>    <span class="hljs-string">&quot;[&#123;offset: 0, color: &#x27;#c86589&#x27;&#125;, &#123;offset: 1, color: &#x27;#06a7ff&#x27;&#125;], false)&quot;</span><br>)<br>area_color_js = (<br>    <span class="hljs-string">&quot;new echarts.graphic.LinearGradient(0, 0, 0, 1, &quot;</span><br>    <span class="hljs-string">&quot;[&#123;offset: 0, color: &#x27;#eb64fb&#x27;&#125;, &#123;offset: 1, color: &#x27;#3fbbff0d&#x27;&#125;], false)&quot;</span><br>)<br><br><br>bar = (<br>    Bar(<span class="hljs-attribute">init_opts</span>=opts.InitOpts(bg_color=JsCode(background_color_js), <span class="hljs-attribute">width</span>=<span class="hljs-string">&#x27;700px&#x27;</span>, <span class="hljs-attribute">height</span>=<span class="hljs-string">&#x27;450px&#x27;</span>))     ## width, height修改画布大小<br>    .add_xaxis(<span class="hljs-attribute">xaxis_data</span>=x_data)<br>    .add_yaxis(<br>        <span class="hljs-attribute">series_name</span>=<span class="hljs-string">&quot;&quot;</span>,<br>        <span class="hljs-attribute">y_axis</span>=z_data,<br>        <span class="hljs-attribute">label_opts</span>=opts.LabelOpts(is_show=False),<br>        <span class="hljs-attribute">itemstyle_opts</span>=opts.ItemStyleOpts(<br>            ### 调用js代码绘制不同颜色<br>            <span class="hljs-attribute">color</span>=JsCode(<br>                <span class="hljs-string">&quot;&quot;</span><span class="hljs-string">&quot;</span><br><span class="hljs-string">                    function(params) &#123;</span><br><span class="hljs-string">                        var colorList;</span><br><span class="hljs-string">                        if (params.data &gt;= 0) &#123;</span><br><span class="hljs-string">                          colorList = &#x27;#FF4500&#x27;;</span><br><span class="hljs-string">                        &#125; else &#123;</span><br><span class="hljs-string">                          colorList = &#x27;#14b143&#x27;;</span><br><span class="hljs-string">                        &#125;</span><br><span class="hljs-string">                        return colorList;</span><br><span class="hljs-string">                    &#125;</span><br><span class="hljs-string">                    &quot;</span><span class="hljs-string">&quot;&quot;</span><br>                )<br>            )<br>        )<br>    .set_global_opts(<br>        <span class="hljs-attribute">title_opts</span>=opts.TitleOpts(<br>            <span class="hljs-attribute">title</span>=fund_name,<br>            <span class="hljs-attribute">pos_bottom</span>=<span class="hljs-string">&quot;90%&quot;</span>,<br>            <span class="hljs-attribute">pos_left</span>=<span class="hljs-string">&quot;center&quot;</span>,<br>            <span class="hljs-attribute">title_textstyle_opts</span>=opts.TextStyleOpts(color=&quot;#fff&quot;, <span class="hljs-attribute">font_size</span>=16),<br>        ),<br>        <span class="hljs-attribute">xaxis_opts</span>=opts.AxisOpts(<br>            <span class="hljs-attribute">type_</span>=<span class="hljs-string">&quot;category&quot;</span>,<br>            <span class="hljs-attribute">boundary_gap</span>=<span class="hljs-literal">False</span>,<br>            <span class="hljs-attribute">axislabel_opts</span>=opts.LabelOpts(margin=30, <span class="hljs-attribute">color</span>=<span class="hljs-string">&quot;#ffffff63&quot;</span>),<br>            <span class="hljs-attribute">axisline_opts</span>=opts.AxisLineOpts(is_show=False),<br>            <span class="hljs-attribute">axistick_opts</span>=opts.AxisTickOpts(<br>                <span class="hljs-attribute">is_show</span>=<span class="hljs-literal">True</span>,<br>                <span class="hljs-attribute">length</span>=25,<br>                <span class="hljs-attribute">linestyle_opts</span>=opts.LineStyleOpts(color=&quot;#ffffff1f&quot;),<br>            ),<br>            <span class="hljs-attribute">splitline_opts</span>=opts.SplitLineOpts(<br>                <span class="hljs-attribute">is_show</span>=<span class="hljs-literal">True</span>, <span class="hljs-attribute">linestyle_opts</span>=opts.LineStyleOpts(color=&quot;#ffffff1f&quot;)<br>            ),<br>        ),<br>        <span class="hljs-attribute">yaxis_opts</span>=opts.AxisOpts(<br>            <span class="hljs-attribute">type_</span>=<span class="hljs-string">&quot;value&quot;</span>,<br>            <span class="hljs-attribute">position</span>=<span class="hljs-string">&quot;left&quot;</span>,<br>            <span class="hljs-attribute">axislabel_opts</span>=opts.LabelOpts(margin=20, <span class="hljs-attribute">color</span>=<span class="hljs-string">&quot;#ffffff63&quot;</span>),<br>            <span class="hljs-attribute">axisline_opts</span>=opts.AxisLineOpts(<br>                <span class="hljs-attribute">linestyle_opts</span>=opts.LineStyleOpts(width=2, <span class="hljs-attribute">color</span>=<span class="hljs-string">&quot;#fff&quot;</span>)<br>            ),<br>            <span class="hljs-attribute">axistick_opts</span>=opts.AxisTickOpts(<br>                <span class="hljs-attribute">is_show</span>=<span class="hljs-literal">True</span>,<br>                <span class="hljs-attribute">length</span>=15,<br>                <span class="hljs-attribute">linestyle_opts</span>=opts.LineStyleOpts(color=&quot;#ffffff1f&quot;),<br>            ),<br>            <span class="hljs-attribute">splitline_opts</span>=opts.SplitLineOpts(<br>                <span class="hljs-attribute">is_show</span>=<span class="hljs-literal">True</span>, <span class="hljs-attribute">linestyle_opts</span>=opts.LineStyleOpts(color=&quot;#ffffff1f&quot;)<br>            ),<br>        ),<br><span class="hljs-comment">#         legend_opts=opts.LegendOpts(is_show=True),</span><br>        datazoom_opts=[opts.DataZoomOpts(), opts.DataZoomOpts(<span class="hljs-attribute">type_</span>=<span class="hljs-string">&quot;inside&quot;</span>)]    ## 时间轴显示并可同通过鼠标滑动<br>    )<br>)<br><br><br>line = (<br>    Line(<span class="hljs-attribute">init_opts</span>=opts.InitOpts(bg_color=JsCode(background_color_js)))<br>    .add_xaxis(<span class="hljs-attribute">xaxis_data</span>=x_data)<br>    .add_yaxis(<br>        <span class="hljs-attribute">series_name</span>=<span class="hljs-string">&quot;&quot;</span>,<br>        y_axis=[round(i * 10, 2) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> y_data],<br>        <span class="hljs-attribute">is_smooth</span>=<span class="hljs-literal">True</span>,<br>        <span class="hljs-attribute">is_symbol_show</span>=<span class="hljs-literal">True</span>,<br>        <span class="hljs-attribute">symbol</span>=<span class="hljs-string">&quot;circle&quot;</span>,<br>        <span class="hljs-attribute">symbol_size</span>=6,<br>        <span class="hljs-attribute">linestyle_opts</span>=opts.LineStyleOpts(color=&quot;#fff&quot;),<br>        <span class="hljs-attribute">label_opts</span>=opts.LabelOpts(is_show=True, <span class="hljs-attribute">position</span>=<span class="hljs-string">&quot;top&quot;</span>, <span class="hljs-attribute">color</span>=<span class="hljs-string">&quot;white&quot;</span>),<br>        <span class="hljs-attribute">itemstyle_opts</span>=opts.ItemStyleOpts(<br>            <span class="hljs-attribute">color</span>=<span class="hljs-string">&quot;red&quot;</span>, <span class="hljs-attribute">border_color</span>=<span class="hljs-string">&quot;#fff&quot;</span>, <span class="hljs-attribute">border_width</span>=3<br>        ),<br>        <span class="hljs-attribute">tooltip_opts</span>=opts.TooltipOpts(is_show=False),<br>        <span class="hljs-attribute">areastyle_opts</span>=opts.AreaStyleOpts(color=JsCode(area_color_js), <span class="hljs-attribute">opacity</span>=1),<br>    )<br>)<br><br>bar.overlap(line)        ## 混合柱状图和线图<br>bar.render_notebook()<br><br></code></pre></td></tr></table></figure><p>结果如下</p><iframe src="/img/bar_line.html" width="100%" height="500" name="topFrame" scrolling="yes"  noresize="noresize" frameborder="0" id="topFrame"></iframe><p>参考</p><ul><li><a href="https://gallery.pyecharts.org/#/Candlestick/professional_kline_chart">https://gallery.pyecharts.org/#/Candlestick/professional_kline_chart</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pyecharts</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch 学习入门</title>
    <link href="/2021/09/16/Pytorch-learning/"/>
    <url>/2021/09/16/Pytorch-learning/</url>
    
    <content type="html"><![CDATA[<h2 id="Pytorch-Learning-Note"><a href="#Pytorch-Learning-Note" class="headerlink" title="Pytorch Learning Note"></a>Pytorch Learning Note</h2><span id="more"></span><h5 id="torch-nn"><a href="#torch-nn" class="headerlink" title="torch.nn"></a>torch.nn</h5><p>Module：创建一个行为类似于函数的可调用对象，但也可以包含状态（例如神经网络层权重）。 它知道其中包含的 Parameter ，并且可以将其所有坡度归零，遍历它们以进行权重更新等。<br>Parameter：张量的包装器，用于告知 Module 具有在反向传播期间需要更新的权重。 仅更新具有require_grad属性集的张量<br>functional：一个模块（通常按照惯例导入到 F 名称空间中），其中包含激活函数，损失函数等。 以及卷积和线性层等层的无状态版本。</p><h5 id="torch-optim"><a href="#torch-optim" class="headerlink" title="torch.optim"></a>torch.optim</h5><p>包含诸如 SGD 的优化程序，这些优化程序在后退步骤</p><h5 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h5><p>更新 Parameter 的权重。 具有__len__和__getitem__的对象，包括 Pytorch 提供的类，例如 TensorDataset</p><h5 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h5><p>获取任何 Dataset 并创建一个迭代器，该迭代器返回批量数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path<br><span class="hljs-keyword">import</span> requests<br><br>DATA_PATH = Path(<span class="hljs-string">&quot;data&quot;</span>)<br>PATH = DATA_PATH / <span class="hljs-string">&quot;mnist&quot;</span><br><br>PATH.mkdir(parents=<span class="hljs-literal">True</span>, exist_ok=<span class="hljs-literal">True</span>)<br><br>URL = <span class="hljs-string">&quot;https://github.com/pytorch/tutorials/raw/master/_static/&quot;</span><br>FILENAME = <span class="hljs-string">&quot;mnist.pkl.gz&quot;</span><br><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> (PATH / FILENAME).exists():<br>        content = requests.get(URL + FILENAME).content<br>        (PATH / FILENAME).<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;wb&quot;</span>).write(content)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">import</span> gzip<br><br><span class="hljs-keyword">with</span> gzip.<span class="hljs-built_in">open</span>((PATH / FILENAME).as_posix(), <span class="hljs-string">&quot;rb&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=<span class="hljs-string">&quot;latin-1&quot;</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>pyplot.imshow(x_train[<span class="hljs-number">0</span>].reshape((<span class="hljs-number">28</span>, <span class="hljs-number">28</span>)), cmap=<span class="hljs-string">&quot;gray&quot;</span>)<br><span class="hljs-built_in">print</span>(x_train.shape)<br></code></pre></td></tr></table></figure><pre><code>(50000, 784)</code></pre><!-- ![png](output_2_1.png) --><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br>x_train, y_train, x_valid, y_valid = <span class="hljs-built_in">map</span>(<br>    torch.tensor, (x_train, y_train, x_valid, y_valid)<br>)<br>n, c = x_train.shape<br>x_train, x_train.shape, y_train.<span class="hljs-built_in">min</span>(), y_train.<span class="hljs-built_in">max</span>()<br><span class="hljs-built_in">print</span>(x_train, y_train)<br><span class="hljs-built_in">print</span>(x_train.shape)<br><span class="hljs-built_in">print</span>(y_train.<span class="hljs-built_in">min</span>(), y_train.<span class="hljs-built_in">max</span>())<br></code></pre></td></tr></table></figure><pre><code>tensor([[0., 0., 0.,  ..., 0., 0., 0.],        [0., 0., 0.,  ..., 0., 0., 0.],        [0., 0., 0.,  ..., 0., 0., 0.],        ...,        [0., 0., 0.,  ..., 0., 0., 0.],        [0., 0., 0.,  ..., 0., 0., 0.],        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])torch.Size([50000, 784])tensor(0) tensor(9)</code></pre><h5 id="从0构建神经网络线性模型"><a href="#从0构建神经网络线性模型" class="headerlink" title="从0构建神经网络线性模型"></a>从0构建神经网络线性模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><br>weights = torch.randn(<span class="hljs-number">784</span>, <span class="hljs-number">10</span>) / math.sqrt(<span class="hljs-number">784</span>)<br>weights.requires_grad_()<br>bias = torch.zeros(<span class="hljs-number">10</span>, requires_grad=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment">## softmax激活函数</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">log_softmax</span>(<span class="hljs-params">x</span>):</span><br>    <span class="hljs-keyword">return</span> x - x.exp().<span class="hljs-built_in">sum</span>(-<span class="hljs-number">1</span>).log().unsqueeze(-<span class="hljs-number">1</span>)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">model</span>(<span class="hljs-params">xb</span>):</span><br>    <span class="hljs-keyword">return</span> log_softmax(xb @ weights + bias)  <span class="hljs-comment">#  @代表点积运算</span><br><br>bs = <span class="hljs-number">64</span>  <span class="hljs-comment"># batch size</span><br><br>xb = x_train[<span class="hljs-number">0</span>:bs]  <span class="hljs-comment"># a mini-batch from x</span><br>preds = model(xb)  <span class="hljs-comment"># predictions</span><br>preds[<span class="hljs-number">0</span>], preds.shape<br><span class="hljs-built_in">print</span>(preds[<span class="hljs-number">0</span>], preds.shape)<br><br><span class="hljs-comment">## 损失函数</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">nll</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, target</span>):</span><br>    <span class="hljs-keyword">return</span> -<span class="hljs-built_in">input</span>[<span class="hljs-built_in">range</span>(target.shape[<span class="hljs-number">0</span>]), target].mean()<br><br>loss_func = nll<br><br>yb = y_train[<span class="hljs-number">0</span>:bs]<br><span class="hljs-built_in">print</span>(loss_func(preds, yb))<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">accuracy</span>(<span class="hljs-params">out, yb</span>):</span><br>    preds = torch.argmax(out, dim=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> (preds == yb).<span class="hljs-built_in">float</span>().mean()<br><br><span class="hljs-built_in">print</span>(accuracy(preds, yb))<br><br><span class="hljs-keyword">from</span> IPython.core.debugger <span class="hljs-keyword">import</span> set_trace<br><br>lr = <span class="hljs-number">0.5</span>  <span class="hljs-comment"># learning rate</span><br>epochs = <span class="hljs-number">2</span>  <span class="hljs-comment"># how many epochs to train for</span><br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((n - <span class="hljs-number">1</span>) // bs + <span class="hljs-number">1</span>):<br>        <span class="hljs-comment">#         set_trace()</span><br>        start_i = i * bs<br>        end_i = start_i + bs<br>        xb = x_train[start_i:end_i]<br>        yb = y_train[start_i:end_i]<br>        pred = model(xb)<br>        loss = loss_func(pred, yb)<br><br>        loss.backward()<br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            weights -= weights.grad * lr<br>            bias -= bias.grad * lr<br>            weights.grad.zero_()<br>            bias.grad.zero_()<br>            <br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb), accuracy(model(xb), yb))<br><br></code></pre></td></tr></table></figure><pre><code>tensor([-2.5487, -2.8346, -2.7262, -2.1794, -2.1199, -2.1041, -1.9327, -2.1947,        -2.5637, -2.2133], grad_fn=&lt;SelectBackward&gt;) torch.Size([64, 10])tensor(2.3308, grad_fn=&lt;NegBackward&gt;)tensor(0.1094)tensor(0.0806, grad_fn=&lt;NegBackward&gt;) tensor(1.)</code></pre><h5 id="使用torch-nn-functional-重构"><a href="#使用torch-nn-functional-重构" class="headerlink" title="使用torch.nn.functional 重构"></a>使用torch.nn.functional 重构</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br>loss_func = F.cross_entropy<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">model</span>(<span class="hljs-params">xb</span>):</span><br>    <span class="hljs-keyword">return</span> xb @ weights + bias<br><br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb), accuracy(model(xb), yb))<br><br></code></pre></td></tr></table></figure><pre><code>tensor(0.0806, grad_fn=&lt;NllLossBackward&gt;) tensor(1.)</code></pre><h5 id="使用nn-Module重构"><a href="#使用nn-Module重构" class="headerlink" title="使用nn.Module重构"></a>使用nn.Module重构</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Mnist_Logistic</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.weights = nn.Parameter(torch.randn(<span class="hljs-number">784</span>, <span class="hljs-number">10</span>) / math.sqrt(<span class="hljs-number">784</span>))<br>        self.bias = nn.Parameter(torch.zeros(<span class="hljs-number">10</span>))<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, xb</span>):</span><br>        <span class="hljs-keyword">return</span> xb @ self.weights + self.bias<br>    <br>model = Mnist_Logistic()<br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb))<br><br>    <br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit</span>():</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((n - <span class="hljs-number">1</span>) // bs + <span class="hljs-number">1</span>):<br>            start_i = i * bs<br>            end_i = start_i + bs<br>            xb = x_train[start_i:end_i]<br>            yb = y_train[start_i:end_i]<br>            pred = model(xb)<br>            loss = loss_func(pred, yb)<br><br>            loss.backward()<br>            <span class="hljs-keyword">with</span> torch.no_grad():<br>                <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> model.parameters():<br>                    p -= p.grad * lr<br>                model.zero_grad()<br><br>fit()<br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb))<br><br></code></pre></td></tr></table></figure><pre><code>tensor(2.4222, grad_fn=&lt;NllLossBackward&gt;)tensor(0.0817, grad_fn=&lt;NllLossBackward&gt;)</code></pre><h5 id="使用nn-Linear重构"><a href="#使用nn-Linear重构" class="headerlink" title="使用nn.Linear重构"></a>使用nn.Linear重构</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Mnist_Logistic</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.lin = nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, xb</span>):</span><br>        <span class="hljs-keyword">return</span> self.lin(xb)<br>    <br>model = Mnist_Logistic()<br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb))<br>fit()<br><br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb))<br></code></pre></td></tr></table></figure><pre><code>tensor(2.3090, grad_fn=&lt;NllLossBackward&gt;)tensor(0.0824, grad_fn=&lt;NllLossBackward&gt;)</code></pre><h5 id="使用optim重构"><a href="#使用optim重构" class="headerlink" title="使用optim重构"></a>使用optim重构</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> optim<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_model</span>():</span><br>    model = Mnist_Logistic()<br>    <span class="hljs-keyword">return</span> model, optim.SGD(model.parameters(), lr=lr)<br><br>model, opt = get_model()<br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb))<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((n - <span class="hljs-number">1</span>) // bs + <span class="hljs-number">1</span>):<br>        start_i = i * bs<br>        end_i = start_i + bs<br>        xb = x_train[start_i:end_i]<br>        yb = y_train[start_i:end_i]<br>        pred = model(xb)<br>        loss = loss_func(pred, yb)<br><br>        loss.backward()<br>        opt.step()<br>        opt.zero_grad()<br><br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb))<br></code></pre></td></tr></table></figure><pre><code>tensor(2.2990, grad_fn=&lt;NllLossBackward&gt;)tensor(0.0805, grad_fn=&lt;NllLossBackward&gt;)</code></pre><h5 id="使用Dataset重构"><a href="#使用Dataset重构" class="headerlink" title="使用Dataset重构"></a>使用Dataset重构</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> TensorDataset<br><br>train_ds = TensorDataset(x_train, y_train)<br>xb,yb = train_ds[i*bs : i*bs+bs]<br>model, opt = get_model()<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((n - <span class="hljs-number">1</span>) // bs + <span class="hljs-number">1</span>):<br>        xb, yb = train_ds[i * bs: i * bs + bs]<br>        pred = model(xb)<br>        loss = loss_func(pred, yb)<br><br>        loss.backward()<br>        opt.step()<br>        opt.zero_grad()<br><br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb))<br></code></pre></td></tr></table></figure><pre><code>tensor(0.0817, grad_fn=&lt;NllLossBackward&gt;)</code></pre><h5 id="使用DataLoader重构"><a href="#使用DataLoader重构" class="headerlink" title="使用DataLoader重构"></a>使用DataLoader重构</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br>train_ds = TensorDataset(x_train, y_train)<br>train_dl = DataLoader(train_ds, batch_size=bs)<br><br>model, opt = get_model()<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>    <span class="hljs-keyword">for</span> xb, yb <span class="hljs-keyword">in</span> train_dl:<br>        pred = model(xb)<br>        loss = loss_func(pred, yb)<br><br>        loss.backward()<br>        opt.step()<br>        opt.zero_grad()<br><br><span class="hljs-built_in">print</span>(loss_func(model(xb), yb))<br></code></pre></td></tr></table></figure><pre><code>tensor(0.0803, grad_fn=&lt;NllLossBackward&gt;)</code></pre><h5 id="添加验证"><a href="#添加验证" class="headerlink" title="添加验证"></a>添加验证</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python">train_ds = TensorDataset(x_train, y_train)<br>train_dl = DataLoader(train_ds, batch_size=bs, shuffle=<span class="hljs-literal">True</span>)<br><br>valid_ds = TensorDataset(x_valid, y_valid)<br>valid_dl = DataLoader(valid_ds, batch_size=bs * <span class="hljs-number">2</span>)<br><br>model, opt = get_model()<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>    model.train()<br>    <span class="hljs-keyword">for</span> xb, yb <span class="hljs-keyword">in</span> train_dl:<br>        pred = model(xb)<br>        loss = loss_func(pred, yb)<br><br>        loss.backward()<br>        opt.step()<br>        opt.zero_grad()<br><br>    model.<span class="hljs-built_in">eval</span>()<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        valid_loss = <span class="hljs-built_in">sum</span>(loss_func(model(xb), yb) <span class="hljs-keyword">for</span> xb, yb <span class="hljs-keyword">in</span> valid_dl)<br><br>    <span class="hljs-built_in">print</span>(epoch, valid_loss / <span class="hljs-built_in">len</span>(valid_dl))<br></code></pre></td></tr></table></figure><pre><code>0 tensor(0.3093)1 tensor(0.3198)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">## 创建fit()和get_data()</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">loss_batch</span>(<span class="hljs-params">model, loss_func, xb, yb, opt=<span class="hljs-literal">None</span></span>):</span><br>    loss = loss_func(model(xb), yb)<br><br>    <span class="hljs-keyword">if</span> opt <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        loss.backward()<br>        opt.step()<br>        opt.zero_grad()<br><br>    <span class="hljs-keyword">return</span> loss.item(), <span class="hljs-built_in">len</span>(xb)<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit</span>(<span class="hljs-params">epochs, model, loss_func, opt, train_dl, valid_dl</span>):</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>        model.train()<br>        <span class="hljs-keyword">for</span> xb, yb <span class="hljs-keyword">in</span> train_dl:<br>            loss_batch(model, loss_func, xb, yb, opt)<br><br>        model.<span class="hljs-built_in">eval</span>()<br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            losses, nums = <span class="hljs-built_in">zip</span>(<br>                *[loss_batch(model, loss_func, xb, yb) <span class="hljs-keyword">for</span> xb, yb <span class="hljs-keyword">in</span> valid_dl]<br>            )<br>        val_loss = np.<span class="hljs-built_in">sum</span>(np.multiply(losses, nums)) / np.<span class="hljs-built_in">sum</span>(nums)<br><br>        <span class="hljs-built_in">print</span>(epoch, val_loss)<br>        <br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_data</span>(<span class="hljs-params">train_ds, valid_ds, bs</span>):</span><br>    <span class="hljs-keyword">return</span> (<br>        DataLoader(train_ds, batch_size=bs, shuffle=<span class="hljs-literal">True</span>),<br>        DataLoader(valid_ds, batch_size=bs * <span class="hljs-number">2</span>),<br>    )<br><br>train_dl, valid_dl = get_data(train_ds, valid_ds, bs)<br>model, opt = get_model()<br>fit(epochs, model, loss_func, opt, train_dl, valid_dl)<br></code></pre></td></tr></table></figure><pre><code>0 0.33136114755868911 0.35820939881801606</code></pre><h5 id="切换到-CNN"><a href="#切换到-CNN" class="headerlink" title="切换到 CNN"></a>切换到 CNN</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Mnist_CNN</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>        self.conv2 = nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>        self.conv3 = nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">10</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, xb</span>):</span><br>        xb = xb.view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>)<br>        xb = F.relu(self.conv1(xb))<br>        xb = F.relu(self.conv2(xb))<br>        xb = F.relu(self.conv3(xb))<br>        xb = F.avg_pool2d(xb, <span class="hljs-number">4</span>)<br>        <span class="hljs-keyword">return</span> xb.view(-<span class="hljs-number">1</span>, xb.size(<span class="hljs-number">1</span>))<br><br>lr = <span class="hljs-number">0.1</span><br><br>model = Mnist_CNN()<br>opt = optim.SGD(model.parameters(), lr=lr, momentum=<span class="hljs-number">0.9</span>)<br><br>fit(epochs, model, loss_func, opt, train_dl, valid_dl)<br></code></pre></td></tr></table></figure><pre><code>0 0.29366704518795011 0.21561954822540283</code></pre><h5 id="nn-Sequential-Sequential对象以顺序方式运行其中包含的每个模块。"><a href="#nn-Sequential-Sequential对象以顺序方式运行其中包含的每个模块。" class="headerlink" title="nn.Sequential   Sequential对象以顺序方式运行其中包含的每个模块。"></a>nn.Sequential   Sequential对象以顺序方式运行其中包含的每个模块。</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Lambda</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, func</span>):</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.func = func<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        <span class="hljs-keyword">return</span> self.func(x)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">preprocess</span>(<span class="hljs-params">x</span>):</span><br>    <span class="hljs-keyword">return</span> x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>)<br><br>model = nn.Sequential(<br>    Lambda(preprocess),<br>    nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<br>    nn.ReLU(),<br>    nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<br>    nn.ReLU(),<br>    nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">10</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<br>    nn.ReLU(),<br>    nn.AvgPool2d(<span class="hljs-number">4</span>),<br>    Lambda(<span class="hljs-keyword">lambda</span> x: x.view(x.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)),<br>)<br><br>opt = optim.SGD(model.parameters(), lr=lr, momentum=<span class="hljs-number">0.9</span>)<br><br>fit(epochs, model, loss_func, opt, train_dl, valid_dl)<br></code></pre></td></tr></table></figure><pre><code>0 0.40379241023063661 0.25595326462984086</code></pre><h5 id="包装DataLoader"><a href="#包装DataLoader" class="headerlink" title="包装DataLoader"></a>包装DataLoader</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">preprocess</span>(<span class="hljs-params">x, y</span>):</span><br>    <span class="hljs-keyword">return</span> x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>), y<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">WrappedDataLoader</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, dl, func</span>):</span><br>        self.dl = dl<br>        self.func = func<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.dl)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__iter__</span>(<span class="hljs-params">self</span>):</span><br>        batches = <span class="hljs-built_in">iter</span>(self.dl)<br>        <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> batches:<br>            <span class="hljs-keyword">yield</span> (self.func(*b))<br><br>train_dl, valid_dl = get_data(train_ds, valid_ds, bs)<br>train_dl = WrappedDataLoader(train_dl, preprocess)<br>valid_dl = WrappedDataLoader(valid_dl, preprocess)<br><br>model = nn.Sequential(<br>    nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<br>    nn.ReLU(),<br>    nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<br>    nn.ReLU(),<br>    nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">10</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<br>    nn.ReLU(),<br>    nn.AdaptiveAvgPool2d(<span class="hljs-number">1</span>),<br>    Lambda(<span class="hljs-keyword">lambda</span> x: x.view(x.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)),<br>)<br><br>opt = optim.SGD(model.parameters(), lr=lr, momentum=<span class="hljs-number">0.9</span>)<br><br>fit(epochs, model, loss_func, opt, train_dl, valid_dl)<br><br></code></pre></td></tr></table></figure><pre><code>0 0.313964178180694551 0.2551067463874817</code></pre><h5 id="使用GPU，，，如果有"><a href="#使用GPU，，，如果有" class="headerlink" title="使用GPU，，，如果有"></a>使用GPU，，，如果有</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(torch.cuda.is_available())<br>dev = torch.device(<br>    <span class="hljs-string">&quot;cuda&quot;</span>) <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">preprocess</span>(<span class="hljs-params">x, y</span>):</span><br>    <span class="hljs-keyword">return</span> x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>).to(dev), y.to(dev)<br><br>train_dl, valid_dl = get_data(train_ds, valid_ds, bs)<br>train_dl = WrappedDataLoader(train_dl, preprocess)<br>valid_dl = WrappedDataLoader(valid_dl, preprocess)<br><br>model.to(dev)<br>opt = optim.SGD(model.parameters(), lr=lr, momentum=<span class="hljs-number">0.9</span>)<br>fit(epochs, model, loss_func, opt, train_dl, valid_dl)<br><br></code></pre></td></tr></table></figure><pre><code>False0 0.223737240695953381 0.2494806985616684</code></pre>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>iPhone 快捷指令上下班半自动打卡</title>
    <link href="/2021/09/10/iPhone/"/>
    <url>/2021/09/10/iPhone/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><p>打工人有时候会忘记打卡，为了能尽量少忘记，有时候会设定闹钟来提醒。在iPhone上还有个稍微半自动化的应用也可以实现，就是快捷指令。为啥是半自动化呢，因为息屏状态下是无法执行的，只是会有提醒，需要解锁后点击才能执行。当然了在不息屏的状态下是完全可以实现自动化的，但是也不可能一直不息屏吧。iPhone的那点点电量就不说了。<br>还有个前提就是提前设置好打卡APP的快捷打卡功能。</p><h6 id="快捷指令APP（一般自带，不小心删了可以去APP-Store重新下载）"><a href="#快捷指令APP（一般自带，不小心删了可以去APP-Store重新下载）" class="headerlink" title="快捷指令APP（一般自带，不小心删了可以去APP Store重新下载）"></a>快捷指令APP（一般自带，不小心删了可以去APP Store重新下载）</h6><p>打开快捷指令app，点击自动化，点击创建个人自动化<br><img src="/img/article/iphone/0.jpg"></p><h5 id="选择特定时间"><a href="#选择特定时间" class="headerlink" title="选择特定时间"></a>选择特定时间</h5><p>这个页面还有其它事件，比如到达、离开等。一般现在企业微信或者钉钉亦或者是公司自己的打卡APP都是基于距离进行定位打卡，所以这里也可以选择到达或者离开，这里以特定时间为例，其它事件可以自行摸索。<br>然后设置上下班时间，可以选择每天，每周（可选周一至周五），按心情选择。<br><img src="/img/article/iphone/1.jpg"></p><h5 id="点击下一步，点击添加操作。"><a href="#点击下一步，点击添加操作。" class="headerlink" title="点击下一步，点击添加操作。"></a>点击下一步，点击添加操作。</h5><p><img src="/img/article/iphone/2.jpg"></p><h5 id="搜索输入：打开app，点击打开app，点击选择。"><a href="#搜索输入：打开app，点击打开app，点击选择。" class="headerlink" title="搜索输入：打开app，点击打开app，点击选择。"></a>搜索输入：打开app，点击打开app，点击选择。</h5><p><img src="/img/article/iphone/3.jpg"></p><h5 id="搜索输入企业微信，点击企业微信，点击下一步。"><a href="#搜索输入企业微信，点击企业微信，点击下一步。" class="headerlink" title="搜索输入企业微信，点击企业微信，点击下一步。"></a>搜索输入企业微信，点击企业微信，点击下一步。</h5><p><img src="/img/article/iphone/4.jpg"></p><h5 id="将运行前询问关闭，点击不询问，点击完成。"><a href="#将运行前询问关闭，点击不询问，点击完成。" class="headerlink" title="将运行前询问关闭，点击不询问，点击完成。"></a>将运行前询问关闭，点击不询问，点击完成。</h5><p><img src="/img/article/iphone/5.jpg"></p><h5 id="题外话"><a href="#题外话" class="headerlink" title="题外话"></a>题外话</h5><p>iPhone的快捷指令有点像编程，所以功能不止这些，网上还有如何实现敲击背面显示健康码等，有兴趣的可以搜来看看。</p>]]></content>
    
    
    <categories>
      
      <category>iPhone</category>
      
    </categories>
    
    
    <tags>
      
      <tag>玩</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python 监控</title>
    <link href="/2021/09/02/python%E7%9B%91%E6%8E%A7/"/>
    <url>/2021/09/02/python%E7%9B%91%E6%8E%A7/</url>
    
    <content type="html"><![CDATA[<h2 id="使用python监控电脑键盘、鼠标并拍照录像"><a href="#使用python监控电脑键盘、鼠标并拍照录像" class="headerlink" title="使用python监控电脑键盘、鼠标并拍照录像"></a>使用python监控电脑键盘、鼠标并拍照录像</h2><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> keyboard<br><span class="hljs-keyword">from</span> cv2 <span class="hljs-keyword">import</span> cv2<br><span class="hljs-comment"># from pynput.mouse import Listener</span><br><span class="hljs-keyword">import</span> pyautogui <span class="hljs-keyword">as</span> pag    <span class="hljs-comment">#监听鼠标</span><br><span class="hljs-comment"># from pynput.keyboard import Key, Listener</span><br><span class="hljs-keyword">from</span> threading <span class="hljs-keyword">import</span> Thread<br><br>x1, y1 = pag.position()<br><span class="hljs-comment"># print(x1, y1)</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">camera</span>():</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    拍照</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    cap = cv2.VideoCapture(<span class="hljs-number">0</span>)<br>    ret,frame = cap.read() <span class="hljs-comment">#读取摄像头内容</span><br>    cv2.imwrite(<span class="hljs-string">&quot;./test.jpg&quot;</span>,frame) <span class="hljs-comment">#保存到磁盘</span><br>    <span class="hljs-comment">#释放摄像头</span><br>    cap.release()<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">record_video</span>():</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    录制视频</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    cap = cv2.VideoCapture(<span class="hljs-number">0</span>)<br>    fps = <span class="hljs-number">30</span><br>    size=(<span class="hljs-built_in">int</span>(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),<span class="hljs-built_in">int</span>(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))<br>    videoWriter=cv2.VideoWriter(<span class="hljs-string">&#x27;./test.avi&#x27;</span>,cv2.VideoWriter_fourcc(<span class="hljs-string">&#x27;X&#x27;</span>,<span class="hljs-string">&#x27;V&#x27;</span>,<span class="hljs-string">&#x27;I&#x27;</span>,<span class="hljs-string">&#x27;D&#x27;</span>),fps,size)<br>    success,frame = cap.read()<br>    numFrameRemaining = <span class="hljs-number">5</span> * fps    <span class="hljs-comment">#摄像头捕获持续时间</span><br>    <span class="hljs-keyword">while</span> success <span class="hljs-keyword">and</span> numFrameRemaining &gt; <span class="hljs-number">0</span>:<br>        videoWriter.write(frame)<br>        success,frame = cap.read()<br>        numFrameRemaining -= <span class="hljs-number">1</span><br><br>    cap.release()<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">display_video</span>():</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    实时窗口</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    face_locations = []<br>    cap = cv2.VideoCapture(<span class="hljs-number">0</span>)<br><br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        <span class="hljs-comment"># Grab a single frame of video</span><br>        ret, frame = cap.read()<br><br>        <span class="hljs-comment"># Convert the image from BGR color (whichOpenCV uses) to RGB color (which face_recognition uses)</span><br>        rgb_frame = frame[:, :, ::-<span class="hljs-number">1</span>]<br><br>        <span class="hljs-comment"># Find all the faces in the current frameof video</span><br>        face_locations = face_recognition.face_locations(rgb_frame)<br><br>        <span class="hljs-comment"># Display the results</span><br>        <span class="hljs-keyword">for</span> top, right, bottom, left <span class="hljs-keyword">in</span> face_locations:<br>            <span class="hljs-comment"># Draw a box around the face</span><br>            cv2.rectangle(frame, (left, top),(right, bottom), (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>), <span class="hljs-number">2</span>)<br><br>        <span class="hljs-comment"># Display the resulting image</span><br>        cv2.imshow(<span class="hljs-string">&#x27;Video&#x27;</span>, frame)<br><br>        <span class="hljs-comment"># Hit &#x27;q&#x27; on the keyboard to quit!</span><br>        <span class="hljs-keyword">if</span> cv2.waitKey(<span class="hljs-number">1</span>) &amp; <span class="hljs-number">0xFF</span> == <span class="hljs-built_in">ord</span>(<span class="hljs-string">&#x27;q&#x27;</span>):<br>            <span class="hljs-keyword">break</span><br><br>    <span class="hljs-comment"># Release handle tothe webcam</span><br>    cap.release()<br>    cv2.destroyAllWindows()<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">display_video2</span>():</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    实时检测</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment">#存储知道人名列表</span><br>    known_names=[<span class="hljs-string">&#x27;yahaha1&#x27;</span>, <span class="hljs-string">&#x27;yahaha2&#x27;</span>] <br>    <span class="hljs-comment">#存储知道的特征值</span><br>    known_faces=[]<br><br>    image1 =face_recognition.load_image_file(<span class="hljs-string">&quot;yahaha2.jpg&quot;</span>)<br>    face_encoding1 =face_recognition.face_encodings(image1)<br><br>    image2 =face_recognition.load_image_file(<span class="hljs-string">&quot;yahaha1.jpg&quot;</span>)<br>    face_encoding2 =face_recognition.face_encodings(image1)<br><br>    <span class="hljs-keyword">if</span> face_encoding1 <span class="hljs-keyword">and</span> face_encoding2:<br>        face_encoding1 = face_encoding1[<span class="hljs-number">0</span>]<br>        face_encoding2 = face_encoding2[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">else</span>:<br>        sys.exit()<br><br>    known_faces = [face_encoding1, face_encoding2]<br><br>    cap = cv2.VideoCapture(<span class="hljs-number">0</span>)<br><br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        <span class="hljs-comment"># Grab a single frame of video</span><br>        ret, frame = cap.read()<br>        <span class="hljs-comment"># Convert the image from BGR color (whichOpenCV uses) to RGB color (which face_recognition uses)</span><br>        rgb_frame = frame[:, :, ::-<span class="hljs-number">1</span>]<br><br>        <span class="hljs-comment"># Find all the faces and face encodings inthe current frame of video</span><br>        face_locations =face_recognition.face_locations(rgb_frame)  <span class="hljs-comment"># 如有gpu可添加参数model=&#x27;cnn&#x27;提升精度</span><br>        face_encodings =face_recognition.face_encodings(rgb_frame, face_locations)<br><br>        face_names = []<br>        <span class="hljs-keyword">for</span> face_encoding <span class="hljs-keyword">in</span> face_encodings:<br>            <span class="hljs-comment"># See if the face is a match for theknown face(s)</span><br>            matches =face_recognition.compare_faces(known_faces, face_encoding, tolerance=<span class="hljs-number">0.60</span>)<br><br>            name = <span class="hljs-literal">None</span><br>            <span class="hljs-comment"># if match[0]:</span><br>            <span class="hljs-comment">#     name = &quot;Yahaha&quot;</span><br>            <span class="hljs-built_in">print</span>(matches)<br>            <span class="hljs-keyword">if</span> <span class="hljs-literal">True</span> <span class="hljs-keyword">in</span> matches:<br>                first_match_index = matches.index(<span class="hljs-literal">True</span>)<br>                name = known_names[first_match_index]<br>            <span class="hljs-keyword">else</span>:<br>                name = <span class="hljs-string">&#x27;Unkonwn&#x27;</span><br><br>            face_names.append(name)<br><br>        <span class="hljs-comment"># Label the results</span><br>        <span class="hljs-keyword">for</span> (top, right, bottom, left), name <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(face_locations, face_names):<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> name:<br>                <span class="hljs-keyword">continue</span><br><br>            <span class="hljs-comment"># Draw a box around the face</span><br>            cv2.rectangle(frame, (left, top),(right, bottom), (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>), <span class="hljs-number">2</span>)<br>            <span class="hljs-comment"># Draw a label with a name below theface</span><br>            cv2.rectangle(frame, (left, bottom -<span class="hljs-number">25</span>), (right, bottom), (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>), cv2.FILLED)<br>            font = cv2.FONT_HERSHEY_DUPLEX<br>            cv2.putText(frame, name, (left + <span class="hljs-number">6</span>,bottom - <span class="hljs-number">6</span>), font, <span class="hljs-number">0.5</span>, (<span class="hljs-number">255</span>, <span class="hljs-number">255</span>, <span class="hljs-number">255</span>), <span class="hljs-number">1</span>)<br><br>        cv2.imshow(<span class="hljs-string">&#x27;Video&#x27;</span>, frame)<br><br>        <span class="hljs-comment"># Hit &#x27;q&#x27; on the keyboard to quit!</span><br>        <span class="hljs-keyword">if</span> cv2.waitKey(<span class="hljs-number">1</span>) &amp; <span class="hljs-number">0xFF</span> == <span class="hljs-built_in">ord</span>(<span class="hljs-string">&#x27;q&#x27;</span>):<br>            <span class="hljs-keyword">break</span><br>    <span class="hljs-comment"># All done!</span><br>    cap.release()<br>    cv2.destroyAllWindows()<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">proof</span>(<span class="hljs-params">x</span>):</span><br>    <span class="hljs-comment"># print(x)</span><br>    <span class="hljs-comment"># record_video()</span><br>    camera()<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">monitor_keyboard</span>():</span><br>    keyboard.hook(proof)<br>    <span class="hljs-comment">#按下任何按键时，都会调用proof，其中一定会传一个值，就是键盘事件</span><br>    keyboard.wait()<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">monitor_mouse</span>():</span><br>    x2, y2 = pag.position()<br>    <span class="hljs-keyword">while</span> x1 == x2:<br>        x2, y2 = pag.position()<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># record_video()</span><br>        camera()<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    k = Thread(target=monitor_keyboard, args=())<br>    m = Thread(target=monitor_mouse, args=())<br>    k.start()<br>    m.start()<br>    k.join()<br>    m.join()<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>玩</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>We Are SVIP</title>
    <link href="/2021/08/20/WeAreSVIP/"/>
    <url>/2021/08/20/WeAreSVIP/</url>
    
    <content type="html"><![CDATA[<h2 id="薅各大厂视频羊毛"><a href="#薅各大厂视频羊毛" class="headerlink" title="薅各大厂视频羊毛"></a>薅各大厂视频羊毛</h2><span id="more"></span><p>周末了又可以追剧了，最近在看扫黑风暴，但是吧，现在各大视频网站都是需要VIP才能看，有的甚至更可恶，还要超前点播。这嘴脸真的是穷凶极恶。都是大厂了，说好的回报社会呢，，，就这样回报社会呢。人家（我没有）都已经忍痛购买你的VIP了，还不满足。算了，你有张良计，我有过墙梯。<br>今天就给大家分享个可以薅他们VIP的插件——油猴，确切的说是各路大神开发的脚本，油猴只是个脚本管家。如果能上google的话就方便很多，直接搜索油猴插件进行安装。但是国内吧，，，，可能很多人都无法上谷歌。这里就介绍下本地安装油猴插件的方法。</p><h5 id="No-1"><a href="#No-1" class="headerlink" title="No.1"></a>No.1</h5><p>首先先下载下油猴，链接在此：<a href="https://pan.baidu.com/s/1FQZBBjqr2s8f-9idizxI6w">https://pan.baidu.com/s/1FQZBBjqr2s8f-9idizxI6w</a> ;提取码：<span  style="color: #519D9E; ">8fmu</span><br>下载完成后直接解压到该文件夹。<br>然后打开我们的谷歌浏览器，在搜索地址栏输入：<span  style="color: #519D9E; ">chrome://extensions/</span>，进入扩展程序界面，<span  style="color: #519D9E; ">打开右上角的开发者模式</span>。接着选择<span  style="color: #519D9E; ">左上角的加载已解压的扩展程序</span>，然后选择我们刚刚解压过的油猴的目录即可，到这里油猴插件就完成了。接下来就是安装脚本了。</p><h5 id="No-2"><a href="#No-2" class="headerlink" title="No.2"></a>No.2</h5><p>然后进入这个网站：<a href="https://greasyfork.org/zh-CN">https://greasyfork.org/zh-CN</a> ，搜索VIP，会出现很多个脚本，自行选择就好。我选择的是 <a href="https://greasyfork.org/zh-CN/scripts/370634-%E6%87%92%E4%BA%BA%E4%B8%93%E7%94%A8-%E5%85%A8%E7%BD%91vip%E8%A7%86%E9%A2%91%E5%85%8D%E8%B4%B9%E7%A0%B4%E8%A7%A3%E5%8E%BB%E5%B9%BF%E5%91%8A-%E5%85%A8%E7%BD%91%E9%9F%B3%E4%B9%90%E7%9B%B4%E6%8E%A5%E4%B8%8B%E8%BD%BD-%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98%E7%9B%B4%E6%8E%A5%E4%B8%8B%E8%BD%BD%E7%AD%89%E5%A4%9A%E5%90%88%E4%B8%80%E7%89%88-%E9%95%BF%E6%9C%9F%E6%9B%B4%E6%96%B0-%E6%94%BE%E5%BF%83%E4%BD%BF%E7%94%A8">https://greasyfork.org/zh-CN/scripts/370634-%E6%87%92%E4%BA%BA%E4%B8%93%E7%94%A8-%E5%85%A8%E7%BD%91vip%E8%A7%86%E9%A2%91%E5%85%8D%E8%B4%B9%E7%A0%B4%E8%A7%A3%E5%8E%BB%E5%B9%BF%E5%91%8A-%E5%85%A8%E7%BD%91%E9%9F%B3%E4%B9%90%E7%9B%B4%E6%8E%A5%E4%B8%8B%E8%BD%BD-%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98%E7%9B%B4%E6%8E%A5%E4%B8%8B%E8%BD%BD%E7%AD%89%E5%A4%9A%E5%90%88%E4%B8%80%E7%89%88-%E9%95%BF%E6%9C%9F%E6%9B%B4%E6%96%B0-%E6%94%BE%E5%BF%83%E4%BD%BF%E7%94%A8</a> 这个，觉得还是比较好用的。之后点击安装就大功告成啦。</p><h4 id="No-3"><a href="#No-3" class="headerlink" title="No.3"></a>No.3</h4><p>利器有了，就可以去各大视频网站薅一波了，超前点播也可以薅哦。油猴这个插件及其脚本的功能不仅限于此，有兴趣可以自行摸索。</p>]]></content>
    
    
    <categories>
      
      <category>TroubleShoot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>薅羊毛</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>水一篇</title>
    <link href="/2021/08/20/%E6%B0%B4%E4%B8%80%E7%AF%87/"/>
    <url>/2021/08/20/%E6%B0%B4%E4%B8%80%E7%AF%87/</url>
    
    <content type="html"><![CDATA[<h2 id="如题"><a href="#如题" class="headerlink" title="如题"></a>如题</h2><span id="more"></span><p>虽然参照这篇文章设置了，但还是站点地图显示无法获取，不知道是不是时间的问题，等等吧。</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs applescript"><span class="hljs-comment">## 创建sitemap.xml</span><br>npm install hexo-generator-sitemap <span class="hljs-comment">--save</span><br></code></pre></td></tr></table></figure><iframe src="https://www.gongsunqi.xyz/2021/08/14/%E8%AE%A9%E8%87%AA%E5%B7%B1%E9%80%9A%E8%BF%87Hexo%E5%BB%BA%E7%AB%8B%E7%9A%84%E5%8D%9A%E5%AE%A2%E8%A2%AB%E8%B0%B7%E6%AD%8C%E6%90%9C%E7%B4%A2%E5%88%B0/" width="100%" height="500" name="topFrame" scrolling="yes"  noresize="noresize" frameborder="0" id="topFrame"></iframe>]]></content>
    
    
    <categories>
      
      <category>Working</category>
      
    </categories>
    
    
    <tags>
      
      <tag>划水摸鱼</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Trouble No Shoot</title>
    <link href="/2021/08/20/TroubleNoShoot/"/>
    <url>/2021/08/20/TroubleNoShoot/</url>
    
    <content type="html"><![CDATA[<h2 id="升级hexo遇到的问题"><a href="#升级hexo遇到的问题" class="headerlink" title="升级hexo遇到的问题"></a>升级hexo遇到的问题</h2><span id="more"></span><p>hexo的一个插件需要5.0以上的版本，看了下自己安装的是4.3的版本，所以想着升级一下。查了半天也没找到有效的方法。之后又查看了node的版本看着也很低，想升级的心又来了。折腾了半天愣是没升级成功，还把系统搞坏了，apt、dpkg这些也都没法用了。网上的资料有时候也不能盲目跟着做，还是用root账户删的，真是细思极恐，这要是公司的生产环境，这估计是要被祭天的。估计我也是仗着这是自己电脑里的子系统才敢这么胡作非为。系统坏了，本来想挽救一下的，发现越挽救问题越大。顺放弃。。。于是重新卸载Linux子系统，再重新安装，前后没花10分钟。果然还是微软baba的子系统安装卸载方便啊。<br>系统重新安装了，很多东西就要重新配置，比如github的免密提交等，这里也简单记录下。</p><h5 id="首先配置github及生成ssh秘钥，执行"><a href="#首先配置github及生成ssh秘钥，执行" class="headerlink" title="首先配置github及生成ssh秘钥，执行"></a>首先配置github及生成ssh秘钥，执行</h5><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs verilog">git <span class="hljs-keyword">config</span> --<span class="hljs-keyword">global</span> user<span class="hljs-variable">.email</span> <span class="hljs-string">&quot;you@example.com&quot;</span>    ## 我的 git <span class="hljs-keyword">config</span> --<span class="hljs-keyword">global</span> user<span class="hljs-variable">.email</span> <span class="hljs-string">&quot;jrwjb@sina.com&quot;</span>   <br>git <span class="hljs-keyword">config</span> --<span class="hljs-keyword">global</span> user<span class="hljs-variable">.name</span> <span class="hljs-string">&quot;Your Name&quot;</span>  ## 我的 git <span class="hljs-keyword">config</span> --<span class="hljs-keyword">global</span> user<span class="hljs-variable">.name</span> <span class="hljs-string">&quot;shubihu&quot;</span><br>ssh-keygen        ## 一路回车即可<br></code></pre></td></tr></table></figure><p>执行完后会在家目录的.ssh下生成下面几个文件</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs clean">id_rsa   ## 私钥<br>id_rsa.pub  ## 共钥<br></code></pre></td></tr></table></figure><p>然后把公钥的内容添加到github上即可。<br><img src="/img/article/gitssh.jpg"></p><h5 id="回到最开始的问题，升级hexo、node。"><a href="#回到最开始的问题，升级hexo、node。" class="headerlink" title="回到最开始的问题，升级hexo、node。"></a>回到最开始的问题，升级hexo、node。</h5><p>因为是新系统，所以相对简单些，直接安装新版的node，可以从官网下载最新的稳定版进行安装，不过我嫌麻烦懒得去下载，所以参考了这篇文章进行安装。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">## 使用nvm进行安装</span><br>curl -o- https:<span class="hljs-regexp">//</span>raw.githubusercontent.com<span class="hljs-regexp">/nvm-sh/</span>nvm<span class="hljs-regexp">/v0.35.3/i</span>nstall.sh | bash<br>nvm install node<br></code></pre></td></tr></table></figure><!-- <iframe src="https://www.myfreax.com/how-to-install-node-js-on-ubuntu-18-04/" width="100%" height="500" name="topFrame" scrolling="yes"  noresize="noresize" frameborder="0" id="topFrame"></iframe> --><h5 id="最后是升级hexo"><a href="#最后是升级hexo" class="headerlink" title="最后是升级hexo"></a>最后是升级hexo</h5><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs coffeescript"><span class="hljs-comment"># 使用淘宝源的 cnpm 替换 npm</span><br><span class="hljs-built_in">npm</span> install -g cnpm --registry=https://registry.<span class="hljs-built_in">npm</span>.taobao.org<br><br>cnpm install -g cnpm                 <span class="hljs-comment"># 升级 npm</span><br>cnpm cache clean -f                 <span class="hljs-comment"># 清除 npm 缓存</span><br><br>===更新 hexo: 进入 blog 目录，执行如下命令=== <br><span class="hljs-comment"># 更新 package.json 中的 hexo 及个插件版本</span><br>cnpm install -g <span class="hljs-built_in">npm</span>-check           <span class="hljs-comment"># 检查之前安装的插件，都有哪些是可以升级的 </span><br>cnpm install -g <span class="hljs-built_in">npm</span>-upgrade         <span class="hljs-comment"># 升级系统中的插件</span><br><span class="hljs-built_in">npm</span>-check<br><span class="hljs-built_in">npm</span>-upgrade<br><br><span class="hljs-comment"># 更新 hexo 及所有插件</span><br>cnpm update<br><br><span class="hljs-comment"># 确认 hexo 已经更新</span><br>hexo -v<br></code></pre></td></tr></table></figure><!-- <iframe src="https://xmuli.tech/posts/cb1e6c4f/" width="100%" height="500" name="topFrame" scrolling="yes"  noresize="noresize" frameborder="0" id="topFrame"></iframe> --><p>参考</p><ul><li><a href="https://xmuli.tech/posts/cb1e6c4f">https://xmuli.tech/posts/cb1e6c4f</a></li><li><a href="https://www.myfreax.com/how-to-install-node-js-on-ubuntu-18-04">https://www.myfreax.com/how-to-install-node-js-on-ubuntu-18-04</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>TroubleShoot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TroubleShoot</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python Sort Algorithm</title>
    <link href="/2021/08/16/PythonSortAlgorithm/"/>
    <url>/2021/08/16/PythonSortAlgorithm/</url>
    
    <content type="html"><![CDATA[<h2 id="Python常用排序算法"><a href="#Python常用排序算法" class="headerlink" title="Python常用排序算法"></a>Python常用排序算法</h2><span id="more"></span><h5 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sql">def quick_sort(<span class="hljs-keyword">array</span>):<br>    if len(<span class="hljs-keyword">array</span>) <span class="hljs-operator">&lt;=</span> <span class="hljs-number">1</span>:  # 递归跳出条件<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">array</span><br>    pivot <span class="hljs-operator">=</span> <span class="hljs-keyword">array</span>[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">left</span> <span class="hljs-operator">=</span> [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-keyword">array</span>[<span class="hljs-number">1</span>:] if i <span class="hljs-operator">&lt;</span> pivot]<br>    <span class="hljs-keyword">right</span> <span class="hljs-operator">=</span> [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-keyword">array</span>[<span class="hljs-number">1</span>:] if i <span class="hljs-operator">&gt;=</span> pivot]<br>    <span class="hljs-keyword">return</span> quick_sort(<span class="hljs-keyword">left</span>) <span class="hljs-operator">+</span> [pivot] <span class="hljs-operator">+</span> quick_sort(<span class="hljs-keyword">right</span>)<br></code></pre></td></tr></table></figure><h5 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h5><figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sas">def bubble_sort(<span class="hljs-meta">array</span>):<br>    for i <span class="hljs-meta">in</span><span class="hljs-meta"> range(</span>l<span class="hljs-meta">en(</span><span class="hljs-meta">array</span>) - 1):<br>        for j <span class="hljs-meta">in</span><span class="hljs-meta"> range(</span>l<span class="hljs-meta">en(</span><span class="hljs-meta">array</span>) - i -1): # 已排序好的部分不需再遍历<br>            <span class="hljs-meta">if</span> <span class="hljs-meta">array</span>[j] &gt; <span class="hljs-meta">array</span>[j+1]:<br>                <span class="hljs-meta">array</span>[j], <span class="hljs-meta">array</span>[j+1] = <span class="hljs-meta">array</span>[j+1], <span class="hljs-meta">array</span>[j]<br>    <span class="hljs-meta">return</span> <span class="hljs-meta">array</span><br></code></pre></td></tr></table></figure><h5 id="桶排"><a href="#桶排" class="headerlink" title="桶排"></a>桶排</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs sql">def bucker_sort(<span class="hljs-keyword">array</span>):<br>    <span class="hljs-keyword">result</span> <span class="hljs-operator">=</span> []<br>    minVal, maxVal <span class="hljs-operator">=</span> <span class="hljs-built_in">min</span>(<span class="hljs-keyword">array</span>), <span class="hljs-built_in">max</span>(<span class="hljs-keyword">array</span>)<br>    bucket <span class="hljs-operator">=</span> [<span class="hljs-number">0</span>] <span class="hljs-operator">*</span> (maxVal <span class="hljs-operator">-</span> minVal <span class="hljs-operator">+</span> <span class="hljs-number">1</span>)  # 所需的桶数<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-keyword">array</span>:<br>        bucket[i <span class="hljs-operator">-</span> minVal] <span class="hljs-operator">+</span><span class="hljs-operator">=</span> <span class="hljs-number">1</span>     # 每个数字出现的次数<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-keyword">range</span>(len(bucket)):<br>        if bucket[i]:<br>            <span class="hljs-keyword">result</span> <span class="hljs-operator">+</span><span class="hljs-operator">=</span> [i <span class="hljs-operator">+</span> minVal] <span class="hljs-operator">*</span> bucket[i]<br>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">result</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux One Line Command</title>
    <link href="/2021/08/13/OneLineCommand/"/>
    <url>/2021/08/13/OneLineCommand/</url>
    
    <content type="html"><![CDATA[<h2 id="Linux-常用命令"><a href="#Linux-常用命令" class="headerlink" title="Linux 常用命令"></a>Linux 常用命令</h2><span id="more"></span><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs clean">sh -n ##判断是否有语法错误<br>sh -x ##执行详细过程<br>## 修改目录颜色<br>dircolors -p &gt; ~/.dircolors   ## 编辑 ~/.dircolors 修改<br>## 忽略大小写<br>echo <span class="hljs-string">&#x27;set completion-ignore-case on&#x27;</span> &gt; ~/.inputrc<br></code></pre></td></tr></table></figure><h5 id="Linux-两个文件求交集、并集、差集"><a href="#Linux-两个文件求交集、并集、差集" class="headerlink" title="Linux 两个文件求交集、并集、差集"></a>Linux 两个文件求交集、并集、差集</h5><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver"><span class="hljs-built_in">sort</span> <span class="hljs-keyword">a</span>.txt b.txt | uniq -d   <span class="hljs-comment">### 交集</span><br><span class="hljs-built_in">sort</span> <span class="hljs-keyword">a</span>.txt b.txt | uniq   <span class="hljs-comment">###并集 </span><br><span class="hljs-built_in">sort</span> <span class="hljs-keyword">a</span>.txt b.txt b.txt | uniq -u  <span class="hljs-comment">## 差集 a-b</span><br><span class="hljs-built_in">sort</span> b.txt <span class="hljs-keyword">a</span>.txt <span class="hljs-keyword">a</span>.txt | uniq -u  <span class="hljs-comment">## 差集 b-a</span><br></code></pre></td></tr></table></figure><p>使用sort可以将文件进行排序，可以使用sort后面的玲玲，例如 -n 按照数字格式排序，例如 -i 忽略大小写，例如使用-r 为逆序输出等<br>uniq为删除文件中重复的行，得到文件中唯一的行，后面的命令 -d 表示的是输出出现次数大于1的内容 -u表示的是输出出现次数为1的内容，那么对于上述的求交集并集差集的命令做如下的解释：</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs less"><span class="hljs-selector-tag">sort</span> <span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.txt</span> <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt</span> | <span class="hljs-selector-tag">uniq</span> <span class="hljs-selector-tag">-d</span> #将<span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.txt</span> <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt</span>文件进行排序，<span class="hljs-selector-tag">uniq</span>使得两个文件中的内容为唯一的，使用<span class="hljs-selector-tag">-d</span>输出两个文件中次数大于<span class="hljs-selector-tag">1</span>的内容，即是得到交集<br><span class="hljs-selector-tag">sort</span> <span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.txt</span> <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt</span> | <span class="hljs-selector-tag">uniq</span>  #将<span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.txt</span> <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt</span>文件进行排序，<span class="hljs-selector-tag">uniq</span>使得两个文件中的内容为唯一的，即可得到两个文件的并集<br><span class="hljs-selector-tag">sort</span> <span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.txt</span> <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt</span> <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt</span> | <span class="hljs-selector-tag">uniq</span> <span class="hljs-selector-tag">-u</span> #将两个文件排序，最后输出<span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.txt</span> <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt</span> <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt</span>文件中只出现过一次的内容，因为有两个<span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt</span>所以只会输出只在<span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.txt</span>出现过一次的内容，即是<span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.txt-b</span><span class="hljs-selector-class">.txt</span>差集<br>#对于<span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.txt-a</span><span class="hljs-selector-class">.txt</span>为同理<br></code></pre></td></tr></table></figure><h5 id="grep-命令是常用的搜索文本内容的，要找交集，如下即可："><a href="#grep-命令是常用的搜索文本内容的，要找交集，如下即可：" class="headerlink" title="grep 命令是常用的搜索文本内容的，要找交集，如下即可："></a>grep 命令是常用的搜索文本内容的，要找交集，如下即可：</h5><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">grep <span class="hljs-operator">-F</span> <span class="hljs-operator">-f</span> a.txt b.txt | <span class="hljs-built_in">sort</span> | uniq<br></code></pre></td></tr></table></figure><h5 id="差集"><a href="#差集" class="headerlink" title="差集:"></a>差集:</h5><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">grep -F -v -f <span class="hljs-keyword">a</span>.txt b.txt | <span class="hljs-built_in">sort</span> | uniq<br>grep -F -v -f b.txt <span class="hljs-keyword">a</span>.txt | <span class="hljs-built_in">sort</span> | uniq<br><span class="hljs-comment">#第一行结果为b-a；第二行为a-b。注意顺序很重要</span><br></code></pre></td></tr></table></figure><h5 id="根据id提取fastq"><a href="#根据id提取fastq" class="headerlink" title="根据id提取fastq"></a>根据id提取fastq</h5><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs clean">grep -f id -A <span class="hljs-number">3</span> BC01.fq &gt; test.fq   ### -f 参数为ID文件<br></code></pre></td></tr></table></figure><h5 id="批量重命名文件"><a href="#批量重命名文件" class="headerlink" title="批量重命名文件"></a>批量重命名文件</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#只更改户后缀</span><br>rename <span class="hljs-string">&#x27;s/.txt/.log/&#x27;</span> *.txt   <span class="hljs-comment">#### 把txt后缀改为log</span><br><span class="hljs-comment">#小写变大写</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> `ls`;<span class="hljs-keyword">do</span> mv -f <span class="hljs-variable">$i</span> `<span class="hljs-built_in">echo</span> <span class="hljs-variable">$i</span> | tr a-z A-Z`;<span class="hljs-keyword">done</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> `ls`;<span class="hljs-keyword">do</span> mv -f <span class="hljs-variable">$i</span> `<span class="hljs-built_in">echo</span> <span class="hljs-variable">$i</span> | sed <span class="hljs-string">&#x27;s/..../..../&#x27;</span>`;<span class="hljs-keyword">done</span>  <span class="hljs-comment">##使用sed替换q</span><br>rename <span class="hljs-string">&#x27;s/small/large/&#x27;</span> image_*.png<br></code></pre></td></tr></table></figure><h5 id="删除空行"><a href="#删除空行" class="headerlink" title="删除空行"></a>删除空行</h5><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs vim">sed -i <span class="hljs-string">&#x27;/^$/d&#x27;</span> <span class="hljs-keyword">file</span><br><span class="hljs-keyword">grep</span> -v <span class="hljs-string">&#x27;^$&#x27;</span> <span class="hljs-keyword">file</span>   或  sed <span class="hljs-string">&#x27;/^$/d&#x27;</span> <span class="hljs-keyword">file</span> 或 sed -n <span class="hljs-string">&#x27;/./p&#x27;</span> <span class="hljs-keyword">file</span><br>awk <span class="hljs-string">&#x27;/./&#123;print&#125;&#x27;</span> <span class="hljs-keyword">file</span> 或  <span class="hljs-keyword">tr</span> -s <span class="hljs-string">&#x27;n&#x27;</span><br>#删除最后一列<br>sed -r -<span class="hljs-keyword">e</span> <span class="hljs-string">&#x27;s/\t[^\t]*$//g&#x27;</span> <span class="hljs-keyword">file</span>   <br></code></pre></td></tr></table></figure><h5 id="统计文件大小"><a href="#统计文件大小" class="headerlink" title="统计文件大小"></a>统计文件大小</h5><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim">du -<span class="hljs-keyword">sh</span> * 或者 du -h --<span class="hljs-built_in">max</span>-depth=<span class="hljs-number">1</span>  或 du -<span class="hljs-keyword">sh</span> * | <span class="hljs-keyword">grep</span> [GM] | <span class="hljs-keyword">sort</span> 提取G 和 M的文件并排序<br></code></pre></td></tr></table></figure><h5 id="计算reads数"><a href="#计算reads数" class="headerlink" title="计算reads数"></a>计算reads数</h5><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">expr <span class="hljs-constructor">$(<span class="hljs-params">wc</span> -<span class="hljs-params">l</span> &lt; <span class="hljs-operator">*</span>.<span class="hljs-params">fastq</span>)</span><span class="hljs-operator"> / </span><span class="hljs-number">4</span><br>expr <span class="hljs-constructor">$(<span class="hljs-params">zcat</span> <span class="hljs-params">test</span><span class="hljs-operator">/</span>1.R1.<span class="hljs-params">fq</span>.<span class="hljs-params">gz</span> | <span class="hljs-params">wc</span> -<span class="hljs-params">l</span>)</span><span class="hljs-operator"> / </span><span class="hljs-number">4</span><br></code></pre></td></tr></table></figure><h5 id="fastq-转-fasta"><a href="#fastq-转-fasta" class="headerlink" title="fastq 转 fasta"></a>fastq 转 fasta</h5><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">awk</span> &#x27;&#123;if(NR%<span class="hljs-number">4</span> == <span class="hljs-number">1</span>)&#123;print <span class="hljs-string">&quot;&gt;&quot;</span> substr($<span class="hljs-number">0</span>, <span class="hljs-number">2</span>)&#125;&#125;&#123;if(NR%<span class="hljs-number">4</span> == <span class="hljs-number">2</span>)&#123;print&#125;&#125;&#x27; xx.fastq &gt;xx.fasta<br><span class="hljs-attribute">awk</span> &#x27;&#123;if(NR%<span class="hljs-number">4</span> == <span class="hljs-number">1</span>)&#123;print <span class="hljs-string">&quot;&gt;&quot;</span> <span class="hljs-string">&quot;&#x27;$j&#x27;&quot;</span><span class="hljs-string">&quot;_&quot;</span>NR&#125;&#125;&#123;if(NR%<span class="hljs-number">4</span> == <span class="hljs-number">2</span>)&#123;print&#125;&#125;&#x27;    #   <span class="hljs-string">&quot;&#x27;$j&#x27;&quot;</span> awk中引用外部变量<br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">sort</span> -k<span class="hljs-number">1</span>,<span class="hljs-number">1</span>V -k<span class="hljs-number">2</span>,<span class="hljs-number">2</span>n file   ## V 参数忽略第一列中的文本按数字排序<br><span class="hljs-attribute">awk</span> &#x27;$<span class="hljs-number">1</span> ~ /chr<span class="hljs-number">1</span>|chr<span class="hljs-number">3</span>/&#x27; file ## 第一列匹配chr<span class="hljs-number">1</span>或chr<span class="hljs-number">3</span><br><span class="hljs-attribute">awk</span> &#x27;NR &gt; <span class="hljs-number">3</span>&#x27; file ## 取出第四行以后<br><span class="hljs-attribute">sed</span> -n &#x27;<span class="hljs-number">20</span>,<span class="hljs-number">50</span>p&#x27; file # 取出<span class="hljs-number">20</span>到<span class="hljs-number">50</span>行<br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">paste</span> file<span class="hljs-number">1</span> file<span class="hljs-number">2</span>  # 横向拼接文件，拼接前可用dos<span class="hljs-number">2</span>unix转换文件类型<br></code></pre></td></tr></table></figure><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs clean"><span class="hljs-string">&#x27;%&#x27;</span> 从后向前删除, <span class="hljs-string">&#x27;#&#x27;</span> 从前向后删除<br>sed 替换每行最后一个匹配的字符<br>sed <span class="hljs-string">&#x27;s/\(.*\)src_str\(.*\)/\1dst_str\2/&#x27;</span>  yourfile   ##  src_str：要匹配的字符  dst_str: 要替换的字符<br></code></pre></td></tr></table></figure><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">biom</span>=<span class="hljs-variable">$&#123;i##*/&#125;</span>    <span class="hljs-comment">#返回 / 后的字符</span><br><span class="hljs-attr">biom</span>=<span class="hljs-variable">$&#123;i%/*&#125;</span>     <span class="hljs-comment">#返回最后 / 前的字符</span><br></code></pre></td></tr></table></figure><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">ls -<span class="hljs-keyword">ld</span> 列出文件全路径<br></code></pre></td></tr></table></figure><h5 id="使用-wget-完成批量下载"><a href="#使用-wget-完成批量下载" class="headerlink" title="使用 wget 完成批量下载"></a>使用 wget 完成批量下载</h5><p>如果想下载一个网站上目录中的所有文件, 我需要执行一长串wget命令, 但这样做会更好:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">wget -nd -r -l1 --no-parent http:<span class="hljs-regexp">//</span>www.foo.com<span class="hljs-regexp">/mp3/</span><br></code></pre></td></tr></table></figure><p>这条命令可以执行的很好, 但有时会下载像 index.@xx 这样一些我不想要的文件. 如果你知道想要文件的格式, 可以用下面的命令来避免下载那些多余的文件:</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">wget -nd -r -l1 --no-parent -<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">A</span>.</span></span>mp3 -<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">A</span>.</span></span>wma http:<span class="hljs-comment">//www.foo.com/mp3/</span><br></code></pre></td></tr></table></figure><p>我来简单的介绍一下命令中指定选项的作用.<br>-nd 不创建目录, wget默认会创建一个目录<br>-r 递归下载<br>-l1 (L one) 递归一层,只下载指定文件夹中的内容, 不下载下一级目录中的.<br>–no-parent 不下载父目录中的文件</p><h5 id="rsync可视化复制文件时的进度"><a href="#rsync可视化复制文件时的进度" class="headerlink" title="rsync可视化复制文件时的进度"></a>rsync可视化复制文件时的进度</h5><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">rsync</span> -avPh 源文件 目标文件<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>知网羊毛</title>
    <link href="/2021/08/12/%E7%9F%A5%E7%BD%91%E7%BE%8A%E6%AF%9B/"/>
    <url>/2021/08/12/%E7%9F%A5%E7%BD%91%E7%BE%8A%E6%AF%9B/</url>
    
    <content type="html"><![CDATA[<h2 id="薅社会主义羊毛-知网"><a href="#薅社会主义羊毛-知网" class="headerlink" title="薅社会主义羊毛-知网"></a>薅社会主义羊毛-知网</h2><span id="more"></span><p>工作中经常会受到同事、朋友的求助帮忙下载论文，中文的、外文的都遇到过。外文文献一般都在Sci_hub(<a href="https://tool.yovisun.com/scihub/">https://tool.yovisun.com/scihub/</a>) 上查找，当然也会有些找不到。中文的文献莫过于知网了，但是知网也是收费模式的。于是在网上挖了下，找到了两三个相对靠谱的可以薅知网羊毛的方法，但是也是有些限制的。</p><h5 id="iData-https-www-cn-ki-net"><a href="#iData-https-www-cn-ki-net" class="headerlink" title="iData(https://www.cn-ki.net/)"></a>iData(<a href="https://www.cn-ki.net/">https://www.cn-ki.net/</a>)</h5><p>直接注册便可使用，缺点就是每天只能下载几篇吧</p><h5 id="80图书馆-官网-http-www-80lib-com-知网-http-www-80lib-com-cnki"><a href="#80图书馆-官网-http-www-80lib-com-知网-http-www-80lib-com-cnki" class="headerlink" title="80图书馆(官网:http://www.80lib.com/ 知网:http://www.80lib.com/cnki/)"></a>80图书馆(官网:<a href="http://www.80lib.com/">http://www.80lib.com/</a> 知网:<a href="http://www.80lib.com/cnki/">http://www.80lib.com/cnki/</a>)</h5><p>优点是无限篇下载，缺点就是只有三天试用，不过应该可以换个邮箱再注册。还有个缺点就是使用相对麻烦，需要使用谷歌浏览器以及对应的插件，不过好在官网都提供了详细的步骤，这里不再赘述。</p><h5 id="科研通-www-ablesci-com"><a href="#科研通-www-ablesci-com" class="headerlink" title="科研通(www.ablesci.com)"></a>科研通(<a href="http://www.ablesci.com/">www.ablesci.com</a>)</h5><p>类似于百度文献互助</p><h5 id="百度文献互助-备用"><a href="#百度文献互助-备用" class="headerlink" title="百度文献互助(备用)"></a>百度文献互助(备用)</h5><p>缺点每天两篇，时间长，还不一定成功。</p>]]></content>
    
    
    <categories>
      
      <category>TroubleShoot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TroubleShoot</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python 异步</title>
    <link href="/2021/08/11/Python_%E5%BC%82%E6%AD%A5/"/>
    <url>/2021/08/11/Python_%E5%BC%82%E6%AD%A5/</url>
    
    <content type="html"><![CDATA[<h2 id="Python中异步、同步、多进程及多线程的比较"><a href="#Python中异步、同步、多进程及多线程的比较" class="headerlink" title="Python中异步、同步、多进程及多线程的比较"></a>Python中异步、同步、多进程及多线程的比较</h2><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> urllib <span class="hljs-keyword">import</span> request<br><span class="hljs-keyword">from</span> urllib <span class="hljs-keyword">import</span> parse<br><span class="hljs-keyword">from</span> urllib.request <span class="hljs-keyword">import</span> urlopen<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-comment"># 用于多进程</span><br><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Process<br><span class="hljs-comment"># 用于多线程</span><br><span class="hljs-keyword">from</span> threading <span class="hljs-keyword">import</span> Thread<br><span class="hljs-comment"># 用于协程+异步</span><br><span class="hljs-keyword">import</span> aiohttp<br><span class="hljs-keyword">import</span> asyncio<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">aiohttp:异步发送POST请求</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">city_rule_asy</span>():</span><br>    data = &#123;<span class="hljs-string">&quot;key&quot;</span>: <span class="hljs-string">&quot;&quot;</span>&#125;<br>    myPostUrl = <span class="hljs-string">&quot;http://api.chinadatapay.com/government/traffic/2299&quot;</span><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> aiohttp.ClientSession() <span class="hljs-keyword">as</span> session:<br>        <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> session.post(myPostUrl, data=data) <span class="hljs-keyword">as</span> res:<br>            <span class="hljs-comment"># print(res.status)</span><br>            <span class="hljs-keyword">return</span> json.loads(<span class="hljs-keyword">await</span> res.text())<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span>():</span><br>    tasks = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>        task = asyncio.ensure_future(city_rule_asy())<br>        tasks.append(task)<br>    loop = asyncio.get_event_loop()<br>    result = loop.run_until_complete(asyncio.gather(*tasks))<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;city_rules.txt&#x27;</span>, <span class="hljs-string">&#x27;a+&#x27;</span>) <span class="hljs-keyword">as</span> fw:<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> response[<span class="hljs-string">&#x27;data&#x27;</span>]:<br>           <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> i[<span class="hljs-string">&#x27;cities&#x27;</span>]:<br>                fw.write(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;city&#x27;</span>]&#125;</span>\t<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;engine&#x27;</span>]&#125;</span>\t<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;prefix&#x27;</span>]&#125;</span>\t<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;vin&#x27;</span>]&#125;</span>\t<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;model&#x27;</span>]&#125;</span>\n&quot;</span>)<br><span class="hljs-comment">#### ============================================ ###</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">city_rule</span>():</span><br>    myPostUrl = <span class="hljs-string">&quot;http://api.chinadatapay.com/government/traffic/2299&quot;</span><br>    data = &#123;<span class="hljs-string">&quot;key&quot;</span>: <span class="hljs-string">&quot;&quot;</span>&#125;<br>    params = parse.urlencode(data).encode(<span class="hljs-string">&#x27;utf-8&#x27;</span>)  <span class="hljs-comment"># 提交类型不能为str，需要为byte类型</span><br>    req = request.Request(myPostUrl, params)<br>    response = json.loads(urlopen(req).read().decode())<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;city_rules.txt&#x27;</span>, <span class="hljs-string">&#x27;a+&#x27;</span>) <span class="hljs-keyword">as</span> fw:<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> response[<span class="hljs-string">&#x27;data&#x27;</span>]:<br>           <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> i[<span class="hljs-string">&#x27;cities&#x27;</span>]:<br>                fw.write(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;city&#x27;</span>]&#125;</span>\t<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;engine&#x27;</span>]&#125;</span>\t<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;prefix&#x27;</span>]&#125;</span>\t<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;vin&#x27;</span>]&#125;</span>\t<span class="hljs-subst">&#123;j[<span class="hljs-string">&#x27;model&#x27;</span>]&#125;</span>\n&quot;</span>)<br><span class="hljs-comment">## 单进程单线程同步</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">single_process</span>():</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>        city_rule()<br><span class="hljs-comment"># 多进程并行</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mul_process</span>():</span><br>    processes = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>        p = Process(target=city_rule, args=())     <span class="hljs-comment"># 一个参数 args=(prameter,)</span><br>        processes.append(p)<br>        p.start()<br>    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> processes:<br>        p.join()<br><span class="hljs-comment"># 多线程并发</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mul_thead</span>():</span><br>    threads = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>        t = Thread(target=city_rule, args=())<br>        threads.append(t)<br>        t.start()<br>    <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> threads:<br>        t.join()<br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-comment"># 异步</span><br>    run()<br>    <span class="hljs-comment"># 同步</span><br>    single_process()<br>    <span class="hljs-comment"># 多进程</span><br>    mul_process()<br>    <span class="hljs-comment">#多线程</span><br>    mul_thead()<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python Notes</title>
    <link href="/2021/02/02/Python-Notes/"/>
    <url>/2021/02/02/Python-Notes/</url>
    
    <content type="html"><![CDATA[<h2 id="Python学习随笔"><a href="#Python学习随笔" class="headerlink" title="Python学习随笔"></a>Python学习随笔</h2><span id="more"></span><h3 id="字典转dataframe"><a href="#字典转dataframe" class="headerlink" title="字典转dataframe"></a>字典转dataframe</h3><p>不定义列名时：pd.DataFrame.from_dict(data, orient=’index’)<br>定义列名时：pd.DataFrame.from_dict(data, orient=’index’, columns=[‘A’, ‘B’, ‘C’, ‘D’])</p><h3 id="pandas筛选"><a href="#pandas筛选" class="headerlink" title="pandas筛选"></a>pandas筛选</h3><h4 id="选取某列值等于某些值的行用-，不等于用-！-，data-loc-data-‘a’-‘one’"><a href="#选取某列值等于某些值的行用-，不等于用-！-，data-loc-data-‘a’-‘one’" class="headerlink" title="选取某列值等于某些值的行用 == ，不等于用 ！= ，data.loc[data[‘a’] == ‘one’]"></a>选取某列值等于某些值的行用 == ，不等于用 ！= ，data.loc[data[‘a’] == ‘one’]</h4><h4 id="选取某列值是否是某一类型的数值用-isin-取反用"><a href="#选取某列值是否是某一类型的数值用-isin-取反用" class="headerlink" title="选取某列值是否是某一类型的数值用 isin ,取反用 ~"></a>选取某列值是否是某一类型的数值用 isin ,取反用 ~</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs language">data.loc[data[&#x27;a&#x27;].isin([&#x27;one&#x27;, &#x27;two&#x27;])]<br>data.loc[~data[&#x27;a&#x27;].isin([&#x27;one&#x27;, &#x27;two&#x27;])]<br></code></pre></td></tr></table></figure><h4 id="多种条件的选取用-amp-data-loc-data-‘a’-‘one’-amp-data-‘b’-‘two’"><a href="#多种条件的选取用-amp-data-loc-data-‘a’-‘one’-amp-data-‘b’-‘two’" class="headerlink" title="多种条件的选取用 &amp; , data.loc[(data[‘a’] == ‘one’) &amp; (data[‘b’] == ‘two’)]"></a>多种条件的选取用 &amp; , data.loc[(data[‘a’] == ‘one’) &amp; (data[‘b’] == ‘two’)]</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs language">np.linspace(start, stop, num) ##参数为起点，终点，点数，num默认为50<br></code></pre></td></tr></table></figure><h3 id="把某列值设为index，df-set-index-‘columns’-df-reset-index-重置索引"><a href="#把某列值设为index，df-set-index-‘columns’-df-reset-index-重置索引" class="headerlink" title="把某列值设为index，df.set_index(‘columns’)  (df.reset_index()重置索引)"></a>把某列值设为index，df.set_index(‘columns’)  (df.reset_index()重置索引)</h3><p>df中merge函数按 键 合并，concat函数按 轴 合并</p><h3 id="按键-key-合并可以分「单键合并」和「多键合并」"><a href="#按键-key-合并可以分「单键合并」和「多键合并」" class="headerlink" title="按键 (key) 合并可以分「单键合并」和「多键合并」"></a>按键 (key) 合并可以分「单键合并」和「多键合并」</h3><h3 id="单键合并："><a href="#单键合并：" class="headerlink" title="单键合并："></a>单键合并：</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs language">pd.merge(df1, df2, how=s, on=c ) ##c 是 df1 和 df2 共有的一栏，合并方式 (how=s) 有四种：<br></code></pre></td></tr></table></figure><h6 id="左连接-left-：合并之后显示-df1-的所有行"><a href="#左连接-left-：合并之后显示-df1-的所有行" class="headerlink" title="左连接 (left)：合并之后显示 df1 的所有行"></a>左连接 (left)：合并之后显示 df1 的所有行</h6><h6 id="右连接-right-：合并之后显示-df2-的所有行"><a href="#右连接-right-：合并之后显示-df2-的所有行" class="headerlink" title="右连接 (right)：合并之后显示 df2 的所有行"></a>右连接 (right)：合并之后显示 df2 的所有行</h6><h6 id="外连接-outer-：合并-df1-和-df2-共有的所有行"><a href="#外连接-outer-：合并-df1-和-df2-共有的所有行" class="headerlink" title="外连接 (outer)：合并 df1 和 df2 共有的所有行"></a>外连接 (outer)：合并 df1 和 df2 共有的所有行</h6><h6 id="内连接-inner-：只保留两个表中公共部分的信息-默认情况"><a href="#内连接-inner-：只保留两个表中公共部分的信息-默认情况" class="headerlink" title="内连接 (inner)：只保留两个表中公共部分的信息 (默认情况)"></a>内连接 (inner)：只保留两个表中公共部分的信息 (默认情况)</h6><h6 id="多键合并-俩组数据均有该列"><a href="#多键合并-俩组数据均有该列" class="headerlink" title="多键合并(俩组数据均有该列)"></a>多键合并(俩组数据均有该列)</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs language">pd.merge( df1, df2, how=s, on=c )  ## c 是多栏（如一个列表<br></code></pre></td></tr></table></figure><h3 id="多键合并-两组数据不同的列名）"><a href="#多键合并-两组数据不同的列名）" class="headerlink" title="多键合并(两组数据不同的列名）"></a>多键合并(两组数据不同的列名）</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs language">pd.merge(df1, df2, left_on = &#x27;key1&#x27;, right_on = &#x27;key2&#x27;)<br></code></pre></td></tr></table></figure><h3 id="插入列：除在最右侧插入用标签直接创建外，其他列用-insert-方法进行插入，比如table-insert-0-’date’-date"><a href="#插入列：除在最右侧插入用标签直接创建外，其他列用-insert-方法进行插入，比如table-insert-0-’date’-date" class="headerlink" title="插入列：除在最右侧插入用标签直接创建外，其他列用.insert()方法进行插入，比如table.insert(0,’date’,date)"></a>插入列：除在最右侧插入用标签直接创建外，其他列用.insert()方法进行插入，比如table.insert(0,’date’,date)</h3><p>当 df1 和 df2 有两个相同的列 (Asset 和 Instrument) 时，单单只对一列 (Asset) 做合并产出的 DataFrame 会有另一列 (Instrument) 重复的名称。<br>这时 merge 函数给重复的名称加个后缀 _x, _y，也可以设定 suffixes 来改后缀</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs language">pd.concat([df1,df2], axis=0, ignore_index=True)  # 默认axis=0（行连接）<br></code></pre></td></tr></table></figure><h3 id="列索引-→-行索引，用-stack-函数-行索引-→-列索引，用-unstack-函数"><a href="#列索引-→-行索引，用-stack-函数-行索引-→-列索引，用-unstack-函数" class="headerlink" title="列索引 → 行索引，用 stack 函数;行索引 → 列索引，用 unstack 函数"></a>列索引 → 行索引，用 stack 函数;行索引 → 列索引，用 unstack 函数</h3><h3 id="数据透视："><a href="#数据透视：" class="headerlink" title="数据透视："></a>数据透视：</h3><p>用 pivot 函数将「一张长表」变「多张宽表」，<br>用 melt 函数将「多张宽表」变「一张长表」  # 函数 melt 实际是将「源表」转化成 id-variable 类型的 DataFrame</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">data_pivot = data.pivot(index=<span class="hljs-string">&#x27;Date&#x27;</span>,columns=<span class="hljs-string">&#x27;Symbol&#x27;</span>,values=<span class="hljs-string">&#x27;Adj Close&#x27;</span>) <span class="hljs-comment">#若不设置value参数，剩下的列都用来透视</span><br>melted_data = pd.melt(data, id_vars=[<span class="hljs-string">&#x27;Date&#x27;</span>,<span class="hljs-string">&#x27;Symbol&#x27;</span>])<br><span class="hljs-built_in">sorted</span>(<span class="hljs-built_in">set</span>(<span class="hljs-built_in">list</span>), key=<span class="hljs-built_in">list</span>.index)  <span class="hljs-comment">## 消除重复元素不改变原始数据顺序</span><br><span class="hljs-built_in">sorted</span>(<span class="hljs-built_in">dict</span>.items(),key=<span class="hljs-keyword">lambda</span> x:x[<span class="hljs-number">1</span>],reverse=<span class="hljs-literal">True</span>)  <span class="hljs-comment">## 对字典按值反向排序（x[0]按键排序）</span><br></code></pre></td></tr></table></figure><h3 id="pandas-删除列"><a href="#pandas-删除列" class="headerlink" title="pandas 删除列"></a>pandas 删除列</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">df = df.drop([<span class="hljs-string">&#x27;c&#x27;</span>, <span class="hljs-string">&#x27;e&#x27;</span>], <span class="hljs-attribute">axis</span>=1)<br><span class="hljs-comment">#或者</span><br>df.drop([<span class="hljs-string">&#x27;c&#x27;</span>, <span class="hljs-string">&#x27;e&#x27;</span>], <span class="hljs-attribute">axis</span>=1, <span class="hljs-attribute">inplace</span>=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><h3 id="对行-z-score-标准化"><a href="#对行-z-score-标准化" class="headerlink" title="对行 z-score 标准化"></a>对行 z-score 标准化</h3><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs maxima">df.<span class="hljs-built_in">apply</span>(<span class="hljs-built_in">lambda</span> x: (x - <span class="hljs-built_in">np</span>.<span class="hljs-built_in">mean</span>(x)) / (<span class="hljs-built_in">np</span>.<span class="hljs-built_in">std</span>(x,ddof=<span class="hljs-number">1</span>)), axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><h3 id="对-Majority-protein-IDs-列转成多行"><a href="#对-Majority-protein-IDs-列转成多行" class="headerlink" title="对 Majority protein IDs 列转成多行"></a>对 Majority protein IDs 列转成多行</h3><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">df = df[~df[<span class="hljs-string">&#x27;Majority protein IDs&#x27;</span>].str.contains(<span class="hljs-string">&#x27;CON|REV&#x27;</span>, regex=<span class="hljs-keyword">True</span>)]<br>df = df.<span class="hljs-keyword">drop</span>(<span class="hljs-string">&#x27;Majority protein IDs&#x27;</span>, axis=<span class="hljs-number">1</span>).<span class="hljs-keyword">join</span>(df[<span class="hljs-string">&#x27;Majority protein IDs&#x27;</span>].str.split(<span class="hljs-string">&#x27;;&#x27;</span>, expand=<span class="hljs-keyword">True</span>).stack().reset_index(<span class="hljs-keyword">level</span>=<span class="hljs-number">1</span>, <span class="hljs-keyword">drop</span>=<span class="hljs-keyword">True</span>).<span class="hljs-keyword">rename</span>(<span class="hljs-string">&#x27;Majority protein IDs&#x27;</span>))<br><br>def ab(df): <br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;;&#x27;</span>.<span class="hljs-keyword">join</span>(df.<span class="hljs-keyword">values</span>)<br>newcolumns = df_merge.<span class="hljs-keyword">columns</span>.tolist()<br>newcolumns.remove(<span class="hljs-string">&#x27;Majority protein IDs&#x27;</span>)<br>newdf = df_merge.groupby(newcolumns)[<span class="hljs-string">&#x27;Majority protein IDs&#x27;</span>].apply(ab)   ## 多行合并一行<br></code></pre></td></tr></table></figure><h3 id="for、while循环中的else扩展用法"><a href="#for、while循环中的else扩展用法" class="headerlink" title="for、while循环中的else扩展用法"></a>for、while循环中的else扩展用法</h3><p>else中的程序只在一种条件下执行，即循环正常遍历所有内容或者由于条件不成立而结束循环，没有因break或者return而退出循环。continue对else没影响</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs language">for i in range(10):<br>    if i==5:<br>        break<br>    print(&#x27;i=&#x27;,i,end=&#x27;,&#x27;)<br>else:<br>    print(&#x27;success&#x27;)#不输出   在for循环中含有break时则直接终止循环，并不会执行else子句。<br><br>for i in range(10):<br>    if i==5:<br>        continue<br>    print(&#x27;i=&#x27;,i,end=&#x27;,&#x27;)<br>else:<br>    print(&#x27;success&#x27;)#输出<br></code></pre></td></tr></table></figure><h3 id="展平嵌套列表"><a href="#展平嵌套列表" class="headerlink" title="展平嵌套列表"></a>展平嵌套列表</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs language">newlist = [item for items in newlist for item in items]<br>#或者您可以像这样从chain中使用itertools<br>from itertools import chain<br>newlist = list(chain(*newlist))<br>#或者您可以使用chain.from_iterable，其中无需解压缩列表<br>from itertools import chain<br>newlist = list(chain.from_iterable(newlist)) #效率更高<br></code></pre></td></tr></table></figure><h3 id="生成requirements-txt"><a href="#生成requirements-txt" class="headerlink" title="生成requirements.txt"></a>生成requirements.txt</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs language">pipreqs ./ --encoding=utf-8 --force<br></code></pre></td></tr></table></figure><h3 id="单例"><a href="#单例" class="headerlink" title="单例"></a>单例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs language">class Singleton(object):<br>    __instance = None<br><br>    def __new__(cls, age, name):<br>        if not cls.__instance:<br>            cls.__instance = object.__new__(cls)<br>        return cls.__instance<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
